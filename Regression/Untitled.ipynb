{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e3dd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28f42e",
   "metadata": {},
   "source": [
    "# Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144d8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.normal(0, 1, size=(100, 1)) \n",
    "X2 = np.random.normal(0, 1, size=(100, 1)) \n",
    "X3 = np.random.normal(0,1 , size=(100, 1)) \n",
    "Y = 1*X1+2*X2+4*X3+3 + np.random.normal(0,1 , size=(100, 1))\n",
    "X = np.hstack((X1,X2, X3))\n",
    "X_Train = Variable(torch.Tensor(X))\n",
    "Y_Train = Variable(torch.Tensor(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25f967fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.575049</td>\n",
       "      <td>1.462458</td>\n",
       "      <td>-0.438670</td>\n",
       "      <td>4.531069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.343925</td>\n",
       "      <td>-0.589662</td>\n",
       "      <td>0.621959</td>\n",
       "      <td>3.995380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.473574</td>\n",
       "      <td>-0.087061</td>\n",
       "      <td>-0.832309</td>\n",
       "      <td>-1.202699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.547790</td>\n",
       "      <td>1.213853</td>\n",
       "      <td>0.076693</td>\n",
       "      <td>7.167453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.122368</td>\n",
       "      <td>-0.921258</td>\n",
       "      <td>-0.731452</td>\n",
       "      <td>-2.644413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-0.827159</td>\n",
       "      <td>-0.240044</td>\n",
       "      <td>1.879741</td>\n",
       "      <td>8.732666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1.104205</td>\n",
       "      <td>1.783585</td>\n",
       "      <td>0.567293</td>\n",
       "      <td>8.361414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.199489</td>\n",
       "      <td>-0.140796</td>\n",
       "      <td>1.674478</td>\n",
       "      <td>9.089247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.688404</td>\n",
       "      <td>-1.372876</td>\n",
       "      <td>-0.155236</td>\n",
       "      <td>-2.585457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-0.721709</td>\n",
       "      <td>-0.494141</td>\n",
       "      <td>-2.236710</td>\n",
       "      <td>-6.905832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2        X3         Y\n",
       "0   0.575049  1.462458 -0.438670  4.531069\n",
       "1   0.343925 -0.589662  0.621959  3.995380\n",
       "2  -0.473574 -0.087061 -0.832309 -1.202699\n",
       "3   0.547790  1.213853  0.076693  7.167453\n",
       "4  -1.122368 -0.921258 -0.731452 -2.644413\n",
       "..       ...       ...       ...       ...\n",
       "95 -0.827159 -0.240044  1.879741  8.732666\n",
       "96  1.104205  1.783585  0.567293  8.361414\n",
       "97  0.199489 -0.140796  1.674478  9.089247\n",
       "98 -0.688404 -1.372876 -0.155236 -2.585457\n",
       "99 -0.721709 -0.494141 -2.236710 -6.905832\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"X1\" : X1[:,0],\"X2\" : X2[:,0],\"X3\" : X3[:,0], \"Y\":Y[:,0]}\n",
    "df = pd.DataFrame(data)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d94308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.154893</td>\n",
       "      <td>-0.220490</td>\n",
       "      <td>0.854107</td>\n",
       "      <td>3.820555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.719194</td>\n",
       "      <td>-0.213630</td>\n",
       "      <td>0.908401</td>\n",
       "      <td>4.487152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.788780</td>\n",
       "      <td>0.658063</td>\n",
       "      <td>-0.548548</td>\n",
       "      <td>2.910713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.832647</td>\n",
       "      <td>-0.029061</td>\n",
       "      <td>-0.684627</td>\n",
       "      <td>-0.629276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488314</td>\n",
       "      <td>1.195539</td>\n",
       "      <td>-0.711891</td>\n",
       "      <td>3.031830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.037158</td>\n",
       "      <td>-2.561116</td>\n",
       "      <td>-2.611551</td>\n",
       "      <td>-12.531276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1.569149</td>\n",
       "      <td>1.724678</td>\n",
       "      <td>0.254074</td>\n",
       "      <td>9.034802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>2.353843</td>\n",
       "      <td>-1.341353</td>\n",
       "      <td>-0.168997</td>\n",
       "      <td>1.995149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.200322</td>\n",
       "      <td>-0.515604</td>\n",
       "      <td>0.936444</td>\n",
       "      <td>5.914889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.059950</td>\n",
       "      <td>0.710705</td>\n",
       "      <td>-0.862388</td>\n",
       "      <td>0.911910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3          Y\n",
       "0   -2.154893 -0.220490  0.854107   3.820555\n",
       "1   -1.719194 -0.213630  0.908401   4.487152\n",
       "2    0.788780  0.658063 -0.548548   2.910713\n",
       "3   -0.832647 -0.029061 -0.684627  -0.629276\n",
       "4    0.488314  1.195539 -0.711891   3.031830\n",
       "..        ...       ...       ...        ...\n",
       "995  0.037158 -2.561116 -2.611551 -12.531276\n",
       "996  1.569149  1.724678  0.254074   9.034802\n",
       "997  2.353843 -1.341353 -0.168997   1.995149\n",
       "998  0.200322 -0.515604  0.936444   5.914889\n",
       "999 -0.059950  0.710705 -0.862388   0.911910\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = torch.normal(0, 1, (1000, 3))\n",
    "y = torch.matmul(X, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0, torch.Size([1000]))/1000000\n",
    "############\n",
    "Y = y.reshape((-1, 1))\n",
    "X_Train = X\n",
    "Y_Train = Y\n",
    "data = {\"X1\" : X.numpy()[:,0],\"X2\" : X.numpy()[:,1],\"X3\" : X.numpy()[:,2], \"Y\":y}\n",
    "df = pd.DataFrame(data)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "e25f267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train  = torch.normal(0, 1, (1000, 3))\n",
    "y = torch.matmul(X, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0, torch.Size([1000]))/100000\n",
    "############\n",
    "Y_Train = y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31273ef0",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8311728",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDim = 3\n",
    "OutputDim = 1\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(LinearRegression, self).__init__() \n",
    "        self.linear = torch.nn.Linear(InputDim, OutputDim)  \n",
    "    def forward(self, x): \n",
    "        y_hat = self.linear(x) \n",
    "        return y_hat \n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c055deb",
   "metadata": {},
   "source": [
    "# Define the Loss Function and an Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab3babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define_criterion = torch.nn.MSELoss(size_average=False) replace with:\n",
    "criterion = torch.nn.MSELoss( reduction='sum')\n",
    "Optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7507bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss function 38140.2578125\n",
      "epoch 1, loss function 37982.9921875\n",
      "epoch 2, loss function 37826.375\n",
      "epoch 3, loss function 37670.40234375\n",
      "epoch 4, loss function 37515.078125\n",
      "epoch 5, loss function 37360.39453125\n",
      "epoch 6, loss function 37206.34765625\n",
      "epoch 7, loss function 37052.93359375\n",
      "epoch 8, loss function 36900.15625\n",
      "epoch 9, loss function 36748.0078125\n",
      "epoch 10, loss function 36596.48828125\n",
      "epoch 11, loss function 36445.59375\n",
      "epoch 12, loss function 36295.32421875\n",
      "epoch 13, loss function 36145.66796875\n",
      "epoch 14, loss function 35996.6328125\n",
      "epoch 15, loss function 35848.21484375\n",
      "epoch 16, loss function 35700.40625\n",
      "epoch 17, loss function 35553.2109375\n",
      "epoch 18, loss function 35406.62109375\n",
      "epoch 19, loss function 35260.63671875\n",
      "epoch 20, loss function 35115.25390625\n",
      "epoch 21, loss function 34970.47265625\n",
      "epoch 22, loss function 34826.28515625\n",
      "epoch 23, loss function 34682.6953125\n",
      "epoch 24, loss function 34539.69921875\n",
      "epoch 25, loss function 34397.29296875\n",
      "epoch 26, loss function 34255.47265625\n",
      "epoch 27, loss function 34114.23828125\n",
      "epoch 28, loss function 33973.5859375\n",
      "epoch 29, loss function 33833.515625\n",
      "epoch 30, loss function 33694.01953125\n",
      "epoch 31, loss function 33555.1015625\n",
      "epoch 32, loss function 33416.7578125\n",
      "epoch 33, loss function 33278.984375\n",
      "epoch 34, loss function 33141.78125\n",
      "epoch 35, loss function 33005.140625\n",
      "epoch 36, loss function 32869.0703125\n",
      "epoch 37, loss function 32733.5546875\n",
      "epoch 38, loss function 32598.59765625\n",
      "epoch 39, loss function 32464.19921875\n",
      "epoch 40, loss function 32330.35546875\n",
      "epoch 41, loss function 32197.06640625\n",
      "epoch 42, loss function 32064.32421875\n",
      "epoch 43, loss function 31932.1328125\n",
      "epoch 44, loss function 31800.484375\n",
      "epoch 45, loss function 31669.380859375\n",
      "epoch 46, loss function 31538.81640625\n",
      "epoch 47, loss function 31408.79296875\n",
      "epoch 48, loss function 31279.3046875\n",
      "epoch 49, loss function 31150.34765625\n",
      "epoch 50, loss function 31021.92578125\n",
      "epoch 51, loss function 30894.037109375\n",
      "epoch 52, loss function 30766.669921875\n",
      "epoch 53, loss function 30639.833984375\n",
      "epoch 54, loss function 30513.515625\n",
      "epoch 55, loss function 30387.720703125\n",
      "epoch 56, loss function 30262.44921875\n",
      "epoch 57, loss function 30137.6875\n",
      "epoch 58, loss function 30013.4453125\n",
      "epoch 59, loss function 29889.712890625\n",
      "epoch 60, loss function 29766.4921875\n",
      "epoch 61, loss function 29643.783203125\n",
      "epoch 62, loss function 29521.578125\n",
      "epoch 63, loss function 29399.873046875\n",
      "epoch 64, loss function 29278.673828125\n",
      "epoch 65, loss function 29157.974609375\n",
      "epoch 66, loss function 29037.775390625\n",
      "epoch 67, loss function 28918.068359375\n",
      "epoch 68, loss function 28798.85546875\n",
      "epoch 69, loss function 28680.13671875\n",
      "epoch 70, loss function 28561.90625\n",
      "epoch 71, loss function 28444.166015625\n",
      "epoch 72, loss function 28326.90625\n",
      "epoch 73, loss function 28210.1328125\n",
      "epoch 74, loss function 28093.845703125\n",
      "epoch 75, loss function 27978.033203125\n",
      "epoch 76, loss function 27862.69921875\n",
      "epoch 77, loss function 27747.84375\n",
      "epoch 78, loss function 27633.4609375\n",
      "epoch 79, loss function 27519.546875\n",
      "epoch 80, loss function 27406.10546875\n",
      "epoch 81, loss function 27293.134765625\n",
      "epoch 82, loss function 27180.623046875\n",
      "epoch 83, loss function 27068.580078125\n",
      "epoch 84, loss function 26957.0\n",
      "epoch 85, loss function 26845.8828125\n",
      "epoch 86, loss function 26735.216796875\n",
      "epoch 87, loss function 26625.01171875\n",
      "epoch 88, loss function 26515.26171875\n",
      "epoch 89, loss function 26405.962890625\n",
      "epoch 90, loss function 26297.11328125\n",
      "epoch 91, loss function 26188.716796875\n",
      "epoch 92, loss function 26080.765625\n",
      "epoch 93, loss function 25973.259765625\n",
      "epoch 94, loss function 25866.19921875\n",
      "epoch 95, loss function 25759.57421875\n",
      "epoch 96, loss function 25653.39453125\n",
      "epoch 97, loss function 25547.654296875\n",
      "epoch 98, loss function 25442.34765625\n",
      "epoch 99, loss function 25337.474609375\n",
      "epoch 100, loss function 25233.037109375\n",
      "epoch 101, loss function 25129.02734375\n",
      "epoch 102, loss function 25025.4453125\n",
      "epoch 103, loss function 24922.294921875\n",
      "epoch 104, loss function 24819.56640625\n",
      "epoch 105, loss function 24717.265625\n",
      "epoch 106, loss function 24615.38671875\n",
      "epoch 107, loss function 24513.923828125\n",
      "epoch 108, loss function 24412.880859375\n",
      "epoch 109, loss function 24312.2578125\n",
      "epoch 110, loss function 24212.046875\n",
      "epoch 111, loss function 24112.251953125\n",
      "epoch 112, loss function 24012.86328125\n",
      "epoch 113, loss function 23913.888671875\n",
      "epoch 114, loss function 23815.322265625\n",
      "epoch 115, loss function 23717.1640625\n",
      "epoch 116, loss function 23619.40625\n",
      "epoch 117, loss function 23522.0546875\n",
      "epoch 118, loss function 23425.10546875\n",
      "epoch 119, loss function 23328.556640625\n",
      "epoch 120, loss function 23232.40234375\n",
      "epoch 121, loss function 23136.64453125\n",
      "epoch 122, loss function 23041.2890625\n",
      "epoch 123, loss function 22946.3203125\n",
      "epoch 124, loss function 22851.74609375\n",
      "epoch 125, loss function 22757.560546875\n",
      "epoch 126, loss function 22663.763671875\n",
      "epoch 127, loss function 22570.353515625\n",
      "epoch 128, loss function 22477.328125\n",
      "epoch 129, loss function 22384.6875\n",
      "epoch 130, loss function 22292.431640625\n",
      "epoch 131, loss function 22200.55078125\n",
      "epoch 132, loss function 22109.05078125\n",
      "epoch 133, loss function 22017.931640625\n",
      "epoch 134, loss function 21927.185546875\n",
      "epoch 135, loss function 21836.8125\n",
      "epoch 136, loss function 21746.814453125\n",
      "epoch 137, loss function 21657.1875\n",
      "epoch 138, loss function 21567.9296875\n",
      "epoch 139, loss function 21479.0390625\n",
      "epoch 140, loss function 21390.515625\n",
      "epoch 141, loss function 21302.357421875\n",
      "epoch 142, loss function 21214.564453125\n",
      "epoch 143, loss function 21127.130859375\n",
      "epoch 144, loss function 21040.0625\n",
      "epoch 145, loss function 20953.349609375\n",
      "epoch 146, loss function 20866.99609375\n",
      "epoch 147, loss function 20780.99609375\n",
      "epoch 148, loss function 20695.3515625\n",
      "epoch 149, loss function 20610.060546875\n",
      "epoch 150, loss function 20525.123046875\n",
      "epoch 151, loss function 20440.537109375\n",
      "epoch 152, loss function 20356.296875\n",
      "epoch 153, loss function 20272.404296875\n",
      "epoch 154, loss function 20188.859375\n",
      "epoch 155, loss function 20105.65625\n",
      "epoch 156, loss function 20022.798828125\n",
      "epoch 157, loss function 19940.28125\n",
      "epoch 158, loss function 19858.10546875\n",
      "epoch 159, loss function 19776.26953125\n",
      "epoch 160, loss function 19694.76953125\n",
      "epoch 161, loss function 19613.603515625\n",
      "epoch 162, loss function 19532.77734375\n",
      "epoch 163, loss function 19452.28125\n",
      "epoch 164, loss function 19372.119140625\n",
      "epoch 165, loss function 19292.28515625\n",
      "epoch 166, loss function 19212.78125\n",
      "epoch 167, loss function 19133.60546875\n",
      "epoch 168, loss function 19054.7578125\n",
      "epoch 169, loss function 18976.234375\n",
      "epoch 170, loss function 18898.03515625\n",
      "epoch 171, loss function 18820.158203125\n",
      "epoch 172, loss function 18742.6015625\n",
      "epoch 173, loss function 18665.36328125\n",
      "epoch 174, loss function 18588.4453125\n",
      "epoch 175, loss function 18511.84765625\n",
      "epoch 176, loss function 18435.560546875\n",
      "epoch 177, loss function 18359.591796875\n",
      "epoch 178, loss function 18283.9375\n",
      "epoch 179, loss function 18208.58984375\n",
      "epoch 180, loss function 18133.556640625\n",
      "epoch 181, loss function 18058.83203125\n",
      "epoch 182, loss function 17984.416015625\n",
      "epoch 183, loss function 17910.306640625\n",
      "epoch 184, loss function 17836.50390625\n",
      "epoch 185, loss function 17763.00390625\n",
      "epoch 186, loss function 17689.80859375\n",
      "epoch 187, loss function 17616.9140625\n",
      "epoch 188, loss function 17544.318359375\n",
      "epoch 189, loss function 17472.025390625\n",
      "epoch 190, loss function 17400.029296875\n",
      "epoch 191, loss function 17328.330078125\n",
      "epoch 192, loss function 17256.92578125\n",
      "epoch 193, loss function 17185.81640625\n",
      "epoch 194, loss function 17115.001953125\n",
      "epoch 195, loss function 17044.4765625\n",
      "epoch 196, loss function 16974.24609375\n",
      "epoch 197, loss function 16904.302734375\n",
      "epoch 198, loss function 16834.6484375\n",
      "epoch 199, loss function 16765.279296875\n",
      "epoch 200, loss function 16696.19921875\n",
      "epoch 201, loss function 16627.400390625\n",
      "epoch 202, loss function 16558.888671875\n",
      "epoch 203, loss function 16490.658203125\n",
      "epoch 204, loss function 16422.708984375\n",
      "epoch 205, loss function 16355.04296875\n",
      "epoch 206, loss function 16287.650390625\n",
      "epoch 207, loss function 16220.5390625\n",
      "epoch 208, loss function 16153.705078125\n",
      "epoch 209, loss function 16087.14453125\n",
      "epoch 210, loss function 16020.8603515625\n",
      "epoch 211, loss function 15954.8486328125\n",
      "epoch 212, loss function 15889.1103515625\n",
      "epoch 213, loss function 15823.6416015625\n",
      "epoch 214, loss function 15758.443359375\n",
      "epoch 215, loss function 15693.513671875\n",
      "epoch 216, loss function 15628.8505859375\n",
      "epoch 217, loss function 15564.45703125\n",
      "epoch 218, loss function 15500.3271484375\n",
      "epoch 219, loss function 15436.462890625\n",
      "epoch 220, loss function 15372.859375\n",
      "epoch 221, loss function 15309.5205078125\n",
      "epoch 222, loss function 15246.4423828125\n",
      "epoch 223, loss function 15183.625\n",
      "epoch 224, loss function 15121.06640625\n",
      "epoch 225, loss function 15058.7646484375\n",
      "epoch 226, loss function 14996.720703125\n",
      "epoch 227, loss function 14934.931640625\n",
      "epoch 228, loss function 14873.3984375\n",
      "epoch 229, loss function 14812.119140625\n",
      "epoch 230, loss function 14751.08984375\n",
      "epoch 231, loss function 14690.3154296875\n",
      "epoch 232, loss function 14629.7900390625\n",
      "epoch 233, loss function 14569.515625\n",
      "epoch 234, loss function 14509.48828125\n",
      "epoch 235, loss function 14449.7099609375\n",
      "epoch 236, loss function 14390.1767578125\n",
      "epoch 237, loss function 14330.888671875\n",
      "epoch 238, loss function 14271.84765625\n",
      "epoch 239, loss function 14213.0478515625\n",
      "epoch 240, loss function 14154.490234375\n",
      "epoch 241, loss function 14096.1748046875\n",
      "epoch 242, loss function 14038.099609375\n",
      "epoch 243, loss function 13980.263671875\n",
      "epoch 244, loss function 13922.6669921875\n",
      "epoch 245, loss function 13865.30859375\n",
      "epoch 246, loss function 13808.1845703125\n",
      "epoch 247, loss function 13751.296875\n",
      "epoch 248, loss function 13694.64453125\n",
      "epoch 249, loss function 13638.2255859375\n",
      "epoch 250, loss function 13582.0380859375\n",
      "epoch 251, loss function 13526.0830078125\n",
      "epoch 252, loss function 13470.357421875\n",
      "epoch 253, loss function 13414.8642578125\n",
      "epoch 254, loss function 13359.5986328125\n",
      "epoch 255, loss function 13304.560546875\n",
      "epoch 256, loss function 13249.7490234375\n",
      "epoch 257, loss function 13195.1640625\n",
      "epoch 258, loss function 13140.8046875\n",
      "epoch 259, loss function 13086.66796875\n",
      "epoch 260, loss function 13032.755859375\n",
      "epoch 261, loss function 12979.0654296875\n",
      "epoch 262, loss function 12925.5966796875\n",
      "epoch 263, loss function 12872.3486328125\n",
      "epoch 264, loss function 12819.3193359375\n",
      "epoch 265, loss function 12766.509765625\n",
      "epoch 266, loss function 12713.916015625\n",
      "epoch 267, loss function 12661.5400390625\n",
      "epoch 268, loss function 12609.380859375\n",
      "epoch 269, loss function 12557.4365234375\n",
      "epoch 270, loss function 12505.7060546875\n",
      "epoch 271, loss function 12454.1875\n",
      "epoch 272, loss function 12402.884765625\n",
      "epoch 273, loss function 12351.7900390625\n",
      "epoch 274, loss function 12300.9072265625\n",
      "epoch 275, loss function 12250.2333984375\n",
      "epoch 276, loss function 12199.7705078125\n",
      "epoch 277, loss function 12149.513671875\n",
      "epoch 278, loss function 12099.4658203125\n",
      "epoch 279, loss function 12049.623046875\n",
      "epoch 280, loss function 11999.986328125\n",
      "epoch 281, loss function 11950.5546875\n",
      "epoch 282, loss function 11901.3251953125\n",
      "epoch 283, loss function 11852.2998046875\n",
      "epoch 284, loss function 11803.4775390625\n",
      "epoch 285, loss function 11754.8544921875\n",
      "epoch 286, loss function 11706.4326171875\n",
      "epoch 287, loss function 11658.212890625\n",
      "epoch 288, loss function 11610.1884765625\n",
      "epoch 289, loss function 11562.3623046875\n",
      "epoch 290, loss function 11514.734375\n",
      "epoch 291, loss function 11467.3037109375\n",
      "epoch 292, loss function 11420.06640625\n",
      "epoch 293, loss function 11373.0244140625\n",
      "epoch 294, loss function 11326.1787109375\n",
      "epoch 295, loss function 11279.5234375\n",
      "epoch 296, loss function 11233.0625\n",
      "epoch 297, loss function 11186.7919921875\n",
      "epoch 298, loss function 11140.712890625\n",
      "epoch 299, loss function 11094.822265625\n",
      "epoch 300, loss function 11049.1220703125\n",
      "epoch 301, loss function 11003.6103515625\n",
      "epoch 302, loss function 10958.2861328125\n",
      "epoch 303, loss function 10913.1484375\n",
      "epoch 304, loss function 10868.1962890625\n",
      "epoch 305, loss function 10823.4306640625\n",
      "epoch 306, loss function 10778.84765625\n",
      "epoch 307, loss function 10734.4501953125\n",
      "epoch 308, loss function 10690.2353515625\n",
      "epoch 309, loss function 10646.203125\n",
      "epoch 310, loss function 10602.3525390625\n",
      "epoch 311, loss function 10558.681640625\n",
      "epoch 312, loss function 10515.19140625\n",
      "epoch 313, loss function 10471.8798828125\n",
      "epoch 314, loss function 10428.748046875\n",
      "epoch 315, loss function 10385.79296875\n",
      "epoch 316, loss function 10343.015625\n",
      "epoch 317, loss function 10300.4140625\n",
      "epoch 318, loss function 10257.9892578125\n",
      "epoch 319, loss function 10215.73828125\n",
      "epoch 320, loss function 10173.662109375\n",
      "epoch 321, loss function 10131.7587890625\n",
      "epoch 322, loss function 10090.0283203125\n",
      "epoch 323, loss function 10048.4716796875\n",
      "epoch 324, loss function 10007.083984375\n",
      "epoch 325, loss function 9965.8671875\n",
      "epoch 326, loss function 9924.8203125\n",
      "epoch 327, loss function 9883.9423828125\n",
      "epoch 328, loss function 9843.2353515625\n",
      "epoch 329, loss function 9802.6943359375\n",
      "epoch 330, loss function 9762.3193359375\n",
      "epoch 331, loss function 9722.1123046875\n",
      "epoch 332, loss function 9682.0703125\n",
      "epoch 333, loss function 9642.193359375\n",
      "epoch 334, loss function 9602.4814453125\n",
      "epoch 335, loss function 9562.93359375\n",
      "epoch 336, loss function 9523.546875\n",
      "epoch 337, loss function 9484.3232421875\n",
      "epoch 338, loss function 9445.2626953125\n",
      "epoch 339, loss function 9406.3623046875\n",
      "epoch 340, loss function 9367.623046875\n",
      "epoch 341, loss function 9329.0419921875\n",
      "epoch 342, loss function 9290.6201171875\n",
      "epoch 343, loss function 9252.3564453125\n",
      "epoch 344, loss function 9214.251953125\n",
      "epoch 345, loss function 9176.302734375\n",
      "epoch 346, loss function 9138.51171875\n",
      "epoch 347, loss function 9100.875\n",
      "epoch 348, loss function 9063.3935546875\n",
      "epoch 349, loss function 9026.06640625\n",
      "epoch 350, loss function 8988.8935546875\n",
      "epoch 351, loss function 8951.8759765625\n",
      "epoch 352, loss function 8915.0078125\n",
      "epoch 353, loss function 8878.29296875\n",
      "epoch 354, loss function 8841.7294921875\n",
      "epoch 355, loss function 8805.318359375\n",
      "epoch 356, loss function 8769.0537109375\n",
      "epoch 357, loss function 8732.94140625\n",
      "epoch 358, loss function 8696.9765625\n",
      "epoch 359, loss function 8661.16015625\n",
      "epoch 360, loss function 8625.4921875\n",
      "epoch 361, loss function 8589.9697265625\n",
      "epoch 362, loss function 8554.5947265625\n",
      "epoch 363, loss function 8519.3642578125\n",
      "epoch 364, loss function 8484.28125\n",
      "epoch 365, loss function 8449.341796875\n",
      "epoch 366, loss function 8414.546875\n",
      "epoch 367, loss function 8379.89453125\n",
      "epoch 368, loss function 8345.384765625\n",
      "epoch 369, loss function 8311.0166015625\n",
      "epoch 370, loss function 8276.7919921875\n",
      "epoch 371, loss function 8242.70703125\n",
      "epoch 372, loss function 8208.763671875\n",
      "epoch 373, loss function 8174.96044921875\n",
      "epoch 374, loss function 8141.2958984375\n",
      "epoch 375, loss function 8107.76904296875\n",
      "epoch 376, loss function 8074.3818359375\n",
      "epoch 377, loss function 8041.1318359375\n",
      "epoch 378, loss function 8008.0185546875\n",
      "epoch 379, loss function 7975.04150390625\n",
      "epoch 380, loss function 7942.201171875\n",
      "epoch 381, loss function 7909.49609375\n",
      "epoch 382, loss function 7876.9248046875\n",
      "epoch 383, loss function 7844.48876953125\n",
      "epoch 384, loss function 7812.18603515625\n",
      "epoch 385, loss function 7780.01611328125\n",
      "epoch 386, loss function 7747.9794921875\n",
      "epoch 387, loss function 7716.0751953125\n",
      "epoch 388, loss function 7684.3017578125\n",
      "epoch 389, loss function 7652.65869140625\n",
      "epoch 390, loss function 7621.14599609375\n",
      "epoch 391, loss function 7589.7646484375\n",
      "epoch 392, loss function 7558.5107421875\n",
      "epoch 393, loss function 7527.38671875\n",
      "epoch 394, loss function 7496.39111328125\n",
      "epoch 395, loss function 7465.5234375\n",
      "epoch 396, loss function 7434.7822265625\n",
      "epoch 397, loss function 7404.16796875\n",
      "epoch 398, loss function 7373.67919921875\n",
      "epoch 399, loss function 7343.31689453125\n",
      "epoch 400, loss function 7313.0791015625\n",
      "epoch 401, loss function 7282.966796875\n",
      "epoch 402, loss function 7252.9775390625\n",
      "epoch 403, loss function 7223.11279296875\n",
      "epoch 404, loss function 7193.37060546875\n",
      "epoch 405, loss function 7163.75146484375\n",
      "epoch 406, loss function 7134.25390625\n",
      "epoch 407, loss function 7104.8779296875\n",
      "epoch 408, loss function 7075.6240234375\n",
      "epoch 409, loss function 7046.4892578125\n",
      "epoch 410, loss function 7017.4755859375\n",
      "epoch 411, loss function 6988.5810546875\n",
      "epoch 412, loss function 6959.8056640625\n",
      "epoch 413, loss function 6931.1494140625\n",
      "epoch 414, loss function 6902.60888671875\n",
      "epoch 415, loss function 6874.18798828125\n",
      "epoch 416, loss function 6845.8828125\n",
      "epoch 417, loss function 6817.69580078125\n",
      "epoch 418, loss function 6789.62451171875\n",
      "epoch 419, loss function 6761.6689453125\n",
      "epoch 420, loss function 6733.82861328125\n",
      "epoch 421, loss function 6706.10302734375\n",
      "epoch 422, loss function 6678.49169921875\n",
      "epoch 423, loss function 6650.99365234375\n",
      "epoch 424, loss function 6623.609375\n",
      "epoch 425, loss function 6596.337890625\n",
      "epoch 426, loss function 6569.1787109375\n",
      "epoch 427, loss function 6542.13134765625\n",
      "epoch 428, loss function 6515.1953125\n",
      "epoch 429, loss function 6488.37158203125\n",
      "epoch 430, loss function 6461.6572265625\n",
      "epoch 431, loss function 6435.0537109375\n",
      "epoch 432, loss function 6408.55859375\n",
      "epoch 433, loss function 6382.17333984375\n",
      "epoch 434, loss function 6355.89599609375\n",
      "epoch 435, loss function 6329.72802734375\n",
      "epoch 436, loss function 6303.6669921875\n",
      "epoch 437, loss function 6277.71435546875\n",
      "epoch 438, loss function 6251.8681640625\n",
      "epoch 439, loss function 6226.1279296875\n",
      "epoch 440, loss function 6200.494140625\n",
      "epoch 441, loss function 6174.966796875\n",
      "epoch 442, loss function 6149.54443359375\n",
      "epoch 443, loss function 6124.22607421875\n",
      "epoch 444, loss function 6099.0126953125\n",
      "epoch 445, loss function 6073.90234375\n",
      "epoch 446, loss function 6048.8955078125\n",
      "epoch 447, loss function 6023.99267578125\n",
      "epoch 448, loss function 5999.19140625\n",
      "epoch 449, loss function 5974.49365234375\n",
      "epoch 450, loss function 5949.8974609375\n",
      "epoch 451, loss function 5925.4013671875\n",
      "epoch 452, loss function 5901.00732421875\n",
      "epoch 453, loss function 5876.7138671875\n",
      "epoch 454, loss function 5852.52001953125\n",
      "epoch 455, loss function 5828.42578125\n",
      "epoch 456, loss function 5804.4306640625\n",
      "epoch 457, loss function 5780.53466796875\n",
      "epoch 458, loss function 5756.7373046875\n",
      "epoch 459, loss function 5733.03759765625\n",
      "epoch 460, loss function 5709.43603515625\n",
      "epoch 461, loss function 5685.931640625\n",
      "epoch 462, loss function 5662.52392578125\n",
      "epoch 463, loss function 5639.21240234375\n",
      "epoch 464, loss function 5615.99658203125\n",
      "epoch 465, loss function 5592.8779296875\n",
      "epoch 466, loss function 5569.853515625\n",
      "epoch 467, loss function 5546.9248046875\n",
      "epoch 468, loss function 5524.08935546875\n",
      "epoch 469, loss function 5501.34912109375\n",
      "epoch 470, loss function 5478.70166015625\n",
      "epoch 471, loss function 5456.1484375\n",
      "epoch 472, loss function 5433.68701171875\n",
      "epoch 473, loss function 5411.318359375\n",
      "epoch 474, loss function 5389.04296875\n",
      "epoch 475, loss function 5366.8583984375\n",
      "epoch 476, loss function 5344.7646484375\n",
      "epoch 477, loss function 5322.76220703125\n",
      "epoch 478, loss function 5300.8505859375\n",
      "epoch 479, loss function 5279.029296875\n",
      "epoch 480, loss function 5257.2978515625\n",
      "epoch 481, loss function 5235.65576171875\n",
      "epoch 482, loss function 5214.10302734375\n",
      "epoch 483, loss function 5192.6396484375\n",
      "epoch 484, loss function 5171.2646484375\n",
      "epoch 485, loss function 5149.97705078125\n",
      "epoch 486, loss function 5128.77783203125\n",
      "epoch 487, loss function 5107.6650390625\n",
      "epoch 488, loss function 5086.6396484375\n",
      "epoch 489, loss function 5065.70068359375\n",
      "epoch 490, loss function 5044.8486328125\n",
      "epoch 491, loss function 5024.08154296875\n",
      "epoch 492, loss function 5003.40087890625\n",
      "epoch 493, loss function 4982.8056640625\n",
      "epoch 494, loss function 4962.29443359375\n",
      "epoch 495, loss function 4941.86865234375\n",
      "epoch 496, loss function 4921.5263671875\n",
      "epoch 497, loss function 4901.26806640625\n",
      "epoch 498, loss function 4881.09375\n",
      "epoch 499, loss function 4861.0029296875\n",
      "epoch 500, loss function 4840.99365234375\n",
      "epoch 501, loss function 4821.06689453125\n",
      "epoch 502, loss function 4801.2216796875\n",
      "epoch 503, loss function 4781.45947265625\n",
      "epoch 504, loss function 4761.7783203125\n",
      "epoch 505, loss function 4742.17822265625\n",
      "epoch 506, loss function 4722.658203125\n",
      "epoch 507, loss function 4703.21923828125\n",
      "epoch 508, loss function 4683.85986328125\n",
      "epoch 509, loss function 4664.5810546875\n",
      "epoch 510, loss function 4645.38134765625\n",
      "epoch 511, loss function 4626.26025390625\n",
      "epoch 512, loss function 4607.21826171875\n",
      "epoch 513, loss function 4588.25390625\n",
      "epoch 514, loss function 4569.36865234375\n",
      "epoch 515, loss function 4550.560546875\n",
      "epoch 516, loss function 4531.830078125\n",
      "epoch 517, loss function 4513.1767578125\n",
      "epoch 518, loss function 4494.6005859375\n",
      "epoch 519, loss function 4476.1015625\n",
      "epoch 520, loss function 4457.67822265625\n",
      "epoch 521, loss function 4439.3310546875\n",
      "epoch 522, loss function 4421.05859375\n",
      "epoch 523, loss function 4402.86181640625\n",
      "epoch 524, loss function 4384.740234375\n",
      "epoch 525, loss function 4366.6923828125\n",
      "epoch 526, loss function 4348.7197265625\n",
      "epoch 527, loss function 4330.8212890625\n",
      "epoch 528, loss function 4312.99609375\n",
      "epoch 529, loss function 4295.2451171875\n",
      "epoch 530, loss function 4277.56640625\n",
      "epoch 531, loss function 4259.96044921875\n",
      "epoch 532, loss function 4242.42724609375\n",
      "epoch 533, loss function 4224.96630859375\n",
      "epoch 534, loss function 4207.5771484375\n",
      "epoch 535, loss function 4190.259765625\n",
      "epoch 536, loss function 4173.013671875\n",
      "epoch 537, loss function 4155.8388671875\n",
      "epoch 538, loss function 4138.73486328125\n",
      "epoch 539, loss function 4121.701171875\n",
      "epoch 540, loss function 4104.73779296875\n",
      "epoch 541, loss function 4087.844482421875\n",
      "epoch 542, loss function 4071.019775390625\n",
      "epoch 543, loss function 4054.264892578125\n",
      "epoch 544, loss function 4037.5791015625\n",
      "epoch 545, loss function 4020.9619140625\n",
      "epoch 546, loss function 4004.412841796875\n",
      "epoch 547, loss function 3987.9326171875\n",
      "epoch 548, loss function 3971.519775390625\n",
      "epoch 549, loss function 3955.1748046875\n",
      "epoch 550, loss function 3938.8974609375\n",
      "epoch 551, loss function 3922.6865234375\n",
      "epoch 552, loss function 3906.54296875\n",
      "epoch 553, loss function 3890.4658203125\n",
      "epoch 554, loss function 3874.45556640625\n",
      "epoch 555, loss function 3858.509765625\n",
      "epoch 556, loss function 3842.6298828125\n",
      "epoch 557, loss function 3826.815673828125\n",
      "epoch 558, loss function 3811.067138671875\n",
      "epoch 559, loss function 3795.38330078125\n",
      "epoch 560, loss function 3779.763427734375\n",
      "epoch 561, loss function 3764.208251953125\n",
      "epoch 562, loss function 3748.71728515625\n",
      "epoch 563, loss function 3733.289794921875\n",
      "epoch 564, loss function 3717.92626953125\n",
      "epoch 565, loss function 3702.626220703125\n",
      "epoch 566, loss function 3687.388427734375\n",
      "epoch 567, loss function 3672.214111328125\n",
      "epoch 568, loss function 3657.101806640625\n",
      "epoch 569, loss function 3642.0517578125\n",
      "epoch 570, loss function 3627.06396484375\n",
      "epoch 571, loss function 3612.137939453125\n",
      "epoch 572, loss function 3597.27294921875\n",
      "epoch 573, loss function 3582.4697265625\n",
      "epoch 574, loss function 3567.72705078125\n",
      "epoch 575, loss function 3553.045654296875\n",
      "epoch 576, loss function 3538.42431640625\n",
      "epoch 577, loss function 3523.863525390625\n",
      "epoch 578, loss function 3509.362060546875\n",
      "epoch 579, loss function 3494.920166015625\n",
      "epoch 580, loss function 3480.53857421875\n",
      "epoch 581, loss function 3466.215576171875\n",
      "epoch 582, loss function 3451.951904296875\n",
      "epoch 583, loss function 3437.7470703125\n",
      "epoch 584, loss function 3423.6005859375\n",
      "epoch 585, loss function 3409.511962890625\n",
      "epoch 586, loss function 3395.48193359375\n",
      "epoch 587, loss function 3381.509765625\n",
      "epoch 588, loss function 3367.594970703125\n",
      "epoch 589, loss function 3353.737060546875\n",
      "epoch 590, loss function 3339.93701171875\n",
      "epoch 591, loss function 3326.19384765625\n",
      "epoch 592, loss function 3312.50634765625\n",
      "epoch 593, loss function 3298.87548828125\n",
      "epoch 594, loss function 3285.301025390625\n",
      "epoch 595, loss function 3271.782470703125\n",
      "epoch 596, loss function 3258.3193359375\n",
      "epoch 597, loss function 3244.91162109375\n",
      "epoch 598, loss function 3231.559814453125\n",
      "epoch 599, loss function 3218.2626953125\n",
      "epoch 600, loss function 3205.020263671875\n",
      "epoch 601, loss function 3191.83203125\n",
      "epoch 602, loss function 3178.6982421875\n",
      "epoch 603, loss function 3165.61865234375\n",
      "epoch 604, loss function 3152.5927734375\n",
      "epoch 605, loss function 3139.62060546875\n",
      "epoch 606, loss function 3126.701904296875\n",
      "epoch 607, loss function 3113.836181640625\n",
      "epoch 608, loss function 3101.02392578125\n",
      "epoch 609, loss function 3088.263916015625\n",
      "epoch 610, loss function 3075.556640625\n",
      "epoch 611, loss function 3062.9013671875\n",
      "epoch 612, loss function 3050.298828125\n",
      "epoch 613, loss function 3037.748046875\n",
      "epoch 614, loss function 3025.248779296875\n",
      "epoch 615, loss function 3012.801025390625\n",
      "epoch 616, loss function 3000.404052734375\n",
      "epoch 617, loss function 2988.05859375\n",
      "epoch 618, loss function 2975.763916015625\n",
      "epoch 619, loss function 2963.519775390625\n",
      "epoch 620, loss function 2951.326171875\n",
      "epoch 621, loss function 2939.182861328125\n",
      "epoch 622, loss function 2927.08984375\n",
      "epoch 623, loss function 2915.04638671875\n",
      "epoch 624, loss function 2903.05224609375\n",
      "epoch 625, loss function 2891.107666015625\n",
      "epoch 626, loss function 2879.212646484375\n",
      "epoch 627, loss function 2867.365966796875\n",
      "epoch 628, loss function 2855.56884765625\n",
      "epoch 629, loss function 2843.81982421875\n",
      "epoch 630, loss function 2832.119140625\n",
      "epoch 631, loss function 2820.46630859375\n",
      "epoch 632, loss function 2808.86181640625\n",
      "epoch 633, loss function 2797.304931640625\n",
      "epoch 634, loss function 2785.795654296875\n",
      "epoch 635, loss function 2774.334228515625\n",
      "epoch 636, loss function 2762.91943359375\n",
      "epoch 637, loss function 2751.55224609375\n",
      "epoch 638, loss function 2740.231201171875\n",
      "epoch 639, loss function 2728.95703125\n",
      "epoch 640, loss function 2717.72900390625\n",
      "epoch 641, loss function 2706.548095703125\n",
      "epoch 642, loss function 2695.41259765625\n",
      "epoch 643, loss function 2684.32275390625\n",
      "epoch 644, loss function 2673.27880859375\n",
      "epoch 645, loss function 2662.280517578125\n",
      "epoch 646, loss function 2651.327392578125\n",
      "epoch 647, loss function 2640.419189453125\n",
      "epoch 648, loss function 2629.55615234375\n",
      "epoch 649, loss function 2618.73779296875\n",
      "epoch 650, loss function 2607.96435546875\n",
      "epoch 651, loss function 2597.234375\n",
      "epoch 652, loss function 2586.54931640625\n",
      "epoch 653, loss function 2575.908447265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 654, loss function 2565.310791015625\n",
      "epoch 655, loss function 2554.757080078125\n",
      "epoch 656, loss function 2544.246337890625\n",
      "epoch 657, loss function 2533.779052734375\n",
      "epoch 658, loss function 2523.355712890625\n",
      "epoch 659, loss function 2512.97509765625\n",
      "epoch 660, loss function 2502.636962890625\n",
      "epoch 661, loss function 2492.340576171875\n",
      "epoch 662, loss function 2482.0869140625\n",
      "epoch 663, loss function 2471.8759765625\n",
      "epoch 664, loss function 2461.70703125\n",
      "epoch 665, loss function 2451.580078125\n",
      "epoch 666, loss function 2441.494873046875\n",
      "epoch 667, loss function 2431.450927734375\n",
      "epoch 668, loss function 2421.448486328125\n",
      "epoch 669, loss function 2411.487548828125\n",
      "epoch 670, loss function 2401.56640625\n",
      "epoch 671, loss function 2391.686767578125\n",
      "epoch 672, loss function 2381.847900390625\n",
      "epoch 673, loss function 2372.049560546875\n",
      "epoch 674, loss function 2362.291259765625\n",
      "epoch 675, loss function 2352.5732421875\n",
      "epoch 676, loss function 2342.8955078125\n",
      "epoch 677, loss function 2333.257568359375\n",
      "epoch 678, loss function 2323.659423828125\n",
      "epoch 679, loss function 2314.100830078125\n",
      "epoch 680, loss function 2304.581298828125\n",
      "epoch 681, loss function 2295.10107421875\n",
      "epoch 682, loss function 2285.66015625\n",
      "epoch 683, loss function 2276.2578125\n",
      "epoch 684, loss function 2266.893798828125\n",
      "epoch 685, loss function 2257.568603515625\n",
      "epoch 686, loss function 2248.2822265625\n",
      "epoch 687, loss function 2239.03369140625\n",
      "epoch 688, loss function 2229.8232421875\n",
      "epoch 689, loss function 2220.65087890625\n",
      "epoch 690, loss function 2211.51611328125\n",
      "epoch 691, loss function 2202.418701171875\n",
      "epoch 692, loss function 2193.358642578125\n",
      "epoch 693, loss function 2184.33642578125\n",
      "epoch 694, loss function 2175.350830078125\n",
      "epoch 695, loss function 2166.40283203125\n",
      "epoch 696, loss function 2157.491455078125\n",
      "epoch 697, loss function 2148.61669921875\n",
      "epoch 698, loss function 2139.778564453125\n",
      "epoch 699, loss function 2130.976806640625\n",
      "epoch 700, loss function 2122.211181640625\n",
      "epoch 701, loss function 2113.481689453125\n",
      "epoch 702, loss function 2104.787841796875\n",
      "epoch 703, loss function 2096.13037109375\n",
      "epoch 704, loss function 2087.50830078125\n",
      "epoch 705, loss function 2078.921630859375\n",
      "epoch 706, loss function 2070.37060546875\n",
      "epoch 707, loss function 2061.854736328125\n",
      "epoch 708, loss function 2053.373779296875\n",
      "epoch 709, loss function 2044.927490234375\n",
      "epoch 710, loss function 2036.516357421875\n",
      "epoch 711, loss function 2028.1400146484375\n",
      "epoch 712, loss function 2019.7977294921875\n",
      "epoch 713, loss function 2011.48974609375\n",
      "epoch 714, loss function 2003.216064453125\n",
      "epoch 715, loss function 1994.97607421875\n",
      "epoch 716, loss function 1986.7708740234375\n",
      "epoch 717, loss function 1978.5992431640625\n",
      "epoch 718, loss function 1970.4609375\n",
      "epoch 719, loss function 1962.356201171875\n",
      "epoch 720, loss function 1954.2852783203125\n",
      "epoch 721, loss function 1946.247314453125\n",
      "epoch 722, loss function 1938.2425537109375\n",
      "epoch 723, loss function 1930.270263671875\n",
      "epoch 724, loss function 1922.3309326171875\n",
      "epoch 725, loss function 1914.424072265625\n",
      "epoch 726, loss function 1906.5501708984375\n",
      "epoch 727, loss function 1898.7086181640625\n",
      "epoch 728, loss function 1890.899169921875\n",
      "epoch 729, loss function 1883.1219482421875\n",
      "epoch 730, loss function 1875.376953125\n",
      "epoch 731, loss function 1867.66357421875\n",
      "epoch 732, loss function 1859.98193359375\n",
      "epoch 733, loss function 1852.33154296875\n",
      "epoch 734, loss function 1844.713134765625\n",
      "epoch 735, loss function 1837.1258544921875\n",
      "epoch 736, loss function 1829.56982421875\n",
      "epoch 737, loss function 1822.045166015625\n",
      "epoch 738, loss function 1814.5513916015625\n",
      "epoch 739, loss function 1807.0885009765625\n",
      "epoch 740, loss function 1799.656005859375\n",
      "epoch 741, loss function 1792.255126953125\n",
      "epoch 742, loss function 1784.8837890625\n",
      "epoch 743, loss function 1777.543212890625\n",
      "epoch 744, loss function 1770.232421875\n",
      "epoch 745, loss function 1762.9521484375\n",
      "epoch 746, loss function 1755.701171875\n",
      "epoch 747, loss function 1748.4801025390625\n",
      "epoch 748, loss function 1741.2890625\n",
      "epoch 749, loss function 1734.127197265625\n",
      "epoch 750, loss function 1726.9952392578125\n",
      "epoch 751, loss function 1719.892822265625\n",
      "epoch 752, loss function 1712.819091796875\n",
      "epoch 753, loss function 1705.7745361328125\n",
      "epoch 754, loss function 1698.7596435546875\n",
      "epoch 755, loss function 1691.7734375\n",
      "epoch 756, loss function 1684.81591796875\n",
      "epoch 757, loss function 1677.886962890625\n",
      "epoch 758, loss function 1670.9862060546875\n",
      "epoch 759, loss function 1664.114013671875\n",
      "epoch 760, loss function 1657.2705078125\n",
      "epoch 761, loss function 1650.4554443359375\n",
      "epoch 762, loss function 1643.6676025390625\n",
      "epoch 763, loss function 1636.908203125\n",
      "epoch 764, loss function 1630.1766357421875\n",
      "epoch 765, loss function 1623.472900390625\n",
      "epoch 766, loss function 1616.7960205078125\n",
      "epoch 767, loss function 1610.14697265625\n",
      "epoch 768, loss function 1603.5252685546875\n",
      "epoch 769, loss function 1596.9310302734375\n",
      "epoch 770, loss function 1590.3638916015625\n",
      "epoch 771, loss function 1583.82373046875\n",
      "epoch 772, loss function 1577.3099365234375\n",
      "epoch 773, loss function 1570.823486328125\n",
      "epoch 774, loss function 1564.3638916015625\n",
      "epoch 775, loss function 1557.930908203125\n",
      "epoch 776, loss function 1551.524169921875\n",
      "epoch 777, loss function 1545.1436767578125\n",
      "epoch 778, loss function 1538.789794921875\n",
      "epoch 779, loss function 1532.4615478515625\n",
      "epoch 780, loss function 1526.15966796875\n",
      "epoch 781, loss function 1519.88330078125\n",
      "epoch 782, loss function 1513.63330078125\n",
      "epoch 783, loss function 1507.40869140625\n",
      "epoch 784, loss function 1501.210205078125\n",
      "epoch 785, loss function 1495.036865234375\n",
      "epoch 786, loss function 1488.88916015625\n",
      "epoch 787, loss function 1482.7664794921875\n",
      "epoch 788, loss function 1476.6689453125\n",
      "epoch 789, loss function 1470.5966796875\n",
      "epoch 790, loss function 1464.5496826171875\n",
      "epoch 791, loss function 1458.5269775390625\n",
      "epoch 792, loss function 1452.5294189453125\n",
      "epoch 793, loss function 1446.5567626953125\n",
      "epoch 794, loss function 1440.6082763671875\n",
      "epoch 795, loss function 1434.6845703125\n",
      "epoch 796, loss function 1428.784912109375\n",
      "epoch 797, loss function 1422.9100341796875\n",
      "epoch 798, loss function 1417.0589599609375\n",
      "epoch 799, loss function 1411.2322998046875\n",
      "epoch 800, loss function 1405.429443359375\n",
      "epoch 801, loss function 1399.650390625\n",
      "epoch 802, loss function 1393.895263671875\n",
      "epoch 803, loss function 1388.16357421875\n",
      "epoch 804, loss function 1382.4556884765625\n",
      "epoch 805, loss function 1376.77099609375\n",
      "epoch 806, loss function 1371.110107421875\n",
      "epoch 807, loss function 1365.4722900390625\n",
      "epoch 808, loss function 1359.85791015625\n",
      "epoch 809, loss function 1354.26611328125\n",
      "epoch 810, loss function 1348.697509765625\n",
      "epoch 811, loss function 1343.1517333984375\n",
      "epoch 812, loss function 1337.62890625\n",
      "epoch 813, loss function 1332.1287841796875\n",
      "epoch 814, loss function 1326.651123046875\n",
      "epoch 815, loss function 1321.1961669921875\n",
      "epoch 816, loss function 1315.763916015625\n",
      "epoch 817, loss function 1310.3533935546875\n",
      "epoch 818, loss function 1304.965576171875\n",
      "epoch 819, loss function 1299.6002197265625\n",
      "epoch 820, loss function 1294.2567138671875\n",
      "epoch 821, loss function 1288.93505859375\n",
      "epoch 822, loss function 1283.635009765625\n",
      "epoch 823, loss function 1278.3572998046875\n",
      "epoch 824, loss function 1273.1014404296875\n",
      "epoch 825, loss function 1267.866943359375\n",
      "epoch 826, loss function 1262.65380859375\n",
      "epoch 827, loss function 1257.4620361328125\n",
      "epoch 828, loss function 1252.2918701171875\n",
      "epoch 829, loss function 1247.143310546875\n",
      "epoch 830, loss function 1242.015625\n",
      "epoch 831, loss function 1236.908935546875\n",
      "epoch 832, loss function 1231.823486328125\n",
      "epoch 833, loss function 1226.759033203125\n",
      "epoch 834, loss function 1221.715087890625\n",
      "epoch 835, loss function 1216.6920166015625\n",
      "epoch 836, loss function 1211.6898193359375\n",
      "epoch 837, loss function 1206.7080078125\n",
      "epoch 838, loss function 1201.746337890625\n",
      "epoch 839, loss function 1196.805419921875\n",
      "epoch 840, loss function 1191.8851318359375\n",
      "epoch 841, loss function 1186.9849853515625\n",
      "epoch 842, loss function 1182.104736328125\n",
      "epoch 843, loss function 1177.24462890625\n",
      "epoch 844, loss function 1172.40478515625\n",
      "epoch 845, loss function 1167.584716796875\n",
      "epoch 846, loss function 1162.784423828125\n",
      "epoch 847, loss function 1158.00390625\n",
      "epoch 848, loss function 1153.2431640625\n",
      "epoch 849, loss function 1148.5020751953125\n",
      "epoch 850, loss function 1143.7803955078125\n",
      "epoch 851, loss function 1139.078125\n",
      "epoch 852, loss function 1134.3955078125\n",
      "epoch 853, loss function 1129.7320556640625\n",
      "epoch 854, loss function 1125.08740234375\n",
      "epoch 855, loss function 1120.461669921875\n",
      "epoch 856, loss function 1115.855224609375\n",
      "epoch 857, loss function 1111.2679443359375\n",
      "epoch 858, loss function 1106.6995849609375\n",
      "epoch 859, loss function 1102.149658203125\n",
      "epoch 860, loss function 1097.61865234375\n",
      "epoch 861, loss function 1093.1064453125\n",
      "epoch 862, loss function 1088.6123046875\n",
      "epoch 863, loss function 1084.1368408203125\n",
      "epoch 864, loss function 1079.68017578125\n",
      "epoch 865, loss function 1075.241455078125\n",
      "epoch 866, loss function 1070.8212890625\n",
      "epoch 867, loss function 1066.4189453125\n",
      "epoch 868, loss function 1062.0350341796875\n",
      "epoch 869, loss function 1057.6688232421875\n",
      "epoch 870, loss function 1053.3209228515625\n",
      "epoch 871, loss function 1048.990478515625\n",
      "epoch 872, loss function 1044.6781005859375\n",
      "epoch 873, loss function 1040.3834228515625\n",
      "epoch 874, loss function 1036.106689453125\n",
      "epoch 875, loss function 1031.847412109375\n",
      "epoch 876, loss function 1027.60546875\n",
      "epoch 877, loss function 1023.3812255859375\n",
      "epoch 878, loss function 1019.174072265625\n",
      "epoch 879, loss function 1014.984375\n",
      "epoch 880, loss function 1010.8120727539062\n",
      "epoch 881, loss function 1006.6568603515625\n",
      "epoch 882, loss function 1002.5185546875\n",
      "epoch 883, loss function 998.3974609375\n",
      "epoch 884, loss function 994.2932739257812\n",
      "epoch 885, loss function 990.205810546875\n",
      "epoch 886, loss function 986.1351318359375\n",
      "epoch 887, loss function 982.0812377929688\n",
      "epoch 888, loss function 978.0439453125\n",
      "epoch 889, loss function 974.0235595703125\n",
      "epoch 890, loss function 970.019775390625\n",
      "epoch 891, loss function 966.0322875976562\n",
      "epoch 892, loss function 962.0613403320312\n",
      "epoch 893, loss function 958.1067504882812\n",
      "epoch 894, loss function 954.1686401367188\n",
      "epoch 895, loss function 950.24658203125\n",
      "epoch 896, loss function 946.3403930664062\n",
      "epoch 897, loss function 942.4505004882812\n",
      "epoch 898, loss function 938.5765991210938\n",
      "epoch 899, loss function 934.71875\n",
      "epoch 900, loss function 930.8764038085938\n",
      "epoch 901, loss function 927.0498046875\n",
      "epoch 902, loss function 923.2392578125\n",
      "epoch 903, loss function 919.4441528320312\n",
      "epoch 904, loss function 915.6649780273438\n",
      "epoch 905, loss function 911.9010620117188\n",
      "epoch 906, loss function 908.1527099609375\n",
      "epoch 907, loss function 904.419677734375\n",
      "epoch 908, loss function 900.7021484375\n",
      "epoch 909, loss function 896.9998779296875\n",
      "epoch 910, loss function 893.3126220703125\n",
      "epoch 911, loss function 889.6408081054688\n",
      "epoch 912, loss function 885.9843139648438\n",
      "epoch 913, loss function 882.3424682617188\n",
      "epoch 914, loss function 878.7156372070312\n",
      "epoch 915, loss function 875.1036376953125\n",
      "epoch 916, loss function 871.5067138671875\n",
      "epoch 917, loss function 867.9244384765625\n",
      "epoch 918, loss function 864.357177734375\n",
      "epoch 919, loss function 860.8045654296875\n",
      "epoch 920, loss function 857.2662353515625\n",
      "epoch 921, loss function 853.7427368164062\n",
      "epoch 922, loss function 850.2338256835938\n",
      "epoch 923, loss function 846.7394409179688\n",
      "epoch 924, loss function 843.2592163085938\n",
      "epoch 925, loss function 839.7931518554688\n",
      "epoch 926, loss function 836.3416137695312\n",
      "epoch 927, loss function 832.9039916992188\n",
      "epoch 928, loss function 829.4805908203125\n",
      "epoch 929, loss function 826.0711669921875\n",
      "epoch 930, loss function 822.676025390625\n",
      "epoch 931, loss function 819.2945556640625\n",
      "epoch 932, loss function 815.92724609375\n",
      "epoch 933, loss function 812.5738525390625\n",
      "epoch 934, loss function 809.234130859375\n",
      "epoch 935, loss function 805.9080810546875\n",
      "epoch 936, loss function 802.595947265625\n",
      "epoch 937, loss function 799.2973022460938\n",
      "epoch 938, loss function 796.011962890625\n",
      "epoch 939, loss function 792.740478515625\n",
      "epoch 940, loss function 789.482421875\n",
      "epoch 941, loss function 786.2373046875\n",
      "epoch 942, loss function 783.0057983398438\n",
      "epoch 943, loss function 779.787841796875\n",
      "epoch 944, loss function 776.5831298828125\n",
      "epoch 945, loss function 773.3916015625\n",
      "epoch 946, loss function 770.2130126953125\n",
      "epoch 947, loss function 767.047607421875\n",
      "epoch 948, loss function 763.8951416015625\n",
      "epoch 949, loss function 760.755859375\n",
      "epoch 950, loss function 757.62939453125\n",
      "epoch 951, loss function 754.5159301757812\n",
      "epoch 952, loss function 751.4148559570312\n",
      "epoch 953, loss function 748.3267211914062\n",
      "epoch 954, loss function 745.2512817382812\n",
      "epoch 955, loss function 742.1883544921875\n",
      "epoch 956, loss function 739.13818359375\n",
      "epoch 957, loss function 736.1005859375\n",
      "epoch 958, loss function 733.0755615234375\n",
      "epoch 959, loss function 730.0628662109375\n",
      "epoch 960, loss function 727.062255859375\n",
      "epoch 961, loss function 724.074462890625\n",
      "epoch 962, loss function 721.0988159179688\n",
      "epoch 963, loss function 718.13525390625\n",
      "epoch 964, loss function 715.1839599609375\n",
      "epoch 965, loss function 712.244873046875\n",
      "epoch 966, loss function 709.3177490234375\n",
      "epoch 967, loss function 706.4027709960938\n",
      "epoch 968, loss function 703.499755859375\n",
      "epoch 969, loss function 700.6085205078125\n",
      "epoch 970, loss function 697.729248046875\n",
      "epoch 971, loss function 694.86181640625\n",
      "epoch 972, loss function 692.0064697265625\n",
      "epoch 973, loss function 689.1627197265625\n",
      "epoch 974, loss function 686.330810546875\n",
      "epoch 975, loss function 683.5104370117188\n",
      "epoch 976, loss function 680.7015991210938\n",
      "epoch 977, loss function 677.9044189453125\n",
      "epoch 978, loss function 675.1187133789062\n",
      "epoch 979, loss function 672.3443603515625\n",
      "epoch 980, loss function 669.5813598632812\n",
      "epoch 981, loss function 666.8296508789062\n",
      "epoch 982, loss function 664.08935546875\n",
      "epoch 983, loss function 661.3604736328125\n",
      "epoch 984, loss function 658.642822265625\n",
      "epoch 985, loss function 655.9363403320312\n",
      "epoch 986, loss function 653.24072265625\n",
      "epoch 987, loss function 650.556396484375\n",
      "epoch 988, loss function 647.8831787109375\n",
      "epoch 989, loss function 645.2208251953125\n",
      "epoch 990, loss function 642.5692749023438\n",
      "epoch 991, loss function 639.928955078125\n",
      "epoch 992, loss function 637.2994384765625\n",
      "epoch 993, loss function 634.6805419921875\n",
      "epoch 994, loss function 632.0723876953125\n",
      "epoch 995, loss function 629.4752197265625\n",
      "epoch 996, loss function 626.8885498046875\n",
      "epoch 997, loss function 624.3126831054688\n",
      "epoch 998, loss function 621.7472534179688\n",
      "epoch 999, loss function 619.1924438476562\n",
      "epoch 1000, loss function 616.6480712890625\n",
      "epoch 1001, loss function 614.1141967773438\n",
      "epoch 1002, loss function 611.5907592773438\n",
      "epoch 1003, loss function 609.07763671875\n",
      "epoch 1004, loss function 606.5747680664062\n",
      "epoch 1005, loss function 604.08203125\n",
      "epoch 1006, loss function 601.5999145507812\n",
      "epoch 1007, loss function 599.127685546875\n",
      "epoch 1008, loss function 596.6658935546875\n",
      "epoch 1009, loss function 594.2141723632812\n",
      "epoch 1010, loss function 591.7724609375\n",
      "epoch 1011, loss function 589.3408203125\n",
      "epoch 1012, loss function 586.9192504882812\n",
      "epoch 1013, loss function 584.507568359375\n",
      "epoch 1014, loss function 582.1058959960938\n",
      "epoch 1015, loss function 579.7139892578125\n",
      "epoch 1016, loss function 577.332275390625\n",
      "epoch 1017, loss function 574.9599609375\n",
      "epoch 1018, loss function 572.5975341796875\n",
      "epoch 1019, loss function 570.2448120117188\n",
      "epoch 1020, loss function 567.9016723632812\n",
      "epoch 1021, loss function 565.5682983398438\n",
      "epoch 1022, loss function 563.2442626953125\n",
      "epoch 1023, loss function 560.929931640625\n",
      "epoch 1024, loss function 558.6251220703125\n",
      "epoch 1025, loss function 556.329833984375\n",
      "epoch 1026, loss function 554.044189453125\n",
      "epoch 1027, loss function 551.7676391601562\n",
      "epoch 1028, loss function 549.5006103515625\n",
      "epoch 1029, loss function 547.2427978515625\n",
      "epoch 1030, loss function 544.9942016601562\n",
      "epoch 1031, loss function 542.7548828125\n",
      "epoch 1032, loss function 540.5247802734375\n",
      "epoch 1033, loss function 538.303955078125\n",
      "epoch 1034, loss function 536.09228515625\n",
      "epoch 1035, loss function 533.889892578125\n",
      "epoch 1036, loss function 531.6964111328125\n",
      "epoch 1037, loss function 529.5119018554688\n",
      "epoch 1038, loss function 527.3362426757812\n",
      "epoch 1039, loss function 525.1697387695312\n",
      "epoch 1040, loss function 523.0120849609375\n",
      "epoch 1041, loss function 520.8632202148438\n",
      "epoch 1042, loss function 518.7232055664062\n",
      "epoch 1043, loss function 516.5922241210938\n",
      "epoch 1044, loss function 514.4697265625\n",
      "epoch 1045, loss function 512.35595703125\n",
      "epoch 1046, loss function 510.25103759765625\n",
      "epoch 1047, loss function 508.15447998046875\n",
      "epoch 1048, loss function 506.0669250488281\n",
      "epoch 1049, loss function 503.9876708984375\n",
      "epoch 1050, loss function 501.9170227050781\n",
      "epoch 1051, loss function 499.8551330566406\n",
      "epoch 1052, loss function 497.8015441894531\n",
      "epoch 1053, loss function 495.7565002441406\n",
      "epoch 1054, loss function 493.7196044921875\n",
      "epoch 1055, loss function 491.69134521484375\n",
      "epoch 1056, loss function 489.67132568359375\n",
      "epoch 1057, loss function 487.65972900390625\n",
      "epoch 1058, loss function 485.6561584472656\n",
      "epoch 1059, loss function 483.6609802246094\n",
      "epoch 1060, loss function 481.67401123046875\n",
      "epoch 1061, loss function 479.69525146484375\n",
      "epoch 1062, loss function 477.7243957519531\n",
      "epoch 1063, loss function 475.7618103027344\n",
      "epoch 1064, loss function 473.8070983886719\n",
      "epoch 1065, loss function 471.8606872558594\n",
      "epoch 1066, loss function 469.92230224609375\n",
      "epoch 1067, loss function 467.9917907714844\n",
      "epoch 1068, loss function 466.0692138671875\n",
      "epoch 1069, loss function 464.1545104980469\n",
      "epoch 1070, loss function 462.2477722167969\n",
      "epoch 1071, loss function 460.34893798828125\n",
      "epoch 1072, loss function 458.45770263671875\n",
      "epoch 1073, loss function 456.5743103027344\n",
      "epoch 1074, loss function 454.6986389160156\n",
      "epoch 1075, loss function 452.8306884765625\n",
      "epoch 1076, loss function 450.9706726074219\n",
      "epoch 1077, loss function 449.1181640625\n",
      "epoch 1078, loss function 447.2732238769531\n",
      "epoch 1079, loss function 445.43597412109375\n",
      "epoch 1080, loss function 443.606201171875\n",
      "epoch 1081, loss function 441.78387451171875\n",
      "epoch 1082, loss function 439.9689025878906\n",
      "epoch 1083, loss function 438.1615295410156\n",
      "epoch 1084, loss function 436.3616027832031\n",
      "epoch 1085, loss function 434.5690612792969\n",
      "epoch 1086, loss function 432.7840576171875\n",
      "epoch 1087, loss function 431.00628662109375\n",
      "epoch 1088, loss function 429.23583984375\n",
      "epoch 1089, loss function 427.4725341796875\n",
      "epoch 1090, loss function 425.716552734375\n",
      "epoch 1091, loss function 423.9678039550781\n",
      "epoch 1092, loss function 422.22607421875\n",
      "epoch 1093, loss function 420.4916076660156\n",
      "epoch 1094, loss function 418.7644348144531\n",
      "epoch 1095, loss function 417.0444030761719\n",
      "epoch 1096, loss function 415.3311767578125\n",
      "epoch 1097, loss function 413.62506103515625\n",
      "epoch 1098, loss function 411.9261169433594\n",
      "epoch 1099, loss function 410.2340393066406\n",
      "epoch 1100, loss function 408.5488586425781\n",
      "epoch 1101, loss function 406.87066650390625\n",
      "epoch 1102, loss function 405.19927978515625\n",
      "epoch 1103, loss function 403.534912109375\n",
      "epoch 1104, loss function 401.8772277832031\n",
      "epoch 1105, loss function 400.2265625\n",
      "epoch 1106, loss function 398.5823974609375\n",
      "epoch 1107, loss function 396.9451904296875\n",
      "epoch 1108, loss function 395.3146667480469\n",
      "epoch 1109, loss function 393.69085693359375\n",
      "epoch 1110, loss function 392.07373046875\n",
      "epoch 1111, loss function 390.46319580078125\n",
      "epoch 1112, loss function 388.859375\n",
      "epoch 1113, loss function 387.2620849609375\n",
      "epoch 1114, loss function 385.6712951660156\n",
      "epoch 1115, loss function 384.0871276855469\n",
      "epoch 1116, loss function 382.5095520019531\n",
      "epoch 1117, loss function 380.93841552734375\n",
      "epoch 1118, loss function 379.3737487792969\n",
      "epoch 1119, loss function 377.8153991699219\n",
      "epoch 1120, loss function 376.263671875\n",
      "epoch 1121, loss function 374.7181701660156\n",
      "epoch 1122, loss function 373.1790771484375\n",
      "epoch 1123, loss function 371.64642333984375\n",
      "epoch 1124, loss function 370.11993408203125\n",
      "epoch 1125, loss function 368.59979248046875\n",
      "epoch 1126, loss function 367.08587646484375\n",
      "epoch 1127, loss function 365.578125\n",
      "epoch 1128, loss function 364.0765075683594\n",
      "epoch 1129, loss function 362.5810852050781\n",
      "epoch 1130, loss function 361.0919189453125\n",
      "epoch 1131, loss function 359.6088562011719\n",
      "epoch 1132, loss function 358.1317138671875\n",
      "epoch 1133, loss function 356.6607360839844\n",
      "epoch 1134, loss function 355.1960144042969\n",
      "epoch 1135, loss function 353.7371520996094\n",
      "epoch 1136, loss function 352.28436279296875\n",
      "epoch 1137, loss function 350.83740234375\n",
      "epoch 1138, loss function 349.396240234375\n",
      "epoch 1139, loss function 347.9613037109375\n",
      "epoch 1140, loss function 346.5321350097656\n",
      "epoch 1141, loss function 345.1090087890625\n",
      "epoch 1142, loss function 343.691650390625\n",
      "epoch 1143, loss function 342.2801513671875\n",
      "epoch 1144, loss function 340.8743896484375\n",
      "epoch 1145, loss function 339.47442626953125\n",
      "epoch 1146, loss function 338.0802001953125\n",
      "epoch 1147, loss function 336.6916809082031\n",
      "epoch 1148, loss function 335.308837890625\n",
      "epoch 1149, loss function 333.9317932128906\n",
      "epoch 1150, loss function 332.560302734375\n",
      "epoch 1151, loss function 331.194580078125\n",
      "epoch 1152, loss function 329.83428955078125\n",
      "epoch 1153, loss function 328.4797668457031\n",
      "epoch 1154, loss function 327.1305236816406\n",
      "epoch 1155, loss function 325.78704833984375\n",
      "epoch 1156, loss function 324.448974609375\n",
      "epoch 1157, loss function 323.11651611328125\n",
      "epoch 1158, loss function 321.7895202636719\n",
      "epoch 1159, loss function 320.4681091308594\n",
      "epoch 1160, loss function 319.1520690917969\n",
      "epoch 1161, loss function 317.8414306640625\n",
      "epoch 1162, loss function 316.5359191894531\n",
      "epoch 1163, loss function 315.2359924316406\n",
      "epoch 1164, loss function 313.94140625\n",
      "epoch 1165, loss function 312.6520690917969\n",
      "epoch 1166, loss function 311.3680725097656\n",
      "epoch 1167, loss function 310.0894470214844\n",
      "epoch 1168, loss function 308.8160705566406\n",
      "epoch 1169, loss function 307.5477294921875\n",
      "epoch 1170, loss function 306.28472900390625\n",
      "epoch 1171, loss function 305.0270080566406\n",
      "epoch 1172, loss function 303.77423095703125\n",
      "epoch 1173, loss function 302.5267639160156\n",
      "epoch 1174, loss function 301.28436279296875\n",
      "epoch 1175, loss function 300.04705810546875\n",
      "epoch 1176, loss function 298.8149108886719\n",
      "epoch 1177, loss function 297.587646484375\n",
      "epoch 1178, loss function 296.36572265625\n",
      "epoch 1179, loss function 295.1485595703125\n",
      "epoch 1180, loss function 293.93646240234375\n",
      "epoch 1181, loss function 292.7294006347656\n",
      "epoch 1182, loss function 291.52728271484375\n",
      "epoch 1183, loss function 290.33001708984375\n",
      "epoch 1184, loss function 289.1379089355469\n",
      "epoch 1185, loss function 287.95037841796875\n",
      "epoch 1186, loss function 286.7680358886719\n",
      "epoch 1187, loss function 285.59033203125\n",
      "epoch 1188, loss function 284.4176025390625\n",
      "epoch 1189, loss function 283.2495422363281\n",
      "epoch 1190, loss function 282.0865478515625\n",
      "epoch 1191, loss function 280.9282531738281\n",
      "epoch 1192, loss function 279.7745361328125\n",
      "epoch 1193, loss function 278.6258239746094\n",
      "epoch 1194, loss function 277.4816589355469\n",
      "epoch 1195, loss function 276.3421936035156\n",
      "epoch 1196, loss function 275.2074890136719\n",
      "epoch 1197, loss function 274.0774841308594\n",
      "epoch 1198, loss function 272.9520263671875\n",
      "epoch 1199, loss function 271.8311462402344\n",
      "epoch 1200, loss function 270.71502685546875\n",
      "epoch 1201, loss function 269.6032409667969\n",
      "epoch 1202, loss function 268.49615478515625\n",
      "epoch 1203, loss function 267.39373779296875\n",
      "epoch 1204, loss function 266.295654296875\n",
      "epoch 1205, loss function 265.20220947265625\n",
      "epoch 1206, loss function 264.11309814453125\n",
      "epoch 1207, loss function 263.0285949707031\n",
      "epoch 1208, loss function 261.9486389160156\n",
      "epoch 1209, loss function 260.8729553222656\n",
      "epoch 1210, loss function 259.8018798828125\n",
      "epoch 1211, loss function 258.735107421875\n",
      "epoch 1212, loss function 257.672607421875\n",
      "epoch 1213, loss function 256.6146240234375\n",
      "epoch 1214, loss function 255.56097412109375\n",
      "epoch 1215, loss function 254.51148986816406\n",
      "epoch 1216, loss function 253.46652221679688\n",
      "epoch 1217, loss function 252.42587280273438\n",
      "epoch 1218, loss function 251.3894805908203\n",
      "epoch 1219, loss function 250.3572998046875\n",
      "epoch 1220, loss function 249.32933044433594\n",
      "epoch 1221, loss function 248.30572509765625\n",
      "epoch 1222, loss function 247.28628540039062\n",
      "epoch 1223, loss function 246.2710418701172\n",
      "epoch 1224, loss function 245.25991821289062\n",
      "epoch 1225, loss function 244.25289916992188\n",
      "epoch 1226, loss function 243.25001525878906\n",
      "epoch 1227, loss function 242.2512664794922\n",
      "epoch 1228, loss function 241.25657653808594\n",
      "epoch 1229, loss function 240.2659454345703\n",
      "epoch 1230, loss function 239.27944946289062\n",
      "epoch 1231, loss function 238.29698181152344\n",
      "epoch 1232, loss function 237.31854248046875\n",
      "epoch 1233, loss function 236.34422302246094\n",
      "epoch 1234, loss function 235.37384033203125\n",
      "epoch 1235, loss function 234.4073028564453\n",
      "epoch 1236, loss function 233.44479370117188\n",
      "epoch 1237, loss function 232.48635864257812\n",
      "epoch 1238, loss function 231.53187561035156\n",
      "epoch 1239, loss function 230.58143615722656\n",
      "epoch 1240, loss function 229.63467407226562\n",
      "epoch 1241, loss function 228.69189453125\n",
      "epoch 1242, loss function 227.75302124023438\n",
      "epoch 1243, loss function 226.81802368164062\n",
      "epoch 1244, loss function 225.88681030273438\n",
      "epoch 1245, loss function 224.95941162109375\n",
      "epoch 1246, loss function 224.03590393066406\n",
      "epoch 1247, loss function 223.1161346435547\n",
      "epoch 1248, loss function 222.20005798339844\n",
      "epoch 1249, loss function 221.2877197265625\n",
      "epoch 1250, loss function 220.3792724609375\n",
      "epoch 1251, loss function 219.4744415283203\n",
      "epoch 1252, loss function 218.57339477539062\n",
      "epoch 1253, loss function 217.67605590820312\n",
      "epoch 1254, loss function 216.78237915039062\n",
      "epoch 1255, loss function 215.89247131347656\n",
      "epoch 1256, loss function 215.00621032714844\n",
      "epoch 1257, loss function 214.1234588623047\n",
      "epoch 1258, loss function 213.24429321289062\n",
      "epoch 1259, loss function 212.36880493164062\n",
      "epoch 1260, loss function 211.4968719482422\n",
      "epoch 1261, loss function 210.628662109375\n",
      "epoch 1262, loss function 209.76394653320312\n",
      "epoch 1263, loss function 208.90274047851562\n",
      "epoch 1264, loss function 208.04501342773438\n",
      "epoch 1265, loss function 207.19088745117188\n",
      "epoch 1266, loss function 206.34034729003906\n",
      "epoch 1267, loss function 205.49325561523438\n",
      "epoch 1268, loss function 204.6495361328125\n",
      "epoch 1269, loss function 203.80947875976562\n",
      "epoch 1270, loss function 202.9727783203125\n",
      "epoch 1271, loss function 202.13954162597656\n",
      "epoch 1272, loss function 201.30967712402344\n",
      "epoch 1273, loss function 200.48326110839844\n",
      "epoch 1274, loss function 199.66017150878906\n",
      "epoch 1275, loss function 198.84051513671875\n",
      "epoch 1276, loss function 198.02413940429688\n",
      "epoch 1277, loss function 197.211181640625\n",
      "epoch 1278, loss function 196.40155029296875\n",
      "epoch 1279, loss function 195.5952911376953\n",
      "epoch 1280, loss function 194.79225158691406\n",
      "epoch 1281, loss function 193.99261474609375\n",
      "epoch 1282, loss function 193.19622802734375\n",
      "epoch 1283, loss function 192.40313720703125\n",
      "epoch 1284, loss function 191.6133270263672\n",
      "epoch 1285, loss function 190.82669067382812\n",
      "epoch 1286, loss function 190.04327392578125\n",
      "epoch 1287, loss function 189.26329040527344\n",
      "epoch 1288, loss function 188.4862823486328\n",
      "epoch 1289, loss function 187.71255493164062\n",
      "epoch 1290, loss function 186.94192504882812\n",
      "epoch 1291, loss function 186.17465209960938\n",
      "epoch 1292, loss function 185.41041564941406\n",
      "epoch 1293, loss function 184.64935302734375\n",
      "epoch 1294, loss function 183.89132690429688\n",
      "epoch 1295, loss function 183.13648986816406\n",
      "epoch 1296, loss function 182.38461303710938\n",
      "epoch 1297, loss function 181.63592529296875\n",
      "epoch 1298, loss function 180.89036560058594\n",
      "epoch 1299, loss function 180.14788818359375\n",
      "epoch 1300, loss function 179.40843200683594\n",
      "epoch 1301, loss function 178.67208862304688\n",
      "epoch 1302, loss function 177.93865966796875\n",
      "epoch 1303, loss function 177.20819091796875\n",
      "epoch 1304, loss function 176.4807891845703\n",
      "epoch 1305, loss function 175.75631713867188\n",
      "epoch 1306, loss function 175.034912109375\n",
      "epoch 1307, loss function 174.31640625\n",
      "epoch 1308, loss function 173.60081481933594\n",
      "epoch 1309, loss function 172.88818359375\n",
      "epoch 1310, loss function 172.17849731445312\n",
      "epoch 1311, loss function 171.4718017578125\n",
      "epoch 1312, loss function 170.76797485351562\n",
      "epoch 1313, loss function 170.0669708251953\n",
      "epoch 1314, loss function 169.36898803710938\n",
      "epoch 1315, loss function 168.67376708984375\n",
      "epoch 1316, loss function 167.98143005371094\n",
      "epoch 1317, loss function 167.2919921875\n",
      "epoch 1318, loss function 166.60537719726562\n",
      "epoch 1319, loss function 165.92160034179688\n",
      "epoch 1320, loss function 165.2406005859375\n",
      "epoch 1321, loss function 164.5623779296875\n",
      "epoch 1322, loss function 163.8868865966797\n",
      "epoch 1323, loss function 163.2141571044922\n",
      "epoch 1324, loss function 162.5441436767578\n",
      "epoch 1325, loss function 161.87710571289062\n",
      "epoch 1326, loss function 161.21270751953125\n",
      "epoch 1327, loss function 160.55099487304688\n",
      "epoch 1328, loss function 159.89190673828125\n",
      "epoch 1329, loss function 159.23561096191406\n",
      "epoch 1330, loss function 158.58209228515625\n",
      "epoch 1331, loss function 157.93121337890625\n",
      "epoch 1332, loss function 157.28298950195312\n",
      "epoch 1333, loss function 156.63739013671875\n",
      "epoch 1334, loss function 155.99444580078125\n",
      "epoch 1335, loss function 155.3542938232422\n",
      "epoch 1336, loss function 154.7166748046875\n",
      "epoch 1337, loss function 154.0816650390625\n",
      "epoch 1338, loss function 153.4492950439453\n",
      "epoch 1339, loss function 152.81951904296875\n",
      "epoch 1340, loss function 152.19229125976562\n",
      "epoch 1341, loss function 151.56765747070312\n",
      "epoch 1342, loss function 150.945556640625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1343, loss function 150.32594299316406\n",
      "epoch 1344, loss function 149.70904541015625\n",
      "epoch 1345, loss function 149.09471130371094\n",
      "epoch 1346, loss function 148.48280334472656\n",
      "epoch 1347, loss function 147.87347412109375\n",
      "epoch 1348, loss function 147.26658630371094\n",
      "epoch 1349, loss function 146.6621856689453\n",
      "epoch 1350, loss function 146.06028747558594\n",
      "epoch 1351, loss function 145.46084594726562\n",
      "epoch 1352, loss function 144.86395263671875\n",
      "epoch 1353, loss function 144.2693634033203\n",
      "epoch 1354, loss function 143.6772918701172\n",
      "epoch 1355, loss function 143.08761596679688\n",
      "epoch 1356, loss function 142.50039672851562\n",
      "epoch 1357, loss function 141.91554260253906\n",
      "epoch 1358, loss function 141.3331298828125\n",
      "epoch 1359, loss function 140.75315856933594\n",
      "epoch 1360, loss function 140.1755828857422\n",
      "epoch 1361, loss function 139.60037231445312\n",
      "epoch 1362, loss function 139.02749633789062\n",
      "epoch 1363, loss function 138.45697021484375\n",
      "epoch 1364, loss function 137.88868713378906\n",
      "epoch 1365, loss function 137.3227081298828\n",
      "epoch 1366, loss function 136.7591552734375\n",
      "epoch 1367, loss function 136.1978759765625\n",
      "epoch 1368, loss function 135.63894653320312\n",
      "epoch 1369, loss function 135.08233642578125\n",
      "epoch 1370, loss function 134.52804565429688\n",
      "epoch 1371, loss function 133.97605895996094\n",
      "epoch 1372, loss function 133.42611694335938\n",
      "epoch 1373, loss function 132.87857055664062\n",
      "epoch 1374, loss function 132.333251953125\n",
      "epoch 1375, loss function 131.79010009765625\n",
      "epoch 1376, loss function 131.24928283691406\n",
      "epoch 1377, loss function 130.71072387695312\n",
      "epoch 1378, loss function 130.17422485351562\n",
      "epoch 1379, loss function 129.63999938964844\n",
      "epoch 1380, loss function 129.1079864501953\n",
      "epoch 1381, loss function 128.57814025878906\n",
      "epoch 1382, loss function 128.05056762695312\n",
      "epoch 1383, loss function 127.52508544921875\n",
      "epoch 1384, loss function 127.00167846679688\n",
      "epoch 1385, loss function 126.48053741455078\n",
      "epoch 1386, loss function 125.9615707397461\n",
      "epoch 1387, loss function 125.44464111328125\n",
      "epoch 1388, loss function 124.9298095703125\n",
      "epoch 1389, loss function 124.41720581054688\n",
      "epoch 1390, loss function 123.90672302246094\n",
      "epoch 1391, loss function 123.39823150634766\n",
      "epoch 1392, loss function 122.891845703125\n",
      "epoch 1393, loss function 122.38755798339844\n",
      "epoch 1394, loss function 121.88532257080078\n",
      "epoch 1395, loss function 121.38520812988281\n",
      "epoch 1396, loss function 120.88711547851562\n",
      "epoch 1397, loss function 120.3909912109375\n",
      "epoch 1398, loss function 119.89694213867188\n",
      "epoch 1399, loss function 119.4049072265625\n",
      "epoch 1400, loss function 118.9149398803711\n",
      "epoch 1401, loss function 118.427001953125\n",
      "epoch 1402, loss function 117.94110870361328\n",
      "epoch 1403, loss function 117.4571533203125\n",
      "epoch 1404, loss function 116.97515869140625\n",
      "epoch 1405, loss function 116.49517822265625\n",
      "epoch 1406, loss function 116.01716613769531\n",
      "epoch 1407, loss function 115.54105377197266\n",
      "epoch 1408, loss function 115.06687927246094\n",
      "epoch 1409, loss function 114.59469604492188\n",
      "epoch 1410, loss function 114.12456512451172\n",
      "epoch 1411, loss function 113.65631103515625\n",
      "epoch 1412, loss function 113.19004821777344\n",
      "epoch 1413, loss function 112.72563171386719\n",
      "epoch 1414, loss function 112.26313781738281\n",
      "epoch 1415, loss function 111.80250549316406\n",
      "epoch 1416, loss function 111.34381103515625\n",
      "epoch 1417, loss function 110.88697052001953\n",
      "epoch 1418, loss function 110.43204498291016\n",
      "epoch 1419, loss function 109.97891235351562\n",
      "epoch 1420, loss function 109.5276870727539\n",
      "epoch 1421, loss function 109.07832336425781\n",
      "epoch 1422, loss function 108.63081359863281\n",
      "epoch 1423, loss function 108.18500518798828\n",
      "epoch 1424, loss function 107.74108123779297\n",
      "epoch 1425, loss function 107.29895782470703\n",
      "epoch 1426, loss function 106.85868072509766\n",
      "epoch 1427, loss function 106.42019653320312\n",
      "epoch 1428, loss function 105.98355865478516\n",
      "epoch 1429, loss function 105.54871368408203\n",
      "epoch 1430, loss function 105.1156997680664\n",
      "epoch 1431, loss function 104.68441009521484\n",
      "epoch 1432, loss function 104.25489044189453\n",
      "epoch 1433, loss function 103.82720947265625\n",
      "epoch 1434, loss function 103.40115356445312\n",
      "epoch 1435, loss function 102.97694396972656\n",
      "epoch 1436, loss function 102.55439758300781\n",
      "epoch 1437, loss function 102.13362884521484\n",
      "epoch 1438, loss function 101.71460723876953\n",
      "epoch 1439, loss function 101.29735565185547\n",
      "epoch 1440, loss function 100.88176727294922\n",
      "epoch 1441, loss function 100.46786499023438\n",
      "epoch 1442, loss function 100.05561828613281\n",
      "epoch 1443, loss function 99.64514923095703\n",
      "epoch 1444, loss function 99.23643493652344\n",
      "epoch 1445, loss function 98.82921600341797\n",
      "epoch 1446, loss function 98.42376708984375\n",
      "epoch 1447, loss function 98.01997375488281\n",
      "epoch 1448, loss function 97.61785888671875\n",
      "epoch 1449, loss function 97.21739196777344\n",
      "epoch 1450, loss function 96.81851196289062\n",
      "epoch 1451, loss function 96.42132568359375\n",
      "epoch 1452, loss function 96.02568054199219\n",
      "epoch 1453, loss function 95.63172912597656\n",
      "epoch 1454, loss function 95.23937225341797\n",
      "epoch 1455, loss function 94.84869384765625\n",
      "epoch 1456, loss function 94.45954132080078\n",
      "epoch 1457, loss function 94.07203674316406\n",
      "epoch 1458, loss function 93.68612670898438\n",
      "epoch 1459, loss function 93.30169677734375\n",
      "epoch 1460, loss function 92.91891479492188\n",
      "epoch 1461, loss function 92.53775787353516\n",
      "epoch 1462, loss function 92.15811157226562\n",
      "epoch 1463, loss function 91.78005981445312\n",
      "epoch 1464, loss function 91.4034423828125\n",
      "epoch 1465, loss function 91.02853393554688\n",
      "epoch 1466, loss function 90.6551513671875\n",
      "epoch 1467, loss function 90.28324890136719\n",
      "epoch 1468, loss function 89.912841796875\n",
      "epoch 1469, loss function 89.54389190673828\n",
      "epoch 1470, loss function 89.17656707763672\n",
      "epoch 1471, loss function 88.81080627441406\n",
      "epoch 1472, loss function 88.44644165039062\n",
      "epoch 1473, loss function 88.08360290527344\n",
      "epoch 1474, loss function 87.72223663330078\n",
      "epoch 1475, loss function 87.3623046875\n",
      "epoch 1476, loss function 87.00386047363281\n",
      "epoch 1477, loss function 86.64701843261719\n",
      "epoch 1478, loss function 86.29153442382812\n",
      "epoch 1479, loss function 85.93756103515625\n",
      "epoch 1480, loss function 85.58499908447266\n",
      "epoch 1481, loss function 85.2339096069336\n",
      "epoch 1482, loss function 84.88420104980469\n",
      "epoch 1483, loss function 84.53598022460938\n",
      "epoch 1484, loss function 84.18912506103516\n",
      "epoch 1485, loss function 83.84375\n",
      "epoch 1486, loss function 83.49974060058594\n",
      "epoch 1487, loss function 83.15718841552734\n",
      "epoch 1488, loss function 82.81603240966797\n",
      "epoch 1489, loss function 82.47640991210938\n",
      "epoch 1490, loss function 82.13806915283203\n",
      "epoch 1491, loss function 81.80120849609375\n",
      "epoch 1492, loss function 81.46571350097656\n",
      "epoch 1493, loss function 81.13147735595703\n",
      "epoch 1494, loss function 80.79871368408203\n",
      "epoch 1495, loss function 80.46727752685547\n",
      "epoch 1496, loss function 80.13724517822266\n",
      "epoch 1497, loss function 79.80854034423828\n",
      "epoch 1498, loss function 79.48113250732422\n",
      "epoch 1499, loss function 79.15515899658203\n",
      "epoch 1500, loss function 78.83049011230469\n",
      "epoch 1501, loss function 78.50706481933594\n",
      "epoch 1502, loss function 78.1850814819336\n",
      "epoch 1503, loss function 77.86441040039062\n",
      "epoch 1504, loss function 77.5450439453125\n",
      "epoch 1505, loss function 77.22703552246094\n",
      "epoch 1506, loss function 76.91028594970703\n",
      "epoch 1507, loss function 76.59478759765625\n",
      "epoch 1508, loss function 76.28059387207031\n",
      "epoch 1509, loss function 75.96768188476562\n",
      "epoch 1510, loss function 75.65599060058594\n",
      "epoch 1511, loss function 75.34567260742188\n",
      "epoch 1512, loss function 75.03660583496094\n",
      "epoch 1513, loss function 74.72877502441406\n",
      "epoch 1514, loss function 74.42229461669922\n",
      "epoch 1515, loss function 74.11707305908203\n",
      "epoch 1516, loss function 73.81309509277344\n",
      "epoch 1517, loss function 73.51036071777344\n",
      "epoch 1518, loss function 73.20890808105469\n",
      "epoch 1519, loss function 72.9085922241211\n",
      "epoch 1520, loss function 72.6095199584961\n",
      "epoch 1521, loss function 72.31167602539062\n",
      "epoch 1522, loss function 72.01502990722656\n",
      "epoch 1523, loss function 71.71971130371094\n",
      "epoch 1524, loss function 71.4255599975586\n",
      "epoch 1525, loss function 71.13262939453125\n",
      "epoch 1526, loss function 70.84080505371094\n",
      "epoch 1527, loss function 70.55020904541016\n",
      "epoch 1528, loss function 70.26085662841797\n",
      "epoch 1529, loss function 69.97270202636719\n",
      "epoch 1530, loss function 69.68572998046875\n",
      "epoch 1531, loss function 69.39994812011719\n",
      "epoch 1532, loss function 69.11524963378906\n",
      "epoch 1533, loss function 68.83175659179688\n",
      "epoch 1534, loss function 68.54939270019531\n",
      "epoch 1535, loss function 68.26831817626953\n",
      "epoch 1536, loss function 67.98827362060547\n",
      "epoch 1537, loss function 67.7094497680664\n",
      "epoch 1538, loss function 67.4317398071289\n",
      "epoch 1539, loss function 67.15515899658203\n",
      "epoch 1540, loss function 66.8797836303711\n",
      "epoch 1541, loss function 66.60543823242188\n",
      "epoch 1542, loss function 66.33221435546875\n",
      "epoch 1543, loss function 66.06015014648438\n",
      "epoch 1544, loss function 65.7891845703125\n",
      "epoch 1545, loss function 65.5194091796875\n",
      "epoch 1546, loss function 65.2507095336914\n",
      "epoch 1547, loss function 64.98319244384766\n",
      "epoch 1548, loss function 64.71663665771484\n",
      "epoch 1549, loss function 64.45124053955078\n",
      "epoch 1550, loss function 64.18693542480469\n",
      "epoch 1551, loss function 63.923744201660156\n",
      "epoch 1552, loss function 63.661590576171875\n",
      "epoch 1553, loss function 63.40052795410156\n",
      "epoch 1554, loss function 63.14055252075195\n",
      "epoch 1555, loss function 62.8816032409668\n",
      "epoch 1556, loss function 62.62372970581055\n",
      "epoch 1557, loss function 62.366943359375\n",
      "epoch 1558, loss function 62.11114501953125\n",
      "epoch 1559, loss function 61.85643768310547\n",
      "epoch 1560, loss function 61.60281753540039\n",
      "epoch 1561, loss function 61.350196838378906\n",
      "epoch 1562, loss function 61.0986213684082\n",
      "epoch 1563, loss function 60.848052978515625\n",
      "epoch 1564, loss function 60.59853744506836\n",
      "epoch 1565, loss function 60.35002517700195\n",
      "epoch 1566, loss function 60.10244369506836\n",
      "epoch 1567, loss function 59.85593795776367\n",
      "epoch 1568, loss function 59.610450744628906\n",
      "epoch 1569, loss function 59.36598205566406\n",
      "epoch 1570, loss function 59.122528076171875\n",
      "epoch 1571, loss function 58.880027770996094\n",
      "epoch 1572, loss function 58.63856506347656\n",
      "epoch 1573, loss function 58.398155212402344\n",
      "epoch 1574, loss function 58.15869140625\n",
      "epoch 1575, loss function 57.92024230957031\n",
      "epoch 1576, loss function 57.682674407958984\n",
      "epoch 1577, loss function 57.44610595703125\n",
      "epoch 1578, loss function 57.21045684814453\n",
      "epoch 1579, loss function 56.975852966308594\n",
      "epoch 1580, loss function 56.74216079711914\n",
      "epoch 1581, loss function 56.5095100402832\n",
      "epoch 1582, loss function 56.27785110473633\n",
      "epoch 1583, loss function 56.04703903198242\n",
      "epoch 1584, loss function 55.81718444824219\n",
      "epoch 1585, loss function 55.58828353881836\n",
      "epoch 1586, loss function 55.36037826538086\n",
      "epoch 1587, loss function 55.13335418701172\n",
      "epoch 1588, loss function 54.90724563598633\n",
      "epoch 1589, loss function 54.68207550048828\n",
      "epoch 1590, loss function 54.45783615112305\n",
      "epoch 1591, loss function 54.234519958496094\n",
      "epoch 1592, loss function 54.012149810791016\n",
      "epoch 1593, loss function 53.79063415527344\n",
      "epoch 1594, loss function 53.570091247558594\n",
      "epoch 1595, loss function 53.35041809082031\n",
      "epoch 1596, loss function 53.13170623779297\n",
      "epoch 1597, loss function 52.913841247558594\n",
      "epoch 1598, loss function 52.69681930541992\n",
      "epoch 1599, loss function 52.48073959350586\n",
      "epoch 1600, loss function 52.26555633544922\n",
      "epoch 1601, loss function 52.05122375488281\n",
      "epoch 1602, loss function 51.83775329589844\n",
      "epoch 1603, loss function 51.6252326965332\n",
      "epoch 1604, loss function 51.413578033447266\n",
      "epoch 1605, loss function 51.20280456542969\n",
      "epoch 1606, loss function 50.99286651611328\n",
      "epoch 1607, loss function 50.78374481201172\n",
      "epoch 1608, loss function 50.575496673583984\n",
      "epoch 1609, loss function 50.36809158325195\n",
      "epoch 1610, loss function 50.161624908447266\n",
      "epoch 1611, loss function 49.95591354370117\n",
      "epoch 1612, loss function 49.75102233886719\n",
      "epoch 1613, loss function 49.547080993652344\n",
      "epoch 1614, loss function 49.343868255615234\n",
      "epoch 1615, loss function 49.141597747802734\n",
      "epoch 1616, loss function 48.94014358520508\n",
      "epoch 1617, loss function 48.739418029785156\n",
      "epoch 1618, loss function 48.53963088989258\n",
      "epoch 1619, loss function 48.34062194824219\n",
      "epoch 1620, loss function 48.14237976074219\n",
      "epoch 1621, loss function 47.94501876831055\n",
      "epoch 1622, loss function 47.748416900634766\n",
      "epoch 1623, loss function 47.55261993408203\n",
      "epoch 1624, loss function 47.35770034790039\n",
      "epoch 1625, loss function 47.16351318359375\n",
      "epoch 1626, loss function 46.97013854980469\n",
      "epoch 1627, loss function 46.77751922607422\n",
      "epoch 1628, loss function 46.585723876953125\n",
      "epoch 1629, loss function 46.39469909667969\n",
      "epoch 1630, loss function 46.20448303222656\n",
      "epoch 1631, loss function 46.01506805419922\n",
      "epoch 1632, loss function 45.82637023925781\n",
      "epoch 1633, loss function 45.63847732543945\n",
      "epoch 1634, loss function 45.45132827758789\n",
      "epoch 1635, loss function 45.26498794555664\n",
      "epoch 1636, loss function 45.079368591308594\n",
      "epoch 1637, loss function 44.89455032348633\n",
      "epoch 1638, loss function 44.71048355102539\n",
      "epoch 1639, loss function 44.52716827392578\n",
      "epoch 1640, loss function 44.344539642333984\n",
      "epoch 1641, loss function 44.16273498535156\n",
      "epoch 1642, loss function 43.98163604736328\n",
      "epoch 1643, loss function 43.80134201049805\n",
      "epoch 1644, loss function 43.6216926574707\n",
      "epoch 1645, loss function 43.44286346435547\n",
      "epoch 1646, loss function 43.26473617553711\n",
      "epoch 1647, loss function 43.08734893798828\n",
      "epoch 1648, loss function 42.91066360473633\n",
      "epoch 1649, loss function 42.73477554321289\n",
      "epoch 1650, loss function 42.55953598022461\n",
      "epoch 1651, loss function 42.38507080078125\n",
      "epoch 1652, loss function 42.21128463745117\n",
      "epoch 1653, loss function 42.038230895996094\n",
      "epoch 1654, loss function 41.86588668823242\n",
      "epoch 1655, loss function 41.69429397583008\n",
      "epoch 1656, loss function 41.52336120605469\n",
      "epoch 1657, loss function 41.353084564208984\n",
      "epoch 1658, loss function 41.18354034423828\n",
      "epoch 1659, loss function 41.01466369628906\n",
      "epoch 1660, loss function 40.84654235839844\n",
      "epoch 1661, loss function 40.679080963134766\n",
      "epoch 1662, loss function 40.51227569580078\n",
      "epoch 1663, loss function 40.34620666503906\n",
      "epoch 1664, loss function 40.18076705932617\n",
      "epoch 1665, loss function 40.015995025634766\n",
      "epoch 1666, loss function 39.85198211669922\n",
      "epoch 1667, loss function 39.68859100341797\n",
      "epoch 1668, loss function 39.52591323852539\n",
      "epoch 1669, loss function 39.363853454589844\n",
      "epoch 1670, loss function 39.20250701904297\n",
      "epoch 1671, loss function 39.04177474975586\n",
      "epoch 1672, loss function 38.881690979003906\n",
      "epoch 1673, loss function 38.72234344482422\n",
      "epoch 1674, loss function 38.56363296508789\n",
      "epoch 1675, loss function 38.405540466308594\n",
      "epoch 1676, loss function 38.24813461303711\n",
      "epoch 1677, loss function 38.091339111328125\n",
      "epoch 1678, loss function 37.93516540527344\n",
      "epoch 1679, loss function 37.7796745300293\n",
      "epoch 1680, loss function 37.62479782104492\n",
      "epoch 1681, loss function 37.47051239013672\n",
      "epoch 1682, loss function 37.31692123413086\n",
      "epoch 1683, loss function 37.16392517089844\n",
      "epoch 1684, loss function 37.0116081237793\n",
      "epoch 1685, loss function 36.85986328125\n",
      "epoch 1686, loss function 36.70881652832031\n",
      "epoch 1687, loss function 36.5583381652832\n",
      "epoch 1688, loss function 36.40848922729492\n",
      "epoch 1689, loss function 36.25926971435547\n",
      "epoch 1690, loss function 36.110660552978516\n",
      "epoch 1691, loss function 35.96262741088867\n",
      "epoch 1692, loss function 35.81521224975586\n",
      "epoch 1693, loss function 35.66840744018555\n",
      "epoch 1694, loss function 35.522216796875\n",
      "epoch 1695, loss function 35.3765869140625\n",
      "epoch 1696, loss function 35.2315559387207\n",
      "epoch 1697, loss function 35.087154388427734\n",
      "epoch 1698, loss function 34.94334411621094\n",
      "epoch 1699, loss function 34.80009460449219\n",
      "epoch 1700, loss function 34.65742492675781\n",
      "epoch 1701, loss function 34.51532745361328\n",
      "epoch 1702, loss function 34.373870849609375\n",
      "epoch 1703, loss function 34.23295974731445\n",
      "epoch 1704, loss function 34.09264373779297\n",
      "epoch 1705, loss function 33.95286178588867\n",
      "epoch 1706, loss function 33.81366729736328\n",
      "epoch 1707, loss function 33.67509078979492\n",
      "epoch 1708, loss function 33.53705978393555\n",
      "epoch 1709, loss function 33.39959716796875\n",
      "epoch 1710, loss function 33.26268768310547\n",
      "epoch 1711, loss function 33.126312255859375\n",
      "epoch 1712, loss function 32.99058532714844\n",
      "epoch 1713, loss function 32.855377197265625\n",
      "epoch 1714, loss function 32.72074508666992\n",
      "epoch 1715, loss function 32.586639404296875\n",
      "epoch 1716, loss function 32.45307540893555\n",
      "epoch 1717, loss function 32.320068359375\n",
      "epoch 1718, loss function 32.18754577636719\n",
      "epoch 1719, loss function 32.05561065673828\n",
      "epoch 1720, loss function 31.924205780029297\n",
      "epoch 1721, loss function 31.793354034423828\n",
      "epoch 1722, loss function 31.66302490234375\n",
      "epoch 1723, loss function 31.533233642578125\n",
      "epoch 1724, loss function 31.40398406982422\n",
      "epoch 1725, loss function 31.27524757385254\n",
      "epoch 1726, loss function 31.147048950195312\n",
      "epoch 1727, loss function 31.019371032714844\n",
      "epoch 1728, loss function 30.89227294921875\n",
      "epoch 1729, loss function 30.76569938659668\n",
      "epoch 1730, loss function 30.639585494995117\n",
      "epoch 1731, loss function 30.51400375366211\n",
      "epoch 1732, loss function 30.388925552368164\n",
      "epoch 1733, loss function 30.26436996459961\n",
      "epoch 1734, loss function 30.14031410217285\n",
      "epoch 1735, loss function 30.016796112060547\n",
      "epoch 1736, loss function 29.893770217895508\n",
      "epoch 1737, loss function 29.771268844604492\n",
      "epoch 1738, loss function 29.649202346801758\n",
      "epoch 1739, loss function 29.52766990661621\n",
      "epoch 1740, loss function 29.406620025634766\n",
      "epoch 1741, loss function 29.286073684692383\n",
      "epoch 1742, loss function 29.166025161743164\n",
      "epoch 1743, loss function 29.046470642089844\n",
      "epoch 1744, loss function 28.92742919921875\n",
      "epoch 1745, loss function 28.808887481689453\n",
      "epoch 1746, loss function 28.690824508666992\n",
      "epoch 1747, loss function 28.57326316833496\n",
      "epoch 1748, loss function 28.4561767578125\n",
      "epoch 1749, loss function 28.339599609375\n",
      "epoch 1750, loss function 28.223464965820312\n",
      "epoch 1751, loss function 28.107803344726562\n",
      "epoch 1752, loss function 27.992631912231445\n",
      "epoch 1753, loss function 27.877933502197266\n",
      "epoch 1754, loss function 27.763717651367188\n",
      "epoch 1755, loss function 27.649953842163086\n",
      "epoch 1756, loss function 27.53664779663086\n",
      "epoch 1757, loss function 27.423778533935547\n",
      "epoch 1758, loss function 27.311363220214844\n",
      "epoch 1759, loss function 27.199443817138672\n",
      "epoch 1760, loss function 27.087928771972656\n",
      "epoch 1761, loss function 26.976865768432617\n",
      "epoch 1762, loss function 26.866294860839844\n",
      "epoch 1763, loss function 26.756214141845703\n",
      "epoch 1764, loss function 26.646522521972656\n",
      "epoch 1765, loss function 26.537311553955078\n",
      "epoch 1766, loss function 26.428550720214844\n",
      "epoch 1767, loss function 26.320268630981445\n",
      "epoch 1768, loss function 26.212358474731445\n",
      "epoch 1769, loss function 26.104942321777344\n",
      "epoch 1770, loss function 25.997982025146484\n",
      "epoch 1771, loss function 25.8914737701416\n",
      "epoch 1772, loss function 25.785348892211914\n",
      "epoch 1773, loss function 25.6796932220459\n",
      "epoch 1774, loss function 25.574443817138672\n",
      "epoch 1775, loss function 25.469655990600586\n",
      "epoch 1776, loss function 25.365257263183594\n",
      "epoch 1777, loss function 25.261287689208984\n",
      "epoch 1778, loss function 25.157777786254883\n",
      "epoch 1779, loss function 25.054683685302734\n",
      "epoch 1780, loss function 24.952003479003906\n",
      "epoch 1781, loss function 24.849782943725586\n",
      "epoch 1782, loss function 24.74798583984375\n",
      "epoch 1783, loss function 24.646533966064453\n",
      "epoch 1784, loss function 24.545547485351562\n",
      "epoch 1785, loss function 24.44496726989746\n",
      "epoch 1786, loss function 24.344772338867188\n",
      "epoch 1787, loss function 24.245018005371094\n",
      "epoch 1788, loss function 24.145689010620117\n",
      "epoch 1789, loss function 24.046737670898438\n",
      "epoch 1790, loss function 23.948183059692383\n",
      "epoch 1791, loss function 23.850051879882812\n",
      "epoch 1792, loss function 23.75230598449707\n",
      "epoch 1793, loss function 23.65496826171875\n",
      "epoch 1794, loss function 23.558067321777344\n",
      "epoch 1795, loss function 23.461536407470703\n",
      "epoch 1796, loss function 23.3653621673584\n",
      "epoch 1797, loss function 23.269628524780273\n",
      "epoch 1798, loss function 23.17427635192871\n",
      "epoch 1799, loss function 23.07931137084961\n",
      "epoch 1800, loss function 22.98478889465332\n",
      "epoch 1801, loss function 22.890575408935547\n",
      "epoch 1802, loss function 22.796772003173828\n",
      "epoch 1803, loss function 22.703372955322266\n",
      "epoch 1804, loss function 22.610334396362305\n",
      "epoch 1805, loss function 22.517715454101562\n",
      "epoch 1806, loss function 22.4254150390625\n",
      "epoch 1807, loss function 22.333515167236328\n",
      "epoch 1808, loss function 22.24201202392578\n",
      "epoch 1809, loss function 22.150875091552734\n",
      "epoch 1810, loss function 22.060108184814453\n",
      "epoch 1811, loss function 21.969715118408203\n",
      "epoch 1812, loss function 21.879695892333984\n",
      "epoch 1813, loss function 21.79009246826172\n",
      "epoch 1814, loss function 21.700761795043945\n",
      "epoch 1815, loss function 21.611845016479492\n",
      "epoch 1816, loss function 21.523298263549805\n",
      "epoch 1817, loss function 21.435121536254883\n",
      "epoch 1818, loss function 21.34728240966797\n",
      "epoch 1819, loss function 21.25979995727539\n",
      "epoch 1820, loss function 21.17270278930664\n",
      "epoch 1821, loss function 21.085941314697266\n",
      "epoch 1822, loss function 20.999534606933594\n",
      "epoch 1823, loss function 20.913509368896484\n",
      "epoch 1824, loss function 20.827823638916016\n",
      "epoch 1825, loss function 20.742469787597656\n",
      "epoch 1826, loss function 20.65746307373047\n",
      "epoch 1827, loss function 20.57283592224121\n",
      "epoch 1828, loss function 20.48855209350586\n",
      "epoch 1829, loss function 20.40458869934082\n",
      "epoch 1830, loss function 20.320959091186523\n",
      "epoch 1831, loss function 20.237709045410156\n",
      "epoch 1832, loss function 20.15479278564453\n",
      "epoch 1833, loss function 20.072206497192383\n",
      "epoch 1834, loss function 19.990005493164062\n",
      "epoch 1835, loss function 19.908071517944336\n",
      "epoch 1836, loss function 19.82651138305664\n",
      "epoch 1837, loss function 19.745269775390625\n",
      "epoch 1838, loss function 19.66436767578125\n",
      "epoch 1839, loss function 19.58379554748535\n",
      "epoch 1840, loss function 19.50357437133789\n",
      "epoch 1841, loss function 19.423625946044922\n",
      "epoch 1842, loss function 19.34406089782715\n",
      "epoch 1843, loss function 19.26480484008789\n",
      "epoch 1844, loss function 19.185876846313477\n",
      "epoch 1845, loss function 19.107240676879883\n",
      "epoch 1846, loss function 19.028995513916016\n",
      "epoch 1847, loss function 18.95100212097168\n",
      "epoch 1848, loss function 18.873374938964844\n",
      "epoch 1849, loss function 18.796049118041992\n",
      "epoch 1850, loss function 18.719053268432617\n",
      "epoch 1851, loss function 18.642358779907227\n",
      "epoch 1852, loss function 18.56597328186035\n",
      "epoch 1853, loss function 18.489892959594727\n",
      "epoch 1854, loss function 18.414180755615234\n",
      "epoch 1855, loss function 18.338726043701172\n",
      "epoch 1856, loss function 18.263614654541016\n",
      "epoch 1857, loss function 18.188756942749023\n",
      "epoch 1858, loss function 18.114261627197266\n",
      "epoch 1859, loss function 18.040075302124023\n",
      "epoch 1860, loss function 17.96611785888672\n",
      "epoch 1861, loss function 17.892532348632812\n",
      "epoch 1862, loss function 17.819194793701172\n",
      "epoch 1863, loss function 17.746206283569336\n",
      "epoch 1864, loss function 17.673498153686523\n",
      "epoch 1865, loss function 17.601112365722656\n",
      "epoch 1866, loss function 17.529008865356445\n",
      "epoch 1867, loss function 17.45719337463379\n",
      "epoch 1868, loss function 17.385679244995117\n",
      "epoch 1869, loss function 17.314430236816406\n",
      "epoch 1870, loss function 17.243499755859375\n",
      "epoch 1871, loss function 17.172849655151367\n",
      "epoch 1872, loss function 17.10251808166504\n",
      "epoch 1873, loss function 17.03245735168457\n",
      "epoch 1874, loss function 16.962671279907227\n",
      "epoch 1875, loss function 16.893203735351562\n",
      "epoch 1876, loss function 16.8239688873291\n",
      "epoch 1877, loss function 16.755056381225586\n",
      "epoch 1878, loss function 16.686389923095703\n",
      "epoch 1879, loss function 16.61806297302246\n",
      "epoch 1880, loss function 16.549962997436523\n",
      "epoch 1881, loss function 16.48215675354004\n",
      "epoch 1882, loss function 16.414615631103516\n",
      "epoch 1883, loss function 16.347370147705078\n",
      "epoch 1884, loss function 16.28045082092285\n",
      "epoch 1885, loss function 16.213762283325195\n",
      "epoch 1886, loss function 16.147327423095703\n",
      "epoch 1887, loss function 16.08119010925293\n",
      "epoch 1888, loss function 16.01532554626465\n",
      "epoch 1889, loss function 15.949734687805176\n",
      "epoch 1890, loss function 15.884425163269043\n",
      "epoch 1891, loss function 15.819352149963379\n",
      "epoch 1892, loss function 15.754578590393066\n",
      "epoch 1893, loss function 15.690034866333008\n",
      "epoch 1894, loss function 15.625746726989746\n",
      "epoch 1895, loss function 15.561734199523926\n",
      "epoch 1896, loss function 15.497974395751953\n",
      "epoch 1897, loss function 15.434476852416992\n",
      "epoch 1898, loss function 15.371241569519043\n",
      "epoch 1899, loss function 15.308276176452637\n",
      "epoch 1900, loss function 15.245549201965332\n",
      "epoch 1901, loss function 15.183113098144531\n",
      "epoch 1902, loss function 15.12090015411377\n",
      "epoch 1903, loss function 15.058959007263184\n",
      "epoch 1904, loss function 14.99726390838623\n",
      "epoch 1905, loss function 14.935848236083984\n",
      "epoch 1906, loss function 14.874651908874512\n",
      "epoch 1907, loss function 14.81373405456543\n",
      "epoch 1908, loss function 14.753055572509766\n",
      "epoch 1909, loss function 14.69260025024414\n",
      "epoch 1910, loss function 14.632425308227539\n",
      "epoch 1911, loss function 14.572474479675293\n",
      "epoch 1912, loss function 14.512785911560059\n",
      "epoch 1913, loss function 14.453343391418457\n",
      "epoch 1914, loss function 14.394161224365234\n",
      "epoch 1915, loss function 14.335186004638672\n",
      "epoch 1916, loss function 14.276470184326172\n",
      "epoch 1917, loss function 14.217994689941406\n",
      "epoch 1918, loss function 14.159749984741211\n",
      "epoch 1919, loss function 14.10177230834961\n",
      "epoch 1920, loss function 14.04401683807373\n",
      "epoch 1921, loss function 13.986473083496094\n",
      "epoch 1922, loss function 13.929179191589355\n",
      "epoch 1923, loss function 13.872130393981934\n",
      "epoch 1924, loss function 13.815319061279297\n",
      "epoch 1925, loss function 13.758735656738281\n",
      "epoch 1926, loss function 13.702377319335938\n",
      "epoch 1927, loss function 13.646265029907227\n",
      "epoch 1928, loss function 13.590354919433594\n",
      "epoch 1929, loss function 13.534693717956543\n",
      "epoch 1930, loss function 13.47928237915039\n",
      "epoch 1931, loss function 13.42406177520752\n",
      "epoch 1932, loss function 13.369098663330078\n",
      "epoch 1933, loss function 13.314318656921387\n",
      "epoch 1934, loss function 13.259769439697266\n",
      "epoch 1935, loss function 13.205482482910156\n",
      "epoch 1936, loss function 13.151390075683594\n",
      "epoch 1937, loss function 13.09748649597168\n",
      "epoch 1938, loss function 13.04387092590332\n",
      "epoch 1939, loss function 12.990442276000977\n",
      "epoch 1940, loss function 12.937239646911621\n",
      "epoch 1941, loss function 12.884255409240723\n",
      "epoch 1942, loss function 12.831483840942383\n",
      "epoch 1943, loss function 12.778945922851562\n",
      "epoch 1944, loss function 12.726615905761719\n",
      "epoch 1945, loss function 12.674464225769043\n",
      "epoch 1946, loss function 12.622598648071289\n",
      "epoch 1947, loss function 12.570900917053223\n",
      "epoch 1948, loss function 12.519416809082031\n",
      "epoch 1949, loss function 12.468147277832031\n",
      "epoch 1950, loss function 12.417068481445312\n",
      "epoch 1951, loss function 12.366223335266113\n",
      "epoch 1952, loss function 12.315601348876953\n",
      "epoch 1953, loss function 12.26516056060791\n",
      "epoch 1954, loss function 12.214914321899414\n",
      "epoch 1955, loss function 12.164887428283691\n",
      "epoch 1956, loss function 12.115092277526855\n",
      "epoch 1957, loss function 12.065473556518555\n",
      "epoch 1958, loss function 12.0160493850708\n",
      "epoch 1959, loss function 11.966837882995605\n",
      "epoch 1960, loss function 11.917814254760742\n",
      "epoch 1961, loss function 11.869011878967285\n",
      "epoch 1962, loss function 11.820422172546387\n",
      "epoch 1963, loss function 11.772015571594238\n",
      "epoch 1964, loss function 11.723800659179688\n",
      "epoch 1965, loss function 11.675758361816406\n",
      "epoch 1966, loss function 11.627973556518555\n",
      "epoch 1967, loss function 11.580349922180176\n",
      "epoch 1968, loss function 11.53292465209961\n",
      "epoch 1969, loss function 11.485674858093262\n",
      "epoch 1970, loss function 11.438626289367676\n",
      "epoch 1971, loss function 11.391779899597168\n",
      "epoch 1972, loss function 11.345131874084473\n",
      "epoch 1973, loss function 11.29868221282959\n",
      "epoch 1974, loss function 11.25242805480957\n",
      "epoch 1975, loss function 11.206335067749023\n",
      "epoch 1976, loss function 11.160417556762695\n",
      "epoch 1977, loss function 11.114726066589355\n",
      "epoch 1978, loss function 11.06922721862793\n",
      "epoch 1979, loss function 11.023894309997559\n",
      "epoch 1980, loss function 10.978757858276367\n",
      "epoch 1981, loss function 10.9337797164917\n",
      "epoch 1982, loss function 10.889012336730957\n",
      "epoch 1983, loss function 10.844411849975586\n",
      "epoch 1984, loss function 10.799978256225586\n",
      "epoch 1985, loss function 10.755751609802246\n",
      "epoch 1986, loss function 10.711732864379883\n",
      "epoch 1987, loss function 10.667872428894043\n",
      "epoch 1988, loss function 10.624181747436523\n",
      "epoch 1989, loss function 10.580659866333008\n",
      "epoch 1990, loss function 10.537344932556152\n",
      "epoch 1991, loss function 10.494193077087402\n",
      "epoch 1992, loss function 10.451201438903809\n",
      "epoch 1993, loss function 10.408411979675293\n",
      "epoch 1994, loss function 10.365785598754883\n",
      "epoch 1995, loss function 10.3233642578125\n",
      "epoch 1996, loss function 10.281099319458008\n",
      "epoch 1997, loss function 10.23900318145752\n",
      "epoch 1998, loss function 10.197067260742188\n",
      "epoch 1999, loss function 10.155279159545898\n",
      "epoch 2000, loss function 10.11370849609375\n",
      "epoch 2001, loss function 10.072287559509277\n",
      "epoch 2002, loss function 10.031058311462402\n",
      "epoch 2003, loss function 9.98997974395752\n",
      "epoch 2004, loss function 9.94907283782959\n",
      "epoch 2005, loss function 9.90832805633545\n",
      "epoch 2006, loss function 9.867765426635742\n",
      "epoch 2007, loss function 9.827373504638672\n",
      "epoch 2008, loss function 9.787134170532227\n",
      "epoch 2009, loss function 9.747037887573242\n",
      "epoch 2010, loss function 9.707107543945312\n",
      "epoch 2011, loss function 9.667330741882324\n",
      "epoch 2012, loss function 9.627747535705566\n",
      "epoch 2013, loss function 9.588319778442383\n",
      "epoch 2014, loss function 9.549065589904785\n",
      "epoch 2015, loss function 9.509970664978027\n",
      "epoch 2016, loss function 9.47103500366211\n",
      "epoch 2017, loss function 9.432256698608398\n",
      "epoch 2018, loss function 9.393654823303223\n",
      "epoch 2019, loss function 9.355201721191406\n",
      "epoch 2020, loss function 9.316903114318848\n",
      "epoch 2021, loss function 9.278759002685547\n",
      "epoch 2022, loss function 9.240751266479492\n",
      "epoch 2023, loss function 9.202901840209961\n",
      "epoch 2024, loss function 9.165206909179688\n",
      "epoch 2025, loss function 9.127686500549316\n",
      "epoch 2026, loss function 9.090319633483887\n",
      "epoch 2027, loss function 9.053101539611816\n",
      "epoch 2028, loss function 9.01601791381836\n",
      "epoch 2029, loss function 8.97908878326416\n",
      "epoch 2030, loss function 8.942302703857422\n",
      "epoch 2031, loss function 8.905671119689941\n",
      "epoch 2032, loss function 8.869222640991211\n",
      "epoch 2033, loss function 8.832929611206055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2034, loss function 8.796785354614258\n",
      "epoch 2035, loss function 8.760796546936035\n",
      "epoch 2036, loss function 8.724940299987793\n",
      "epoch 2037, loss function 8.68923568725586\n",
      "epoch 2038, loss function 8.653663635253906\n",
      "epoch 2039, loss function 8.618233680725098\n",
      "epoch 2040, loss function 8.582956314086914\n",
      "epoch 2041, loss function 8.547812461853027\n",
      "epoch 2042, loss function 8.512818336486816\n",
      "epoch 2043, loss function 8.4779634475708\n",
      "epoch 2044, loss function 8.443262100219727\n",
      "epoch 2045, loss function 8.408711433410645\n",
      "epoch 2046, loss function 8.374296188354492\n",
      "epoch 2047, loss function 8.340015411376953\n",
      "epoch 2048, loss function 8.305893898010254\n",
      "epoch 2049, loss function 8.271893501281738\n",
      "epoch 2050, loss function 8.238027572631836\n",
      "epoch 2051, loss function 8.204309463500977\n",
      "epoch 2052, loss function 8.1707124710083\n",
      "epoch 2053, loss function 8.1372652053833\n",
      "epoch 2054, loss function 8.1039457321167\n",
      "epoch 2055, loss function 8.070762634277344\n",
      "epoch 2056, loss function 8.037725448608398\n",
      "epoch 2057, loss function 8.004841804504395\n",
      "epoch 2058, loss function 7.972087860107422\n",
      "epoch 2059, loss function 7.939475059509277\n",
      "epoch 2060, loss function 7.906979560852051\n",
      "epoch 2061, loss function 7.874630928039551\n",
      "epoch 2062, loss function 7.842411041259766\n",
      "epoch 2063, loss function 7.810318470001221\n",
      "epoch 2064, loss function 7.778376579284668\n",
      "epoch 2065, loss function 7.746515274047852\n",
      "epoch 2066, loss function 7.7147932052612305\n",
      "epoch 2067, loss function 7.683200836181641\n",
      "epoch 2068, loss function 7.651733875274658\n",
      "epoch 2069, loss function 7.6204023361206055\n",
      "epoch 2070, loss function 7.589189529418945\n",
      "epoch 2071, loss function 7.558114051818848\n",
      "epoch 2072, loss function 7.527158737182617\n",
      "epoch 2073, loss function 7.4963250160217285\n",
      "epoch 2074, loss function 7.465640068054199\n",
      "epoch 2075, loss function 7.435070991516113\n",
      "epoch 2076, loss function 7.404623508453369\n",
      "epoch 2077, loss function 7.37431526184082\n",
      "epoch 2078, loss function 7.344122886657715\n",
      "epoch 2079, loss function 7.314053535461426\n",
      "epoch 2080, loss function 7.284113883972168\n",
      "epoch 2081, loss function 7.254286766052246\n",
      "epoch 2082, loss function 7.224595069885254\n",
      "epoch 2083, loss function 7.195021152496338\n",
      "epoch 2084, loss function 7.165569305419922\n",
      "epoch 2085, loss function 7.1362199783325195\n",
      "epoch 2086, loss function 7.1069841384887695\n",
      "epoch 2087, loss function 7.077874660491943\n",
      "epoch 2088, loss function 7.048894882202148\n",
      "epoch 2089, loss function 7.020025730133057\n",
      "epoch 2090, loss function 6.991284370422363\n",
      "epoch 2091, loss function 6.962656021118164\n",
      "epoch 2092, loss function 6.934152603149414\n",
      "epoch 2093, loss function 6.905776023864746\n",
      "epoch 2094, loss function 6.877507209777832\n",
      "epoch 2095, loss function 6.849369525909424\n",
      "epoch 2096, loss function 6.8213396072387695\n",
      "epoch 2097, loss function 6.793400764465332\n",
      "epoch 2098, loss function 6.765578746795654\n",
      "epoch 2099, loss function 6.737878799438477\n",
      "epoch 2100, loss function 6.7102861404418945\n",
      "epoch 2101, loss function 6.682815074920654\n",
      "epoch 2102, loss function 6.655473232269287\n",
      "epoch 2103, loss function 6.628233432769775\n",
      "epoch 2104, loss function 6.6011128425598145\n",
      "epoch 2105, loss function 6.574105262756348\n",
      "epoch 2106, loss function 6.547207355499268\n",
      "epoch 2107, loss function 6.5204010009765625\n",
      "epoch 2108, loss function 6.493716716766357\n",
      "epoch 2109, loss function 6.467137336730957\n",
      "epoch 2110, loss function 6.440673351287842\n",
      "epoch 2111, loss function 6.4143218994140625\n",
      "epoch 2112, loss function 6.388049602508545\n",
      "epoch 2113, loss function 6.361900806427002\n",
      "epoch 2114, loss function 6.335860729217529\n",
      "epoch 2115, loss function 6.309928894042969\n",
      "epoch 2116, loss function 6.284085750579834\n",
      "epoch 2117, loss function 6.258356094360352\n",
      "epoch 2118, loss function 6.232735633850098\n",
      "epoch 2119, loss function 6.207222938537598\n",
      "epoch 2120, loss function 6.181818008422852\n",
      "epoch 2121, loss function 6.156526565551758\n",
      "epoch 2122, loss function 6.131335735321045\n",
      "epoch 2123, loss function 6.106239318847656\n",
      "epoch 2124, loss function 6.081247806549072\n",
      "epoch 2125, loss function 6.056363105773926\n",
      "epoch 2126, loss function 6.031569004058838\n",
      "epoch 2127, loss function 6.006871223449707\n",
      "epoch 2128, loss function 5.9822845458984375\n",
      "epoch 2129, loss function 5.9578094482421875\n",
      "epoch 2130, loss function 5.933408260345459\n",
      "epoch 2131, loss function 5.909117698669434\n",
      "epoch 2132, loss function 5.884930610656738\n",
      "epoch 2133, loss function 5.860847473144531\n",
      "epoch 2134, loss function 5.836875915527344\n",
      "epoch 2135, loss function 5.8129987716674805\n",
      "epoch 2136, loss function 5.789231777191162\n",
      "epoch 2137, loss function 5.7655158042907715\n",
      "epoch 2138, loss function 5.741898059844971\n",
      "epoch 2139, loss function 5.718393325805664\n",
      "epoch 2140, loss function 5.694981098175049\n",
      "epoch 2141, loss function 5.6716837882995605\n",
      "epoch 2142, loss function 5.6484832763671875\n",
      "epoch 2143, loss function 5.625364780426025\n",
      "epoch 2144, loss function 5.602336406707764\n",
      "epoch 2145, loss function 5.579427242279053\n",
      "epoch 2146, loss function 5.556585311889648\n",
      "epoch 2147, loss function 5.533848762512207\n",
      "epoch 2148, loss function 5.511210918426514\n",
      "epoch 2149, loss function 5.488644123077393\n",
      "epoch 2150, loss function 5.466186046600342\n",
      "epoch 2151, loss function 5.443814277648926\n",
      "epoch 2152, loss function 5.42154598236084\n",
      "epoch 2153, loss function 5.399354934692383\n",
      "epoch 2154, loss function 5.377244472503662\n",
      "epoch 2155, loss function 5.355221271514893\n",
      "epoch 2156, loss function 5.333304405212402\n",
      "epoch 2157, loss function 5.311483860015869\n",
      "epoch 2158, loss function 5.289754390716553\n",
      "epoch 2159, loss function 5.268111705780029\n",
      "epoch 2160, loss function 5.24655818939209\n",
      "epoch 2161, loss function 5.2250847816467285\n",
      "epoch 2162, loss function 5.203700542449951\n",
      "epoch 2163, loss function 5.182403087615967\n",
      "epoch 2164, loss function 5.161181926727295\n",
      "epoch 2165, loss function 5.140069484710693\n",
      "epoch 2166, loss function 5.11904239654541\n",
      "epoch 2167, loss function 5.098082542419434\n",
      "epoch 2168, loss function 5.077229022979736\n",
      "epoch 2169, loss function 5.056437969207764\n",
      "epoch 2170, loss function 5.035746097564697\n",
      "epoch 2171, loss function 5.015136241912842\n",
      "epoch 2172, loss function 4.994625091552734\n",
      "epoch 2173, loss function 4.974164962768555\n",
      "epoch 2174, loss function 4.953799724578857\n",
      "epoch 2175, loss function 4.9335222244262695\n",
      "epoch 2176, loss function 4.913344383239746\n",
      "epoch 2177, loss function 4.893254280090332\n",
      "epoch 2178, loss function 4.873231887817383\n",
      "epoch 2179, loss function 4.853269577026367\n",
      "epoch 2180, loss function 4.833401679992676\n",
      "epoch 2181, loss function 4.813626289367676\n",
      "epoch 2182, loss function 4.793921947479248\n",
      "epoch 2183, loss function 4.774309158325195\n",
      "epoch 2184, loss function 4.754760265350342\n",
      "epoch 2185, loss function 4.735311508178711\n",
      "epoch 2186, loss function 4.715936660766602\n",
      "epoch 2187, loss function 4.696628570556641\n",
      "epoch 2188, loss function 4.677412986755371\n",
      "epoch 2189, loss function 4.658290386199951\n",
      "epoch 2190, loss function 4.639233589172363\n",
      "epoch 2191, loss function 4.620242595672607\n",
      "epoch 2192, loss function 4.6013360023498535\n",
      "epoch 2193, loss function 4.58251428604126\n",
      "epoch 2194, loss function 4.563783168792725\n",
      "epoch 2195, loss function 4.54509973526001\n",
      "epoch 2196, loss function 4.526492595672607\n",
      "epoch 2197, loss function 4.507981300354004\n",
      "epoch 2198, loss function 4.489554405212402\n",
      "epoch 2199, loss function 4.471166610717773\n",
      "epoch 2200, loss function 4.452859878540039\n",
      "epoch 2201, loss function 4.43464994430542\n",
      "epoch 2202, loss function 4.416489601135254\n",
      "epoch 2203, loss function 4.398427963256836\n",
      "epoch 2204, loss function 4.380420684814453\n",
      "epoch 2205, loss function 4.362494468688965\n",
      "epoch 2206, loss function 4.344638824462891\n",
      "epoch 2207, loss function 4.3268632888793945\n",
      "epoch 2208, loss function 4.309157371520996\n",
      "epoch 2209, loss function 4.291531085968018\n",
      "epoch 2210, loss function 4.2739577293396\n",
      "epoch 2211, loss function 4.256472110748291\n",
      "epoch 2212, loss function 4.239071369171143\n",
      "epoch 2213, loss function 4.221707820892334\n",
      "epoch 2214, loss function 4.204431533813477\n",
      "epoch 2215, loss function 4.187231540679932\n",
      "epoch 2216, loss function 4.170107841491699\n",
      "epoch 2217, loss function 4.153027057647705\n",
      "epoch 2218, loss function 4.136036396026611\n",
      "epoch 2219, loss function 4.119117259979248\n",
      "epoch 2220, loss function 4.102256774902344\n",
      "epoch 2221, loss function 4.0854597091674805\n",
      "epoch 2222, loss function 4.068745136260986\n",
      "epoch 2223, loss function 4.05211067199707\n",
      "epoch 2224, loss function 4.035531044006348\n",
      "epoch 2225, loss function 4.019006252288818\n",
      "epoch 2226, loss function 4.002564430236816\n",
      "epoch 2227, loss function 3.9861812591552734\n",
      "epoch 2228, loss function 3.9698798656463623\n",
      "epoch 2229, loss function 3.9536335468292236\n",
      "epoch 2230, loss function 3.937465190887451\n",
      "epoch 2231, loss function 3.921351909637451\n",
      "epoch 2232, loss function 3.9053196907043457\n",
      "epoch 2233, loss function 3.8893487453460693\n",
      "epoch 2234, loss function 3.873422861099243\n",
      "epoch 2235, loss function 3.857579231262207\n",
      "epoch 2236, loss function 3.8418078422546387\n",
      "epoch 2237, loss function 3.826082706451416\n",
      "epoch 2238, loss function 3.8104286193847656\n",
      "epoch 2239, loss function 3.7948458194732666\n",
      "epoch 2240, loss function 3.779310464859009\n",
      "epoch 2241, loss function 3.763842821121216\n",
      "epoch 2242, loss function 3.748452663421631\n",
      "epoch 2243, loss function 3.7331137657165527\n",
      "epoch 2244, loss function 3.717829465866089\n",
      "epoch 2245, loss function 3.7026278972625732\n",
      "epoch 2246, loss function 3.6874709129333496\n",
      "epoch 2247, loss function 3.6723692417144775\n",
      "epoch 2248, loss function 3.657343864440918\n",
      "epoch 2249, loss function 3.64239501953125\n",
      "epoch 2250, loss function 3.6274983882904053\n",
      "epoch 2251, loss function 3.612652063369751\n",
      "epoch 2252, loss function 3.5978846549987793\n",
      "epoch 2253, loss function 3.583174228668213\n",
      "epoch 2254, loss function 3.5685009956359863\n",
      "epoch 2255, loss function 3.553910493850708\n",
      "epoch 2256, loss function 3.5393712520599365\n",
      "epoch 2257, loss function 3.524892568588257\n",
      "epoch 2258, loss function 3.5104613304138184\n",
      "epoch 2259, loss function 3.496093988418579\n",
      "epoch 2260, loss function 3.4818079471588135\n",
      "epoch 2261, loss function 3.4675498008728027\n",
      "epoch 2262, loss function 3.4533650875091553\n",
      "epoch 2263, loss function 3.439241886138916\n",
      "epoch 2264, loss function 3.425157070159912\n",
      "epoch 2265, loss function 3.4111452102661133\n",
      "epoch 2266, loss function 3.3971989154815674\n",
      "epoch 2267, loss function 3.3832883834838867\n",
      "epoch 2268, loss function 3.3694417476654053\n",
      "epoch 2269, loss function 3.3556723594665527\n",
      "epoch 2270, loss function 3.341933012008667\n",
      "epoch 2271, loss function 3.328256130218506\n",
      "epoch 2272, loss function 3.314652681350708\n",
      "epoch 2273, loss function 3.3010823726654053\n",
      "epoch 2274, loss function 3.2875804901123047\n",
      "epoch 2275, loss function 3.274139642715454\n",
      "epoch 2276, loss function 3.2607314586639404\n",
      "epoch 2277, loss function 3.2474000453948975\n",
      "epoch 2278, loss function 3.2341079711914062\n",
      "epoch 2279, loss function 3.220869779586792\n",
      "epoch 2280, loss function 3.2076938152313232\n",
      "epoch 2281, loss function 3.194575071334839\n",
      "epoch 2282, loss function 3.181492805480957\n",
      "epoch 2283, loss function 3.168490409851074\n",
      "epoch 2284, loss function 3.155522108078003\n",
      "epoch 2285, loss function 3.142613172531128\n",
      "epoch 2286, loss function 3.129748582839966\n",
      "epoch 2287, loss function 3.116950273513794\n",
      "epoch 2288, loss function 3.104193687438965\n",
      "epoch 2289, loss function 3.091485023498535\n",
      "epoch 2290, loss function 3.0788540840148926\n",
      "epoch 2291, loss function 3.0662574768066406\n",
      "epoch 2292, loss function 3.0537123680114746\n",
      "epoch 2293, loss function 3.041229009628296\n",
      "epoch 2294, loss function 3.0287766456604004\n",
      "epoch 2295, loss function 3.016388177871704\n",
      "epoch 2296, loss function 3.004068613052368\n",
      "epoch 2297, loss function 2.9917733669281006\n",
      "epoch 2298, loss function 2.979536533355713\n",
      "epoch 2299, loss function 2.9673523902893066\n",
      "epoch 2300, loss function 2.955212116241455\n",
      "epoch 2301, loss function 2.9431304931640625\n",
      "epoch 2302, loss function 2.9310812950134277\n",
      "epoch 2303, loss function 2.9190964698791504\n",
      "epoch 2304, loss function 2.907151460647583\n",
      "epoch 2305, loss function 2.895251512527466\n",
      "epoch 2306, loss function 2.8834152221679688\n",
      "epoch 2307, loss function 2.8716256618499756\n",
      "epoch 2308, loss function 2.859879970550537\n",
      "epoch 2309, loss function 2.84818172454834\n",
      "epoch 2310, loss function 2.8365185260772705\n",
      "epoch 2311, loss function 2.824920654296875\n",
      "epoch 2312, loss function 2.813370943069458\n",
      "epoch 2313, loss function 2.801863193511963\n",
      "epoch 2314, loss function 2.7903966903686523\n",
      "epoch 2315, loss function 2.778987169265747\n",
      "epoch 2316, loss function 2.767622947692871\n",
      "epoch 2317, loss function 2.7563064098358154\n",
      "epoch 2318, loss function 2.7450289726257324\n",
      "epoch 2319, loss function 2.7337915897369385\n",
      "epoch 2320, loss function 2.722616195678711\n",
      "epoch 2321, loss function 2.711470603942871\n",
      "epoch 2322, loss function 2.7003824710845947\n",
      "epoch 2323, loss function 2.6893322467803955\n",
      "epoch 2324, loss function 2.6783292293548584\n",
      "epoch 2325, loss function 2.667384624481201\n",
      "epoch 2326, loss function 2.6564552783966064\n",
      "epoch 2327, loss function 2.6455907821655273\n",
      "epoch 2328, loss function 2.6347904205322266\n",
      "epoch 2329, loss function 2.624013662338257\n",
      "epoch 2330, loss function 2.613283395767212\n",
      "epoch 2331, loss function 2.6025922298431396\n",
      "epoch 2332, loss function 2.591949462890625\n",
      "epoch 2333, loss function 2.5813465118408203\n",
      "epoch 2334, loss function 2.5707855224609375\n",
      "epoch 2335, loss function 2.5602684020996094\n",
      "epoch 2336, loss function 2.5497970581054688\n",
      "epoch 2337, loss function 2.5393736362457275\n",
      "epoch 2338, loss function 2.5289742946624756\n",
      "epoch 2339, loss function 2.518634557723999\n",
      "epoch 2340, loss function 2.5083374977111816\n",
      "epoch 2341, loss function 2.498076915740967\n",
      "epoch 2342, loss function 2.4878528118133545\n",
      "epoch 2343, loss function 2.4776692390441895\n",
      "epoch 2344, loss function 2.4675509929656982\n",
      "epoch 2345, loss function 2.4574575424194336\n",
      "epoch 2346, loss function 2.447413206100464\n",
      "epoch 2347, loss function 2.4374072551727295\n",
      "epoch 2348, loss function 2.4274356365203857\n",
      "epoch 2349, loss function 2.417508602142334\n",
      "epoch 2350, loss function 2.40761137008667\n",
      "epoch 2351, loss function 2.397756338119507\n",
      "epoch 2352, loss function 2.387960433959961\n",
      "epoch 2353, loss function 2.378178596496582\n",
      "epoch 2354, loss function 2.3684606552124023\n",
      "epoch 2355, loss function 2.3587732315063477\n",
      "epoch 2356, loss function 2.349128007888794\n",
      "epoch 2357, loss function 2.3395137786865234\n",
      "epoch 2358, loss function 2.329944133758545\n",
      "epoch 2359, loss function 2.320430040359497\n",
      "epoch 2360, loss function 2.3109302520751953\n",
      "epoch 2361, loss function 2.3014872074127197\n",
      "epoch 2362, loss function 2.2920663356781006\n",
      "epoch 2363, loss function 2.282696485519409\n",
      "epoch 2364, loss function 2.2733523845672607\n",
      "epoch 2365, loss function 2.2640531063079834\n",
      "epoch 2366, loss function 2.25479793548584\n",
      "epoch 2367, loss function 2.245575428009033\n",
      "epoch 2368, loss function 2.2364070415496826\n",
      "epoch 2369, loss function 2.2272515296936035\n",
      "epoch 2370, loss function 2.2181549072265625\n",
      "epoch 2371, loss function 2.2090766429901123\n",
      "epoch 2372, loss function 2.2000555992126465\n",
      "epoch 2373, loss function 2.1910476684570312\n",
      "epoch 2374, loss function 2.1820931434631348\n",
      "epoch 2375, loss function 2.17315936088562\n",
      "epoch 2376, loss function 2.1642777919769287\n",
      "epoch 2377, loss function 2.155426263809204\n",
      "epoch 2378, loss function 2.1466164588928223\n",
      "epoch 2379, loss function 2.1378393173217773\n",
      "epoch 2380, loss function 2.129098892211914\n",
      "epoch 2381, loss function 2.120389223098755\n",
      "epoch 2382, loss function 2.1117191314697266\n",
      "epoch 2383, loss function 2.1030783653259277\n",
      "epoch 2384, loss function 2.0944793224334717\n",
      "epoch 2385, loss function 2.085906505584717\n",
      "epoch 2386, loss function 2.0773706436157227\n",
      "epoch 2387, loss function 2.0688703060150146\n",
      "epoch 2388, loss function 2.0604097843170166\n",
      "epoch 2389, loss function 2.0519766807556152\n",
      "epoch 2390, loss function 2.043590545654297\n",
      "epoch 2391, loss function 2.0352306365966797\n",
      "epoch 2392, loss function 2.0269157886505127\n",
      "epoch 2393, loss function 2.018618106842041\n",
      "epoch 2394, loss function 2.0103652477264404\n",
      "epoch 2395, loss function 2.0021374225616455\n",
      "epoch 2396, loss function 1.9939589500427246\n",
      "epoch 2397, loss function 1.9857937097549438\n",
      "epoch 2398, loss function 1.9776809215545654\n",
      "epoch 2399, loss function 1.9695825576782227\n",
      "epoch 2400, loss function 1.9615366458892822\n",
      "epoch 2401, loss function 1.9535030126571655\n",
      "epoch 2402, loss function 1.945519208908081\n",
      "epoch 2403, loss function 1.93755042552948\n",
      "epoch 2404, loss function 1.9296369552612305\n",
      "epoch 2405, loss function 1.921733021736145\n",
      "epoch 2406, loss function 1.9138777256011963\n",
      "epoch 2407, loss function 1.906041145324707\n",
      "epoch 2408, loss function 1.8982521295547485\n",
      "epoch 2409, loss function 1.8904763460159302\n",
      "epoch 2410, loss function 1.8827468156814575\n",
      "epoch 2411, loss function 1.8750419616699219\n",
      "epoch 2412, loss function 1.8673803806304932\n",
      "epoch 2413, loss function 1.8597350120544434\n",
      "epoch 2414, loss function 1.8521344661712646\n",
      "epoch 2415, loss function 1.8445531129837036\n",
      "epoch 2416, loss function 1.83701491355896\n",
      "epoch 2417, loss function 1.8294932842254639\n",
      "epoch 2418, loss function 1.8220176696777344\n",
      "epoch 2419, loss function 1.8145596981048584\n",
      "epoch 2420, loss function 1.807147741317749\n",
      "epoch 2421, loss function 1.7997498512268066\n",
      "epoch 2422, loss function 1.7923966646194458\n",
      "epoch 2423, loss function 1.7850621938705444\n",
      "epoch 2424, loss function 1.7777714729309082\n",
      "epoch 2425, loss function 1.7704975605010986\n",
      "epoch 2426, loss function 1.763263463973999\n",
      "epoch 2427, loss function 1.756048321723938\n",
      "epoch 2428, loss function 1.7488631010055542\n",
      "epoch 2429, loss function 1.7417112588882446\n",
      "epoch 2430, loss function 1.7345843315124512\n",
      "epoch 2431, loss function 1.7274888753890991\n",
      "epoch 2432, loss function 1.7204256057739258\n",
      "epoch 2433, loss function 1.7133924961090088\n",
      "epoch 2434, loss function 1.7063829898834229\n",
      "epoch 2435, loss function 1.699408769607544\n",
      "epoch 2436, loss function 1.6924577951431274\n",
      "epoch 2437, loss function 1.6855435371398926\n",
      "epoch 2438, loss function 1.6786489486694336\n",
      "epoch 2439, loss function 1.6717910766601562\n",
      "epoch 2440, loss function 1.6649590730667114\n",
      "epoch 2441, loss function 1.6581453084945679\n",
      "epoch 2442, loss function 1.6513683795928955\n",
      "epoch 2443, loss function 1.644613265991211\n",
      "epoch 2444, loss function 1.6378953456878662\n",
      "epoch 2445, loss function 1.6311962604522705\n",
      "epoch 2446, loss function 1.6245338916778564\n",
      "epoch 2447, loss function 1.6178934574127197\n",
      "epoch 2448, loss function 1.6112760305404663\n",
      "epoch 2449, loss function 1.6046888828277588\n",
      "epoch 2450, loss function 1.5981271266937256\n",
      "epoch 2451, loss function 1.591597080230713\n",
      "epoch 2452, loss function 1.5850803852081299\n",
      "epoch 2453, loss function 1.5786064863204956\n",
      "epoch 2454, loss function 1.5721440315246582\n",
      "epoch 2455, loss function 1.5657227039337158\n",
      "epoch 2456, loss function 1.5593149662017822\n",
      "epoch 2457, loss function 1.5529546737670898\n",
      "epoch 2458, loss function 1.5465984344482422\n",
      "epoch 2459, loss function 1.5402905941009521\n",
      "epoch 2460, loss function 1.5339950323104858\n",
      "epoch 2461, loss function 1.5277127027511597\n",
      "epoch 2462, loss function 1.5214678049087524\n",
      "epoch 2463, loss function 1.5152406692504883\n",
      "epoch 2464, loss function 1.5090510845184326\n",
      "epoch 2465, loss function 1.5028738975524902\n",
      "epoch 2466, loss function 1.4967379570007324\n",
      "epoch 2467, loss function 1.4906147718429565\n",
      "epoch 2468, loss function 1.4845209121704102\n",
      "epoch 2469, loss function 1.4784512519836426\n",
      "epoch 2470, loss function 1.4724096059799194\n",
      "epoch 2471, loss function 1.4663926362991333\n",
      "epoch 2472, loss function 1.4603893756866455\n",
      "epoch 2473, loss function 1.454424500465393\n",
      "epoch 2474, loss function 1.448479413986206\n",
      "epoch 2475, loss function 1.4425650835037231\n",
      "epoch 2476, loss function 1.4366650581359863\n",
      "epoch 2477, loss function 1.4307897090911865\n",
      "epoch 2478, loss function 1.4249459505081177\n",
      "epoch 2479, loss function 1.4191226959228516\n",
      "epoch 2480, loss function 1.4133234024047852\n",
      "epoch 2481, loss function 1.4075415134429932\n",
      "epoch 2482, loss function 1.4017841815948486\n",
      "epoch 2483, loss function 1.3960545063018799\n",
      "epoch 2484, loss function 1.3903461694717407\n",
      "epoch 2485, loss function 1.3846626281738281\n",
      "epoch 2486, loss function 1.3790063858032227\n",
      "epoch 2487, loss function 1.3733760118484497\n",
      "epoch 2488, loss function 1.3677558898925781\n",
      "epoch 2489, loss function 1.362156629562378\n",
      "epoch 2490, loss function 1.3565880060195923\n",
      "epoch 2491, loss function 1.3510414361953735\n",
      "epoch 2492, loss function 1.345524549484253\n",
      "epoch 2493, loss function 1.3400300741195679\n",
      "epoch 2494, loss function 1.334545373916626\n",
      "epoch 2495, loss function 1.329087734222412\n",
      "epoch 2496, loss function 1.3236504793167114\n",
      "epoch 2497, loss function 1.3182415962219238\n",
      "epoch 2498, loss function 1.3128522634506226\n",
      "epoch 2499, loss function 1.3074904680252075\n",
      "epoch 2500, loss function 1.3021512031555176\n",
      "epoch 2501, loss function 1.2968275547027588\n",
      "epoch 2502, loss function 1.291525959968567\n",
      "epoch 2503, loss function 1.2862451076507568\n",
      "epoch 2504, loss function 1.2809910774230957\n",
      "epoch 2505, loss function 1.275756597518921\n",
      "epoch 2506, loss function 1.2705366611480713\n",
      "epoch 2507, loss function 1.265337586402893\n",
      "epoch 2508, loss function 1.2601704597473145\n",
      "epoch 2509, loss function 1.255020022392273\n",
      "epoch 2510, loss function 1.2498914003372192\n",
      "epoch 2511, loss function 1.2447770833969116\n",
      "epoch 2512, loss function 1.2396938800811768\n",
      "epoch 2513, loss function 1.2346283197402954\n",
      "epoch 2514, loss function 1.22958242893219\n",
      "epoch 2515, loss function 1.2245604991912842\n",
      "epoch 2516, loss function 1.2195501327514648\n",
      "epoch 2517, loss function 1.2145733833312988\n",
      "epoch 2518, loss function 1.2096093893051147\n",
      "epoch 2519, loss function 1.2046613693237305\n",
      "epoch 2520, loss function 1.1997424364089966\n",
      "epoch 2521, loss function 1.1948319673538208\n",
      "epoch 2522, loss function 1.1899601221084595\n",
      "epoch 2523, loss function 1.1850955486297607\n",
      "epoch 2524, loss function 1.1802382469177246\n",
      "epoch 2525, loss function 1.1754220724105835\n",
      "epoch 2526, loss function 1.1706080436706543\n",
      "epoch 2527, loss function 1.1658365726470947\n",
      "epoch 2528, loss function 1.1610726118087769\n",
      "epoch 2529, loss function 1.156314730644226\n",
      "epoch 2530, loss function 1.1515934467315674\n",
      "epoch 2531, loss function 1.146880865097046\n",
      "epoch 2532, loss function 1.1422080993652344\n",
      "epoch 2533, loss function 1.1375395059585571\n",
      "epoch 2534, loss function 1.1328787803649902\n",
      "epoch 2535, loss function 1.1282589435577393\n",
      "epoch 2536, loss function 1.1236408948898315\n",
      "epoch 2537, loss function 1.119052529335022\n",
      "epoch 2538, loss function 1.114480972290039\n",
      "epoch 2539, loss function 1.1099168062210083\n",
      "epoch 2540, loss function 1.1053879261016846\n",
      "epoch 2541, loss function 1.10086989402771\n",
      "epoch 2542, loss function 1.0963630676269531\n",
      "epoch 2543, loss function 1.0918891429901123\n",
      "epoch 2544, loss function 1.08742356300354\n",
      "epoch 2545, loss function 1.0829758644104004\n",
      "epoch 2546, loss function 1.0785512924194336\n",
      "epoch 2547, loss function 1.0741395950317383\n",
      "epoch 2548, loss function 1.0697568655014038\n",
      "epoch 2549, loss function 1.065382719039917\n",
      "epoch 2550, loss function 1.061028242111206\n",
      "epoch 2551, loss function 1.0566970109939575\n",
      "epoch 2552, loss function 1.052375078201294\n",
      "epoch 2553, loss function 1.0480738878250122\n",
      "epoch 2554, loss function 1.043792724609375\n",
      "epoch 2555, loss function 1.0395243167877197\n",
      "epoch 2556, loss function 1.0352706909179688\n",
      "epoch 2557, loss function 1.0310416221618652\n",
      "epoch 2558, loss function 1.0268301963806152\n",
      "epoch 2559, loss function 1.0226391553878784\n",
      "epoch 2560, loss function 1.0184577703475952\n",
      "epoch 2561, loss function 1.0142940282821655\n",
      "epoch 2562, loss function 1.0101511478424072\n",
      "epoch 2563, loss function 1.0060176849365234\n",
      "epoch 2564, loss function 1.0019057989120483\n",
      "epoch 2565, loss function 0.9978158473968506\n",
      "epoch 2566, loss function 0.993744432926178\n",
      "epoch 2567, loss function 0.9896765947341919\n",
      "epoch 2568, loss function 0.9856340885162354\n",
      "epoch 2569, loss function 0.9816071391105652\n",
      "epoch 2570, loss function 0.9775902032852173\n",
      "epoch 2571, loss function 0.9735912680625916\n",
      "epoch 2572, loss function 0.9696142673492432\n",
      "epoch 2573, loss function 0.9656568765640259\n",
      "epoch 2574, loss function 0.9617082476615906\n",
      "epoch 2575, loss function 0.9577763080596924\n",
      "epoch 2576, loss function 0.9538633823394775\n",
      "epoch 2577, loss function 0.9499725103378296\n",
      "epoch 2578, loss function 0.9460898041725159\n",
      "epoch 2579, loss function 0.9422224164009094\n",
      "epoch 2580, loss function 0.9383792877197266\n",
      "epoch 2581, loss function 0.9345402717590332\n",
      "epoch 2582, loss function 0.9307231903076172\n",
      "epoch 2583, loss function 0.9269223809242249\n",
      "epoch 2584, loss function 0.9231300950050354\n",
      "epoch 2585, loss function 0.9193587303161621\n",
      "epoch 2586, loss function 0.9156028628349304\n",
      "epoch 2587, loss function 0.9118579626083374\n",
      "epoch 2588, loss function 0.9081318378448486\n",
      "epoch 2589, loss function 0.9044188857078552\n",
      "epoch 2590, loss function 0.9007171392440796\n",
      "epoch 2591, loss function 0.8970374464988708\n",
      "epoch 2592, loss function 0.8933709859848022\n",
      "epoch 2593, loss function 0.8897179961204529\n",
      "epoch 2594, loss function 0.8860874176025391\n",
      "epoch 2595, loss function 0.8824660778045654\n",
      "epoch 2596, loss function 0.8788560032844543\n",
      "epoch 2597, loss function 0.8752696514129639\n",
      "epoch 2598, loss function 0.8716946244239807\n",
      "epoch 2599, loss function 0.8681252598762512\n",
      "epoch 2600, loss function 0.8645818829536438\n",
      "epoch 2601, loss function 0.8610517978668213\n",
      "epoch 2602, loss function 0.8575273156166077\n",
      "epoch 2603, loss function 0.8540248274803162\n",
      "epoch 2604, loss function 0.8505386710166931\n",
      "epoch 2605, loss function 0.8470538854598999\n",
      "epoch 2606, loss function 0.8435987234115601\n",
      "epoch 2607, loss function 0.840153694152832\n",
      "epoch 2608, loss function 0.8367117643356323\n",
      "epoch 2609, loss function 0.8332959413528442\n",
      "epoch 2610, loss function 0.8298940658569336\n",
      "epoch 2611, loss function 0.8264949917793274\n",
      "epoch 2612, loss function 0.8231281042098999\n",
      "epoch 2613, loss function 0.819762647151947\n",
      "epoch 2614, loss function 0.8164054155349731\n",
      "epoch 2615, loss function 0.8130791187286377\n",
      "epoch 2616, loss function 0.8097550272941589\n",
      "epoch 2617, loss function 0.8064424991607666\n",
      "epoch 2618, loss function 0.8031534552574158\n",
      "epoch 2619, loss function 0.799871563911438\n",
      "epoch 2620, loss function 0.7965986728668213\n",
      "epoch 2621, loss function 0.793351948261261\n",
      "epoch 2622, loss function 0.7901123762130737\n",
      "epoch 2623, loss function 0.7868781089782715\n",
      "epoch 2624, loss function 0.783669114112854\n",
      "epoch 2625, loss function 0.7804715633392334\n",
      "epoch 2626, loss function 0.777279257774353\n",
      "epoch 2627, loss function 0.7741103768348694\n",
      "epoch 2628, loss function 0.7709539532661438\n",
      "epoch 2629, loss function 0.7677969932556152\n",
      "epoch 2630, loss function 0.7646631002426147\n",
      "epoch 2631, loss function 0.761542558670044\n",
      "epoch 2632, loss function 0.7584254145622253\n",
      "epoch 2633, loss function 0.7553216218948364\n",
      "epoch 2634, loss function 0.7522403597831726\n",
      "epoch 2635, loss function 0.7491644024848938\n",
      "epoch 2636, loss function 0.7460983395576477\n",
      "epoch 2637, loss function 0.7430533766746521\n",
      "epoch 2638, loss function 0.7400192618370056\n",
      "epoch 2639, loss function 0.7369899153709412\n",
      "epoch 2640, loss function 0.7339826822280884\n",
      "epoch 2641, loss function 0.7309880256652832\n",
      "epoch 2642, loss function 0.7279931902885437\n",
      "epoch 2643, loss function 0.7250280380249023\n",
      "epoch 2644, loss function 0.7220680713653564\n",
      "epoch 2645, loss function 0.719113826751709\n",
      "epoch 2646, loss function 0.7161744236946106\n",
      "epoch 2647, loss function 0.7132521867752075\n",
      "epoch 2648, loss function 0.7103350162506104\n",
      "epoch 2649, loss function 0.7074264883995056\n",
      "epoch 2650, loss function 0.7045429348945618\n",
      "epoch 2651, loss function 0.7016650438308716\n",
      "epoch 2652, loss function 0.6987924575805664\n",
      "epoch 2653, loss function 0.6959434151649475\n",
      "epoch 2654, loss function 0.693100094795227\n",
      "epoch 2655, loss function 0.6902669668197632\n",
      "epoch 2656, loss function 0.6874460577964783\n",
      "epoch 2657, loss function 0.6846410632133484\n",
      "epoch 2658, loss function 0.6818420886993408\n",
      "epoch 2659, loss function 0.6790549755096436\n",
      "epoch 2660, loss function 0.6762856245040894\n",
      "epoch 2661, loss function 0.6735216379165649\n",
      "epoch 2662, loss function 0.6707656383514404\n",
      "epoch 2663, loss function 0.6680312156677246\n",
      "epoch 2664, loss function 0.6653048992156982\n",
      "epoch 2665, loss function 0.6625829339027405\n",
      "epoch 2666, loss function 0.6598743200302124\n",
      "epoch 2667, loss function 0.6571836471557617\n",
      "epoch 2668, loss function 0.6544954776763916\n",
      "epoch 2669, loss function 0.6518266797065735\n",
      "epoch 2670, loss function 0.649167001247406\n",
      "epoch 2671, loss function 0.6465118527412415\n",
      "epoch 2672, loss function 0.6438691020011902\n",
      "epoch 2673, loss function 0.6412378549575806\n",
      "epoch 2674, loss function 0.638620913028717\n",
      "epoch 2675, loss function 0.6360107064247131\n",
      "epoch 2676, loss function 0.6334139704704285\n",
      "epoch 2677, loss function 0.6308284997940063\n",
      "epoch 2678, loss function 0.6282500624656677\n",
      "epoch 2679, loss function 0.6256793737411499\n",
      "epoch 2680, loss function 0.6231240034103394\n",
      "epoch 2681, loss function 0.6205768585205078\n",
      "epoch 2682, loss function 0.6180418133735657\n",
      "epoch 2683, loss function 0.6155156493186951\n",
      "epoch 2684, loss function 0.6130064129829407\n",
      "epoch 2685, loss function 0.610504686832428\n",
      "epoch 2686, loss function 0.6080045700073242\n",
      "epoch 2687, loss function 0.6055172085762024\n",
      "epoch 2688, loss function 0.6030466556549072\n",
      "epoch 2689, loss function 0.600581705570221\n",
      "epoch 2690, loss function 0.5981294512748718\n",
      "epoch 2691, loss function 0.5956919193267822\n",
      "epoch 2692, loss function 0.5932598114013672\n",
      "epoch 2693, loss function 0.5908311009407043\n",
      "epoch 2694, loss function 0.5884155631065369\n",
      "epoch 2695, loss function 0.5860180854797363\n",
      "epoch 2696, loss function 0.5836209654808044\n",
      "epoch 2697, loss function 0.5812404751777649\n",
      "epoch 2698, loss function 0.578860342502594\n",
      "epoch 2699, loss function 0.5764985680580139\n",
      "epoch 2700, loss function 0.5741419196128845\n",
      "epoch 2701, loss function 0.5717954039573669\n",
      "epoch 2702, loss function 0.5694639682769775\n",
      "epoch 2703, loss function 0.5671365857124329\n",
      "epoch 2704, loss function 0.5648240447044373\n",
      "epoch 2705, loss function 0.5625146627426147\n",
      "epoch 2706, loss function 0.5602221488952637\n",
      "epoch 2707, loss function 0.5579311847686768\n",
      "epoch 2708, loss function 0.555651068687439\n",
      "epoch 2709, loss function 0.5533814430236816\n",
      "epoch 2710, loss function 0.5511218309402466\n",
      "epoch 2711, loss function 0.54886794090271\n",
      "epoch 2712, loss function 0.5466263294219971\n",
      "epoch 2713, loss function 0.5443909764289856\n",
      "epoch 2714, loss function 0.5421658754348755\n",
      "epoch 2715, loss function 0.539955198764801\n",
      "epoch 2716, loss function 0.5377492904663086\n",
      "epoch 2717, loss function 0.5355567336082458\n",
      "epoch 2718, loss function 0.5333684682846069\n",
      "epoch 2719, loss function 0.5311911702156067\n",
      "epoch 2720, loss function 0.5290206670761108\n",
      "epoch 2721, loss function 0.526861310005188\n",
      "epoch 2722, loss function 0.5247067213058472\n",
      "epoch 2723, loss function 0.5225656628608704\n",
      "epoch 2724, loss function 0.5204306244850159\n",
      "epoch 2725, loss function 0.5183031558990479\n",
      "epoch 2726, loss function 0.5161868333816528\n",
      "epoch 2727, loss function 0.5140762329101562\n",
      "epoch 2728, loss function 0.5119757056236267\n",
      "epoch 2729, loss function 0.509884774684906\n",
      "epoch 2730, loss function 0.5078043937683105\n",
      "epoch 2731, loss function 0.5057305097579956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2732, loss function 0.5036635994911194\n",
      "epoch 2733, loss function 0.501606285572052\n",
      "epoch 2734, loss function 0.4995603561401367\n",
      "epoch 2735, loss function 0.49752160906791687\n",
      "epoch 2736, loss function 0.49548599123954773\n",
      "epoch 2737, loss function 0.4934607446193695\n",
      "epoch 2738, loss function 0.4914475679397583\n",
      "epoch 2739, loss function 0.4894402027130127\n",
      "epoch 2740, loss function 0.48743876814842224\n",
      "epoch 2741, loss function 0.4854463040828705\n",
      "epoch 2742, loss function 0.48346760869026184\n",
      "epoch 2743, loss function 0.4814893305301666\n",
      "epoch 2744, loss function 0.47952204942703247\n",
      "epoch 2745, loss function 0.4775623381137848\n",
      "epoch 2746, loss function 0.47561246156692505\n",
      "epoch 2747, loss function 0.4736710488796234\n",
      "epoch 2748, loss function 0.4717331528663635\n",
      "epoch 2749, loss function 0.46980559825897217\n",
      "epoch 2750, loss function 0.4678896367549896\n",
      "epoch 2751, loss function 0.4659789204597473\n",
      "epoch 2752, loss function 0.4640708565711975\n",
      "epoch 2753, loss function 0.4621734619140625\n",
      "epoch 2754, loss function 0.46028783917427063\n",
      "epoch 2755, loss function 0.45840948820114136\n",
      "epoch 2756, loss function 0.4565335810184479\n",
      "epoch 2757, loss function 0.45466646552085876\n",
      "epoch 2758, loss function 0.45281466841697693\n",
      "epoch 2759, loss function 0.4509623050689697\n",
      "epoch 2760, loss function 0.4491199851036072\n",
      "epoch 2761, loss function 0.4472850561141968\n",
      "epoch 2762, loss function 0.4454590082168579\n",
      "epoch 2763, loss function 0.44364267587661743\n",
      "epoch 2764, loss function 0.44182828068733215\n",
      "epoch 2765, loss function 0.4400237202644348\n",
      "epoch 2766, loss function 0.4382306933403015\n",
      "epoch 2767, loss function 0.4364415109157562\n",
      "epoch 2768, loss function 0.4346572160720825\n",
      "epoch 2769, loss function 0.4328809678554535\n",
      "epoch 2770, loss function 0.43111610412597656\n",
      "epoch 2771, loss function 0.4293569326400757\n",
      "epoch 2772, loss function 0.4276038408279419\n",
      "epoch 2773, loss function 0.4258567988872528\n",
      "epoch 2774, loss function 0.4241181015968323\n",
      "epoch 2775, loss function 0.4223858416080475\n",
      "epoch 2776, loss function 0.4206620752811432\n",
      "epoch 2777, loss function 0.41893768310546875\n",
      "epoch 2778, loss function 0.4172270894050598\n",
      "epoch 2779, loss function 0.4155270755290985\n",
      "epoch 2780, loss function 0.4138302206993103\n",
      "epoch 2781, loss function 0.41213440895080566\n",
      "epoch 2782, loss function 0.41045111417770386\n",
      "epoch 2783, loss function 0.4087791442871094\n",
      "epoch 2784, loss function 0.4071106016635895\n",
      "epoch 2785, loss function 0.4054447412490845\n",
      "epoch 2786, loss function 0.4037916660308838\n",
      "epoch 2787, loss function 0.4021470248699188\n",
      "epoch 2788, loss function 0.40050581097602844\n",
      "epoch 2789, loss function 0.3988679051399231\n",
      "epoch 2790, loss function 0.39723455905914307\n",
      "epoch 2791, loss function 0.3956112861633301\n",
      "epoch 2792, loss function 0.39399898052215576\n",
      "epoch 2793, loss function 0.3923896551132202\n",
      "epoch 2794, loss function 0.3907833993434906\n",
      "epoch 2795, loss function 0.3891867399215698\n",
      "epoch 2796, loss function 0.387602299451828\n",
      "epoch 2797, loss function 0.3860219419002533\n",
      "epoch 2798, loss function 0.384443074464798\n",
      "epoch 2799, loss function 0.3828739523887634\n",
      "epoch 2800, loss function 0.3813157379627228\n",
      "epoch 2801, loss function 0.37976035475730896\n",
      "epoch 2802, loss function 0.3782086968421936\n",
      "epoch 2803, loss function 0.37666091322898865\n",
      "epoch 2804, loss function 0.37512362003326416\n",
      "epoch 2805, loss function 0.3735942244529724\n",
      "epoch 2806, loss function 0.37206771969795227\n",
      "epoch 2807, loss function 0.3705470561981201\n",
      "epoch 2808, loss function 0.36903470754623413\n",
      "epoch 2809, loss function 0.36753371357917786\n",
      "epoch 2810, loss function 0.3660353720188141\n",
      "epoch 2811, loss function 0.3645402193069458\n",
      "epoch 2812, loss function 0.36304739117622375\n",
      "epoch 2813, loss function 0.36156541109085083\n",
      "epoch 2814, loss function 0.3600919544696808\n",
      "epoch 2815, loss function 0.35862231254577637\n",
      "epoch 2816, loss function 0.35715630650520325\n",
      "epoch 2817, loss function 0.3556942641735077\n",
      "epoch 2818, loss function 0.35424765944480896\n",
      "epoch 2819, loss function 0.3528033196926117\n",
      "epoch 2820, loss function 0.3513629138469696\n",
      "epoch 2821, loss function 0.3499250113964081\n",
      "epoch 2822, loss function 0.34849587082862854\n",
      "epoch 2823, loss function 0.34707629680633545\n",
      "epoch 2824, loss function 0.3456609845161438\n",
      "epoch 2825, loss function 0.3442501723766327\n",
      "epoch 2826, loss function 0.3428400754928589\n",
      "epoch 2827, loss function 0.34144026041030884\n",
      "epoch 2828, loss function 0.3400501012802124\n",
      "epoch 2829, loss function 0.3386614918708801\n",
      "epoch 2830, loss function 0.3372773826122284\n",
      "epoch 2831, loss function 0.3358955383300781\n",
      "epoch 2832, loss function 0.334528386592865\n",
      "epoch 2833, loss function 0.3331664204597473\n",
      "epoch 2834, loss function 0.33180683851242065\n",
      "epoch 2835, loss function 0.33044832944869995\n",
      "epoch 2836, loss function 0.32909297943115234\n",
      "epoch 2837, loss function 0.32775381207466125\n",
      "epoch 2838, loss function 0.3264174163341522\n",
      "epoch 2839, loss function 0.32508477568626404\n",
      "epoch 2840, loss function 0.3237539529800415\n",
      "epoch 2841, loss function 0.32243460416793823\n",
      "epoch 2842, loss function 0.32112324237823486\n",
      "epoch 2843, loss function 0.3198128938674927\n",
      "epoch 2844, loss function 0.3185054063796997\n",
      "epoch 2845, loss function 0.31720268726348877\n",
      "epoch 2846, loss function 0.31590816378593445\n",
      "epoch 2847, loss function 0.3146232068538666\n",
      "epoch 2848, loss function 0.3133389949798584\n",
      "epoch 2849, loss function 0.31205862760543823\n",
      "epoch 2850, loss function 0.31078100204467773\n",
      "epoch 2851, loss function 0.30951374769210815\n",
      "epoch 2852, loss function 0.30825257301330566\n",
      "epoch 2853, loss function 0.30699479579925537\n",
      "epoch 2854, loss function 0.3057401180267334\n",
      "epoch 2855, loss function 0.3044891059398651\n",
      "epoch 2856, loss function 0.30324608087539673\n",
      "epoch 2857, loss function 0.30201178789138794\n",
      "epoch 2858, loss function 0.3007807433605194\n",
      "epoch 2859, loss function 0.29955124855041504\n",
      "epoch 2860, loss function 0.2983240783214569\n",
      "epoch 2861, loss function 0.2971057593822479\n",
      "epoch 2862, loss function 0.295896053314209\n",
      "epoch 2863, loss function 0.2946893572807312\n",
      "epoch 2864, loss function 0.29348620772361755\n",
      "epoch 2865, loss function 0.2922832667827606\n",
      "epoch 2866, loss function 0.29109135270118713\n",
      "epoch 2867, loss function 0.2899058163166046\n",
      "epoch 2868, loss function 0.28872382640838623\n",
      "epoch 2869, loss function 0.2875438928604126\n",
      "epoch 2870, loss function 0.28636670112609863\n",
      "epoch 2871, loss function 0.28519773483276367\n",
      "epoch 2872, loss function 0.28403782844543457\n",
      "epoch 2873, loss function 0.2828812301158905\n",
      "epoch 2874, loss function 0.28172433376312256\n",
      "epoch 2875, loss function 0.280571311712265\n",
      "epoch 2876, loss function 0.27942216396331787\n",
      "epoch 2877, loss function 0.2782861590385437\n",
      "epoch 2878, loss function 0.277151882648468\n",
      "epoch 2879, loss function 0.2760198712348938\n",
      "epoch 2880, loss function 0.27489084005355835\n",
      "epoch 2881, loss function 0.2737647593021393\n",
      "epoch 2882, loss function 0.2726512849330902\n",
      "epoch 2883, loss function 0.27154162526130676\n",
      "epoch 2884, loss function 0.270434707403183\n",
      "epoch 2885, loss function 0.2693277895450592\n",
      "epoch 2886, loss function 0.2682240903377533\n",
      "epoch 2887, loss function 0.2671317160129547\n",
      "epoch 2888, loss function 0.26604267954826355\n",
      "epoch 2889, loss function 0.26495930552482605\n",
      "epoch 2890, loss function 0.26387447118759155\n",
      "epoch 2891, loss function 0.2627960443496704\n",
      "epoch 2892, loss function 0.26172178983688354\n",
      "epoch 2893, loss function 0.26065829396247864\n",
      "epoch 2894, loss function 0.25959599018096924\n",
      "epoch 2895, loss function 0.25853705406188965\n",
      "epoch 2896, loss function 0.25747910141944885\n",
      "epoch 2897, loss function 0.2564232051372528\n",
      "epoch 2898, loss function 0.2553802728652954\n",
      "epoch 2899, loss function 0.2543408274650574\n",
      "epoch 2900, loss function 0.2533027231693268\n",
      "epoch 2901, loss function 0.252267450094223\n",
      "epoch 2902, loss function 0.2512347400188446\n",
      "epoch 2903, loss function 0.2502109408378601\n",
      "epoch 2904, loss function 0.24919354915618896\n",
      "epoch 2905, loss function 0.24817773699760437\n",
      "epoch 2906, loss function 0.24716338515281677\n",
      "epoch 2907, loss function 0.2461528480052948\n",
      "epoch 2908, loss function 0.245144784450531\n",
      "epoch 2909, loss function 0.2441466897726059\n",
      "epoch 2910, loss function 0.24315449595451355\n",
      "epoch 2911, loss function 0.242160826921463\n",
      "epoch 2912, loss function 0.241172194480896\n",
      "epoch 2913, loss function 0.24018394947052002\n",
      "epoch 2914, loss function 0.23920512199401855\n",
      "epoch 2915, loss function 0.23823437094688416\n",
      "epoch 2916, loss function 0.23726274073123932\n",
      "epoch 2917, loss function 0.23629210889339447\n",
      "epoch 2918, loss function 0.23532678186893463\n",
      "epoch 2919, loss function 0.23436397314071655\n",
      "epoch 2920, loss function 0.2334078848361969\n",
      "epoch 2921, loss function 0.23245759308338165\n",
      "epoch 2922, loss function 0.23150961101055145\n",
      "epoch 2923, loss function 0.2305644005537033\n",
      "epoch 2924, loss function 0.22962087392807007\n",
      "epoch 2925, loss function 0.22867943346500397\n",
      "epoch 2926, loss function 0.22774994373321533\n",
      "epoch 2927, loss function 0.22682219743728638\n",
      "epoch 2928, loss function 0.22589686512947083\n",
      "epoch 2929, loss function 0.22497454285621643\n",
      "epoch 2930, loss function 0.22405391931533813\n",
      "epoch 2931, loss function 0.22314049303531647\n",
      "epoch 2932, loss function 0.22223332524299622\n",
      "epoch 2933, loss function 0.2213285267353058\n",
      "epoch 2934, loss function 0.22042465209960938\n",
      "epoch 2935, loss function 0.2195235937833786\n",
      "epoch 2936, loss function 0.21862530708312988\n",
      "epoch 2937, loss function 0.21773473918437958\n",
      "epoch 2938, loss function 0.21684876084327698\n",
      "epoch 2939, loss function 0.21596473455429077\n",
      "epoch 2940, loss function 0.2150844931602478\n",
      "epoch 2941, loss function 0.21420502662658691\n",
      "epoch 2942, loss function 0.21332800388336182\n",
      "epoch 2943, loss function 0.2124575972557068\n",
      "epoch 2944, loss function 0.21159429848194122\n",
      "epoch 2945, loss function 0.2107311636209488\n",
      "epoch 2946, loss function 0.2098715901374817\n",
      "epoch 2947, loss function 0.20901282131671906\n",
      "epoch 2948, loss function 0.20815801620483398\n",
      "epoch 2949, loss function 0.20730949938297272\n",
      "epoch 2950, loss function 0.2064666450023651\n",
      "epoch 2951, loss function 0.20562465488910675\n",
      "epoch 2952, loss function 0.20478573441505432\n",
      "epoch 2953, loss function 0.2039490044116974\n",
      "epoch 2954, loss function 0.20311370491981506\n",
      "epoch 2955, loss function 0.20228451490402222\n",
      "epoch 2956, loss function 0.20146340131759644\n",
      "epoch 2957, loss function 0.20064279437065125\n",
      "epoch 2958, loss function 0.19982409477233887\n",
      "epoch 2959, loss function 0.1990068256855011\n",
      "epoch 2960, loss function 0.19819232821464539\n",
      "epoch 2961, loss function 0.19738534092903137\n",
      "epoch 2962, loss function 0.196583092212677\n",
      "epoch 2963, loss function 0.19578160345554352\n",
      "epoch 2964, loss function 0.19498391449451447\n",
      "epoch 2965, loss function 0.19418734312057495\n",
      "epoch 2966, loss function 0.1933923214673996\n",
      "epoch 2967, loss function 0.19259941577911377\n",
      "epoch 2968, loss function 0.1918170154094696\n",
      "epoch 2969, loss function 0.19103682041168213\n",
      "epoch 2970, loss function 0.1902581751346588\n",
      "epoch 2971, loss function 0.18948030471801758\n",
      "epoch 2972, loss function 0.18870513141155243\n",
      "epoch 2973, loss function 0.18793140351772308\n",
      "epoch 2974, loss function 0.18716520071029663\n",
      "epoch 2975, loss function 0.18640616536140442\n",
      "epoch 2976, loss function 0.18564581871032715\n",
      "epoch 2977, loss function 0.18488752841949463\n",
      "epoch 2978, loss function 0.1841311901807785\n",
      "epoch 2979, loss function 0.1833786964416504\n",
      "epoch 2980, loss function 0.1826297640800476\n",
      "epoch 2981, loss function 0.1818886697292328\n",
      "epoch 2982, loss function 0.1811469942331314\n",
      "epoch 2983, loss function 0.18040978908538818\n",
      "epoch 2984, loss function 0.17967146635055542\n",
      "epoch 2985, loss function 0.17893780767917633\n",
      "epoch 2986, loss function 0.17820334434509277\n",
      "epoch 2987, loss function 0.17747582495212555\n",
      "epoch 2988, loss function 0.17675569653511047\n",
      "epoch 2989, loss function 0.17603491246700287\n",
      "epoch 2990, loss function 0.17531533539295197\n",
      "epoch 2991, loss function 0.17459848523139954\n",
      "epoch 2992, loss function 0.17388474941253662\n",
      "epoch 2993, loss function 0.17317619919776917\n",
      "epoch 2994, loss function 0.17247256636619568\n",
      "epoch 2995, loss function 0.17177078127861023\n",
      "epoch 2996, loss function 0.1710699498653412\n",
      "epoch 2997, loss function 0.17037132382392883\n",
      "epoch 2998, loss function 0.16967399418354034\n",
      "epoch 2999, loss function 0.1689789593219757\n",
      "epoch 3000, loss function 0.16828888654708862\n",
      "epoch 3001, loss function 0.167603999376297\n",
      "epoch 3002, loss function 0.16692188382148743\n",
      "epoch 3003, loss function 0.16624200344085693\n",
      "epoch 3004, loss function 0.16556203365325928\n",
      "epoch 3005, loss function 0.16488327085971832\n",
      "epoch 3006, loss function 0.16421306133270264\n",
      "epoch 3007, loss function 0.16354188323020935\n",
      "epoch 3008, loss function 0.16287820041179657\n",
      "epoch 3009, loss function 0.16221307218074799\n",
      "epoch 3010, loss function 0.16155274212360382\n",
      "epoch 3011, loss function 0.16089029610157013\n",
      "epoch 3012, loss function 0.16023319959640503\n",
      "epoch 3013, loss function 0.1595792919397354\n",
      "epoch 3014, loss function 0.15892724692821503\n",
      "epoch 3015, loss function 0.15828201174736023\n",
      "epoch 3016, loss function 0.1576378494501114\n",
      "epoch 3017, loss function 0.15699347853660583\n",
      "epoch 3018, loss function 0.15635046362876892\n",
      "epoch 3019, loss function 0.15571123361587524\n",
      "epoch 3020, loss function 0.15507687628269196\n",
      "epoch 3021, loss function 0.15444357693195343\n",
      "epoch 3022, loss function 0.15381529927253723\n",
      "epoch 3023, loss function 0.15318839251995087\n",
      "epoch 3024, loss function 0.15256336331367493\n",
      "epoch 3025, loss function 0.15193915367126465\n",
      "epoch 3026, loss function 0.1513167917728424\n",
      "epoch 3027, loss function 0.15069986879825592\n",
      "epoch 3028, loss function 0.1500852257013321\n",
      "epoch 3029, loss function 0.14947527647018433\n",
      "epoch 3030, loss function 0.1488656997680664\n",
      "epoch 3031, loss function 0.1482575535774231\n",
      "epoch 3032, loss function 0.14765185117721558\n",
      "epoch 3033, loss function 0.14704802632331848\n",
      "epoch 3034, loss function 0.14644759893417358\n",
      "epoch 3035, loss function 0.1458510011434555\n",
      "epoch 3036, loss function 0.14525704085826874\n",
      "epoch 3037, loss function 0.144666850566864\n",
      "epoch 3038, loss function 0.1440754532814026\n",
      "epoch 3039, loss function 0.1434873789548874\n",
      "epoch 3040, loss function 0.14289917051792145\n",
      "epoch 3041, loss function 0.14231784641742706\n",
      "epoch 3042, loss function 0.14173807203769684\n",
      "epoch 3043, loss function 0.14116171002388\n",
      "epoch 3044, loss function 0.14058679342269897\n",
      "epoch 3045, loss function 0.14001360535621643\n",
      "epoch 3046, loss function 0.13944199681282043\n",
      "epoch 3047, loss function 0.1388709843158722\n",
      "epoch 3048, loss function 0.1383010745048523\n",
      "epoch 3049, loss function 0.13773715496063232\n",
      "epoch 3050, loss function 0.1371782422065735\n",
      "epoch 3051, loss function 0.13662026822566986\n",
      "epoch 3052, loss function 0.1360633224248886\n",
      "epoch 3053, loss function 0.13550804555416107\n",
      "epoch 3054, loss function 0.13495346903800964\n",
      "epoch 3055, loss function 0.13440096378326416\n",
      "epoch 3056, loss function 0.13385388255119324\n",
      "epoch 3057, loss function 0.13330838084220886\n",
      "epoch 3058, loss function 0.13276608288288116\n",
      "epoch 3059, loss function 0.13222531974315643\n",
      "epoch 3060, loss function 0.13168688118457794\n",
      "epoch 3061, loss function 0.1311492919921875\n",
      "epoch 3062, loss function 0.13061118125915527\n",
      "epoch 3063, loss function 0.13007579743862152\n",
      "epoch 3064, loss function 0.12954649329185486\n",
      "epoch 3065, loss function 0.12901629507541656\n",
      "epoch 3066, loss function 0.1284930258989334\n",
      "epoch 3067, loss function 0.12796805799007416\n",
      "epoch 3068, loss function 0.12744715809822083\n",
      "epoch 3069, loss function 0.12692460417747498\n",
      "epoch 3070, loss function 0.12640617787837982\n",
      "epoch 3071, loss function 0.1258915364742279\n",
      "epoch 3072, loss function 0.1253770887851715\n",
      "epoch 3073, loss function 0.12486869096755981\n",
      "epoch 3074, loss function 0.12436174601316452\n",
      "epoch 3075, loss function 0.12385393679141998\n",
      "epoch 3076, loss function 0.12334778904914856\n",
      "epoch 3077, loss function 0.12284326553344727\n",
      "epoch 3078, loss function 0.12234113365411758\n",
      "epoch 3079, loss function 0.12184290587902069\n",
      "epoch 3080, loss function 0.12134568393230438\n",
      "epoch 3081, loss function 0.12085294723510742\n",
      "epoch 3082, loss function 0.12036100029945374\n",
      "epoch 3083, loss function 0.11987068504095078\n",
      "epoch 3084, loss function 0.11938096582889557\n",
      "epoch 3085, loss function 0.11889252066612244\n",
      "epoch 3086, loss function 0.11840551346540451\n",
      "epoch 3087, loss function 0.11792273819446564\n",
      "epoch 3088, loss function 0.1174411028623581\n",
      "epoch 3089, loss function 0.11696469038724899\n",
      "epoch 3090, loss function 0.11648941040039062\n",
      "epoch 3091, loss function 0.11601399630308151\n",
      "epoch 3092, loss function 0.11553974449634552\n",
      "epoch 3093, loss function 0.1150670200586319\n",
      "epoch 3094, loss function 0.11459646373987198\n",
      "epoch 3095, loss function 0.11412835866212845\n",
      "epoch 3096, loss function 0.11366438865661621\n",
      "epoch 3097, loss function 0.11320196092128754\n",
      "epoch 3098, loss function 0.1127423346042633\n",
      "epoch 3099, loss function 0.11228173971176147\n",
      "epoch 3100, loss function 0.11182453483343124\n",
      "epoch 3101, loss function 0.1113661602139473\n",
      "epoch 3102, loss function 0.11091053485870361\n",
      "epoch 3103, loss function 0.11045759916305542\n",
      "epoch 3104, loss function 0.11000709980726242\n",
      "epoch 3105, loss function 0.10955801606178284\n",
      "epoch 3106, loss function 0.10911345481872559\n",
      "epoch 3107, loss function 0.10866837948560715\n",
      "epoch 3108, loss function 0.10822425782680511\n",
      "epoch 3109, loss function 0.10778216272592545\n",
      "epoch 3110, loss function 0.1073414757847786\n",
      "epoch 3111, loss function 0.10690455138683319\n",
      "epoch 3112, loss function 0.10646897554397583\n",
      "epoch 3113, loss function 0.10603432357311249\n",
      "epoch 3114, loss function 0.10560393333435059\n",
      "epoch 3115, loss function 0.10517406463623047\n",
      "epoch 3116, loss function 0.10474473237991333\n",
      "epoch 3117, loss function 0.10431656986474991\n",
      "epoch 3118, loss function 0.10388967394828796\n",
      "epoch 3119, loss function 0.10346616804599762\n",
      "epoch 3120, loss function 0.10304446518421173\n",
      "epoch 3121, loss function 0.10262437909841537\n",
      "epoch 3122, loss function 0.102205790579319\n",
      "epoch 3123, loss function 0.10178960114717484\n",
      "epoch 3124, loss function 0.10137514770030975\n",
      "epoch 3125, loss function 0.10096169263124466\n",
      "epoch 3126, loss function 0.10054938495159149\n",
      "epoch 3127, loss function 0.10013652592897415\n",
      "epoch 3128, loss function 0.09972900152206421\n",
      "epoch 3129, loss function 0.09932337701320648\n",
      "epoch 3130, loss function 0.09891793876886368\n",
      "epoch 3131, loss function 0.0985163077712059\n",
      "epoch 3132, loss function 0.09811525791883469\n",
      "epoch 3133, loss function 0.09771519154310226\n",
      "epoch 3134, loss function 0.09731637686491013\n",
      "epoch 3135, loss function 0.09691838175058365\n",
      "epoch 3136, loss function 0.0965208038687706\n",
      "epoch 3137, loss function 0.09612791240215302\n",
      "epoch 3138, loss function 0.09573668241500854\n",
      "epoch 3139, loss function 0.0953461155295372\n",
      "epoch 3140, loss function 0.09495879709720612\n",
      "epoch 3141, loss function 0.09457201510667801\n",
      "epoch 3142, loss function 0.09418660402297974\n",
      "epoch 3143, loss function 0.09380260109901428\n",
      "epoch 3144, loss function 0.0934174507856369\n",
      "epoch 3145, loss function 0.09303797036409378\n",
      "epoch 3146, loss function 0.09265957027673721\n",
      "epoch 3147, loss function 0.09228136390447617\n",
      "epoch 3148, loss function 0.09190516173839569\n",
      "epoch 3149, loss function 0.09153170138597488\n",
      "epoch 3150, loss function 0.09115936607122421\n",
      "epoch 3151, loss function 0.09078826755285263\n",
      "epoch 3152, loss function 0.090416818857193\n",
      "epoch 3153, loss function 0.09004715085029602\n",
      "epoch 3154, loss function 0.0896817073225975\n",
      "epoch 3155, loss function 0.08931638300418854\n",
      "epoch 3156, loss function 0.08895202726125717\n",
      "epoch 3157, loss function 0.08858955651521683\n",
      "epoch 3158, loss function 0.08822724968194962\n",
      "epoch 3159, loss function 0.08786839246749878\n",
      "epoch 3160, loss function 0.0875094085931778\n",
      "epoch 3161, loss function 0.08715259283781052\n",
      "epoch 3162, loss function 0.08679713308811188\n",
      "epoch 3163, loss function 0.08644049614667892\n",
      "epoch 3164, loss function 0.08608908206224442\n",
      "epoch 3165, loss function 0.08573812246322632\n",
      "epoch 3166, loss function 0.08538830280303955\n",
      "epoch 3167, loss function 0.08503903448581696\n",
      "epoch 3168, loss function 0.08469381183385849\n",
      "epoch 3169, loss function 0.0843489021062851\n",
      "epoch 3170, loss function 0.08400475233793259\n",
      "epoch 3171, loss function 0.0836615338921547\n",
      "epoch 3172, loss function 0.08331885933876038\n",
      "epoch 3173, loss function 0.08297963440418243\n",
      "epoch 3174, loss function 0.08264202624559402\n",
      "epoch 3175, loss function 0.08230569213628769\n",
      "epoch 3176, loss function 0.0819692388176918\n",
      "epoch 3177, loss function 0.0816330686211586\n",
      "epoch 3178, loss function 0.08130159229040146\n",
      "epoch 3179, loss function 0.08097108453512192\n",
      "epoch 3180, loss function 0.08064014464616776\n",
      "epoch 3181, loss function 0.0803096741437912\n",
      "epoch 3182, loss function 0.07998355478048325\n",
      "epoch 3183, loss function 0.0796576738357544\n",
      "epoch 3184, loss function 0.07933323085308075\n",
      "epoch 3185, loss function 0.0790097713470459\n",
      "epoch 3186, loss function 0.07868713140487671\n",
      "epoch 3187, loss function 0.07836776971817017\n",
      "epoch 3188, loss function 0.07804858684539795\n",
      "epoch 3189, loss function 0.07773066312074661\n",
      "epoch 3190, loss function 0.0774131566286087\n",
      "epoch 3191, loss function 0.07709598541259766\n",
      "epoch 3192, loss function 0.07678347080945969\n",
      "epoch 3193, loss function 0.07647110521793365\n",
      "epoch 3194, loss function 0.07615908235311508\n",
      "epoch 3195, loss function 0.07584769278764725\n",
      "epoch 3196, loss function 0.07553859055042267\n",
      "epoch 3197, loss function 0.07522976398468018\n",
      "epoch 3198, loss function 0.07492296397686005\n",
      "epoch 3199, loss function 0.07461710274219513\n",
      "epoch 3200, loss function 0.07431263476610184\n",
      "epoch 3201, loss function 0.0740092471241951\n",
      "epoch 3202, loss function 0.07370741665363312\n",
      "epoch 3203, loss function 0.073408342897892\n",
      "epoch 3204, loss function 0.0731087476015091\n",
      "epoch 3205, loss function 0.07281135022640228\n",
      "epoch 3206, loss function 0.07251255214214325\n",
      "epoch 3207, loss function 0.07221642881631851\n",
      "epoch 3208, loss function 0.07192201912403107\n",
      "epoch 3209, loss function 0.07162968814373016\n",
      "epoch 3210, loss function 0.07133620232343674\n",
      "epoch 3211, loss function 0.07104519754648209\n",
      "epoch 3212, loss function 0.07075659185647964\n",
      "epoch 3213, loss function 0.07046788185834885\n",
      "epoch 3214, loss function 0.07018129527568817\n",
      "epoch 3215, loss function 0.06989554315805435\n",
      "epoch 3216, loss function 0.06960943341255188\n",
      "epoch 3217, loss function 0.06932435184717178\n",
      "epoch 3218, loss function 0.0690428763628006\n",
      "epoch 3219, loss function 0.06876230239868164\n",
      "epoch 3220, loss function 0.06848123669624329\n",
      "epoch 3221, loss function 0.06820069253444672\n",
      "epoch 3222, loss function 0.0679241344332695\n",
      "epoch 3223, loss function 0.0676477774977684\n",
      "epoch 3224, loss function 0.06737247854471207\n",
      "epoch 3225, loss function 0.06709739565849304\n",
      "epoch 3226, loss function 0.06682348996400833\n",
      "epoch 3227, loss function 0.06655009835958481\n",
      "epoch 3228, loss function 0.06627734005451202\n",
      "epoch 3229, loss function 0.06600823253393173\n",
      "epoch 3230, loss function 0.06573894619941711\n",
      "epoch 3231, loss function 0.0654706284403801\n",
      "epoch 3232, loss function 0.06520246714353561\n",
      "epoch 3233, loss function 0.06493827700614929\n",
      "epoch 3234, loss function 0.06467489153146744\n",
      "epoch 3235, loss function 0.06441055238246918\n",
      "epoch 3236, loss function 0.06414736062288284\n",
      "epoch 3237, loss function 0.06388538330793381\n",
      "epoch 3238, loss function 0.06362461298704147\n",
      "epoch 3239, loss function 0.06336364895105362\n",
      "epoch 3240, loss function 0.06310518831014633\n",
      "epoch 3241, loss function 0.0628485232591629\n",
      "epoch 3242, loss function 0.0625922903418541\n",
      "epoch 3243, loss function 0.06233780086040497\n",
      "epoch 3244, loss function 0.062085483223199844\n",
      "epoch 3245, loss function 0.0618322379887104\n",
      "epoch 3246, loss function 0.06158094108104706\n",
      "epoch 3247, loss function 0.061328548938035965\n",
      "epoch 3248, loss function 0.0610790029168129\n",
      "epoch 3249, loss function 0.06082820147275925\n",
      "epoch 3250, loss function 0.060579508543014526\n",
      "epoch 3251, loss function 0.060332395136356354\n",
      "epoch 3252, loss function 0.06008736416697502\n",
      "epoch 3253, loss function 0.05984123796224594\n",
      "epoch 3254, loss function 0.05959891900420189\n",
      "epoch 3255, loss function 0.05935779958963394\n",
      "epoch 3256, loss function 0.05911596864461899\n",
      "epoch 3257, loss function 0.05887477099895477\n",
      "epoch 3258, loss function 0.058634668588638306\n",
      "epoch 3259, loss function 0.058395884931087494\n",
      "epoch 3260, loss function 0.058156054466962814\n",
      "epoch 3261, loss function 0.05791819840669632\n",
      "epoch 3262, loss function 0.05768290162086487\n",
      "epoch 3263, loss function 0.057448387145996094\n",
      "epoch 3264, loss function 0.05721369758248329\n",
      "epoch 3265, loss function 0.05698199197649956\n",
      "epoch 3266, loss function 0.05675085633993149\n",
      "epoch 3267, loss function 0.056520141661167145\n",
      "epoch 3268, loss function 0.056290674954652786\n",
      "epoch 3269, loss function 0.05606084316968918\n",
      "epoch 3270, loss function 0.05583170801401138\n",
      "epoch 3271, loss function 0.055603593587875366\n",
      "epoch 3272, loss function 0.05537610873579979\n",
      "epoch 3273, loss function 0.05514892563223839\n",
      "epoch 3274, loss function 0.05492466688156128\n",
      "epoch 3275, loss function 0.054700639098882675\n",
      "epoch 3276, loss function 0.054477300494909286\n",
      "epoch 3277, loss function 0.05425713211297989\n",
      "epoch 3278, loss function 0.05403674393892288\n",
      "epoch 3279, loss function 0.053816620260477066\n",
      "epoch 3280, loss function 0.05359770357608795\n",
      "epoch 3281, loss function 0.05337926372885704\n",
      "epoch 3282, loss function 0.053160734474658966\n",
      "epoch 3283, loss function 0.05294292792677879\n",
      "epoch 3284, loss function 0.052726779133081436\n",
      "epoch 3285, loss function 0.05251068249344826\n",
      "epoch 3286, loss function 0.05229648947715759\n",
      "epoch 3287, loss function 0.05208342522382736\n",
      "epoch 3288, loss function 0.051873549818992615\n",
      "epoch 3289, loss function 0.051662739366292953\n",
      "epoch 3290, loss function 0.05145395174622536\n",
      "epoch 3291, loss function 0.051244061440229416\n",
      "epoch 3292, loss function 0.05103620886802673\n",
      "epoch 3293, loss function 0.05082743614912033\n",
      "epoch 3294, loss function 0.050620246678590775\n",
      "epoch 3295, loss function 0.050412412732839584\n",
      "epoch 3296, loss function 0.05020697042346001\n",
      "epoch 3297, loss function 0.050000376999378204\n",
      "epoch 3298, loss function 0.04979748651385307\n",
      "epoch 3299, loss function 0.04959399253129959\n",
      "epoch 3300, loss function 0.04939383268356323\n",
      "epoch 3301, loss function 0.04919455200433731\n",
      "epoch 3302, loss function 0.048994604498147964\n",
      "epoch 3303, loss function 0.0487951785326004\n",
      "epoch 3304, loss function 0.04859727621078491\n",
      "epoch 3305, loss function 0.04839956760406494\n",
      "epoch 3306, loss function 0.04820121079683304\n",
      "epoch 3307, loss function 0.048003703355789185\n",
      "epoch 3308, loss function 0.04780743271112442\n",
      "epoch 3309, loss function 0.04761211574077606\n",
      "epoch 3310, loss function 0.04741595685482025\n",
      "epoch 3311, loss function 0.047222692519426346\n",
      "epoch 3312, loss function 0.04703040048480034\n",
      "epoch 3313, loss function 0.04684038460254669\n",
      "epoch 3314, loss function 0.04665076360106468\n",
      "epoch 3315, loss function 0.046461496502161026\n",
      "epoch 3316, loss function 0.046272676438093185\n",
      "epoch 3317, loss function 0.04608442261815071\n",
      "epoch 3318, loss function 0.045896366238594055\n",
      "epoch 3319, loss function 0.0457087866961956\n",
      "epoch 3320, loss function 0.04552158713340759\n",
      "epoch 3321, loss function 0.045334916561841965\n",
      "epoch 3322, loss function 0.0451490618288517\n",
      "epoch 3323, loss function 0.044963009655475616\n",
      "epoch 3324, loss function 0.04478011280298233\n",
      "epoch 3325, loss function 0.04459906369447708\n",
      "epoch 3326, loss function 0.04441974684596062\n",
      "epoch 3327, loss function 0.044240035116672516\n",
      "epoch 3328, loss function 0.04406021162867546\n",
      "epoch 3329, loss function 0.043880902230739594\n",
      "epoch 3330, loss function 0.04370294138789177\n",
      "epoch 3331, loss function 0.04352479800581932\n",
      "epoch 3332, loss function 0.04334622621536255\n",
      "epoch 3333, loss function 0.04316860809922218\n",
      "epoch 3334, loss function 0.04299146682024002\n",
      "epoch 3335, loss function 0.04281521588563919\n",
      "epoch 3336, loss function 0.04263908416032791\n",
      "epoch 3337, loss function 0.04246523603796959\n",
      "epoch 3338, loss function 0.04229472205042839\n",
      "epoch 3339, loss function 0.042123351246118546\n",
      "epoch 3340, loss function 0.04195358231663704\n",
      "epoch 3341, loss function 0.04178281128406525\n",
      "epoch 3342, loss function 0.04161406308412552\n",
      "epoch 3343, loss function 0.041444092988967896\n",
      "epoch 3344, loss function 0.04127548635005951\n",
      "epoch 3345, loss function 0.04110615700483322\n",
      "epoch 3346, loss function 0.04093869403004646\n",
      "epoch 3347, loss function 0.040769923478364944\n",
      "epoch 3348, loss function 0.04060305282473564\n",
      "epoch 3349, loss function 0.04043569788336754\n",
      "epoch 3350, loss function 0.040269818156957626\n",
      "epoch 3351, loss function 0.04010779410600662\n",
      "epoch 3352, loss function 0.03994566202163696\n",
      "epoch 3353, loss function 0.03978455066680908\n",
      "epoch 3354, loss function 0.03962387889623642\n",
      "epoch 3355, loss function 0.03946293145418167\n",
      "epoch 3356, loss function 0.03930239379405975\n",
      "epoch 3357, loss function 0.03914260119199753\n",
      "epoch 3358, loss function 0.03898342326283455\n",
      "epoch 3359, loss function 0.03882348909974098\n",
      "epoch 3360, loss function 0.03866419196128845\n",
      "epoch 3361, loss function 0.03850562497973442\n",
      "epoch 3362, loss function 0.038347482681274414\n",
      "epoch 3363, loss function 0.03819014132022858\n",
      "epoch 3364, loss function 0.03803212568163872\n",
      "epoch 3365, loss function 0.037879250943660736\n",
      "epoch 3366, loss function 0.0377265140414238\n",
      "epoch 3367, loss function 0.03757429122924805\n",
      "epoch 3368, loss function 0.037422262132167816\n",
      "epoch 3369, loss function 0.0372704342007637\n",
      "epoch 3370, loss function 0.03711918741464615\n",
      "epoch 3371, loss function 0.036967683583498\n",
      "epoch 3372, loss function 0.03681691735982895\n",
      "epoch 3373, loss function 0.03666648268699646\n",
      "epoch 3374, loss function 0.03651643171906471\n",
      "epoch 3375, loss function 0.03636682778596878\n",
      "epoch 3376, loss function 0.036217235028743744\n",
      "epoch 3377, loss function 0.03606804832816124\n",
      "epoch 3378, loss function 0.03591962903738022\n",
      "epoch 3379, loss function 0.035773903131484985\n",
      "epoch 3380, loss function 0.03562982380390167\n",
      "epoch 3381, loss function 0.035486094653606415\n",
      "epoch 3382, loss function 0.03534218296408653\n",
      "epoch 3383, loss function 0.03519956022500992\n",
      "epoch 3384, loss function 0.035056740045547485\n",
      "epoch 3385, loss function 0.03491390496492386\n",
      "epoch 3386, loss function 0.03477143868803978\n",
      "epoch 3387, loss function 0.03462982177734375\n",
      "epoch 3388, loss function 0.03448832035064697\n",
      "epoch 3389, loss function 0.03434673696756363\n",
      "epoch 3390, loss function 0.03420530632138252\n",
      "epoch 3391, loss function 0.0340644046664238\n",
      "epoch 3392, loss function 0.03392443433403969\n",
      "epoch 3393, loss function 0.03378612548112869\n",
      "epoch 3394, loss function 0.03364909067749977\n",
      "epoch 3395, loss function 0.033512841910123825\n",
      "epoch 3396, loss function 0.03337854519486427\n",
      "epoch 3397, loss function 0.033242832869291306\n",
      "epoch 3398, loss function 0.03310899809002876\n",
      "epoch 3399, loss function 0.03297387436032295\n",
      "epoch 3400, loss function 0.032840434461832047\n",
      "epoch 3401, loss function 0.03270602226257324\n",
      "epoch 3402, loss function 0.03257331624627113\n",
      "epoch 3403, loss function 0.032439276576042175\n",
      "epoch 3404, loss function 0.032306816428899765\n",
      "epoch 3405, loss function 0.03217346593737602\n",
      "epoch 3406, loss function 0.03204178437590599\n",
      "epoch 3407, loss function 0.03190895542502403\n",
      "epoch 3408, loss function 0.03177962824702263\n",
      "epoch 3409, loss function 0.031650740653276443\n",
      "epoch 3410, loss function 0.03152304142713547\n",
      "epoch 3411, loss function 0.03139565885066986\n",
      "epoch 3412, loss function 0.03126910328865051\n",
      "epoch 3413, loss function 0.031142909079790115\n",
      "epoch 3414, loss function 0.03101631999015808\n",
      "epoch 3415, loss function 0.030890099704265594\n",
      "epoch 3416, loss function 0.03076467476785183\n",
      "epoch 3417, loss function 0.03063940815627575\n",
      "epoch 3418, loss function 0.030513983219861984\n",
      "epoch 3419, loss function 0.030388684943318367\n",
      "epoch 3420, loss function 0.030264221131801605\n",
      "epoch 3421, loss function 0.030140124261379242\n",
      "epoch 3422, loss function 0.030015524476766586\n",
      "epoch 3423, loss function 0.02989335171878338\n",
      "epoch 3424, loss function 0.029771462082862854\n",
      "epoch 3425, loss function 0.029650166630744934\n",
      "epoch 3426, loss function 0.029530668631196022\n",
      "epoch 3427, loss function 0.029411980882287025\n",
      "epoch 3428, loss function 0.0292934812605381\n",
      "epoch 3429, loss function 0.02917471155524254\n",
      "epoch 3430, loss function 0.029056409373879433\n",
      "epoch 3431, loss function 0.02893855981528759\n",
      "epoch 3432, loss function 0.028820548206567764\n",
      "epoch 3433, loss function 0.028702910989522934\n",
      "epoch 3434, loss function 0.028585609048604965\n",
      "epoch 3435, loss function 0.028468569740653038\n",
      "epoch 3436, loss function 0.028351910412311554\n",
      "epoch 3437, loss function 0.028235027566552162\n",
      "epoch 3438, loss function 0.028118735179305077\n",
      "epoch 3439, loss function 0.028004713356494904\n",
      "epoch 3440, loss function 0.027890333905816078\n",
      "epoch 3441, loss function 0.02777625434100628\n",
      "epoch 3442, loss function 0.027663279324769974\n",
      "epoch 3443, loss function 0.027552084997296333\n",
      "epoch 3444, loss function 0.027440685778856277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3445, loss function 0.027329452335834503\n",
      "epoch 3446, loss function 0.027218762785196304\n",
      "epoch 3447, loss function 0.027108732610940933\n",
      "epoch 3448, loss function 0.02699819579720497\n",
      "epoch 3449, loss function 0.026887811720371246\n",
      "epoch 3450, loss function 0.026778321713209152\n",
      "epoch 3451, loss function 0.02666907198727131\n",
      "epoch 3452, loss function 0.02655928209424019\n",
      "epoch 3453, loss function 0.026449793949723244\n",
      "epoch 3454, loss function 0.02634107507765293\n",
      "epoch 3455, loss function 0.026234213262796402\n",
      "epoch 3456, loss function 0.02612772211432457\n",
      "epoch 3457, loss function 0.026021042838692665\n",
      "epoch 3458, loss function 0.02591453678905964\n",
      "epoch 3459, loss function 0.025808967649936676\n",
      "epoch 3460, loss function 0.02570553496479988\n",
      "epoch 3461, loss function 0.025601647794246674\n",
      "epoch 3462, loss function 0.025497809052467346\n",
      "epoch 3463, loss function 0.025394724681973457\n",
      "epoch 3464, loss function 0.025291677564382553\n",
      "epoch 3465, loss function 0.025188785046339035\n",
      "epoch 3466, loss function 0.02508596144616604\n",
      "epoch 3467, loss function 0.02498381957411766\n",
      "epoch 3468, loss function 0.024881482124328613\n",
      "epoch 3469, loss function 0.0247794222086668\n",
      "epoch 3470, loss function 0.024677684530615807\n",
      "epoch 3471, loss function 0.02457606792449951\n",
      "epoch 3472, loss function 0.02447659522294998\n",
      "epoch 3473, loss function 0.02437683753669262\n",
      "epoch 3474, loss function 0.024277236312627792\n",
      "epoch 3475, loss function 0.02417829819023609\n",
      "epoch 3476, loss function 0.024079738184809685\n",
      "epoch 3477, loss function 0.023981235921382904\n",
      "epoch 3478, loss function 0.023884139955043793\n",
      "epoch 3479, loss function 0.02378803864121437\n",
      "epoch 3480, loss function 0.023692026734352112\n",
      "epoch 3481, loss function 0.023595573380589485\n",
      "epoch 3482, loss function 0.023499559611082077\n",
      "epoch 3483, loss function 0.023404404520988464\n",
      "epoch 3484, loss function 0.023308977484703064\n",
      "epoch 3485, loss function 0.023213405162096024\n",
      "epoch 3486, loss function 0.023118117824196815\n",
      "epoch 3487, loss function 0.02302365005016327\n",
      "epoch 3488, loss function 0.02292906865477562\n",
      "epoch 3489, loss function 0.02283642068505287\n",
      "epoch 3490, loss function 0.022743789479136467\n",
      "epoch 3491, loss function 0.022651372477412224\n",
      "epoch 3492, loss function 0.0225590281188488\n",
      "epoch 3493, loss function 0.022467022761702538\n",
      "epoch 3494, loss function 0.02237507328391075\n",
      "epoch 3495, loss function 0.022283555939793587\n",
      "epoch 3496, loss function 0.022193543612957\n",
      "epoch 3497, loss function 0.022104140371084213\n",
      "epoch 3498, loss function 0.02201477438211441\n",
      "epoch 3499, loss function 0.02192537486553192\n",
      "epoch 3500, loss function 0.021836552768945694\n",
      "epoch 3501, loss function 0.021747704595327377\n",
      "epoch 3502, loss function 0.0216591265052557\n",
      "epoch 3503, loss function 0.021570656448602676\n",
      "epoch 3504, loss function 0.021482499316334724\n",
      "epoch 3505, loss function 0.02139434963464737\n",
      "epoch 3506, loss function 0.02130642533302307\n",
      "epoch 3507, loss function 0.021219929680228233\n",
      "epoch 3508, loss function 0.02113375999033451\n",
      "epoch 3509, loss function 0.02104817144572735\n",
      "epoch 3510, loss function 0.020962653681635857\n",
      "epoch 3511, loss function 0.02087724208831787\n",
      "epoch 3512, loss function 0.02079147845506668\n",
      "epoch 3513, loss function 0.020706551149487495\n",
      "epoch 3514, loss function 0.02062183991074562\n",
      "epoch 3515, loss function 0.02053692564368248\n",
      "epoch 3516, loss function 0.020453765988349915\n",
      "epoch 3517, loss function 0.020371463149785995\n",
      "epoch 3518, loss function 0.020288996398448944\n",
      "epoch 3519, loss function 0.02020653709769249\n",
      "epoch 3520, loss function 0.020124133676290512\n",
      "epoch 3521, loss function 0.020042192190885544\n",
      "epoch 3522, loss function 0.019960934296250343\n",
      "epoch 3523, loss function 0.019878800958395004\n",
      "epoch 3524, loss function 0.019797194749116898\n",
      "epoch 3525, loss function 0.019716018810868263\n",
      "epoch 3526, loss function 0.019636444747447968\n",
      "epoch 3527, loss function 0.019556842744350433\n",
      "epoch 3528, loss function 0.019477616995573044\n",
      "epoch 3529, loss function 0.0193986427038908\n",
      "epoch 3530, loss function 0.019319284707307816\n",
      "epoch 3531, loss function 0.01924044080078602\n",
      "epoch 3532, loss function 0.019161788746714592\n",
      "epoch 3533, loss function 0.01908346451818943\n",
      "epoch 3534, loss function 0.01900492236018181\n",
      "epoch 3535, loss function 0.018926575779914856\n",
      "epoch 3536, loss function 0.018850399181246758\n",
      "epoch 3537, loss function 0.01877404935657978\n",
      "epoch 3538, loss function 0.018698006868362427\n",
      "epoch 3539, loss function 0.018622195348143578\n",
      "epoch 3540, loss function 0.01854630932211876\n",
      "epoch 3541, loss function 0.01847085729241371\n",
      "epoch 3542, loss function 0.018395159393548965\n",
      "epoch 3543, loss function 0.01831977069377899\n",
      "epoch 3544, loss function 0.018244754523038864\n",
      "epoch 3545, loss function 0.01817147247493267\n",
      "epoch 3546, loss function 0.01809784397482872\n",
      "epoch 3547, loss function 0.01802424155175686\n",
      "epoch 3548, loss function 0.017951445654034615\n",
      "epoch 3549, loss function 0.017878683283925056\n",
      "epoch 3550, loss function 0.01780557446181774\n",
      "epoch 3551, loss function 0.017732776701450348\n",
      "epoch 3552, loss function 0.01766042411327362\n",
      "epoch 3553, loss function 0.01758834905922413\n",
      "epoch 3554, loss function 0.01751595176756382\n",
      "epoch 3555, loss function 0.017443690448999405\n",
      "epoch 3556, loss function 0.017372053116559982\n",
      "epoch 3557, loss function 0.017302069813013077\n",
      "epoch 3558, loss function 0.017231794074177742\n",
      "epoch 3559, loss function 0.017161818221211433\n",
      "epoch 3560, loss function 0.01709211990237236\n",
      "epoch 3561, loss function 0.017022816464304924\n",
      "epoch 3562, loss function 0.016952987760305405\n",
      "epoch 3563, loss function 0.01688358187675476\n",
      "epoch 3564, loss function 0.016814539209008217\n",
      "epoch 3565, loss function 0.01674715429544449\n",
      "epoch 3566, loss function 0.01667976938188076\n",
      "epoch 3567, loss function 0.01661222241818905\n",
      "epoch 3568, loss function 0.016545072197914124\n",
      "epoch 3569, loss function 0.016477808356285095\n",
      "epoch 3570, loss function 0.01641100086271763\n",
      "epoch 3571, loss function 0.016344083473086357\n",
      "epoch 3572, loss function 0.016277432441711426\n",
      "epoch 3573, loss function 0.016210971400141716\n",
      "epoch 3574, loss function 0.016144584864377975\n",
      "epoch 3575, loss function 0.016078226268291473\n",
      "epoch 3576, loss function 0.016012025997042656\n",
      "epoch 3577, loss function 0.015946201980113983\n",
      "epoch 3578, loss function 0.015881583094596863\n",
      "epoch 3579, loss function 0.01581697352230549\n",
      "epoch 3580, loss function 0.01575279049575329\n",
      "epoch 3581, loss function 0.0156890619546175\n",
      "epoch 3582, loss function 0.015625134110450745\n",
      "epoch 3583, loss function 0.015561376698315144\n",
      "epoch 3584, loss function 0.01549781858921051\n",
      "epoch 3585, loss function 0.015434330329298973\n",
      "epoch 3586, loss function 0.015372147783637047\n",
      "epoch 3587, loss function 0.015310805290937424\n",
      "epoch 3588, loss function 0.015249134972691536\n",
      "epoch 3589, loss function 0.015187328681349754\n",
      "epoch 3590, loss function 0.01512560062110424\n",
      "epoch 3591, loss function 0.015064307488501072\n",
      "epoch 3592, loss function 0.015003422275185585\n",
      "epoch 3593, loss function 0.014942225068807602\n",
      "epoch 3594, loss function 0.014881095848977566\n",
      "epoch 3595, loss function 0.014820506796240807\n",
      "epoch 3596, loss function 0.014759852550923824\n",
      "epoch 3597, loss function 0.014699149876832962\n",
      "epoch 3598, loss function 0.014638502150774002\n",
      "epoch 3599, loss function 0.014578438363969326\n",
      "epoch 3600, loss function 0.014518478885293007\n",
      "epoch 3601, loss function 0.014459356665611267\n",
      "epoch 3602, loss function 0.014400262385606766\n",
      "epoch 3603, loss function 0.014341853559017181\n",
      "epoch 3604, loss function 0.014283733442425728\n",
      "epoch 3605, loss function 0.014225286431610584\n",
      "epoch 3606, loss function 0.014167158864438534\n",
      "epoch 3607, loss function 0.014109447598457336\n",
      "epoch 3608, loss function 0.014052849262952805\n",
      "epoch 3609, loss function 0.01399639155715704\n",
      "epoch 3610, loss function 0.013940279372036457\n",
      "epoch 3611, loss function 0.013883823528885841\n",
      "epoch 3612, loss function 0.013827972114086151\n",
      "epoch 3613, loss function 0.013772252015769482\n",
      "epoch 3614, loss function 0.013716183602809906\n",
      "epoch 3615, loss function 0.013660479336977005\n",
      "epoch 3616, loss function 0.01360488310456276\n",
      "epoch 3617, loss function 0.013549401424825191\n",
      "epoch 3618, loss function 0.01349387876689434\n",
      "epoch 3619, loss function 0.013438602909445763\n",
      "epoch 3620, loss function 0.013383517041802406\n",
      "epoch 3621, loss function 0.013328438624739647\n",
      "epoch 3622, loss function 0.013273565098643303\n",
      "epoch 3623, loss function 0.013218924403190613\n",
      "epoch 3624, loss function 0.013164050877094269\n",
      "epoch 3625, loss function 0.013110574334859848\n",
      "epoch 3626, loss function 0.013057174161076546\n",
      "epoch 3627, loss function 0.013003772124648094\n",
      "epoch 3628, loss function 0.012951074168086052\n",
      "epoch 3629, loss function 0.012898437678813934\n",
      "epoch 3630, loss function 0.012845538556575775\n",
      "epoch 3631, loss function 0.012794501148164272\n",
      "epoch 3632, loss function 0.012742986902594566\n",
      "epoch 3633, loss function 0.01269165426492691\n",
      "epoch 3634, loss function 0.012640806846320629\n",
      "epoch 3635, loss function 0.012589935213327408\n",
      "epoch 3636, loss function 0.012539028190076351\n",
      "epoch 3637, loss function 0.012488082982599735\n",
      "epoch 3638, loss function 0.012437607161700726\n",
      "epoch 3639, loss function 0.012387461960315704\n",
      "epoch 3640, loss function 0.012336735613644123\n",
      "epoch 3641, loss function 0.012286207638680935\n",
      "epoch 3642, loss function 0.01223631203174591\n",
      "epoch 3643, loss function 0.012186308391392231\n",
      "epoch 3644, loss function 0.012136267498135567\n",
      "epoch 3645, loss function 0.012086298316717148\n",
      "epoch 3646, loss function 0.012036504223942757\n",
      "epoch 3647, loss function 0.011987014673650265\n",
      "epoch 3648, loss function 0.011937462724745274\n",
      "epoch 3649, loss function 0.011887598782777786\n",
      "epoch 3650, loss function 0.011838461272418499\n",
      "epoch 3651, loss function 0.01179036870598793\n",
      "epoch 3652, loss function 0.0117421243339777\n",
      "epoch 3653, loss function 0.01169392466545105\n",
      "epoch 3654, loss function 0.011646164581179619\n",
      "epoch 3655, loss function 0.01159983966499567\n",
      "epoch 3656, loss function 0.01155348215252161\n",
      "epoch 3657, loss function 0.011507249437272549\n",
      "epoch 3658, loss function 0.011461040936410427\n",
      "epoch 3659, loss function 0.011415142565965652\n",
      "epoch 3660, loss function 0.011369148269295692\n",
      "epoch 3661, loss function 0.01132325641810894\n",
      "epoch 3662, loss function 0.011277461424469948\n",
      "epoch 3663, loss function 0.011231882497668266\n",
      "epoch 3664, loss function 0.011186233721673489\n",
      "epoch 3665, loss function 0.011140713468194008\n",
      "epoch 3666, loss function 0.011095291934907436\n",
      "epoch 3667, loss function 0.011049985885620117\n",
      "epoch 3668, loss function 0.011004858650267124\n",
      "epoch 3669, loss function 0.010959619656205177\n",
      "epoch 3670, loss function 0.01091458834707737\n",
      "epoch 3671, loss function 0.010869757272303104\n",
      "epoch 3672, loss function 0.01082502119243145\n",
      "epoch 3673, loss function 0.010780276730656624\n",
      "epoch 3674, loss function 0.010735542513430119\n",
      "epoch 3675, loss function 0.010690978728234768\n",
      "epoch 3676, loss function 0.010646438226103783\n",
      "epoch 3677, loss function 0.010603136382997036\n",
      "epoch 3678, loss function 0.010559849441051483\n",
      "epoch 3679, loss function 0.010516623966395855\n",
      "epoch 3680, loss function 0.010474445298314095\n",
      "epoch 3681, loss function 0.010432778857648373\n",
      "epoch 3682, loss function 0.01039117295295\n",
      "epoch 3683, loss function 0.010349555872380733\n",
      "epoch 3684, loss function 0.01030788291245699\n",
      "epoch 3685, loss function 0.010266778990626335\n",
      "epoch 3686, loss function 0.01022564247250557\n",
      "epoch 3687, loss function 0.010184191167354584\n",
      "epoch 3688, loss function 0.010142969898879528\n",
      "epoch 3689, loss function 0.010102177038788795\n",
      "epoch 3690, loss function 0.010061485692858696\n",
      "epoch 3691, loss function 0.010020390152931213\n",
      "epoch 3692, loss function 0.00997957307845354\n",
      "epoch 3693, loss function 0.00993899255990982\n",
      "epoch 3694, loss function 0.009898527525365353\n",
      "epoch 3695, loss function 0.009857909753918648\n",
      "epoch 3696, loss function 0.0098173338919878\n",
      "epoch 3697, loss function 0.00977715477347374\n",
      "epoch 3698, loss function 0.00973704643547535\n",
      "epoch 3699, loss function 0.009696702472865582\n",
      "epoch 3700, loss function 0.009656491689383984\n",
      "epoch 3701, loss function 0.009616805240511894\n",
      "epoch 3702, loss function 0.009576902724802494\n",
      "epoch 3703, loss function 0.009536917321383953\n",
      "epoch 3704, loss function 0.009496998973190784\n",
      "epoch 3705, loss function 0.009457486681640148\n",
      "epoch 3706, loss function 0.009419948793947697\n",
      "epoch 3707, loss function 0.009382101707160473\n",
      "epoch 3708, loss function 0.009344974532723427\n",
      "epoch 3709, loss function 0.009307501837611198\n",
      "epoch 3710, loss function 0.009270173497498035\n",
      "epoch 3711, loss function 0.009233036078512669\n",
      "epoch 3712, loss function 0.009196207858622074\n",
      "epoch 3713, loss function 0.009159408509731293\n",
      "epoch 3714, loss function 0.00912240520119667\n",
      "epoch 3715, loss function 0.009085699915885925\n",
      "epoch 3716, loss function 0.009049043990671635\n",
      "epoch 3717, loss function 0.009012451395392418\n",
      "epoch 3718, loss function 0.008976134471595287\n",
      "epoch 3719, loss function 0.008939515799283981\n",
      "epoch 3720, loss function 0.00890317838639021\n",
      "epoch 3721, loss function 0.00886702723801136\n",
      "epoch 3722, loss function 0.008830847218632698\n",
      "epoch 3723, loss function 0.008794540539383888\n",
      "epoch 3724, loss function 0.008758646436035633\n",
      "epoch 3725, loss function 0.008722630329430103\n",
      "epoch 3726, loss function 0.008686792105436325\n",
      "epoch 3727, loss function 0.008650892414152622\n",
      "epoch 3728, loss function 0.008615178056061268\n",
      "epoch 3729, loss function 0.008579498156905174\n",
      "epoch 3730, loss function 0.008543950505554676\n",
      "epoch 3731, loss function 0.008508371189236641\n",
      "epoch 3732, loss function 0.008472947403788567\n",
      "epoch 3733, loss function 0.00843772105872631\n",
      "epoch 3734, loss function 0.008403091691434383\n",
      "epoch 3735, loss function 0.008369865827262402\n",
      "epoch 3736, loss function 0.008336720056831837\n",
      "epoch 3737, loss function 0.008303367532789707\n",
      "epoch 3738, loss function 0.008270103484392166\n",
      "epoch 3739, loss function 0.00823718961328268\n",
      "epoch 3740, loss function 0.00820409320294857\n",
      "epoch 3741, loss function 0.008171172812581062\n",
      "epoch 3742, loss function 0.008138108067214489\n",
      "epoch 3743, loss function 0.008105500601232052\n",
      "epoch 3744, loss function 0.008073201403021812\n",
      "epoch 3745, loss function 0.00804047379642725\n",
      "epoch 3746, loss function 0.008007995784282684\n",
      "epoch 3747, loss function 0.007975807413458824\n",
      "epoch 3748, loss function 0.007943645119667053\n",
      "epoch 3749, loss function 0.007911311462521553\n",
      "epoch 3750, loss function 0.007879120297729969\n",
      "epoch 3751, loss function 0.00784726720303297\n",
      "epoch 3752, loss function 0.007815252989530563\n",
      "epoch 3753, loss function 0.00778310839086771\n",
      "epoch 3754, loss function 0.007751078810542822\n",
      "epoch 3755, loss function 0.007719509303569794\n",
      "epoch 3756, loss function 0.007687847595661879\n",
      "epoch 3757, loss function 0.0076560392044484615\n",
      "epoch 3758, loss function 0.007624280638992786\n",
      "epoch 3759, loss function 0.007592794485390186\n",
      "epoch 3760, loss function 0.007561495061963797\n",
      "epoch 3761, loss function 0.0075299665331840515\n",
      "epoch 3762, loss function 0.007498281076550484\n",
      "epoch 3763, loss function 0.007467241492122412\n",
      "epoch 3764, loss function 0.007437003776431084\n",
      "epoch 3765, loss function 0.007406691089272499\n",
      "epoch 3766, loss function 0.007376573979854584\n",
      "epoch 3767, loss function 0.007346436847001314\n",
      "epoch 3768, loss function 0.0073171742260456085\n",
      "epoch 3769, loss function 0.007288014516234398\n",
      "epoch 3770, loss function 0.0072589716874063015\n",
      "epoch 3771, loss function 0.007229981012642384\n",
      "epoch 3772, loss function 0.007200987543910742\n",
      "epoch 3773, loss function 0.007171999663114548\n",
      "epoch 3774, loss function 0.007143106311559677\n",
      "epoch 3775, loss function 0.0071143475361168385\n",
      "epoch 3776, loss function 0.0070855882950127125\n",
      "epoch 3777, loss function 0.007057049311697483\n",
      "epoch 3778, loss function 0.007028602063655853\n",
      "epoch 3779, loss function 0.007000252604484558\n",
      "epoch 3780, loss function 0.0069718430750072\n",
      "epoch 3781, loss function 0.0069435834884643555\n",
      "epoch 3782, loss function 0.006915389094501734\n",
      "epoch 3783, loss function 0.0068871499970555305\n",
      "epoch 3784, loss function 0.0068590883165597916\n",
      "epoch 3785, loss function 0.006831098813563585\n",
      "epoch 3786, loss function 0.006803012453019619\n",
      "epoch 3787, loss function 0.006775157991796732\n",
      "epoch 3788, loss function 0.00674726627767086\n",
      "epoch 3789, loss function 0.006719490513205528\n",
      "epoch 3790, loss function 0.006691612768918276\n",
      "epoch 3791, loss function 0.006663930136710405\n",
      "epoch 3792, loss function 0.006636297795921564\n",
      "epoch 3793, loss function 0.006608724594116211\n",
      "epoch 3794, loss function 0.006581218913197517\n",
      "epoch 3795, loss function 0.006554408930242062\n",
      "epoch 3796, loss function 0.006528153084218502\n",
      "epoch 3797, loss function 0.00650172820314765\n",
      "epoch 3798, loss function 0.006475123111158609\n",
      "epoch 3799, loss function 0.006448635831475258\n",
      "epoch 3800, loss function 0.006422541104257107\n",
      "epoch 3801, loss function 0.0063962675631046295\n",
      "epoch 3802, loss function 0.006370755843818188\n",
      "epoch 3803, loss function 0.006345168687403202\n",
      "epoch 3804, loss function 0.0063199554570019245\n",
      "epoch 3805, loss function 0.006294767372310162\n",
      "epoch 3806, loss function 0.006269433069974184\n",
      "epoch 3807, loss function 0.006244043353945017\n",
      "epoch 3808, loss function 0.006219055969268084\n",
      "epoch 3809, loss function 0.006194133311510086\n",
      "epoch 3810, loss function 0.0061689564026892185\n",
      "epoch 3811, loss function 0.006143840495496988\n",
      "epoch 3812, loss function 0.006119079887866974\n",
      "epoch 3813, loss function 0.006094521842896938\n",
      "epoch 3814, loss function 0.006069754716008902\n",
      "epoch 3815, loss function 0.006045018322765827\n",
      "epoch 3816, loss function 0.006020633969455957\n",
      "epoch 3817, loss function 0.005996265448629856\n",
      "epoch 3818, loss function 0.005971627775579691\n",
      "epoch 3819, loss function 0.005947078578174114\n",
      "epoch 3820, loss function 0.005922893062233925\n",
      "epoch 3821, loss function 0.005898682400584221\n",
      "epoch 3822, loss function 0.005874330177903175\n",
      "epoch 3823, loss function 0.005849990528076887\n",
      "epoch 3824, loss function 0.005826040171086788\n",
      "epoch 3825, loss function 0.0058020418509840965\n",
      "epoch 3826, loss function 0.00577796995639801\n",
      "epoch 3827, loss function 0.005753727629780769\n",
      "epoch 3828, loss function 0.005729910917580128\n",
      "epoch 3829, loss function 0.005706821568310261\n",
      "epoch 3830, loss function 0.005683855153620243\n",
      "epoch 3831, loss function 0.005660829599946737\n",
      "epoch 3832, loss function 0.0056378040462732315\n",
      "epoch 3833, loss function 0.005614934954792261\n",
      "epoch 3834, loss function 0.005592274013906717\n",
      "epoch 3835, loss function 0.005569388158619404\n",
      "epoch 3836, loss function 0.005546607077121735\n",
      "epoch 3837, loss function 0.005523969419300556\n",
      "epoch 3838, loss function 0.0055012512020766735\n",
      "epoch 3839, loss function 0.005479373503476381\n",
      "epoch 3840, loss function 0.005457452032715082\n",
      "epoch 3841, loss function 0.005435640923678875\n",
      "epoch 3842, loss function 0.005413978826254606\n",
      "epoch 3843, loss function 0.0053922273218631744\n",
      "epoch 3844, loss function 0.005370461847633123\n",
      "epoch 3845, loss function 0.005348815582692623\n",
      "epoch 3846, loss function 0.00532727362588048\n",
      "epoch 3847, loss function 0.005305711179971695\n",
      "epoch 3848, loss function 0.005284159444272518\n",
      "epoch 3849, loss function 0.005262749269604683\n",
      "epoch 3850, loss function 0.005241359118372202\n",
      "epoch 3851, loss function 0.0052199168130755424\n",
      "epoch 3852, loss function 0.005198542028665543\n",
      "epoch 3853, loss function 0.00517750158905983\n",
      "epoch 3854, loss function 0.005156438797712326\n",
      "epoch 3855, loss function 0.0051353806629776955\n",
      "epoch 3856, loss function 0.005114391911774874\n",
      "epoch 3857, loss function 0.0050934189930558205\n",
      "epoch 3858, loss function 0.005072648636996746\n",
      "epoch 3859, loss function 0.005051579792052507\n",
      "epoch 3860, loss function 0.005030792206525803\n",
      "epoch 3861, loss function 0.005010050721466541\n",
      "epoch 3862, loss function 0.004989278502762318\n",
      "epoch 3863, loss function 0.004968548193573952\n",
      "epoch 3864, loss function 0.004947893787175417\n",
      "epoch 3865, loss function 0.004927977919578552\n",
      "epoch 3866, loss function 0.00490817055106163\n",
      "epoch 3867, loss function 0.004888696130365133\n",
      "epoch 3868, loss function 0.004868858959525824\n",
      "epoch 3869, loss function 0.004848971497267485\n",
      "epoch 3870, loss function 0.004829471465200186\n",
      "epoch 3871, loss function 0.004809886682778597\n",
      "epoch 3872, loss function 0.0047902693040668964\n",
      "epoch 3873, loss function 0.0047705816105008125\n",
      "epoch 3874, loss function 0.0047512296587228775\n",
      "epoch 3875, loss function 0.0047319428995251656\n",
      "epoch 3876, loss function 0.00471243541687727\n",
      "epoch 3877, loss function 0.004693000577390194\n",
      "epoch 3878, loss function 0.004673678427934647\n",
      "epoch 3879, loss function 0.004655241500586271\n",
      "epoch 3880, loss function 0.00463651679456234\n",
      "epoch 3881, loss function 0.0046177576296031475\n",
      "epoch 3882, loss function 0.004599468782544136\n",
      "epoch 3883, loss function 0.004581124056130648\n",
      "epoch 3884, loss function 0.004562396556138992\n",
      "epoch 3885, loss function 0.004543990828096867\n",
      "epoch 3886, loss function 0.004525706171989441\n",
      "epoch 3887, loss function 0.004507517907768488\n",
      "epoch 3888, loss function 0.0044890278950333595\n",
      "epoch 3889, loss function 0.004470800049602985\n",
      "epoch 3890, loss function 0.004452703520655632\n",
      "epoch 3891, loss function 0.004434611648321152\n",
      "epoch 3892, loss function 0.0044163549318909645\n",
      "epoch 3893, loss function 0.004398188088089228\n",
      "epoch 3894, loss function 0.004380285274237394\n",
      "epoch 3895, loss function 0.004362293519079685\n",
      "epoch 3896, loss function 0.004344280809164047\n",
      "epoch 3897, loss function 0.004326453898102045\n",
      "epoch 3898, loss function 0.004308771342039108\n",
      "epoch 3899, loss function 0.004291209392249584\n",
      "epoch 3900, loss function 0.0042734346352517605\n",
      "epoch 3901, loss function 0.004255514591932297\n",
      "epoch 3902, loss function 0.004238045308738947\n",
      "epoch 3903, loss function 0.004221181385219097\n",
      "epoch 3904, loss function 0.0042043281719088554\n",
      "epoch 3905, loss function 0.004187519196420908\n",
      "epoch 3906, loss function 0.004170836880803108\n",
      "epoch 3907, loss function 0.004154074005782604\n",
      "epoch 3908, loss function 0.004137372598052025\n",
      "epoch 3909, loss function 0.0041206697933375835\n",
      "epoch 3910, loss function 0.004104088060557842\n",
      "epoch 3911, loss function 0.004087407607585192\n",
      "epoch 3912, loss function 0.004070841707289219\n",
      "epoch 3913, loss function 0.004054314456880093\n",
      "epoch 3914, loss function 0.004037841688841581\n",
      "epoch 3915, loss function 0.0040214089676737785\n",
      "epoch 3916, loss function 0.0040049380622804165\n",
      "epoch 3917, loss function 0.003988537471741438\n",
      "epoch 3918, loss function 0.00397217832505703\n",
      "epoch 3919, loss function 0.003955818247050047\n",
      "epoch 3920, loss function 0.003939584828913212\n",
      "epoch 3921, loss function 0.003923267591744661\n",
      "epoch 3922, loss function 0.003907641861587763\n",
      "epoch 3923, loss function 0.0038920193910598755\n",
      "epoch 3924, loss function 0.0038764525670558214\n",
      "epoch 3925, loss function 0.0038608864415436983\n",
      "epoch 3926, loss function 0.0038454546593129635\n",
      "epoch 3927, loss function 0.0038299395237118006\n",
      "epoch 3928, loss function 0.0038144513964653015\n",
      "epoch 3929, loss function 0.003799073863774538\n",
      "epoch 3930, loss function 0.0037837165873497725\n",
      "epoch 3931, loss function 0.003768283175304532\n",
      "epoch 3932, loss function 0.0037530509289354086\n",
      "epoch 3933, loss function 0.0037377066910266876\n",
      "epoch 3934, loss function 0.003722449531778693\n",
      "epoch 3935, loss function 0.003707293886691332\n",
      "epoch 3936, loss function 0.00369200948625803\n",
      "epoch 3937, loss function 0.0036768089048564434\n",
      "epoch 3938, loss function 0.0036617193836718798\n",
      "epoch 3939, loss function 0.0036465993616729975\n",
      "epoch 3940, loss function 0.003631556173786521\n",
      "epoch 3941, loss function 0.003616500645875931\n",
      "epoch 3942, loss function 0.003601502627134323\n",
      "epoch 3943, loss function 0.0035866342950612307\n",
      "epoch 3944, loss function 0.003571822540834546\n",
      "epoch 3945, loss function 0.00355760520324111\n",
      "epoch 3946, loss function 0.0035436060279607773\n",
      "epoch 3947, loss function 0.0035295358393341303\n",
      "epoch 3948, loss function 0.0035154838114976883\n",
      "epoch 3949, loss function 0.0035013356246054173\n",
      "epoch 3950, loss function 0.003487371141090989\n",
      "epoch 3951, loss function 0.0034735391382128\n",
      "epoch 3952, loss function 0.0034595599863678217\n",
      "epoch 3953, loss function 0.0034455580171197653\n",
      "epoch 3954, loss function 0.0034317325334995985\n",
      "epoch 3955, loss function 0.0034180458169430494\n",
      "epoch 3956, loss function 0.0034040813334286213\n",
      "epoch 3957, loss function 0.0033901394344866276\n",
      "epoch 3958, loss function 0.0033765106927603483\n",
      "epoch 3959, loss function 0.003362999763339758\n",
      "epoch 3960, loss function 0.0033490057103335857\n",
      "epoch 3961, loss function 0.0033353115431964397\n",
      "epoch 3962, loss function 0.003321676282212138\n",
      "epoch 3963, loss function 0.0033081891015172005\n",
      "epoch 3964, loss function 0.0032945380080491304\n",
      "epoch 3965, loss function 0.00328082381747663\n",
      "epoch 3966, loss function 0.0032674428075551987\n",
      "epoch 3967, loss function 0.003254030365496874\n",
      "epoch 3968, loss function 0.0032404251396656036\n",
      "epoch 3969, loss function 0.0032268865033984184\n",
      "epoch 3970, loss function 0.0032140796538442373\n",
      "epoch 3971, loss function 0.0032013175077736378\n",
      "epoch 3972, loss function 0.003188303206115961\n",
      "epoch 3973, loss function 0.0031753629446029663\n",
      "epoch 3974, loss function 0.0031627663411200047\n",
      "epoch 3975, loss function 0.0031500933691859245\n",
      "epoch 3976, loss function 0.0031371903605759144\n",
      "epoch 3977, loss function 0.003124452894553542\n",
      "epoch 3978, loss function 0.0031118891201913357\n",
      "epoch 3979, loss function 0.0030993004329502583\n",
      "epoch 3980, loss function 0.0030865236185491085\n",
      "epoch 3981, loss function 0.0030738653149455786\n",
      "epoch 3982, loss function 0.0030613779090344906\n",
      "epoch 3983, loss function 0.003048941493034363\n",
      "epoch 3984, loss function 0.0030363413970917463\n",
      "epoch 3985, loss function 0.0030236695893108845\n",
      "epoch 3986, loss function 0.0030113596003502607\n",
      "epoch 3987, loss function 0.002999016083776951\n",
      "epoch 3988, loss function 0.002986459992825985\n",
      "epoch 3989, loss function 0.0029740314930677414\n",
      "epoch 3990, loss function 0.0029617296531796455\n",
      "epoch 3991, loss function 0.002950073452666402\n",
      "epoch 3992, loss function 0.0029383301734924316\n",
      "epoch 3993, loss function 0.0029266076162457466\n",
      "epoch 3994, loss function 0.002914965618401766\n",
      "epoch 3995, loss function 0.002903474261984229\n",
      "epoch 3996, loss function 0.0028919163160026073\n",
      "epoch 3997, loss function 0.002880386309698224\n",
      "epoch 3998, loss function 0.002868968527764082\n",
      "epoch 3999, loss function 0.002857511630281806\n",
      "epoch 4000, loss function 0.0028460929170250893\n",
      "epoch 4001, loss function 0.002834714250639081\n",
      "epoch 4002, loss function 0.002823316026479006\n",
      "epoch 4003, loss function 0.0028119953349232674\n",
      "epoch 4004, loss function 0.002800769405439496\n",
      "epoch 4005, loss function 0.002789413556456566\n",
      "epoch 4006, loss function 0.002778115216642618\n",
      "epoch 4007, loss function 0.002766889054328203\n",
      "epoch 4008, loss function 0.002755632856860757\n",
      "epoch 4009, loss function 0.002744400640949607\n",
      "epoch 4010, loss function 0.002733284840360284\n",
      "epoch 4011, loss function 0.002722041215747595\n",
      "epoch 4012, loss function 0.0027109095826745033\n",
      "epoch 4013, loss function 0.0026997884269803762\n",
      "epoch 4014, loss function 0.0026887136045843363\n",
      "epoch 4015, loss function 0.0026776406448334455\n",
      "epoch 4016, loss function 0.002666601212695241\n",
      "epoch 4017, loss function 0.002655515680089593\n",
      "epoch 4018, loss function 0.0026445190887898207\n",
      "epoch 4019, loss function 0.002633565105497837\n",
      "epoch 4020, loss function 0.002622663276270032\n",
      "epoch 4021, loss function 0.0026116701774299145\n",
      "epoch 4022, loss function 0.002600752515718341\n",
      "epoch 4023, loss function 0.0025899179745465517\n",
      "epoch 4024, loss function 0.0025796196423470974\n",
      "epoch 4025, loss function 0.002569168107584119\n",
      "epoch 4026, loss function 0.0025588024873286486\n",
      "epoch 4027, loss function 0.002548475982621312\n",
      "epoch 4028, loss function 0.0025382726453244686\n",
      "epoch 4029, loss function 0.002527873730286956\n",
      "epoch 4030, loss function 0.002517593326047063\n",
      "epoch 4031, loss function 0.002507407683879137\n",
      "epoch 4032, loss function 0.0024972574319690466\n",
      "epoch 4033, loss function 0.0024870496708899736\n",
      "epoch 4034, loss function 0.002476820955052972\n",
      "epoch 4035, loss function 0.0024667817633599043\n",
      "epoch 4036, loss function 0.0024565826170146465\n",
      "epoch 4037, loss function 0.002446458674967289\n",
      "epoch 4038, loss function 0.0024363119155168533\n",
      "epoch 4039, loss function 0.0024263067170977592\n",
      "epoch 4040, loss function 0.002416222123429179\n",
      "epoch 4041, loss function 0.002406633924692869\n",
      "epoch 4042, loss function 0.002397299511358142\n",
      "epoch 4043, loss function 0.0023878877982497215\n",
      "epoch 4044, loss function 0.002378426492214203\n",
      "epoch 4045, loss function 0.0023689046502113342\n",
      "epoch 4046, loss function 0.0023596107494086027\n",
      "epoch 4047, loss function 0.002350306138396263\n",
      "epoch 4048, loss function 0.0023409207351505756\n",
      "epoch 4049, loss function 0.002331372583284974\n",
      "epoch 4050, loss function 0.002322189975529909\n",
      "epoch 4051, loss function 0.0023129170294851065\n",
      "epoch 4052, loss function 0.0023035798221826553\n",
      "epoch 4053, loss function 0.002294232603162527\n",
      "epoch 4054, loss function 0.002285085152834654\n",
      "epoch 4055, loss function 0.0022760529536753893\n",
      "epoch 4056, loss function 0.0022668386809527874\n",
      "epoch 4057, loss function 0.0022576451301574707\n",
      "epoch 4058, loss function 0.0022487433161586523\n",
      "epoch 4059, loss function 0.0022397704888135195\n",
      "epoch 4060, loss function 0.002230585552752018\n",
      "epoch 4061, loss function 0.002221533330157399\n",
      "epoch 4062, loss function 0.002212605904787779\n",
      "epoch 4063, loss function 0.0022037129383534193\n",
      "epoch 4064, loss function 0.0021947084460407495\n",
      "epoch 4065, loss function 0.0021857183892279863\n",
      "epoch 4066, loss function 0.0021768449805676937\n",
      "epoch 4067, loss function 0.0021679962519556284\n",
      "epoch 4068, loss function 0.002159032505005598\n",
      "epoch 4069, loss function 0.002150102984160185\n",
      "epoch 4070, loss function 0.002141376491636038\n",
      "epoch 4071, loss function 0.00213263020850718\n",
      "epoch 4072, loss function 0.0021236990578472614\n",
      "epoch 4073, loss function 0.002114832866936922\n",
      "epoch 4074, loss function 0.0021061901934444904\n",
      "epoch 4075, loss function 0.0020975456573069096\n",
      "epoch 4076, loss function 0.002088638022542\n",
      "epoch 4077, loss function 0.0020798167679458857\n",
      "epoch 4078, loss function 0.002071200404316187\n",
      "epoch 4079, loss function 0.0020626005716621876\n",
      "epoch 4080, loss function 0.002053908072412014\n",
      "epoch 4081, loss function 0.00204514735378325\n",
      "epoch 4082, loss function 0.002036617835983634\n",
      "epoch 4083, loss function 0.002028074814006686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4084, loss function 0.002019776962697506\n",
      "epoch 4085, loss function 0.0020115613006055355\n",
      "epoch 4086, loss function 0.002003532601520419\n",
      "epoch 4087, loss function 0.0019955274183303118\n",
      "epoch 4088, loss function 0.0019873627461493015\n",
      "epoch 4089, loss function 0.001979163382202387\n",
      "epoch 4090, loss function 0.0019712040666490793\n",
      "epoch 4091, loss function 0.0019631548784673214\n",
      "epoch 4092, loss function 0.0019550444558262825\n",
      "epoch 4093, loss function 0.0019470156403258443\n",
      "epoch 4094, loss function 0.0019390934612601995\n",
      "epoch 4095, loss function 0.0019311555661261082\n",
      "epoch 4096, loss function 0.0019231290789321065\n",
      "epoch 4097, loss function 0.0019156818743795156\n",
      "epoch 4098, loss function 0.0019081924110651016\n",
      "epoch 4099, loss function 0.0019007675582543015\n",
      "epoch 4100, loss function 0.0018933683168143034\n",
      "epoch 4101, loss function 0.0018859464908018708\n",
      "epoch 4102, loss function 0.0018785424763336778\n",
      "epoch 4103, loss function 0.001871237764135003\n",
      "epoch 4104, loss function 0.001863708021119237\n",
      "epoch 4105, loss function 0.0018563857302069664\n",
      "epoch 4106, loss function 0.001849112450145185\n",
      "epoch 4107, loss function 0.0018417714163661003\n",
      "epoch 4108, loss function 0.001834473223425448\n",
      "epoch 4109, loss function 0.001827124273404479\n",
      "epoch 4110, loss function 0.0018199320184066892\n",
      "epoch 4111, loss function 0.0018126454669982195\n",
      "epoch 4112, loss function 0.0018054473912343383\n",
      "epoch 4113, loss function 0.0017982629360631108\n",
      "epoch 4114, loss function 0.0017909782472997904\n",
      "epoch 4115, loss function 0.0017837324412539601\n",
      "epoch 4116, loss function 0.0017766176024451852\n",
      "epoch 4117, loss function 0.001769423484802246\n",
      "epoch 4118, loss function 0.001762261032126844\n",
      "epoch 4119, loss function 0.0017551530618220568\n",
      "epoch 4120, loss function 0.001747952657751739\n",
      "epoch 4121, loss function 0.0017408633138984442\n",
      "epoch 4122, loss function 0.0017338953912258148\n",
      "epoch 4123, loss function 0.0017269067466259003\n",
      "epoch 4124, loss function 0.0017199967987835407\n",
      "epoch 4125, loss function 0.0017129131592810154\n",
      "epoch 4126, loss function 0.0017059574602171779\n",
      "epoch 4127, loss function 0.0016990441363304853\n",
      "epoch 4128, loss function 0.0016921770293265581\n",
      "epoch 4129, loss function 0.001685216324403882\n",
      "epoch 4130, loss function 0.0016784018371254206\n",
      "epoch 4131, loss function 0.0016714480007067323\n",
      "epoch 4132, loss function 0.0016645726282149553\n",
      "epoch 4133, loss function 0.001657772110775113\n",
      "epoch 4134, loss function 0.0016509330598637462\n",
      "epoch 4135, loss function 0.0016440878389403224\n",
      "epoch 4136, loss function 0.0016371929086744785\n",
      "epoch 4137, loss function 0.0016304521122947335\n",
      "epoch 4138, loss function 0.0016236731316894293\n",
      "epoch 4139, loss function 0.0016169247683137655\n",
      "epoch 4140, loss function 0.0016102285590022802\n",
      "epoch 4141, loss function 0.0016034820582717657\n",
      "epoch 4142, loss function 0.0015967496437951922\n",
      "epoch 4143, loss function 0.0015900376019999385\n",
      "epoch 4144, loss function 0.0015833425568416715\n",
      "epoch 4145, loss function 0.0015766520518809557\n",
      "epoch 4146, loss function 0.0015699226642027497\n",
      "epoch 4147, loss function 0.001563320867717266\n",
      "epoch 4148, loss function 0.001556712668389082\n",
      "epoch 4149, loss function 0.001550053944811225\n",
      "epoch 4150, loss function 0.0015434341039508581\n",
      "epoch 4151, loss function 0.0015369125176221132\n",
      "epoch 4152, loss function 0.00153063063044101\n",
      "epoch 4153, loss function 0.0015245105605572462\n",
      "epoch 4154, loss function 0.0015182740753516555\n",
      "epoch 4155, loss function 0.0015120981261134148\n",
      "epoch 4156, loss function 0.0015059142606332898\n",
      "epoch 4157, loss function 0.0014997819671407342\n",
      "epoch 4158, loss function 0.0014936483930796385\n",
      "epoch 4159, loss function 0.0014875223860144615\n",
      "epoch 4160, loss function 0.0014818842755630612\n",
      "epoch 4161, loss function 0.00147611228749156\n",
      "epoch 4162, loss function 0.0014704101486131549\n",
      "epoch 4163, loss function 0.0014647984644398093\n",
      "epoch 4164, loss function 0.0014592302031815052\n",
      "epoch 4165, loss function 0.0014535387745127082\n",
      "epoch 4166, loss function 0.0014478272059932351\n",
      "epoch 4167, loss function 0.0014423152897506952\n",
      "epoch 4168, loss function 0.0014367953408509493\n",
      "epoch 4169, loss function 0.0014311204431578517\n",
      "epoch 4170, loss function 0.0014254788402467966\n",
      "epoch 4171, loss function 0.0014199555153027177\n",
      "epoch 4172, loss function 0.0014144612941890955\n",
      "epoch 4173, loss function 0.0014088547322899103\n",
      "epoch 4174, loss function 0.0014032525941729546\n",
      "epoch 4175, loss function 0.0013978421920910478\n",
      "epoch 4176, loss function 0.0013923665974289179\n",
      "epoch 4177, loss function 0.0013868326786905527\n",
      "epoch 4178, loss function 0.0013812443939968944\n",
      "epoch 4179, loss function 0.0013758422574028373\n",
      "epoch 4180, loss function 0.001370424055494368\n",
      "epoch 4181, loss function 0.0013649269239977002\n",
      "epoch 4182, loss function 0.0013593899784609675\n",
      "epoch 4183, loss function 0.0013540684012696147\n",
      "epoch 4184, loss function 0.0013486830284819007\n",
      "epoch 4185, loss function 0.0013432009145617485\n",
      "epoch 4186, loss function 0.0013377340510487556\n",
      "epoch 4187, loss function 0.0013324097963050008\n",
      "epoch 4188, loss function 0.0013271174393594265\n",
      "epoch 4189, loss function 0.001321657793596387\n",
      "epoch 4190, loss function 0.001316178822889924\n",
      "epoch 4191, loss function 0.0013109551509842277\n",
      "epoch 4192, loss function 0.0013056413736194372\n",
      "epoch 4193, loss function 0.0013002678751945496\n",
      "epoch 4194, loss function 0.0012948577059432864\n",
      "epoch 4195, loss function 0.001289709354750812\n",
      "epoch 4196, loss function 0.001284429687075317\n",
      "epoch 4197, loss function 0.0012790877372026443\n",
      "epoch 4198, loss function 0.0012737562647089362\n",
      "epoch 4199, loss function 0.0012685625115409493\n",
      "epoch 4200, loss function 0.0012633223086595535\n",
      "epoch 4201, loss function 0.0012581611517816782\n",
      "epoch 4202, loss function 0.001252867397852242\n",
      "epoch 4203, loss function 0.0012478262651711702\n",
      "epoch 4204, loss function 0.00124274636618793\n",
      "epoch 4205, loss function 0.0012375913793221116\n",
      "epoch 4206, loss function 0.001232450595125556\n",
      "epoch 4207, loss function 0.0012274100445210934\n",
      "epoch 4208, loss function 0.001222364604473114\n",
      "epoch 4209, loss function 0.0012171949492767453\n",
      "epoch 4210, loss function 0.0012121055042371154\n",
      "epoch 4211, loss function 0.0012071003438904881\n",
      "epoch 4212, loss function 0.0012021207949146628\n",
      "epoch 4213, loss function 0.001197042758576572\n",
      "epoch 4214, loss function 0.00119195063598454\n",
      "epoch 4215, loss function 0.0011870205635204911\n",
      "epoch 4216, loss function 0.0011820950312539935\n",
      "epoch 4217, loss function 0.0011769887059926987\n",
      "epoch 4218, loss function 0.0011719386093318462\n",
      "epoch 4219, loss function 0.0011670105159282684\n",
      "epoch 4220, loss function 0.0011621462181210518\n",
      "epoch 4221, loss function 0.0011571014765650034\n",
      "epoch 4222, loss function 0.0011521220440045\n",
      "epoch 4223, loss function 0.0011472506448626518\n",
      "epoch 4224, loss function 0.0011424256954342127\n",
      "epoch 4225, loss function 0.0011374267050996423\n",
      "epoch 4226, loss function 0.001132446457631886\n",
      "epoch 4227, loss function 0.0011276300065219402\n",
      "epoch 4228, loss function 0.0011228476651012897\n",
      "epoch 4229, loss function 0.001117897336371243\n",
      "epoch 4230, loss function 0.0011129839112982154\n",
      "epoch 4231, loss function 0.0011082706041634083\n",
      "epoch 4232, loss function 0.0011040414683520794\n",
      "epoch 4233, loss function 0.0010998956859111786\n",
      "epoch 4234, loss function 0.001095761894248426\n",
      "epoch 4235, loss function 0.0010916859610006213\n",
      "epoch 4236, loss function 0.001087539130821824\n",
      "epoch 4237, loss function 0.0010833401465788484\n",
      "epoch 4238, loss function 0.001079286215826869\n",
      "epoch 4239, loss function 0.0010751696536317468\n",
      "epoch 4240, loss function 0.0010710936039686203\n",
      "epoch 4241, loss function 0.001067012781277299\n",
      "epoch 4242, loss function 0.00106295314617455\n",
      "epoch 4243, loss function 0.0010588685981929302\n",
      "epoch 4244, loss function 0.0010548214195296168\n",
      "epoch 4245, loss function 0.0010507259285077453\n",
      "epoch 4246, loss function 0.0010467283427715302\n",
      "epoch 4247, loss function 0.0010426798835396767\n",
      "epoch 4248, loss function 0.0010386643698439002\n",
      "epoch 4249, loss function 0.0010346344206482172\n",
      "epoch 4250, loss function 0.001030653016641736\n",
      "epoch 4251, loss function 0.0010266263270750642\n",
      "epoch 4252, loss function 0.0010226094163954258\n",
      "epoch 4253, loss function 0.0010186262661591172\n",
      "epoch 4254, loss function 0.0010146698914468288\n",
      "epoch 4255, loss function 0.0010107181733474135\n",
      "epoch 4256, loss function 0.001006723497994244\n",
      "epoch 4257, loss function 0.0010027643293142319\n",
      "epoch 4258, loss function 0.000998868839815259\n",
      "epoch 4259, loss function 0.0009949379600584507\n",
      "epoch 4260, loss function 0.0009909393265843391\n",
      "epoch 4261, loss function 0.0009869917994365096\n",
      "epoch 4262, loss function 0.0009831003844738007\n",
      "epoch 4263, loss function 0.000979197327978909\n",
      "epoch 4264, loss function 0.0009752808255143464\n",
      "epoch 4265, loss function 0.0009713698527775705\n",
      "epoch 4266, loss function 0.000967498985119164\n",
      "epoch 4267, loss function 0.0009636319009587169\n",
      "epoch 4268, loss function 0.000959750497713685\n",
      "epoch 4269, loss function 0.0009558593155816197\n",
      "epoch 4270, loss function 0.0009519900195300579\n",
      "epoch 4271, loss function 0.0009482058230787516\n",
      "epoch 4272, loss function 0.0009443223243579268\n",
      "epoch 4273, loss function 0.0009404842276126146\n",
      "epoch 4274, loss function 0.0009366468875668943\n",
      "epoch 4275, loss function 0.0009328818414360285\n",
      "epoch 4276, loss function 0.000929029134567827\n",
      "epoch 4277, loss function 0.0009252394083887339\n",
      "epoch 4278, loss function 0.000921440776437521\n",
      "epoch 4279, loss function 0.00091765500837937\n",
      "epoch 4280, loss function 0.0009138983441516757\n",
      "epoch 4281, loss function 0.0009100667666643858\n",
      "epoch 4282, loss function 0.0009063261095434427\n",
      "epoch 4283, loss function 0.0009025956969708204\n",
      "epoch 4284, loss function 0.0008988521294668317\n",
      "epoch 4285, loss function 0.0008951308554969728\n",
      "epoch 4286, loss function 0.0008913828642107546\n",
      "epoch 4287, loss function 0.0008877225336618721\n",
      "epoch 4288, loss function 0.0008839201764203608\n",
      "epoch 4289, loss function 0.0008802275406196713\n",
      "epoch 4290, loss function 0.0008765113889239728\n",
      "epoch 4291, loss function 0.0008728992543183267\n",
      "epoch 4292, loss function 0.0008691676775924861\n",
      "epoch 4293, loss function 0.0008655101992189884\n",
      "epoch 4294, loss function 0.0008618449792265892\n",
      "epoch 4295, loss function 0.0008581487345509231\n",
      "epoch 4296, loss function 0.0008545982418581843\n",
      "epoch 4297, loss function 0.000851028598845005\n",
      "epoch 4298, loss function 0.0008474252535961568\n",
      "epoch 4299, loss function 0.0008439118973910809\n",
      "epoch 4300, loss function 0.0008403313113376498\n",
      "epoch 4301, loss function 0.0008367627742700279\n",
      "epoch 4302, loss function 0.0008332319557666779\n",
      "epoch 4303, loss function 0.0008297413005493581\n",
      "epoch 4304, loss function 0.0008262086194008589\n",
      "epoch 4305, loss function 0.0008226438076235354\n",
      "epoch 4306, loss function 0.0008191515225917101\n",
      "epoch 4307, loss function 0.0008156874682754278\n",
      "epoch 4308, loss function 0.0008121660212054849\n",
      "epoch 4309, loss function 0.0008086634334176779\n",
      "epoch 4310, loss function 0.0008051893091760576\n",
      "epoch 4311, loss function 0.0008017465006560087\n",
      "epoch 4312, loss function 0.000798282737378031\n",
      "epoch 4313, loss function 0.0007948079728521407\n",
      "epoch 4314, loss function 0.0007913847221061587\n",
      "epoch 4315, loss function 0.0007879495969973505\n",
      "epoch 4316, loss function 0.0007847531815059483\n",
      "epoch 4317, loss function 0.0007816944271326065\n",
      "epoch 4318, loss function 0.0007786466740071774\n",
      "epoch 4319, loss function 0.0007754305843263865\n",
      "epoch 4320, loss function 0.0007723091403022408\n",
      "epoch 4321, loss function 0.0007692865328863263\n",
      "epoch 4322, loss function 0.0007662437274120748\n",
      "epoch 4323, loss function 0.0007631000480614603\n",
      "epoch 4324, loss function 0.0007599805830977857\n",
      "epoch 4325, loss function 0.0007569585577584803\n",
      "epoch 4326, loss function 0.0007539485231973231\n",
      "epoch 4327, loss function 0.0007508342387154698\n",
      "epoch 4328, loss function 0.0007479980704374611\n",
      "epoch 4329, loss function 0.0007452852441929281\n",
      "epoch 4330, loss function 0.0007425122894346714\n",
      "epoch 4331, loss function 0.000739712209906429\n",
      "epoch 4332, loss function 0.0007369086379185319\n",
      "epoch 4333, loss function 0.000734166067559272\n",
      "epoch 4334, loss function 0.0007314685499295592\n",
      "epoch 4335, loss function 0.0007286107284016907\n",
      "epoch 4336, loss function 0.0007258431287482381\n",
      "epoch 4337, loss function 0.0007231716299429536\n",
      "epoch 4338, loss function 0.0007204677676782012\n",
      "epoch 4339, loss function 0.0007176949875429273\n",
      "epoch 4340, loss function 0.0007149167358875275\n",
      "epoch 4341, loss function 0.0007122011738829315\n",
      "epoch 4342, loss function 0.0007095602340996265\n",
      "epoch 4343, loss function 0.0007067903643473983\n",
      "epoch 4344, loss function 0.0007040501805022359\n",
      "epoch 4345, loss function 0.0007014074362814426\n",
      "epoch 4346, loss function 0.0006987255183048546\n",
      "epoch 4347, loss function 0.0006960011669434607\n",
      "epoch 4348, loss function 0.0006932389223948121\n",
      "epoch 4349, loss function 0.0006906273774802685\n",
      "epoch 4350, loss function 0.0006879984866827726\n",
      "epoch 4351, loss function 0.0006852701772004366\n",
      "epoch 4352, loss function 0.0006825624732300639\n",
      "epoch 4353, loss function 0.0006799380062147975\n",
      "epoch 4354, loss function 0.000677353295031935\n",
      "epoch 4355, loss function 0.0006746645085513592\n",
      "epoch 4356, loss function 0.0006719486555084586\n",
      "epoch 4357, loss function 0.0006693318136967719\n",
      "epoch 4358, loss function 0.0006667714915238321\n",
      "epoch 4359, loss function 0.0006640499923378229\n",
      "epoch 4360, loss function 0.0006614105659537017\n",
      "epoch 4361, loss function 0.0006588643882423639\n",
      "epoch 4362, loss function 0.0006562885828316212\n",
      "epoch 4363, loss function 0.0006536184810101986\n",
      "epoch 4364, loss function 0.0006509454688057303\n",
      "epoch 4365, loss function 0.0006484027253463864\n",
      "epoch 4366, loss function 0.0006458656280301511\n",
      "epoch 4367, loss function 0.0006432069931179285\n",
      "epoch 4368, loss function 0.000640593993011862\n",
      "epoch 4369, loss function 0.0006380828563123941\n",
      "epoch 4370, loss function 0.0006355237565003335\n",
      "epoch 4371, loss function 0.0006329053430818021\n",
      "epoch 4372, loss function 0.0006303027621470392\n",
      "epoch 4373, loss function 0.0006278027431108057\n",
      "epoch 4374, loss function 0.0006253108731471002\n",
      "epoch 4375, loss function 0.0006226846599020064\n",
      "epoch 4376, loss function 0.0006201091455295682\n",
      "epoch 4377, loss function 0.0006175949238240719\n",
      "epoch 4378, loss function 0.0006151170819066465\n",
      "epoch 4379, loss function 0.0006125575746409595\n",
      "epoch 4380, loss function 0.000609984970651567\n",
      "epoch 4381, loss function 0.0006074999691918492\n",
      "epoch 4382, loss function 0.0006050470983609557\n",
      "epoch 4383, loss function 0.0006025217589922249\n",
      "epoch 4384, loss function 0.0005999679560773075\n",
      "epoch 4385, loss function 0.000597498205024749\n",
      "epoch 4386, loss function 0.0005950721679255366\n",
      "epoch 4387, loss function 0.0005925320438109338\n",
      "epoch 4388, loss function 0.0005900191608816385\n",
      "epoch 4389, loss function 0.0005875792703591287\n",
      "epoch 4390, loss function 0.0005851513706147671\n",
      "epoch 4391, loss function 0.0005826328415423632\n",
      "epoch 4392, loss function 0.0005801518564112484\n",
      "epoch 4393, loss function 0.0005777004407718778\n",
      "epoch 4394, loss function 0.0005753037985414267\n",
      "epoch 4395, loss function 0.000572850345633924\n",
      "epoch 4396, loss function 0.0005703521310351789\n",
      "epoch 4397, loss function 0.0005679486785084009\n",
      "epoch 4398, loss function 0.0005655756685882807\n",
      "epoch 4399, loss function 0.0005630873492918909\n",
      "epoch 4400, loss function 0.0005606566555798054\n",
      "epoch 4401, loss function 0.0005582759040407836\n",
      "epoch 4402, loss function 0.0005559220444411039\n",
      "epoch 4403, loss function 0.0005534912343136966\n",
      "epoch 4404, loss function 0.0005510161863639951\n",
      "epoch 4405, loss function 0.0005486835143528879\n",
      "epoch 4406, loss function 0.000546327093616128\n",
      "epoch 4407, loss function 0.0005438811494968832\n",
      "epoch 4408, loss function 0.000541513494681567\n",
      "epoch 4409, loss function 0.0005391567246988416\n",
      "epoch 4410, loss function 0.000536855892278254\n",
      "epoch 4411, loss function 0.0005344124510884285\n",
      "epoch 4412, loss function 0.0005320454365573823\n",
      "epoch 4413, loss function 0.0005297312745824456\n",
      "epoch 4414, loss function 0.0005274282884784043\n",
      "epoch 4415, loss function 0.0005250790272839367\n",
      "epoch 4416, loss function 0.00052306626457721\n",
      "epoch 4417, loss function 0.0005210473318584263\n",
      "epoch 4418, loss function 0.0005190473748371005\n",
      "epoch 4419, loss function 0.0005169741343706846\n",
      "epoch 4420, loss function 0.0005150025826878846\n",
      "epoch 4421, loss function 0.0005129537894390523\n",
      "epoch 4422, loss function 0.0005109909689053893\n",
      "epoch 4423, loss function 0.0005089652258902788\n",
      "epoch 4424, loss function 0.0005069973994977772\n",
      "epoch 4425, loss function 0.0005049831815995276\n",
      "epoch 4426, loss function 0.0005029920721426606\n",
      "epoch 4427, loss function 0.0005010010208934546\n",
      "epoch 4428, loss function 0.0004990265588276088\n",
      "epoch 4429, loss function 0.0004969940055161715\n",
      "epoch 4430, loss function 0.0004950733855366707\n",
      "epoch 4431, loss function 0.000493074650876224\n",
      "epoch 4432, loss function 0.0004911391297355294\n",
      "epoch 4433, loss function 0.0004891433054581285\n",
      "epoch 4434, loss function 0.0004872104909736663\n",
      "epoch 4435, loss function 0.0004852573911193758\n",
      "epoch 4436, loss function 0.0004833113634958863\n",
      "epoch 4437, loss function 0.0004813667619600892\n",
      "epoch 4438, loss function 0.0004794339765794575\n",
      "epoch 4439, loss function 0.0004775134730152786\n",
      "epoch 4440, loss function 0.00047556389472447336\n",
      "epoch 4441, loss function 0.00047363509656861424\n",
      "epoch 4442, loss function 0.0004716940165963024\n",
      "epoch 4443, loss function 0.0004697515396401286\n",
      "epoch 4444, loss function 0.00046788837062194943\n",
      "epoch 4445, loss function 0.00046596102765761316\n",
      "epoch 4446, loss function 0.0004640427359845489\n",
      "epoch 4447, loss function 0.00046211242442950606\n",
      "epoch 4448, loss function 0.00046042242320254445\n",
      "epoch 4449, loss function 0.0004587300354614854\n",
      "epoch 4450, loss function 0.0004570271703414619\n",
      "epoch 4451, loss function 0.00045526400208473206\n",
      "epoch 4452, loss function 0.0004536234773695469\n",
      "epoch 4453, loss function 0.00045191493700258434\n",
      "epoch 4454, loss function 0.0004502640222199261\n",
      "epoch 4455, loss function 0.0004485534445848316\n",
      "epoch 4456, loss function 0.000446902442490682\n",
      "epoch 4457, loss function 0.00044521584641188383\n",
      "epoch 4458, loss function 0.00044355870340950787\n",
      "epoch 4459, loss function 0.00044186500599607825\n",
      "epoch 4460, loss function 0.00044024016824550927\n",
      "epoch 4461, loss function 0.00043857278069481254\n",
      "epoch 4462, loss function 0.00043688545702025294\n",
      "epoch 4463, loss function 0.00043522572377696633\n",
      "epoch 4464, loss function 0.00043360842391848564\n",
      "epoch 4465, loss function 0.00043191126314923167\n",
      "epoch 4466, loss function 0.0004302824381738901\n",
      "epoch 4467, loss function 0.00042860591202042997\n",
      "epoch 4468, loss function 0.00042700456106103957\n",
      "epoch 4469, loss function 0.0004253554798197001\n",
      "epoch 4470, loss function 0.00042375182965770364\n",
      "epoch 4471, loss function 0.0004220997216179967\n",
      "epoch 4472, loss function 0.00042048541945405304\n",
      "epoch 4473, loss function 0.0004187907907180488\n",
      "epoch 4474, loss function 0.0004172396147623658\n",
      "epoch 4475, loss function 0.0004155954229645431\n",
      "epoch 4476, loss function 0.000413999572629109\n",
      "epoch 4477, loss function 0.0004123588150832802\n",
      "epoch 4478, loss function 0.00041078421054407954\n",
      "epoch 4479, loss function 0.00040916563011705875\n",
      "epoch 4480, loss function 0.000407554442062974\n",
      "epoch 4481, loss function 0.00040593952871859074\n",
      "epoch 4482, loss function 0.00040437502320855856\n",
      "epoch 4483, loss function 0.00040275714127346873\n",
      "epoch 4484, loss function 0.00040119350887835026\n",
      "epoch 4485, loss function 0.00039957271656021476\n",
      "epoch 4486, loss function 0.00039798716898076236\n",
      "epoch 4487, loss function 0.00039639166789129376\n",
      "epoch 4488, loss function 0.00039486581226810813\n",
      "epoch 4489, loss function 0.0003932408872060478\n",
      "epoch 4490, loss function 0.0003917242574971169\n",
      "epoch 4491, loss function 0.000390137400245294\n",
      "epoch 4492, loss function 0.0003886101476382464\n",
      "epoch 4493, loss function 0.00038698414573445916\n",
      "epoch 4494, loss function 0.0003854765964206308\n",
      "epoch 4495, loss function 0.0003838565025944263\n",
      "epoch 4496, loss function 0.00038232794031500816\n",
      "epoch 4497, loss function 0.00038078753277659416\n",
      "epoch 4498, loss function 0.0003792469506151974\n",
      "epoch 4499, loss function 0.00037768654874525964\n",
      "epoch 4500, loss function 0.0003761631087400019\n",
      "epoch 4501, loss function 0.000374607858248055\n",
      "epoch 4502, loss function 0.00037309442996047437\n",
      "epoch 4503, loss function 0.0003715220373123884\n",
      "epoch 4504, loss function 0.0003700160887092352\n",
      "epoch 4505, loss function 0.0003685111296363175\n",
      "epoch 4506, loss function 0.0003669996513053775\n",
      "epoch 4507, loss function 0.00036545234615914524\n",
      "epoch 4508, loss function 0.00036395221832208335\n",
      "epoch 4509, loss function 0.0003624590171966702\n",
      "epoch 4510, loss function 0.0003609329287428409\n",
      "epoch 4511, loss function 0.00035940122324973345\n",
      "epoch 4512, loss function 0.0003579417534638196\n",
      "epoch 4513, loss function 0.0003563904028851539\n",
      "epoch 4514, loss function 0.0003549190878402442\n",
      "epoch 4515, loss function 0.0003533966955728829\n",
      "epoch 4516, loss function 0.00035194552037864923\n",
      "epoch 4517, loss function 0.000350433198036626\n",
      "epoch 4518, loss function 0.00034898455487564206\n",
      "epoch 4519, loss function 0.00034748701727949083\n",
      "epoch 4520, loss function 0.0003460289444774389\n",
      "epoch 4521, loss function 0.00034452317049726844\n",
      "epoch 4522, loss function 0.0003430742071941495\n",
      "epoch 4523, loss function 0.00034159765345975757\n",
      "epoch 4524, loss function 0.00034011551178991795\n",
      "epoch 4525, loss function 0.00033865650766529143\n",
      "epoch 4526, loss function 0.0003372195060364902\n",
      "epoch 4527, loss function 0.00033575258566997945\n",
      "epoch 4528, loss function 0.0003343129064887762\n",
      "epoch 4529, loss function 0.0003328498569317162\n",
      "epoch 4530, loss function 0.000331408140482381\n",
      "epoch 4531, loss function 0.00032996712252497673\n",
      "epoch 4532, loss function 0.00032854132587090135\n",
      "epoch 4533, loss function 0.00032709274091757834\n",
      "epoch 4534, loss function 0.0003256771306041628\n",
      "epoch 4535, loss function 0.00032422805088572204\n",
      "epoch 4536, loss function 0.0003228234709240496\n",
      "epoch 4537, loss function 0.0003213945310562849\n",
      "epoch 4538, loss function 0.0003199693455826491\n",
      "epoch 4539, loss function 0.00031851668609306216\n",
      "epoch 4540, loss function 0.0003171568678226322\n",
      "epoch 4541, loss function 0.0003157255705446005\n",
      "epoch 4542, loss function 0.00031454331474378705\n",
      "epoch 4543, loss function 0.0003133059071842581\n",
      "epoch 4544, loss function 0.00031205581035465\n",
      "epoch 4545, loss function 0.0003109060926362872\n",
      "epoch 4546, loss function 0.00030972209060564637\n",
      "epoch 4547, loss function 0.00030849079485051334\n",
      "epoch 4548, loss function 0.00030727943521924317\n",
      "epoch 4549, loss function 0.00030612191767431796\n",
      "epoch 4550, loss function 0.0003049637016374618\n",
      "epoch 4551, loss function 0.0003037195128854364\n",
      "epoch 4552, loss function 0.000302486791042611\n",
      "epoch 4553, loss function 0.0003013619570992887\n",
      "epoch 4554, loss function 0.00030021797283552587\n",
      "epoch 4555, loss function 0.0002989900822285563\n",
      "epoch 4556, loss function 0.0002978085831273347\n",
      "epoch 4557, loss function 0.0002966411120723933\n",
      "epoch 4558, loss function 0.0002955412492156029\n",
      "epoch 4559, loss function 0.0002943045983556658\n",
      "epoch 4560, loss function 0.00029311099206097424\n",
      "epoch 4561, loss function 0.00029200350400060415\n",
      "epoch 4562, loss function 0.0002908527385443449\n",
      "epoch 4563, loss function 0.00028966073296032846\n",
      "epoch 4564, loss function 0.00028847044450230896\n",
      "epoch 4565, loss function 0.0002873348130378872\n",
      "epoch 4566, loss function 0.0002862342225853354\n",
      "epoch 4567, loss function 0.00028503977227956057\n",
      "epoch 4568, loss function 0.0002838755026459694\n",
      "epoch 4569, loss function 0.00028275157092139125\n",
      "epoch 4570, loss function 0.00028163223760202527\n",
      "epoch 4571, loss function 0.00028047774685546756\n",
      "epoch 4572, loss function 0.0002793052699416876\n",
      "epoch 4573, loss function 0.0002782047668006271\n",
      "epoch 4574, loss function 0.00027716142358258367\n",
      "epoch 4575, loss function 0.0002760298957582563\n",
      "epoch 4576, loss function 0.000274894991889596\n",
      "epoch 4577, loss function 0.000273868499789387\n",
      "epoch 4578, loss function 0.0002728032413870096\n",
      "epoch 4579, loss function 0.0002716741000767797\n",
      "epoch 4580, loss function 0.00027054891688749194\n",
      "epoch 4581, loss function 0.0002694835711736232\n",
      "epoch 4582, loss function 0.00026844668900594115\n",
      "epoch 4583, loss function 0.00026732918922789395\n",
      "epoch 4584, loss function 0.0002662334591150284\n",
      "epoch 4585, loss function 0.0002652046678122133\n",
      "epoch 4586, loss function 0.000264140369836241\n",
      "epoch 4587, loss function 0.0002630477538332343\n",
      "epoch 4588, loss function 0.0002619488805066794\n",
      "epoch 4589, loss function 0.0002609047805890441\n",
      "epoch 4590, loss function 0.000259882741374895\n",
      "epoch 4591, loss function 0.0002587834023870528\n",
      "epoch 4592, loss function 0.0002577169507276267\n",
      "epoch 4593, loss function 0.00025669147726148367\n",
      "epoch 4594, loss function 0.0002556522376835346\n",
      "epoch 4595, loss function 0.00025456270668655634\n",
      "epoch 4596, loss function 0.0002534887462388724\n",
      "epoch 4597, loss function 0.0002524619922041893\n",
      "epoch 4598, loss function 0.00025146486586891115\n",
      "epoch 4599, loss function 0.0002503833966329694\n",
      "epoch 4600, loss function 0.0002493011998012662\n",
      "epoch 4601, loss function 0.00024828617461025715\n",
      "epoch 4602, loss function 0.0002472731866873801\n",
      "epoch 4603, loss function 0.00024622789351269603\n",
      "epoch 4604, loss function 0.00024517247220501304\n",
      "epoch 4605, loss function 0.0002441451360937208\n",
      "epoch 4606, loss function 0.00024317704082932323\n",
      "epoch 4607, loss function 0.0002421116951154545\n",
      "epoch 4608, loss function 0.0002410591405350715\n",
      "epoch 4609, loss function 0.0002402412355877459\n",
      "epoch 4610, loss function 0.00023935272474773228\n",
      "epoch 4611, loss function 0.00023846565454732627\n",
      "epoch 4612, loss function 0.0002375608019065112\n",
      "epoch 4613, loss function 0.00023670459631830454\n",
      "epoch 4614, loss function 0.00023587817850057036\n",
      "epoch 4615, loss function 0.00023496458015870303\n",
      "epoch 4616, loss function 0.00023407682601828128\n",
      "epoch 4617, loss function 0.00023324499488808215\n",
      "epoch 4618, loss function 0.00023238650464918464\n",
      "epoch 4619, loss function 0.00023148937907535583\n",
      "epoch 4620, loss function 0.0002306104579474777\n",
      "epoch 4621, loss function 0.00022977974731475115\n",
      "epoch 4622, loss function 0.00022895717120263726\n",
      "epoch 4623, loss function 0.0002280749031342566\n",
      "epoch 4624, loss function 0.00022718746913596988\n",
      "epoch 4625, loss function 0.00022637881920672953\n",
      "epoch 4626, loss function 0.0002255287254229188\n",
      "epoch 4627, loss function 0.0002246421208838001\n",
      "epoch 4628, loss function 0.0002237854350823909\n",
      "epoch 4629, loss function 0.0002229652600362897\n",
      "epoch 4630, loss function 0.00022213687770999968\n",
      "epoch 4631, loss function 0.00022125447867438197\n",
      "epoch 4632, loss function 0.00022039984469301999\n",
      "epoch 4633, loss function 0.00021960565936751664\n",
      "epoch 4634, loss function 0.0002187674108427018\n",
      "epoch 4635, loss function 0.00021790638857055455\n",
      "epoch 4636, loss function 0.00021705328254029155\n",
      "epoch 4637, loss function 0.00021625147201120853\n",
      "epoch 4638, loss function 0.0002154280518880114\n",
      "epoch 4639, loss function 0.00021457784168887883\n",
      "epoch 4640, loss function 0.0002137473493348807\n",
      "epoch 4641, loss function 0.00021293024474289268\n",
      "epoch 4642, loss function 0.00021210343402344733\n",
      "epoch 4643, loss function 0.00021126584033481777\n",
      "epoch 4644, loss function 0.00021041565923951566\n",
      "epoch 4645, loss function 0.00020962543203495443\n",
      "epoch 4646, loss function 0.00020884039986412972\n",
      "epoch 4647, loss function 0.00020801638311240822\n",
      "epoch 4648, loss function 0.00020715281425509602\n",
      "epoch 4649, loss function 0.00020635701366700232\n",
      "epoch 4650, loss function 0.00020558125106617808\n",
      "epoch 4651, loss function 0.00020476804638747126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4652, loss function 0.00020391687576193362\n",
      "epoch 4653, loss function 0.00020314710855018348\n",
      "epoch 4654, loss function 0.00020235159900039434\n",
      "epoch 4655, loss function 0.00020152170327492058\n",
      "epoch 4656, loss function 0.00020069981110282242\n",
      "epoch 4657, loss function 0.0001999241067096591\n",
      "epoch 4658, loss function 0.00019914165022782981\n",
      "epoch 4659, loss function 0.00019834170234389603\n",
      "epoch 4660, loss function 0.00019749393686652184\n",
      "epoch 4661, loss function 0.0001967305433936417\n",
      "epoch 4662, loss function 0.00019596803758759052\n",
      "epoch 4663, loss function 0.0001951659651240334\n",
      "epoch 4664, loss function 0.00019434656132943928\n",
      "epoch 4665, loss function 0.0001936055050464347\n",
      "epoch 4666, loss function 0.00019280615379102528\n",
      "epoch 4667, loss function 0.00019200460519641638\n",
      "epoch 4668, loss function 0.00019120464276056737\n",
      "epoch 4669, loss function 0.00019044053624384105\n",
      "epoch 4670, loss function 0.00018968932272400707\n",
      "epoch 4671, loss function 0.00018888518388848752\n",
      "epoch 4672, loss function 0.00018810090841725469\n",
      "epoch 4673, loss function 0.00018734006152953953\n",
      "epoch 4674, loss function 0.00018659126362763345\n",
      "epoch 4675, loss function 0.0001858043106039986\n",
      "epoch 4676, loss function 0.0001849924010457471\n",
      "epoch 4677, loss function 0.00018423034634906799\n",
      "epoch 4678, loss function 0.0001835052971728146\n",
      "epoch 4679, loss function 0.00018272182205691934\n",
      "epoch 4680, loss function 0.00018192670540884137\n",
      "epoch 4681, loss function 0.00018118579464498907\n",
      "epoch 4682, loss function 0.00018045860633719712\n",
      "epoch 4683, loss function 0.000179693364771083\n",
      "epoch 4684, loss function 0.00017888614092953503\n",
      "epoch 4685, loss function 0.0001781599421519786\n",
      "epoch 4686, loss function 0.00017743796342983842\n",
      "epoch 4687, loss function 0.000176677291165106\n",
      "epoch 4688, loss function 0.0001758886210154742\n",
      "epoch 4689, loss function 0.0001751603267621249\n",
      "epoch 4690, loss function 0.00017444317927584052\n",
      "epoch 4691, loss function 0.00017366827523801476\n",
      "epoch 4692, loss function 0.00017288220988120884\n",
      "epoch 4693, loss function 0.00017218213179148734\n",
      "epoch 4694, loss function 0.00017146651225630194\n",
      "epoch 4695, loss function 0.0001707015180727467\n",
      "epoch 4696, loss function 0.0001699342974461615\n",
      "epoch 4697, loss function 0.00016921368660405278\n",
      "epoch 4698, loss function 0.0001685130555415526\n",
      "epoch 4699, loss function 0.0001677556283539161\n",
      "epoch 4700, loss function 0.00016698533727321774\n",
      "epoch 4701, loss function 0.00016628600133117288\n",
      "epoch 4702, loss function 0.00016559354844503105\n",
      "epoch 4703, loss function 0.00016483759100083262\n",
      "epoch 4704, loss function 0.00016409096133429557\n",
      "epoch 4705, loss function 0.00016341899754479527\n",
      "epoch 4706, loss function 0.00016269365733023733\n",
      "epoch 4707, loss function 0.00016195733041968197\n",
      "epoch 4708, loss function 0.00016120892541948706\n",
      "epoch 4709, loss function 0.00016050381236709654\n",
      "epoch 4710, loss function 0.0001599497045390308\n",
      "epoch 4711, loss function 0.00015936995623633265\n",
      "epoch 4712, loss function 0.0001588136947248131\n",
      "epoch 4713, loss function 0.00015822143177501857\n",
      "epoch 4714, loss function 0.00015766589785926044\n",
      "epoch 4715, loss function 0.00015709552098996937\n",
      "epoch 4716, loss function 0.00015652572619728744\n",
      "epoch 4717, loss function 0.00015595476725138724\n",
      "epoch 4718, loss function 0.0001553941983729601\n",
      "epoch 4719, loss function 0.00015483578317798674\n",
      "epoch 4720, loss function 0.00015426584286615252\n",
      "epoch 4721, loss function 0.00015370096662081778\n",
      "epoch 4722, loss function 0.00015313702169805765\n",
      "epoch 4723, loss function 0.00015256473852787167\n",
      "epoch 4724, loss function 0.0001520261139376089\n",
      "epoch 4725, loss function 0.00015145725046750158\n",
      "epoch 4726, loss function 0.00015090421948116273\n",
      "epoch 4727, loss function 0.00015035738761071116\n",
      "epoch 4728, loss function 0.0001497879857197404\n",
      "epoch 4729, loss function 0.00014925043797120452\n",
      "epoch 4730, loss function 0.00014869071310386062\n",
      "epoch 4731, loss function 0.000148140374221839\n",
      "epoch 4732, loss function 0.00014758443285245448\n",
      "epoch 4733, loss function 0.00014703217311762273\n",
      "epoch 4734, loss function 0.00014648164506070316\n",
      "epoch 4735, loss function 0.0001459389750380069\n",
      "epoch 4736, loss function 0.0001453926379326731\n",
      "epoch 4737, loss function 0.00014485485735349357\n",
      "epoch 4738, loss function 0.00014429393922910094\n",
      "epoch 4739, loss function 0.00014375976752489805\n",
      "epoch 4740, loss function 0.00014322386414278299\n",
      "epoch 4741, loss function 0.0001426642993465066\n",
      "epoch 4742, loss function 0.00014212625683285296\n",
      "epoch 4743, loss function 0.00014162244042381644\n",
      "epoch 4744, loss function 0.00014106415619608015\n",
      "epoch 4745, loss function 0.00014050713798496872\n",
      "epoch 4746, loss function 0.00013999071961734444\n",
      "epoch 4747, loss function 0.00013945458340458572\n",
      "epoch 4748, loss function 0.00013892122660763562\n",
      "epoch 4749, loss function 0.00013837906590197235\n",
      "epoch 4750, loss function 0.00013785460032522678\n",
      "epoch 4751, loss function 0.00013732665684074163\n",
      "epoch 4752, loss function 0.00013677997048944235\n",
      "epoch 4753, loss function 0.00013625217252410948\n",
      "epoch 4754, loss function 0.00013573397882282734\n",
      "epoch 4755, loss function 0.00013524122186936438\n",
      "epoch 4756, loss function 0.00013466953532770276\n",
      "epoch 4757, loss function 0.0001341581082670018\n",
      "epoch 4758, loss function 0.00013362991739995778\n",
      "epoch 4759, loss function 0.00013310705253388733\n",
      "epoch 4760, loss function 0.00013257740647532046\n",
      "epoch 4761, loss function 0.00013206117728259414\n",
      "epoch 4762, loss function 0.0001315558038186282\n",
      "epoch 4763, loss function 0.00013102836965117604\n",
      "epoch 4764, loss function 0.00013051250425633043\n",
      "epoch 4765, loss function 0.00013000269245821983\n",
      "epoch 4766, loss function 0.00012948834046255797\n",
      "epoch 4767, loss function 0.00012896553380414844\n",
      "epoch 4768, loss function 0.00012846544268541038\n",
      "epoch 4769, loss function 0.00012792504276148975\n",
      "epoch 4770, loss function 0.00012742826947942376\n",
      "epoch 4771, loss function 0.0001269189378945157\n",
      "epoch 4772, loss function 0.0001264220627490431\n",
      "epoch 4773, loss function 0.0001259018899872899\n",
      "epoch 4774, loss function 0.00012539749150164425\n",
      "epoch 4775, loss function 0.00012489754590205848\n",
      "epoch 4776, loss function 0.00012439493730198592\n",
      "epoch 4777, loss function 0.00012388775940053165\n",
      "epoch 4778, loss function 0.00012337701627984643\n",
      "epoch 4779, loss function 0.0001228841138072312\n",
      "epoch 4780, loss function 0.00012237355986144394\n",
      "epoch 4781, loss function 0.00012186520325485617\n",
      "epoch 4782, loss function 0.0001213858267874457\n",
      "epoch 4783, loss function 0.00012089385563740507\n",
      "epoch 4784, loss function 0.0001203876527142711\n",
      "epoch 4785, loss function 0.00011989699123660102\n",
      "epoch 4786, loss function 0.00011940742115257308\n",
      "epoch 4787, loss function 0.00011891139729414135\n",
      "epoch 4788, loss function 0.0001184174616355449\n",
      "epoch 4789, loss function 0.00011791608994826674\n",
      "epoch 4790, loss function 0.00011743059440050274\n",
      "epoch 4791, loss function 0.00011694847489707172\n",
      "epoch 4792, loss function 0.0001164417335530743\n",
      "epoch 4793, loss function 0.00011596274998737499\n",
      "epoch 4794, loss function 0.00011547681788215414\n",
      "epoch 4795, loss function 0.00011500672553665936\n",
      "epoch 4796, loss function 0.0001145210990216583\n",
      "epoch 4797, loss function 0.00011402471136534587\n",
      "epoch 4798, loss function 0.0001135352358687669\n",
      "epoch 4799, loss function 0.0001130800083046779\n",
      "epoch 4800, loss function 0.0001125918424804695\n",
      "epoch 4801, loss function 0.00011209610966034234\n",
      "epoch 4802, loss function 0.00011163012823089957\n",
      "epoch 4803, loss function 0.00011116015957668424\n",
      "epoch 4804, loss function 0.00011068412277381867\n",
      "epoch 4805, loss function 0.00011019662633771077\n",
      "epoch 4806, loss function 0.0001097444910556078\n",
      "epoch 4807, loss function 0.00010925938113359734\n",
      "epoch 4808, loss function 0.00010878646571654826\n",
      "epoch 4809, loss function 0.00010829912935150787\n",
      "epoch 4810, loss function 0.0001078547938959673\n",
      "epoch 4811, loss function 0.00010740677680587396\n",
      "epoch 4812, loss function 0.00010695862147258595\n",
      "epoch 4813, loss function 0.00010649075557012111\n",
      "epoch 4814, loss function 0.00010606810246827081\n",
      "epoch 4815, loss function 0.0001056236942531541\n",
      "epoch 4816, loss function 0.00010518818453419954\n",
      "epoch 4817, loss function 0.00010473115980857983\n",
      "epoch 4818, loss function 0.00010429860412841663\n",
      "epoch 4819, loss function 0.0001038668560795486\n",
      "epoch 4820, loss function 0.00010342166206100956\n",
      "epoch 4821, loss function 0.0001029724080581218\n",
      "epoch 4822, loss function 0.00010254549124510959\n",
      "epoch 4823, loss function 0.00010214443318545818\n",
      "epoch 4824, loss function 0.00010167359141632915\n",
      "epoch 4825, loss function 0.00010123746324097738\n",
      "epoch 4826, loss function 0.00010081392247229815\n",
      "epoch 4827, loss function 0.00010039875633083284\n",
      "epoch 4828, loss function 9.995282016461715e-05\n",
      "epoch 4829, loss function 9.952499385690317e-05\n",
      "epoch 4830, loss function 9.909325308399275e-05\n",
      "epoch 4831, loss function 9.866483742371202e-05\n",
      "epoch 4832, loss function 9.823052823776379e-05\n",
      "epoch 4833, loss function 9.780247637536377e-05\n",
      "epoch 4834, loss function 9.738351218402386e-05\n",
      "epoch 4835, loss function 9.697503264760599e-05\n",
      "epoch 4836, loss function 9.65389481279999e-05\n",
      "epoch 4837, loss function 9.611806308384985e-05\n",
      "epoch 4838, loss function 9.570271504344419e-05\n",
      "epoch 4839, loss function 9.527634392725304e-05\n",
      "epoch 4840, loss function 9.485783084528521e-05\n",
      "epoch 4841, loss function 9.442699956707656e-05\n",
      "epoch 4842, loss function 9.401918214280158e-05\n",
      "epoch 4843, loss function 9.36121359700337e-05\n",
      "epoch 4844, loss function 9.319164382759482e-05\n",
      "epoch 4845, loss function 9.27667279029265e-05\n",
      "epoch 4846, loss function 9.236458572559059e-05\n",
      "epoch 4847, loss function 9.194335871143267e-05\n",
      "epoch 4848, loss function 9.162828791886568e-05\n",
      "epoch 4849, loss function 9.12853138288483e-05\n",
      "epoch 4850, loss function 9.096656867768615e-05\n",
      "epoch 4851, loss function 9.065454651135951e-05\n",
      "epoch 4852, loss function 9.032081288751215e-05\n",
      "epoch 4853, loss function 9.000523277791217e-05\n",
      "epoch 4854, loss function 8.966641325969249e-05\n",
      "epoch 4855, loss function 8.935650112107396e-05\n",
      "epoch 4856, loss function 8.902448462322354e-05\n",
      "epoch 4857, loss function 8.870642341207713e-05\n",
      "epoch 4858, loss function 8.838500070851296e-05\n",
      "epoch 4859, loss function 8.806693949736655e-05\n",
      "epoch 4860, loss function 8.774445450399071e-05\n",
      "epoch 4861, loss function 8.740842895349488e-05\n",
      "epoch 4862, loss function 8.711530244909227e-05\n",
      "epoch 4863, loss function 8.680431346874684e-05\n",
      "epoch 4864, loss function 8.647603681311011e-05\n",
      "epoch 4865, loss function 8.61639273352921e-05\n",
      "epoch 4866, loss function 8.584038005210459e-05\n",
      "epoch 4867, loss function 8.553064981242642e-05\n",
      "epoch 4868, loss function 8.521378913428634e-05\n",
      "epoch 4869, loss function 8.488238381687552e-05\n",
      "epoch 4870, loss function 8.459870150545612e-05\n",
      "epoch 4871, loss function 8.427349530393258e-05\n",
      "epoch 4872, loss function 8.395635813940316e-05\n",
      "epoch 4873, loss function 8.364874520339072e-05\n",
      "epoch 4874, loss function 8.334487210959196e-05\n",
      "epoch 4875, loss function 8.302423520945013e-05\n",
      "epoch 4876, loss function 8.27152471174486e-05\n",
      "epoch 4877, loss function 8.240092574851587e-05\n",
      "epoch 4878, loss function 8.21046851342544e-05\n",
      "epoch 4879, loss function 8.177945710485801e-05\n",
      "epoch 4880, loss function 8.149192581186071e-05\n",
      "epoch 4881, loss function 8.116924436762929e-05\n",
      "epoch 4882, loss function 8.086476009339094e-05\n",
      "epoch 4883, loss function 8.057062223087996e-05\n",
      "epoch 4884, loss function 8.025352872209623e-05\n",
      "epoch 4885, loss function 7.994943734956905e-05\n",
      "epoch 4886, loss function 7.96538733993657e-05\n",
      "epoch 4887, loss function 7.933794404380023e-05\n",
      "epoch 4888, loss function 7.904312224127352e-05\n",
      "epoch 4889, loss function 7.873448339523748e-05\n",
      "epoch 4890, loss function 7.84461954026483e-05\n",
      "epoch 4891, loss function 7.813484262442216e-05\n",
      "epoch 4892, loss function 7.784439367242157e-05\n",
      "epoch 4893, loss function 7.753272075206041e-05\n",
      "epoch 4894, loss function 7.723690941929817e-05\n",
      "epoch 4895, loss function 7.694161467952654e-05\n",
      "epoch 4896, loss function 7.66318553360179e-05\n",
      "epoch 4897, loss function 7.634333451278508e-05\n",
      "epoch 4898, loss function 7.605820428580046e-05\n",
      "epoch 4899, loss function 7.576157804578543e-05\n",
      "epoch 4900, loss function 7.546359120169654e-05\n",
      "epoch 4901, loss function 7.515333709307015e-05\n",
      "epoch 4902, loss function 7.487906259484589e-05\n",
      "epoch 4903, loss function 7.457539322786033e-05\n",
      "epoch 4904, loss function 7.428542448906228e-05\n",
      "epoch 4905, loss function 7.398534944513813e-05\n",
      "epoch 4906, loss function 7.370015373453498e-05\n",
      "epoch 4907, loss function 7.341161835938692e-05\n",
      "epoch 4908, loss function 7.311871740967035e-05\n",
      "epoch 4909, loss function 7.282215665327385e-05\n",
      "epoch 4910, loss function 7.253892545122653e-05\n",
      "epoch 4911, loss function 7.226511661428958e-05\n",
      "epoch 4912, loss function 7.195906073320657e-05\n",
      "epoch 4913, loss function 7.167581497924402e-05\n",
      "epoch 4914, loss function 7.138017099350691e-05\n",
      "epoch 4915, loss function 7.110618753358722e-05\n",
      "epoch 4916, loss function 7.081452349666506e-05\n",
      "epoch 4917, loss function 7.052904402371496e-05\n",
      "epoch 4918, loss function 7.024022488621995e-05\n",
      "epoch 4919, loss function 6.997223681537434e-05\n",
      "epoch 4920, loss function 6.967480294406414e-05\n",
      "epoch 4921, loss function 6.939349987078458e-05\n",
      "epoch 4922, loss function 6.911339733051136e-05\n",
      "epoch 4923, loss function 6.883475725771859e-05\n",
      "epoch 4924, loss function 6.855264655314386e-05\n",
      "epoch 4925, loss function 6.826358730904758e-05\n",
      "epoch 4926, loss function 6.798251706641167e-05\n",
      "epoch 4927, loss function 6.771009066142142e-05\n",
      "epoch 4928, loss function 6.743102130712941e-05\n",
      "epoch 4929, loss function 6.715357449138537e-05\n",
      "epoch 4930, loss function 6.687385030090809e-05\n",
      "epoch 4931, loss function 6.659969221800566e-05\n",
      "epoch 4932, loss function 6.632248550886288e-05\n",
      "epoch 4933, loss function 6.605099042644724e-05\n",
      "epoch 4934, loss function 6.577229214599356e-05\n",
      "epoch 4935, loss function 6.550902617163956e-05\n",
      "epoch 4936, loss function 6.522605690406635e-05\n",
      "epoch 4937, loss function 6.494413537438959e-05\n",
      "epoch 4938, loss function 6.467446655733511e-05\n",
      "epoch 4939, loss function 6.44155079498887e-05\n",
      "epoch 4940, loss function 6.413838127627969e-05\n",
      "epoch 4941, loss function 6.385914457496256e-05\n",
      "epoch 4942, loss function 6.359035614877939e-05\n",
      "epoch 4943, loss function 6.332353950710967e-05\n",
      "epoch 4944, loss function 6.304596172412857e-05\n",
      "epoch 4945, loss function 6.278731598285958e-05\n",
      "epoch 4946, loss function 6.252308958210051e-05\n",
      "epoch 4947, loss function 6.224978278623894e-05\n",
      "epoch 4948, loss function 6.198370101628825e-05\n",
      "epoch 4949, loss function 6.171352288220078e-05\n",
      "epoch 4950, loss function 6.145208317320794e-05\n",
      "epoch 4951, loss function 6.118865712778643e-05\n",
      "epoch 4952, loss function 6.092608600738458e-05\n",
      "epoch 4953, loss function 6.065998604753986e-05\n",
      "epoch 4954, loss function 6.039031723048538e-05\n",
      "epoch 4955, loss function 6.013716119923629e-05\n",
      "epoch 4956, loss function 5.986788164591417e-05\n",
      "epoch 4957, loss function 5.960522321402095e-05\n",
      "epoch 4958, loss function 5.933878492214717e-05\n",
      "epoch 4959, loss function 5.9087898989673704e-05\n",
      "epoch 4960, loss function 5.8824945881497115e-05\n",
      "epoch 4961, loss function 5.856532879988663e-05\n",
      "epoch 4962, loss function 5.839395453222096e-05\n",
      "epoch 4963, loss function 5.822171806357801e-05\n",
      "epoch 4964, loss function 5.807034904137254e-05\n",
      "epoch 4965, loss function 5.788173439214006e-05\n",
      "epoch 4966, loss function 5.769775452790782e-05\n",
      "epoch 4967, loss function 5.754054291173816e-05\n",
      "epoch 4968, loss function 5.73769721086137e-05\n",
      "epoch 4969, loss function 5.718062675441615e-05\n",
      "epoch 4970, loss function 5.700435576727614e-05\n",
      "epoch 4971, loss function 5.6846569350454956e-05\n",
      "epoch 4972, loss function 5.6687873438932e-05\n",
      "epoch 4973, loss function 5.6501008657505736e-05\n",
      "epoch 4974, loss function 5.632793181575835e-05\n",
      "epoch 4975, loss function 5.616750058834441e-05\n",
      "epoch 4976, loss function 5.6004115322139114e-05\n",
      "epoch 4977, loss function 5.581266668741591e-05\n",
      "epoch 4978, loss function 5.564668390434235e-05\n",
      "epoch 4979, loss function 5.548540866584517e-05\n",
      "epoch 4980, loss function 5.532699651666917e-05\n",
      "epoch 4981, loss function 5.5159907788038254e-05\n",
      "epoch 4982, loss function 5.496676021721214e-05\n",
      "epoch 4983, loss function 5.480948675540276e-05\n",
      "epoch 4984, loss function 5.465207505039871e-05\n",
      "epoch 4985, loss function 5.4474614444188774e-05\n",
      "epoch 4986, loss function 5.4299336625263095e-05\n",
      "epoch 4987, loss function 5.414693441707641e-05\n",
      "epoch 4988, loss function 5.399622386903502e-05\n",
      "epoch 4989, loss function 5.3810708777746186e-05\n",
      "epoch 4990, loss function 5.363402669900097e-05\n",
      "epoch 4991, loss function 5.3481959184864536e-05\n",
      "epoch 4992, loss function 5.332486762199551e-05\n",
      "epoch 4993, loss function 5.314306326908991e-05\n",
      "epoch 4994, loss function 5.297199095366523e-05\n",
      "epoch 4995, loss function 5.281828998704441e-05\n",
      "epoch 4996, loss function 5.2674877224490047e-05\n",
      "epoch 4997, loss function 5.2489296649582684e-05\n",
      "epoch 4998, loss function 5.232249532127753e-05\n",
      "epoch 4999, loss function 5.2168063120916486e-05\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5000): \n",
    "    yhat = linear_model(X_Train)\n",
    "    loss = criterion(yhat, Y_Train) \n",
    "    Optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    Optimizer.step() \n",
    "    print('epoch {}, loss function {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bc890ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.0533]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_variable = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "predict_y = linear_model(test_variable)\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ddeef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1103, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Test  = torch.normal(0, 1, (1, 3))\n",
    "y1 = torch.matmul(X_Test, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0,torch.Size([1]))\n",
    "Y_Test = y1.reshape((-1, 1))\n",
    "yhat = linear_model(X_Test)\n",
    "criterion(yhat, Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "dcef0761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5381]])"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f290f",
   "metadata": {},
   "source": [
    "# Now I want to go deeper into this topic\n",
    "* https://www.docker.com/blog/how-to-train-and-deploy-a-linear-regression-model-using-pytorch-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e71517b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "22313955",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 1000\n",
    "true_m = torch.tensor([2, -3.4, 8])\n",
    "true_c = 4.2\n",
    "X = torch.normal(0, 1, (num_examples, len(true_m)))\n",
    "y = torch.matmul(X, true_m) + true_c\n",
    "y += torch.normal(0, 0.01, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2e9ad5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5992e+01,  1.0520e+01,  1.6187e+01,  3.1880e-01, -3.0951e-01,\n",
       "         5.9327e+00,  1.3813e+01, -4.3555e-01,  7.9810e+00,  9.8630e+00,\n",
       "        -4.1379e+00,  9.9030e+00, -1.0143e+00, -2.8659e+00, -5.8441e+00,\n",
       "         7.4970e+00,  1.0933e+00,  1.8477e+00, -7.8330e+00,  1.7300e+01,\n",
       "         9.8987e+00,  7.7476e+00, -5.5060e+00,  1.7474e+00,  9.5069e+00,\n",
       "        -1.1930e+00, -2.7354e+00, -7.6727e-01,  9.1535e+00,  1.1988e+01,\n",
       "         2.7396e+00,  1.6699e+00,  7.9077e-01, -1.2517e+01,  1.7307e+01,\n",
       "         2.1991e+01,  6.5792e+00, -2.5275e+00,  7.2011e+00, -3.5696e+00,\n",
       "         1.0896e+01,  6.7077e+00, -1.6973e+01,  6.7691e+00,  1.4527e+01,\n",
       "         1.4496e+01,  4.3423e+00, -5.6553e+00,  1.4569e+01,  2.7133e+00,\n",
       "        -1.1959e+01,  2.6006e+00,  9.2810e+00, -9.9610e+00,  7.2776e+00,\n",
       "         2.2769e+00, -6.0013e-01,  2.6475e+00, -7.9681e+00,  6.8091e+00,\n",
       "         4.2370e+00,  9.6687e+00,  7.9880e+00,  1.2205e+01,  1.8572e+01,\n",
       "         3.4821e-01,  5.5847e+00,  1.5187e+01, -1.5010e+01,  2.8282e+01,\n",
       "         1.0402e+01, -3.5058e+00, -6.7540e+00,  3.8747e+00,  6.9673e+00,\n",
       "        -2.3071e+00, -1.3838e+00, -7.4831e+00,  2.2353e+01,  1.9753e+00,\n",
       "        -9.6813e-01,  7.3189e+00,  7.0855e+00, -1.6412e-01,  1.0708e+01,\n",
       "         1.4224e+01,  2.1406e+00, -6.4785e+00,  3.9513e+00, -3.8755e+00,\n",
       "         3.9327e+00,  1.7265e+01,  1.7909e+01,  2.5472e+00,  8.2240e-01,\n",
       "         3.6053e+00,  5.2612e+00, -3.0792e-01, -6.7840e+00,  4.1621e+00,\n",
       "         1.1572e+01, -1.1009e+00, -3.5759e+00,  1.2643e+01,  8.7059e+00,\n",
       "         6.7760e+00,  1.1357e+01, -1.2597e+01, -3.6029e+00, -5.4759e+00,\n",
       "         1.1931e+01,  3.1300e+00,  1.7476e+01, -1.7984e+01,  9.6292e+00,\n",
       "        -6.8533e+00,  2.9563e+00,  1.2772e+01, -1.2842e+01,  2.3524e+00,\n",
       "         7.6107e+00,  9.8800e+00,  1.3822e+01,  1.8430e+01,  4.1049e+00,\n",
       "         6.0980e+00, -8.1540e+00,  5.8308e+00, -7.3575e+00, -1.4568e+01,\n",
       "         1.0804e+01,  5.2543e+00, -4.8453e+00,  6.8319e+00,  3.2821e+00,\n",
       "         2.2017e+01,  5.1454e+00, -3.4420e+00,  1.3452e+00,  1.8176e+00,\n",
       "         8.2351e+00,  7.8859e-01,  5.8989e+00, -3.1409e+00,  2.3682e+00,\n",
       "        -9.9355e+00, -2.8193e+00,  2.1523e+01,  2.2227e+01,  9.9070e-01,\n",
       "        -1.2904e+01,  1.0439e+01,  2.4663e+00,  2.2213e+01,  1.0531e+01,\n",
       "         2.2359e+00, -3.3990e-01,  8.6906e+00,  1.4599e+01,  4.1351e+00,\n",
       "         1.8434e+01, -1.3372e+01,  1.2475e+01,  1.6603e+01,  1.9050e+01,\n",
       "         6.0202e+00,  1.8724e+01,  2.9366e+00,  4.2677e+00,  2.3070e+00,\n",
       "        -3.6485e+00,  1.1722e+01,  6.1357e+00,  1.1908e+01,  2.0268e+01,\n",
       "        -9.1353e+00,  1.3442e+01,  3.9628e+00,  8.6398e-01,  7.9614e+00,\n",
       "        -8.0381e+00,  3.8141e+00,  6.8432e+00,  2.8306e+00, -3.6347e-01,\n",
       "        -2.7163e+00,  4.7276e+00, -2.8169e+00,  2.0642e+01, -1.2756e+00,\n",
       "        -1.3594e+00,  3.7782e+00, -5.4717e+00,  7.3367e+00, -1.5763e+01,\n",
       "        -7.2648e+00,  8.9009e+00,  1.4418e+01,  2.5633e+00, -5.0655e+00,\n",
       "         3.1113e+00, -5.1234e-01, -2.7812e-01,  4.6908e+00, -6.6974e+00,\n",
       "         9.2947e+00, -6.9855e+00,  1.3393e+01,  5.5636e+00, -1.3090e+01,\n",
       "        -1.3105e+01, -2.3743e+01, -4.6048e+00, -6.2351e+00,  1.6458e+01,\n",
       "         1.4312e+00,  1.5084e+01,  1.9372e+01,  2.4456e+00,  1.1132e+01,\n",
       "         3.1904e+01, -1.9326e+00,  8.2112e+00,  2.5707e+00,  1.7789e-02,\n",
       "        -9.8691e+00, -7.5122e+00,  6.7447e+00, -6.0244e+00,  1.7359e+01,\n",
       "         3.3385e-01,  6.7212e+00, -1.6849e+00,  1.5153e+00,  1.6446e+01,\n",
       "         1.3685e+01, -4.5887e-02, -2.4845e+00,  2.1678e+01,  1.6803e+01,\n",
       "         1.9174e+00, -3.5752e+00,  6.4917e+00,  1.6110e+01, -3.9256e+00,\n",
       "        -2.6817e+00,  1.0754e+01, -1.5655e+00,  4.0622e+00,  1.3010e+01,\n",
       "        -2.3365e+00,  5.4094e+00, -8.2419e+00, -1.1790e+00,  6.2360e+00,\n",
       "         2.1044e+01, -1.2322e+01, -3.3937e+00,  5.8006e+00,  8.2829e+00,\n",
       "        -8.6060e+00,  7.1399e+00, -6.3707e+00, -2.4653e+00,  1.8431e+00,\n",
       "        -6.9516e+00,  2.1398e+00,  3.0807e+00,  4.6405e+00,  1.7278e+01,\n",
       "         5.7405e+00,  1.9311e+01, -7.6542e+00,  1.5150e+01, -8.7522e+00,\n",
       "         4.8846e+00, -1.1588e+01, -1.5796e+01, -6.2121e+00,  5.7546e+00,\n",
       "         4.8647e+00, -4.2252e+00,  1.2382e+01,  8.7304e+00, -5.7272e+00,\n",
       "         1.3119e+01,  1.0216e+01,  2.8061e+00,  3.3668e+00,  8.5426e+00,\n",
       "         7.8350e+00, -5.9939e+00,  2.6160e-01,  3.5128e+00, -7.6337e+00,\n",
       "         2.7661e+00,  9.6139e+00,  7.9274e+00,  4.4167e+00,  1.1167e+00,\n",
       "        -1.1127e+00,  1.2854e+01, -3.3816e+00, -1.2178e+01, -5.9192e+00,\n",
       "         2.1507e+00,  8.3203e+00, -5.1383e+00, -5.9940e+00,  1.2286e+01,\n",
       "        -7.9297e+00,  3.0268e+00,  4.6203e+00,  7.9187e+00,  5.0090e+00,\n",
       "        -8.1653e-01,  1.4166e+01,  1.9592e+01,  3.2562e+00,  1.3356e+01,\n",
       "         1.2035e+01,  1.5677e+01,  8.5726e+00,  7.6243e+00,  1.0129e+01,\n",
       "         7.3508e+00, -9.5080e+00, -8.2662e+00,  4.6174e+00, -4.5542e+00,\n",
       "         1.1363e+01, -6.6191e+00,  1.4533e-02,  2.5647e+00, -2.8813e+00,\n",
       "         1.3270e+01,  5.3183e-01, -1.2779e+00, -1.2964e+00, -1.0770e-01,\n",
       "         1.8727e+01,  4.7153e+00,  6.4672e+00,  7.4407e+00,  7.7292e+00,\n",
       "         1.5673e+01, -3.9365e+00, -6.8168e+00, -7.7968e+00,  2.3700e+00,\n",
       "         2.3706e+01,  1.8350e+01,  5.9857e+00, -1.0805e+01,  1.8249e+00,\n",
       "         6.0639e+00,  1.7914e+01, -8.2689e-01, -1.3884e+00,  7.6182e+00,\n",
       "         7.9389e+00,  1.0276e+01, -1.0272e+00,  1.2835e+00, -1.2121e+01,\n",
       "        -1.1289e+01,  1.6578e+01,  9.9521e+00,  1.3900e+01, -5.4462e+00,\n",
       "         7.1072e+00, -4.5436e+00, -1.8632e+01,  1.2657e+01, -4.7188e+00,\n",
       "         1.3013e+01, -4.4684e+00, -1.0046e+01,  1.6130e+00,  1.1245e+01,\n",
       "         9.1352e+00, -6.9535e+00, -3.9289e+00,  1.0264e+01,  1.2087e+01,\n",
       "         9.1528e+00,  2.1594e+01, -7.8064e+00, -1.9454e+00, -7.4161e+00,\n",
       "         2.4856e+00, -3.6942e+00, -4.2260e+00, -3.9647e-01,  5.4784e-01,\n",
       "        -7.2603e-02, -4.7273e+00,  2.5079e+01,  1.1045e+01, -1.3995e+00,\n",
       "         5.2554e-01,  1.0827e+01, -1.0959e+01,  2.5070e+00,  7.3364e+00,\n",
       "         1.6360e+01, -5.3666e+00, -9.7506e+00,  2.3229e+01,  1.5659e+01,\n",
       "         1.2394e+01,  3.3211e+00,  1.7271e+01,  3.8677e+00,  2.4076e+00,\n",
       "         8.9028e+00, -8.1255e+00,  1.9281e+01, -9.9840e+00, -1.0407e+01,\n",
       "         6.6742e+00, -1.4667e+00, -7.1232e+00, -4.8774e+00, -5.7523e+00,\n",
       "        -1.4514e+01,  1.2090e+01, -8.1272e+00, -7.1763e+00, -7.6672e-01,\n",
       "         1.0996e+01,  4.3930e+00, -3.5305e+00,  2.1376e+01, -2.4705e+00,\n",
       "        -4.5434e+00,  7.9395e+00,  1.2014e+01,  1.1672e+00,  3.4701e+00,\n",
       "         2.0694e+01,  6.4897e+00,  8.8901e+00, -1.5025e+00,  1.0177e+01,\n",
       "        -3.7768e+00,  6.6274e+00,  1.1614e+01,  1.4785e-01,  1.0758e+01,\n",
       "        -7.8550e+00, -4.7541e+00,  8.9744e+00,  1.6369e+01,  5.3968e-01,\n",
       "        -2.0186e+01,  2.6185e-01,  1.1957e+01,  1.4659e+00,  6.7324e+00,\n",
       "         1.3326e+00,  9.4719e+00,  5.6339e+00, -2.8488e+00,  9.7334e+00,\n",
       "         3.3534e+00, -1.2733e+00, -2.9777e+00,  2.3459e+01,  1.3237e+01,\n",
       "        -3.2312e+00,  1.2642e+01, -1.5018e+01,  8.1881e+00,  1.1996e+01,\n",
       "         4.3523e+00,  1.4621e+01,  4.2763e-01,  2.6851e+00, -4.2621e+00,\n",
       "         1.0142e+00,  2.0273e+01,  4.4120e+00, -5.0907e-02,  1.6001e+01,\n",
       "         2.7395e+00,  1.5673e+01,  1.2954e+01, -1.4172e+01, -8.1601e+00,\n",
       "         1.0882e+01,  3.8493e+00,  1.1644e+01, -1.9684e+01, -6.7149e+00,\n",
       "        -1.3575e+00, -9.3857e+00,  2.2443e+01,  5.4094e+00,  1.7912e+01,\n",
       "        -2.5346e-01,  3.2429e+00,  6.9100e+00,  3.9488e+00, -5.2058e+00,\n",
       "         1.2656e+01, -3.6970e+00, -5.2622e+00,  9.3036e-01,  1.1061e+01,\n",
       "         1.3362e+01,  9.8525e+00,  1.3598e+01,  7.3098e-01, -9.3137e+00,\n",
       "         1.2016e+01,  2.0902e+01, -2.5209e+00,  8.6290e+00, -6.0640e+00,\n",
       "        -4.9964e+00,  2.3196e+01, -2.9123e+00,  3.2730e+00,  1.4358e+01,\n",
       "         9.8226e+00,  1.9992e+00,  3.4598e+01,  6.2844e-01, -4.2793e+00,\n",
       "        -1.0547e+01,  1.0493e+01, -1.2992e+01,  1.4468e+00,  7.5207e-01,\n",
       "         2.7539e+00, -7.7611e-01, -1.2764e+00,  2.2626e+01,  5.6030e+00,\n",
       "        -7.0018e+00, -5.2588e+00, -1.2937e+00,  7.1057e+00, -1.9013e+01,\n",
       "         9.0072e+00,  1.6532e+00, -1.9414e+01, -1.0303e+01,  1.3633e+01,\n",
       "         1.9015e+00,  3.3027e+00,  1.4602e+01,  4.6173e-02,  1.3715e+00,\n",
       "         7.3839e+00,  5.7270e+00,  1.0756e+01, -2.8658e+00, -6.3454e+00,\n",
       "         3.7007e+00,  4.2566e+00,  2.4889e+00, -1.9475e+00,  7.9468e+00,\n",
       "         8.2207e+00, -4.5918e+00, -6.3430e+00,  1.6693e+01, -6.6801e+00,\n",
       "         2.1210e+01,  1.3223e+01, -1.0080e+01,  6.2050e+00, -1.3271e+01,\n",
       "         1.2231e+01,  1.9470e+01,  2.0339e+01, -4.3693e+00,  6.1724e+00,\n",
       "         5.0942e+00,  1.4988e+00,  8.6469e+00, -5.2662e-01,  2.9463e+00,\n",
       "         2.5223e+00,  4.2858e-01,  8.1953e-01,  1.5330e+01, -5.4762e+00,\n",
       "        -1.2244e+00, -9.2716e+00,  1.4383e+01,  7.3110e-01,  5.8061e+00,\n",
       "        -1.0162e+01,  9.9102e+00,  2.3005e+00,  1.3246e+00,  2.2694e+01,\n",
       "         8.8863e+00,  1.3645e+01,  5.8687e-01, -1.2452e+00, -1.2956e+00,\n",
       "         9.6418e+00,  1.0048e+01,  1.7007e+01,  1.3861e+01, -1.3039e+01,\n",
       "         1.7577e+01,  4.2718e+00,  2.6737e+00, -2.0070e+00,  8.1298e+00,\n",
       "         9.3532e+00,  1.9337e+01,  4.8559e+00,  1.4055e+01,  1.0227e+01,\n",
       "         1.5076e+01,  2.6307e-01, -3.8183e+00,  3.8194e+00,  5.8632e+00,\n",
       "        -2.0879e+00,  8.7732e+00, -2.4144e-01,  8.1840e-01,  1.6637e+01,\n",
       "         2.1450e+01,  4.9594e+00,  1.8736e+01,  5.7762e+00, -1.1959e+01,\n",
       "        -1.8175e-01, -2.8406e+00,  1.3169e+01,  2.5632e+00,  6.2915e+00,\n",
       "         8.1874e+00,  4.6612e+00,  1.0842e+01,  3.6929e+00, -1.3995e+01,\n",
       "         8.3106e+00, -4.1285e+00,  1.1589e+01, -7.3777e+00,  2.3000e+01,\n",
       "         3.9335e+00, -2.4415e+00,  8.6033e+00,  1.0967e+01,  1.2009e+01,\n",
       "         1.0064e+01,  8.2494e+00,  1.3050e+01,  3.4657e+00,  8.0726e+00,\n",
       "         6.3285e+00, -2.1016e+01,  4.4663e+00,  3.9936e+00,  9.0333e+00,\n",
       "         1.9065e+01,  3.7926e+00,  1.2360e+01, -5.0245e+00,  1.1634e+01,\n",
       "         1.2417e+01, -3.9455e-01,  1.4751e+01, -5.9149e+00,  6.0239e+00,\n",
       "         1.0171e+00,  1.3739e+01,  3.3372e+00,  2.7443e+00,  3.3608e+00,\n",
       "         1.4686e+01,  4.6719e+00,  2.7805e+00,  5.9741e+00,  3.1194e+00,\n",
       "         1.3694e+01,  1.1320e+01, -1.8999e-01, -8.5929e+00,  2.3149e+01,\n",
       "         5.6751e+00,  1.0234e-01,  4.6293e-01,  8.3004e+00,  1.0980e+01,\n",
       "        -2.7372e+00,  1.5525e+01,  9.2299e+00,  6.5561e+00, -8.4148e-01,\n",
       "         2.0386e+00, -7.1072e+00, -1.8495e+00,  5.5766e+00, -4.3735e+00,\n",
       "        -1.8604e+01,  8.8345e+00,  9.5867e+00, -9.2901e+00,  7.4710e+00,\n",
       "         5.9083e+00,  1.3723e+00, -7.0134e+00,  1.5009e+01, -8.7778e+00,\n",
       "         2.5686e+00,  3.0497e+00,  7.0673e+00, -1.1930e+01, -4.1693e+00,\n",
       "        -9.7695e-01,  5.6966e+00, -4.6413e+00,  4.0355e+00,  6.1084e+00,\n",
       "         2.5787e-01,  1.6322e+00,  7.9962e+00, -5.8332e+00,  2.9731e+01,\n",
       "         5.7504e+00, -6.2083e+00,  2.3555e+01,  5.2062e+00, -2.4962e+00,\n",
       "        -2.2991e-01, -1.2548e+00,  2.2058e+01,  5.6954e+00,  1.5127e+01,\n",
       "        -1.0786e+00,  1.4842e+01,  3.3425e+00,  2.9391e+00, -7.9280e-01,\n",
       "        -5.8857e+00,  5.6585e+00,  1.8678e+01,  5.7983e+00,  6.9978e+00,\n",
       "        -4.0584e+00, -4.8589e+00,  1.1520e+01,  7.1080e+00, -5.9225e+00,\n",
       "        -1.4133e+01,  2.1328e+01,  1.1953e+01, -2.6450e+00,  1.8447e+01,\n",
       "         1.7573e+01,  3.1125e+00,  6.8041e+00,  1.0322e+01,  1.0578e+01,\n",
       "         5.1834e+00,  5.6886e+00,  9.7483e+00,  5.3421e+00, -5.7937e+00,\n",
       "         7.9412e+00,  9.1768e+00,  8.0607e+00, -2.7024e+00, -4.7162e+00,\n",
       "         1.2667e+00, -9.1225e-01,  2.1248e-03,  2.9123e+00,  9.5907e+00,\n",
       "         1.8958e+00,  7.3428e+00,  1.0228e+01,  5.3266e+00,  7.3307e+00,\n",
       "         1.7528e+01, -6.8669e-03, -1.8642e+01,  4.3624e+00,  4.1399e-01,\n",
       "        -6.6694e+00, -3.1465e+00,  1.4321e+01,  3.1908e+00, -1.7437e+00,\n",
       "        -7.1305e+00,  1.1566e+01,  2.8990e+00, -6.1228e+00, -2.0773e+00,\n",
       "         1.1369e+01,  1.1372e+01,  7.3158e+00,  7.2312e+00,  1.2194e+01,\n",
       "         6.8033e+00,  3.2990e+00,  1.7118e+01, -5.1703e+00,  1.7789e+01,\n",
       "         4.9187e+00,  4.1659e+00,  1.2142e+01, -9.0031e+00,  4.7218e+00,\n",
       "        -1.0257e+01,  3.9083e+00, -2.4608e-01,  7.2900e+00, -1.1843e+00,\n",
       "         1.1430e+01,  1.6659e+00,  3.9482e+00,  8.9647e-01,  7.0888e+00,\n",
       "        -1.2895e+00, -1.4557e+00,  1.4238e+00,  1.5628e+01,  9.0142e+00,\n",
       "         6.0381e-01,  7.7980e+00,  1.0588e+01,  5.6265e+00, -2.2509e+00,\n",
       "         1.1869e+01,  8.4159e-01, -1.8295e+00, -3.7623e+00,  5.9279e+00,\n",
       "        -1.4881e+01,  1.6430e+01, -1.2460e+00,  5.2057e+00,  1.1677e+01,\n",
       "         4.0825e+00,  8.8192e+00,  3.2896e+00,  9.8064e+00,  1.4085e+01,\n",
       "         9.6843e+00,  1.6231e+01,  4.2082e+00,  1.1844e+01,  1.1553e+01,\n",
       "         6.4024e+00,  1.4109e+01, -5.6718e+00,  3.2609e+00,  9.3171e+00,\n",
       "         9.8099e+00, -6.1290e+00,  1.3008e+01, -4.0834e+00,  3.2125e+00,\n",
       "         3.5980e+00,  2.3896e+01, -4.2004e+00,  6.5373e+00,  5.4994e+00,\n",
       "        -4.3510e+00,  1.2986e+00, -4.6921e+00, -5.3699e+00,  2.2812e+00,\n",
       "        -8.2363e+00, -4.9033e+00,  1.3671e+01,  9.7120e+00,  3.7051e+00,\n",
       "         5.4619e+00, -1.1130e+00, -1.1737e+01,  3.0815e-01,  1.6886e+01,\n",
       "         9.0635e+00,  4.3231e+00,  2.0599e+00, -1.2039e+01, -2.7689e+00,\n",
       "         1.8410e+01,  7.4817e+00, -1.7764e+01,  1.9516e+01,  1.0281e+01,\n",
       "        -8.7264e-01,  5.0907e+00,  1.1876e+01, -2.3906e+00, -1.9313e+00,\n",
       "         1.4379e+00,  1.0859e+01, -9.9066e+00,  1.8098e+00,  2.1987e+01,\n",
       "         2.2150e+01, -3.5827e+00, -2.9805e+00, -2.8840e+00,  7.7248e-05,\n",
       "        -2.2995e+01, -6.3231e+00,  1.6887e+01,  9.7318e+00,  3.0228e-01,\n",
       "         2.5666e+00, -9.0575e+00,  5.9352e-01,  1.1187e+01,  5.6152e+00,\n",
       "         4.7389e-01,  1.3879e+01,  1.7284e+00,  8.2942e-01, -7.3225e+00,\n",
       "         2.9350e+00,  4.7754e+00,  7.7851e-01, -2.2753e+00,  1.0715e+01,\n",
       "         7.6006e+00,  4.7917e+00,  1.4307e+01,  6.1563e+00,  6.8157e+00,\n",
       "        -5.5919e+00, -5.3209e+00,  5.1971e+00, -1.5570e-01,  9.3120e+00,\n",
       "        -8.9720e+00,  7.0830e+00, -1.5202e+00, -1.3925e+00,  2.0611e+01,\n",
       "         6.9438e+00, -1.5738e+00, -2.7774e+00,  1.4480e+01,  1.0138e+01,\n",
       "         1.1406e+01,  8.6084e+00,  1.0398e+01,  5.8840e+00,  1.8354e+01,\n",
       "         7.6440e+00,  1.3977e+01, -1.2281e+01,  1.6963e+01, -1.1788e+00,\n",
       "         1.0689e+01,  5.2257e-03,  3.4940e+00, -5.2181e-01,  1.5029e+01,\n",
       "        -6.5594e+00,  2.3259e+01,  5.4361e-01, -4.6186e+00, -1.7060e+01,\n",
       "        -5.5709e+00,  9.5214e+00, -7.9763e+00,  4.2252e+00,  1.5092e+00,\n",
       "         7.0865e+00,  9.0257e+00,  7.0669e+00,  2.4924e+00,  1.2331e+00,\n",
       "         3.7890e+00,  1.7030e+01,  2.2109e+01,  7.1882e+00, -5.2052e+00,\n",
       "         5.0795e+00,  7.2834e+00,  1.2444e+01,  1.4443e+01,  1.8640e+00,\n",
       "         1.5246e+01, -1.0635e+00,  1.4088e+00,  2.8884e+01, -6.2733e-01,\n",
       "        -1.9599e+00,  6.5011e+00,  1.3949e+00,  2.6366e+00, -5.8401e+00])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "9e90c744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "be25b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5992e+01],\n",
       "        [ 1.0520e+01],\n",
       "        [ 1.6187e+01],\n",
       "        [ 3.1880e-01],\n",
       "        [-3.0951e-01],\n",
       "        [ 5.9327e+00],\n",
       "        [ 1.3813e+01],\n",
       "        [-4.3555e-01],\n",
       "        [ 7.9810e+00],\n",
       "        [ 9.8630e+00],\n",
       "        [-4.1379e+00],\n",
       "        [ 9.9030e+00],\n",
       "        [-1.0143e+00],\n",
       "        [-2.8659e+00],\n",
       "        [-5.8441e+00],\n",
       "        [ 7.4970e+00],\n",
       "        [ 1.0933e+00],\n",
       "        [ 1.8477e+00],\n",
       "        [-7.8330e+00],\n",
       "        [ 1.7300e+01],\n",
       "        [ 9.8987e+00],\n",
       "        [ 7.7476e+00],\n",
       "        [-5.5060e+00],\n",
       "        [ 1.7474e+00],\n",
       "        [ 9.5069e+00],\n",
       "        [-1.1930e+00],\n",
       "        [-2.7354e+00],\n",
       "        [-7.6727e-01],\n",
       "        [ 9.1535e+00],\n",
       "        [ 1.1988e+01],\n",
       "        [ 2.7396e+00],\n",
       "        [ 1.6699e+00],\n",
       "        [ 7.9077e-01],\n",
       "        [-1.2517e+01],\n",
       "        [ 1.7307e+01],\n",
       "        [ 2.1991e+01],\n",
       "        [ 6.5792e+00],\n",
       "        [-2.5275e+00],\n",
       "        [ 7.2011e+00],\n",
       "        [-3.5696e+00],\n",
       "        [ 1.0896e+01],\n",
       "        [ 6.7077e+00],\n",
       "        [-1.6973e+01],\n",
       "        [ 6.7691e+00],\n",
       "        [ 1.4527e+01],\n",
       "        [ 1.4496e+01],\n",
       "        [ 4.3423e+00],\n",
       "        [-5.6553e+00],\n",
       "        [ 1.4569e+01],\n",
       "        [ 2.7133e+00],\n",
       "        [-1.1959e+01],\n",
       "        [ 2.6006e+00],\n",
       "        [ 9.2810e+00],\n",
       "        [-9.9610e+00],\n",
       "        [ 7.2776e+00],\n",
       "        [ 2.2769e+00],\n",
       "        [-6.0013e-01],\n",
       "        [ 2.6475e+00],\n",
       "        [-7.9681e+00],\n",
       "        [ 6.8091e+00],\n",
       "        [ 4.2370e+00],\n",
       "        [ 9.6687e+00],\n",
       "        [ 7.9880e+00],\n",
       "        [ 1.2205e+01],\n",
       "        [ 1.8572e+01],\n",
       "        [ 3.4821e-01],\n",
       "        [ 5.5847e+00],\n",
       "        [ 1.5187e+01],\n",
       "        [-1.5010e+01],\n",
       "        [ 2.8282e+01],\n",
       "        [ 1.0402e+01],\n",
       "        [-3.5058e+00],\n",
       "        [-6.7540e+00],\n",
       "        [ 3.8747e+00],\n",
       "        [ 6.9673e+00],\n",
       "        [-2.3071e+00],\n",
       "        [-1.3838e+00],\n",
       "        [-7.4831e+00],\n",
       "        [ 2.2353e+01],\n",
       "        [ 1.9753e+00],\n",
       "        [-9.6813e-01],\n",
       "        [ 7.3189e+00],\n",
       "        [ 7.0855e+00],\n",
       "        [-1.6412e-01],\n",
       "        [ 1.0708e+01],\n",
       "        [ 1.4224e+01],\n",
       "        [ 2.1406e+00],\n",
       "        [-6.4785e+00],\n",
       "        [ 3.9513e+00],\n",
       "        [-3.8755e+00],\n",
       "        [ 3.9327e+00],\n",
       "        [ 1.7265e+01],\n",
       "        [ 1.7909e+01],\n",
       "        [ 2.5472e+00],\n",
       "        [ 8.2240e-01],\n",
       "        [ 3.6053e+00],\n",
       "        [ 5.2612e+00],\n",
       "        [-3.0792e-01],\n",
       "        [-6.7840e+00],\n",
       "        [ 4.1621e+00],\n",
       "        [ 1.1572e+01],\n",
       "        [-1.1009e+00],\n",
       "        [-3.5759e+00],\n",
       "        [ 1.2643e+01],\n",
       "        [ 8.7059e+00],\n",
       "        [ 6.7760e+00],\n",
       "        [ 1.1357e+01],\n",
       "        [-1.2597e+01],\n",
       "        [-3.6029e+00],\n",
       "        [-5.4759e+00],\n",
       "        [ 1.1931e+01],\n",
       "        [ 3.1300e+00],\n",
       "        [ 1.7476e+01],\n",
       "        [-1.7984e+01],\n",
       "        [ 9.6292e+00],\n",
       "        [-6.8533e+00],\n",
       "        [ 2.9563e+00],\n",
       "        [ 1.2772e+01],\n",
       "        [-1.2842e+01],\n",
       "        [ 2.3524e+00],\n",
       "        [ 7.6107e+00],\n",
       "        [ 9.8800e+00],\n",
       "        [ 1.3822e+01],\n",
       "        [ 1.8430e+01],\n",
       "        [ 4.1049e+00],\n",
       "        [ 6.0980e+00],\n",
       "        [-8.1540e+00],\n",
       "        [ 5.8308e+00],\n",
       "        [-7.3575e+00],\n",
       "        [-1.4568e+01],\n",
       "        [ 1.0804e+01],\n",
       "        [ 5.2543e+00],\n",
       "        [-4.8453e+00],\n",
       "        [ 6.8319e+00],\n",
       "        [ 3.2821e+00],\n",
       "        [ 2.2017e+01],\n",
       "        [ 5.1454e+00],\n",
       "        [-3.4420e+00],\n",
       "        [ 1.3452e+00],\n",
       "        [ 1.8176e+00],\n",
       "        [ 8.2351e+00],\n",
       "        [ 7.8859e-01],\n",
       "        [ 5.8989e+00],\n",
       "        [-3.1409e+00],\n",
       "        [ 2.3682e+00],\n",
       "        [-9.9355e+00],\n",
       "        [-2.8193e+00],\n",
       "        [ 2.1523e+01],\n",
       "        [ 2.2227e+01],\n",
       "        [ 9.9070e-01],\n",
       "        [-1.2904e+01],\n",
       "        [ 1.0439e+01],\n",
       "        [ 2.4663e+00],\n",
       "        [ 2.2213e+01],\n",
       "        [ 1.0531e+01],\n",
       "        [ 2.2359e+00],\n",
       "        [-3.3990e-01],\n",
       "        [ 8.6906e+00],\n",
       "        [ 1.4599e+01],\n",
       "        [ 4.1351e+00],\n",
       "        [ 1.8434e+01],\n",
       "        [-1.3372e+01],\n",
       "        [ 1.2475e+01],\n",
       "        [ 1.6603e+01],\n",
       "        [ 1.9050e+01],\n",
       "        [ 6.0202e+00],\n",
       "        [ 1.8724e+01],\n",
       "        [ 2.9366e+00],\n",
       "        [ 4.2677e+00],\n",
       "        [ 2.3070e+00],\n",
       "        [-3.6485e+00],\n",
       "        [ 1.1722e+01],\n",
       "        [ 6.1357e+00],\n",
       "        [ 1.1908e+01],\n",
       "        [ 2.0268e+01],\n",
       "        [-9.1353e+00],\n",
       "        [ 1.3442e+01],\n",
       "        [ 3.9628e+00],\n",
       "        [ 8.6398e-01],\n",
       "        [ 7.9614e+00],\n",
       "        [-8.0381e+00],\n",
       "        [ 3.8141e+00],\n",
       "        [ 6.8432e+00],\n",
       "        [ 2.8306e+00],\n",
       "        [-3.6347e-01],\n",
       "        [-2.7163e+00],\n",
       "        [ 4.7276e+00],\n",
       "        [-2.8169e+00],\n",
       "        [ 2.0642e+01],\n",
       "        [-1.2756e+00],\n",
       "        [-1.3594e+00],\n",
       "        [ 3.7782e+00],\n",
       "        [-5.4717e+00],\n",
       "        [ 7.3367e+00],\n",
       "        [-1.5763e+01],\n",
       "        [-7.2648e+00],\n",
       "        [ 8.9009e+00],\n",
       "        [ 1.4418e+01],\n",
       "        [ 2.5633e+00],\n",
       "        [-5.0655e+00],\n",
       "        [ 3.1113e+00],\n",
       "        [-5.1234e-01],\n",
       "        [-2.7812e-01],\n",
       "        [ 4.6908e+00],\n",
       "        [-6.6974e+00],\n",
       "        [ 9.2947e+00],\n",
       "        [-6.9855e+00],\n",
       "        [ 1.3393e+01],\n",
       "        [ 5.5636e+00],\n",
       "        [-1.3090e+01],\n",
       "        [-1.3105e+01],\n",
       "        [-2.3743e+01],\n",
       "        [-4.6048e+00],\n",
       "        [-6.2351e+00],\n",
       "        [ 1.6458e+01],\n",
       "        [ 1.4312e+00],\n",
       "        [ 1.5084e+01],\n",
       "        [ 1.9372e+01],\n",
       "        [ 2.4456e+00],\n",
       "        [ 1.1132e+01],\n",
       "        [ 3.1904e+01],\n",
       "        [-1.9326e+00],\n",
       "        [ 8.2112e+00],\n",
       "        [ 2.5707e+00],\n",
       "        [ 1.7789e-02],\n",
       "        [-9.8691e+00],\n",
       "        [-7.5122e+00],\n",
       "        [ 6.7447e+00],\n",
       "        [-6.0244e+00],\n",
       "        [ 1.7359e+01],\n",
       "        [ 3.3385e-01],\n",
       "        [ 6.7212e+00],\n",
       "        [-1.6849e+00],\n",
       "        [ 1.5153e+00],\n",
       "        [ 1.6446e+01],\n",
       "        [ 1.3685e+01],\n",
       "        [-4.5887e-02],\n",
       "        [-2.4845e+00],\n",
       "        [ 2.1678e+01],\n",
       "        [ 1.6803e+01],\n",
       "        [ 1.9174e+00],\n",
       "        [-3.5752e+00],\n",
       "        [ 6.4917e+00],\n",
       "        [ 1.6110e+01],\n",
       "        [-3.9256e+00],\n",
       "        [-2.6817e+00],\n",
       "        [ 1.0754e+01],\n",
       "        [-1.5655e+00],\n",
       "        [ 4.0622e+00],\n",
       "        [ 1.3010e+01],\n",
       "        [-2.3365e+00],\n",
       "        [ 5.4094e+00],\n",
       "        [-8.2419e+00],\n",
       "        [-1.1790e+00],\n",
       "        [ 6.2360e+00],\n",
       "        [ 2.1044e+01],\n",
       "        [-1.2322e+01],\n",
       "        [-3.3937e+00],\n",
       "        [ 5.8006e+00],\n",
       "        [ 8.2829e+00],\n",
       "        [-8.6060e+00],\n",
       "        [ 7.1399e+00],\n",
       "        [-6.3707e+00],\n",
       "        [-2.4653e+00],\n",
       "        [ 1.8431e+00],\n",
       "        [-6.9516e+00],\n",
       "        [ 2.1398e+00],\n",
       "        [ 3.0807e+00],\n",
       "        [ 4.6405e+00],\n",
       "        [ 1.7278e+01],\n",
       "        [ 5.7405e+00],\n",
       "        [ 1.9311e+01],\n",
       "        [-7.6542e+00],\n",
       "        [ 1.5150e+01],\n",
       "        [-8.7522e+00],\n",
       "        [ 4.8846e+00],\n",
       "        [-1.1588e+01],\n",
       "        [-1.5796e+01],\n",
       "        [-6.2121e+00],\n",
       "        [ 5.7546e+00],\n",
       "        [ 4.8647e+00],\n",
       "        [-4.2252e+00],\n",
       "        [ 1.2382e+01],\n",
       "        [ 8.7304e+00],\n",
       "        [-5.7272e+00],\n",
       "        [ 1.3119e+01],\n",
       "        [ 1.0216e+01],\n",
       "        [ 2.8061e+00],\n",
       "        [ 3.3668e+00],\n",
       "        [ 8.5426e+00],\n",
       "        [ 7.8350e+00],\n",
       "        [-5.9939e+00],\n",
       "        [ 2.6160e-01],\n",
       "        [ 3.5128e+00],\n",
       "        [-7.6337e+00],\n",
       "        [ 2.7661e+00],\n",
       "        [ 9.6139e+00],\n",
       "        [ 7.9274e+00],\n",
       "        [ 4.4167e+00],\n",
       "        [ 1.1167e+00],\n",
       "        [-1.1127e+00],\n",
       "        [ 1.2854e+01],\n",
       "        [-3.3816e+00],\n",
       "        [-1.2178e+01],\n",
       "        [-5.9192e+00],\n",
       "        [ 2.1507e+00],\n",
       "        [ 8.3203e+00],\n",
       "        [-5.1383e+00],\n",
       "        [-5.9940e+00],\n",
       "        [ 1.2286e+01],\n",
       "        [-7.9297e+00],\n",
       "        [ 3.0268e+00],\n",
       "        [ 4.6203e+00],\n",
       "        [ 7.9187e+00],\n",
       "        [ 5.0090e+00],\n",
       "        [-8.1653e-01],\n",
       "        [ 1.4166e+01],\n",
       "        [ 1.9592e+01],\n",
       "        [ 3.2562e+00],\n",
       "        [ 1.3356e+01],\n",
       "        [ 1.2035e+01],\n",
       "        [ 1.5677e+01],\n",
       "        [ 8.5726e+00],\n",
       "        [ 7.6243e+00],\n",
       "        [ 1.0129e+01],\n",
       "        [ 7.3508e+00],\n",
       "        [-9.5080e+00],\n",
       "        [-8.2662e+00],\n",
       "        [ 4.6174e+00],\n",
       "        [-4.5542e+00],\n",
       "        [ 1.1363e+01],\n",
       "        [-6.6191e+00],\n",
       "        [ 1.4533e-02],\n",
       "        [ 2.5647e+00],\n",
       "        [-2.8813e+00],\n",
       "        [ 1.3270e+01],\n",
       "        [ 5.3183e-01],\n",
       "        [-1.2779e+00],\n",
       "        [-1.2964e+00],\n",
       "        [-1.0770e-01],\n",
       "        [ 1.8727e+01],\n",
       "        [ 4.7153e+00],\n",
       "        [ 6.4672e+00],\n",
       "        [ 7.4407e+00],\n",
       "        [ 7.7292e+00],\n",
       "        [ 1.5673e+01],\n",
       "        [-3.9365e+00],\n",
       "        [-6.8168e+00],\n",
       "        [-7.7968e+00],\n",
       "        [ 2.3700e+00],\n",
       "        [ 2.3706e+01],\n",
       "        [ 1.8350e+01],\n",
       "        [ 5.9857e+00],\n",
       "        [-1.0805e+01],\n",
       "        [ 1.8249e+00],\n",
       "        [ 6.0639e+00],\n",
       "        [ 1.7914e+01],\n",
       "        [-8.2689e-01],\n",
       "        [-1.3884e+00],\n",
       "        [ 7.6182e+00],\n",
       "        [ 7.9389e+00],\n",
       "        [ 1.0276e+01],\n",
       "        [-1.0272e+00],\n",
       "        [ 1.2835e+00],\n",
       "        [-1.2121e+01],\n",
       "        [-1.1289e+01],\n",
       "        [ 1.6578e+01],\n",
       "        [ 9.9521e+00],\n",
       "        [ 1.3900e+01],\n",
       "        [-5.4462e+00],\n",
       "        [ 7.1072e+00],\n",
       "        [-4.5436e+00],\n",
       "        [-1.8632e+01],\n",
       "        [ 1.2657e+01],\n",
       "        [-4.7188e+00],\n",
       "        [ 1.3013e+01],\n",
       "        [-4.4684e+00],\n",
       "        [-1.0046e+01],\n",
       "        [ 1.6130e+00],\n",
       "        [ 1.1245e+01],\n",
       "        [ 9.1352e+00],\n",
       "        [-6.9535e+00],\n",
       "        [-3.9289e+00],\n",
       "        [ 1.0264e+01],\n",
       "        [ 1.2087e+01],\n",
       "        [ 9.1528e+00],\n",
       "        [ 2.1594e+01],\n",
       "        [-7.8064e+00],\n",
       "        [-1.9454e+00],\n",
       "        [-7.4161e+00],\n",
       "        [ 2.4856e+00],\n",
       "        [-3.6942e+00],\n",
       "        [-4.2260e+00],\n",
       "        [-3.9647e-01],\n",
       "        [ 5.4784e-01],\n",
       "        [-7.2603e-02],\n",
       "        [-4.7273e+00],\n",
       "        [ 2.5079e+01],\n",
       "        [ 1.1045e+01],\n",
       "        [-1.3995e+00],\n",
       "        [ 5.2554e-01],\n",
       "        [ 1.0827e+01],\n",
       "        [-1.0959e+01],\n",
       "        [ 2.5070e+00],\n",
       "        [ 7.3364e+00],\n",
       "        [ 1.6360e+01],\n",
       "        [-5.3666e+00],\n",
       "        [-9.7506e+00],\n",
       "        [ 2.3229e+01],\n",
       "        [ 1.5659e+01],\n",
       "        [ 1.2394e+01],\n",
       "        [ 3.3211e+00],\n",
       "        [ 1.7271e+01],\n",
       "        [ 3.8677e+00],\n",
       "        [ 2.4076e+00],\n",
       "        [ 8.9028e+00],\n",
       "        [-8.1255e+00],\n",
       "        [ 1.9281e+01],\n",
       "        [-9.9840e+00],\n",
       "        [-1.0407e+01],\n",
       "        [ 6.6742e+00],\n",
       "        [-1.4667e+00],\n",
       "        [-7.1232e+00],\n",
       "        [-4.8774e+00],\n",
       "        [-5.7523e+00],\n",
       "        [-1.4514e+01],\n",
       "        [ 1.2090e+01],\n",
       "        [-8.1272e+00],\n",
       "        [-7.1763e+00],\n",
       "        [-7.6672e-01],\n",
       "        [ 1.0996e+01],\n",
       "        [ 4.3930e+00],\n",
       "        [-3.5305e+00],\n",
       "        [ 2.1376e+01],\n",
       "        [-2.4705e+00],\n",
       "        [-4.5434e+00],\n",
       "        [ 7.9395e+00],\n",
       "        [ 1.2014e+01],\n",
       "        [ 1.1672e+00],\n",
       "        [ 3.4701e+00],\n",
       "        [ 2.0694e+01],\n",
       "        [ 6.4897e+00],\n",
       "        [ 8.8901e+00],\n",
       "        [-1.5025e+00],\n",
       "        [ 1.0177e+01],\n",
       "        [-3.7768e+00],\n",
       "        [ 6.6274e+00],\n",
       "        [ 1.1614e+01],\n",
       "        [ 1.4785e-01],\n",
       "        [ 1.0758e+01],\n",
       "        [-7.8550e+00],\n",
       "        [-4.7541e+00],\n",
       "        [ 8.9744e+00],\n",
       "        [ 1.6369e+01],\n",
       "        [ 5.3968e-01],\n",
       "        [-2.0186e+01],\n",
       "        [ 2.6185e-01],\n",
       "        [ 1.1957e+01],\n",
       "        [ 1.4659e+00],\n",
       "        [ 6.7324e+00],\n",
       "        [ 1.3326e+00],\n",
       "        [ 9.4719e+00],\n",
       "        [ 5.6339e+00],\n",
       "        [-2.8488e+00],\n",
       "        [ 9.7334e+00],\n",
       "        [ 3.3534e+00],\n",
       "        [-1.2733e+00],\n",
       "        [-2.9777e+00],\n",
       "        [ 2.3459e+01],\n",
       "        [ 1.3237e+01],\n",
       "        [-3.2312e+00],\n",
       "        [ 1.2642e+01],\n",
       "        [-1.5018e+01],\n",
       "        [ 8.1881e+00],\n",
       "        [ 1.1996e+01],\n",
       "        [ 4.3523e+00],\n",
       "        [ 1.4621e+01],\n",
       "        [ 4.2763e-01],\n",
       "        [ 2.6851e+00],\n",
       "        [-4.2621e+00],\n",
       "        [ 1.0142e+00],\n",
       "        [ 2.0273e+01],\n",
       "        [ 4.4120e+00],\n",
       "        [-5.0907e-02],\n",
       "        [ 1.6001e+01],\n",
       "        [ 2.7395e+00],\n",
       "        [ 1.5673e+01],\n",
       "        [ 1.2954e+01],\n",
       "        [-1.4172e+01],\n",
       "        [-8.1601e+00],\n",
       "        [ 1.0882e+01],\n",
       "        [ 3.8493e+00],\n",
       "        [ 1.1644e+01],\n",
       "        [-1.9684e+01],\n",
       "        [-6.7149e+00],\n",
       "        [-1.3575e+00],\n",
       "        [-9.3857e+00],\n",
       "        [ 2.2443e+01],\n",
       "        [ 5.4094e+00],\n",
       "        [ 1.7912e+01],\n",
       "        [-2.5346e-01],\n",
       "        [ 3.2429e+00],\n",
       "        [ 6.9100e+00],\n",
       "        [ 3.9488e+00],\n",
       "        [-5.2058e+00],\n",
       "        [ 1.2656e+01],\n",
       "        [-3.6970e+00],\n",
       "        [-5.2622e+00],\n",
       "        [ 9.3036e-01],\n",
       "        [ 1.1061e+01],\n",
       "        [ 1.3362e+01],\n",
       "        [ 9.8525e+00],\n",
       "        [ 1.3598e+01],\n",
       "        [ 7.3098e-01],\n",
       "        [-9.3137e+00],\n",
       "        [ 1.2016e+01],\n",
       "        [ 2.0902e+01],\n",
       "        [-2.5209e+00],\n",
       "        [ 8.6290e+00],\n",
       "        [-6.0640e+00],\n",
       "        [-4.9964e+00],\n",
       "        [ 2.3196e+01],\n",
       "        [-2.9123e+00],\n",
       "        [ 3.2730e+00],\n",
       "        [ 1.4358e+01],\n",
       "        [ 9.8226e+00],\n",
       "        [ 1.9992e+00],\n",
       "        [ 3.4598e+01],\n",
       "        [ 6.2844e-01],\n",
       "        [-4.2793e+00],\n",
       "        [-1.0547e+01],\n",
       "        [ 1.0493e+01],\n",
       "        [-1.2992e+01],\n",
       "        [ 1.4468e+00],\n",
       "        [ 7.5207e-01],\n",
       "        [ 2.7539e+00],\n",
       "        [-7.7611e-01],\n",
       "        [-1.2764e+00],\n",
       "        [ 2.2626e+01],\n",
       "        [ 5.6030e+00],\n",
       "        [-7.0018e+00],\n",
       "        [-5.2588e+00],\n",
       "        [-1.2937e+00],\n",
       "        [ 7.1057e+00],\n",
       "        [-1.9013e+01],\n",
       "        [ 9.0072e+00],\n",
       "        [ 1.6532e+00],\n",
       "        [-1.9414e+01],\n",
       "        [-1.0303e+01],\n",
       "        [ 1.3633e+01],\n",
       "        [ 1.9015e+00],\n",
       "        [ 3.3027e+00],\n",
       "        [ 1.4602e+01],\n",
       "        [ 4.6173e-02],\n",
       "        [ 1.3715e+00],\n",
       "        [ 7.3839e+00],\n",
       "        [ 5.7270e+00],\n",
       "        [ 1.0756e+01],\n",
       "        [-2.8658e+00],\n",
       "        [-6.3454e+00],\n",
       "        [ 3.7007e+00],\n",
       "        [ 4.2566e+00],\n",
       "        [ 2.4889e+00],\n",
       "        [-1.9475e+00],\n",
       "        [ 7.9468e+00],\n",
       "        [ 8.2207e+00],\n",
       "        [-4.5918e+00],\n",
       "        [-6.3430e+00],\n",
       "        [ 1.6693e+01],\n",
       "        [-6.6801e+00],\n",
       "        [ 2.1210e+01],\n",
       "        [ 1.3223e+01],\n",
       "        [-1.0080e+01],\n",
       "        [ 6.2050e+00],\n",
       "        [-1.3271e+01],\n",
       "        [ 1.2231e+01],\n",
       "        [ 1.9470e+01],\n",
       "        [ 2.0339e+01],\n",
       "        [-4.3693e+00],\n",
       "        [ 6.1724e+00],\n",
       "        [ 5.0942e+00],\n",
       "        [ 1.4988e+00],\n",
       "        [ 8.6469e+00],\n",
       "        [-5.2662e-01],\n",
       "        [ 2.9463e+00],\n",
       "        [ 2.5223e+00],\n",
       "        [ 4.2858e-01],\n",
       "        [ 8.1953e-01],\n",
       "        [ 1.5330e+01],\n",
       "        [-5.4762e+00],\n",
       "        [-1.2244e+00],\n",
       "        [-9.2716e+00],\n",
       "        [ 1.4383e+01],\n",
       "        [ 7.3110e-01],\n",
       "        [ 5.8061e+00],\n",
       "        [-1.0162e+01],\n",
       "        [ 9.9102e+00],\n",
       "        [ 2.3005e+00],\n",
       "        [ 1.3246e+00],\n",
       "        [ 2.2694e+01],\n",
       "        [ 8.8863e+00],\n",
       "        [ 1.3645e+01],\n",
       "        [ 5.8687e-01],\n",
       "        [-1.2452e+00],\n",
       "        [-1.2956e+00],\n",
       "        [ 9.6418e+00],\n",
       "        [ 1.0048e+01],\n",
       "        [ 1.7007e+01],\n",
       "        [ 1.3861e+01],\n",
       "        [-1.3039e+01],\n",
       "        [ 1.7577e+01],\n",
       "        [ 4.2718e+00],\n",
       "        [ 2.6737e+00],\n",
       "        [-2.0070e+00],\n",
       "        [ 8.1298e+00],\n",
       "        [ 9.3532e+00],\n",
       "        [ 1.9337e+01],\n",
       "        [ 4.8559e+00],\n",
       "        [ 1.4055e+01],\n",
       "        [ 1.0227e+01],\n",
       "        [ 1.5076e+01],\n",
       "        [ 2.6307e-01],\n",
       "        [-3.8183e+00],\n",
       "        [ 3.8194e+00],\n",
       "        [ 5.8632e+00],\n",
       "        [-2.0879e+00],\n",
       "        [ 8.7732e+00],\n",
       "        [-2.4144e-01],\n",
       "        [ 8.1840e-01],\n",
       "        [ 1.6637e+01],\n",
       "        [ 2.1450e+01],\n",
       "        [ 4.9594e+00],\n",
       "        [ 1.8736e+01],\n",
       "        [ 5.7762e+00],\n",
       "        [-1.1959e+01],\n",
       "        [-1.8175e-01],\n",
       "        [-2.8406e+00],\n",
       "        [ 1.3169e+01],\n",
       "        [ 2.5632e+00],\n",
       "        [ 6.2915e+00],\n",
       "        [ 8.1874e+00],\n",
       "        [ 4.6612e+00],\n",
       "        [ 1.0842e+01],\n",
       "        [ 3.6929e+00],\n",
       "        [-1.3995e+01],\n",
       "        [ 8.3106e+00],\n",
       "        [-4.1285e+00],\n",
       "        [ 1.1589e+01],\n",
       "        [-7.3777e+00],\n",
       "        [ 2.3000e+01],\n",
       "        [ 3.9335e+00],\n",
       "        [-2.4415e+00],\n",
       "        [ 8.6033e+00],\n",
       "        [ 1.0967e+01],\n",
       "        [ 1.2009e+01],\n",
       "        [ 1.0064e+01],\n",
       "        [ 8.2494e+00],\n",
       "        [ 1.3050e+01],\n",
       "        [ 3.4657e+00],\n",
       "        [ 8.0726e+00],\n",
       "        [ 6.3285e+00],\n",
       "        [-2.1016e+01],\n",
       "        [ 4.4663e+00],\n",
       "        [ 3.9936e+00],\n",
       "        [ 9.0333e+00],\n",
       "        [ 1.9065e+01],\n",
       "        [ 3.7926e+00],\n",
       "        [ 1.2360e+01],\n",
       "        [-5.0245e+00],\n",
       "        [ 1.1634e+01],\n",
       "        [ 1.2417e+01],\n",
       "        [-3.9455e-01],\n",
       "        [ 1.4751e+01],\n",
       "        [-5.9149e+00],\n",
       "        [ 6.0239e+00],\n",
       "        [ 1.0171e+00],\n",
       "        [ 1.3739e+01],\n",
       "        [ 3.3372e+00],\n",
       "        [ 2.7443e+00],\n",
       "        [ 3.3608e+00],\n",
       "        [ 1.4686e+01],\n",
       "        [ 4.6719e+00],\n",
       "        [ 2.7805e+00],\n",
       "        [ 5.9741e+00],\n",
       "        [ 3.1194e+00],\n",
       "        [ 1.3694e+01],\n",
       "        [ 1.1320e+01],\n",
       "        [-1.8999e-01],\n",
       "        [-8.5929e+00],\n",
       "        [ 2.3149e+01],\n",
       "        [ 5.6751e+00],\n",
       "        [ 1.0234e-01],\n",
       "        [ 4.6293e-01],\n",
       "        [ 8.3004e+00],\n",
       "        [ 1.0980e+01],\n",
       "        [-2.7372e+00],\n",
       "        [ 1.5525e+01],\n",
       "        [ 9.2299e+00],\n",
       "        [ 6.5561e+00],\n",
       "        [-8.4148e-01],\n",
       "        [ 2.0386e+00],\n",
       "        [-7.1072e+00],\n",
       "        [-1.8495e+00],\n",
       "        [ 5.5766e+00],\n",
       "        [-4.3735e+00],\n",
       "        [-1.8604e+01],\n",
       "        [ 8.8345e+00],\n",
       "        [ 9.5867e+00],\n",
       "        [-9.2901e+00],\n",
       "        [ 7.4710e+00],\n",
       "        [ 5.9083e+00],\n",
       "        [ 1.3723e+00],\n",
       "        [-7.0134e+00],\n",
       "        [ 1.5009e+01],\n",
       "        [-8.7778e+00],\n",
       "        [ 2.5686e+00],\n",
       "        [ 3.0497e+00],\n",
       "        [ 7.0673e+00],\n",
       "        [-1.1930e+01],\n",
       "        [-4.1693e+00],\n",
       "        [-9.7695e-01],\n",
       "        [ 5.6966e+00],\n",
       "        [-4.6413e+00],\n",
       "        [ 4.0355e+00],\n",
       "        [ 6.1084e+00],\n",
       "        [ 2.5787e-01],\n",
       "        [ 1.6322e+00],\n",
       "        [ 7.9962e+00],\n",
       "        [-5.8332e+00],\n",
       "        [ 2.9731e+01],\n",
       "        [ 5.7504e+00],\n",
       "        [-6.2083e+00],\n",
       "        [ 2.3555e+01],\n",
       "        [ 5.2062e+00],\n",
       "        [-2.4962e+00],\n",
       "        [-2.2991e-01],\n",
       "        [-1.2548e+00],\n",
       "        [ 2.2058e+01],\n",
       "        [ 5.6954e+00],\n",
       "        [ 1.5127e+01],\n",
       "        [-1.0786e+00],\n",
       "        [ 1.4842e+01],\n",
       "        [ 3.3425e+00],\n",
       "        [ 2.9391e+00],\n",
       "        [-7.9280e-01],\n",
       "        [-5.8857e+00],\n",
       "        [ 5.6585e+00],\n",
       "        [ 1.8678e+01],\n",
       "        [ 5.7983e+00],\n",
       "        [ 6.9978e+00],\n",
       "        [-4.0584e+00],\n",
       "        [-4.8589e+00],\n",
       "        [ 1.1520e+01],\n",
       "        [ 7.1080e+00],\n",
       "        [-5.9225e+00],\n",
       "        [-1.4133e+01],\n",
       "        [ 2.1328e+01],\n",
       "        [ 1.1953e+01],\n",
       "        [-2.6450e+00],\n",
       "        [ 1.8447e+01],\n",
       "        [ 1.7573e+01],\n",
       "        [ 3.1125e+00],\n",
       "        [ 6.8041e+00],\n",
       "        [ 1.0322e+01],\n",
       "        [ 1.0578e+01],\n",
       "        [ 5.1834e+00],\n",
       "        [ 5.6886e+00],\n",
       "        [ 9.7483e+00],\n",
       "        [ 5.3421e+00],\n",
       "        [-5.7937e+00],\n",
       "        [ 7.9412e+00],\n",
       "        [ 9.1768e+00],\n",
       "        [ 8.0607e+00],\n",
       "        [-2.7024e+00],\n",
       "        [-4.7162e+00],\n",
       "        [ 1.2667e+00],\n",
       "        [-9.1225e-01],\n",
       "        [ 2.1248e-03],\n",
       "        [ 2.9123e+00],\n",
       "        [ 9.5907e+00],\n",
       "        [ 1.8958e+00],\n",
       "        [ 7.3428e+00],\n",
       "        [ 1.0228e+01],\n",
       "        [ 5.3266e+00],\n",
       "        [ 7.3307e+00],\n",
       "        [ 1.7528e+01],\n",
       "        [-6.8669e-03],\n",
       "        [-1.8642e+01],\n",
       "        [ 4.3624e+00],\n",
       "        [ 4.1399e-01],\n",
       "        [-6.6694e+00],\n",
       "        [-3.1465e+00],\n",
       "        [ 1.4321e+01],\n",
       "        [ 3.1908e+00],\n",
       "        [-1.7437e+00],\n",
       "        [-7.1305e+00],\n",
       "        [ 1.1566e+01],\n",
       "        [ 2.8990e+00],\n",
       "        [-6.1228e+00],\n",
       "        [-2.0773e+00],\n",
       "        [ 1.1369e+01],\n",
       "        [ 1.1372e+01],\n",
       "        [ 7.3158e+00],\n",
       "        [ 7.2312e+00],\n",
       "        [ 1.2194e+01],\n",
       "        [ 6.8033e+00],\n",
       "        [ 3.2990e+00],\n",
       "        [ 1.7118e+01],\n",
       "        [-5.1703e+00],\n",
       "        [ 1.7789e+01],\n",
       "        [ 4.9187e+00],\n",
       "        [ 4.1659e+00],\n",
       "        [ 1.2142e+01],\n",
       "        [-9.0031e+00],\n",
       "        [ 4.7218e+00],\n",
       "        [-1.0257e+01],\n",
       "        [ 3.9083e+00],\n",
       "        [-2.4608e-01],\n",
       "        [ 7.2900e+00],\n",
       "        [-1.1843e+00],\n",
       "        [ 1.1430e+01],\n",
       "        [ 1.6659e+00],\n",
       "        [ 3.9482e+00],\n",
       "        [ 8.9647e-01],\n",
       "        [ 7.0888e+00],\n",
       "        [-1.2895e+00],\n",
       "        [-1.4557e+00],\n",
       "        [ 1.4238e+00],\n",
       "        [ 1.5628e+01],\n",
       "        [ 9.0142e+00],\n",
       "        [ 6.0381e-01],\n",
       "        [ 7.7980e+00],\n",
       "        [ 1.0588e+01],\n",
       "        [ 5.6265e+00],\n",
       "        [-2.2509e+00],\n",
       "        [ 1.1869e+01],\n",
       "        [ 8.4159e-01],\n",
       "        [-1.8295e+00],\n",
       "        [-3.7623e+00],\n",
       "        [ 5.9279e+00],\n",
       "        [-1.4881e+01],\n",
       "        [ 1.6430e+01],\n",
       "        [-1.2460e+00],\n",
       "        [ 5.2057e+00],\n",
       "        [ 1.1677e+01],\n",
       "        [ 4.0825e+00],\n",
       "        [ 8.8192e+00],\n",
       "        [ 3.2896e+00],\n",
       "        [ 9.8064e+00],\n",
       "        [ 1.4085e+01],\n",
       "        [ 9.6843e+00],\n",
       "        [ 1.6231e+01],\n",
       "        [ 4.2082e+00],\n",
       "        [ 1.1844e+01],\n",
       "        [ 1.1553e+01],\n",
       "        [ 6.4024e+00],\n",
       "        [ 1.4109e+01],\n",
       "        [-5.6718e+00],\n",
       "        [ 3.2609e+00],\n",
       "        [ 9.3171e+00],\n",
       "        [ 9.8099e+00],\n",
       "        [-6.1290e+00],\n",
       "        [ 1.3008e+01],\n",
       "        [-4.0834e+00],\n",
       "        [ 3.2125e+00],\n",
       "        [ 3.5980e+00],\n",
       "        [ 2.3896e+01],\n",
       "        [-4.2004e+00],\n",
       "        [ 6.5373e+00],\n",
       "        [ 5.4994e+00],\n",
       "        [-4.3510e+00],\n",
       "        [ 1.2986e+00],\n",
       "        [-4.6921e+00],\n",
       "        [-5.3699e+00],\n",
       "        [ 2.2812e+00],\n",
       "        [-8.2363e+00],\n",
       "        [-4.9033e+00],\n",
       "        [ 1.3671e+01],\n",
       "        [ 9.7120e+00],\n",
       "        [ 3.7051e+00],\n",
       "        [ 5.4619e+00],\n",
       "        [-1.1130e+00],\n",
       "        [-1.1737e+01],\n",
       "        [ 3.0815e-01],\n",
       "        [ 1.6886e+01],\n",
       "        [ 9.0635e+00],\n",
       "        [ 4.3231e+00],\n",
       "        [ 2.0599e+00],\n",
       "        [-1.2039e+01],\n",
       "        [-2.7689e+00],\n",
       "        [ 1.8410e+01],\n",
       "        [ 7.4817e+00],\n",
       "        [-1.7764e+01],\n",
       "        [ 1.9516e+01],\n",
       "        [ 1.0281e+01],\n",
       "        [-8.7264e-01],\n",
       "        [ 5.0907e+00],\n",
       "        [ 1.1876e+01],\n",
       "        [-2.3906e+00],\n",
       "        [-1.9313e+00],\n",
       "        [ 1.4379e+00],\n",
       "        [ 1.0859e+01],\n",
       "        [-9.9066e+00],\n",
       "        [ 1.8098e+00],\n",
       "        [ 2.1987e+01],\n",
       "        [ 2.2150e+01],\n",
       "        [-3.5827e+00],\n",
       "        [-2.9805e+00],\n",
       "        [-2.8840e+00],\n",
       "        [ 7.7248e-05],\n",
       "        [-2.2995e+01],\n",
       "        [-6.3231e+00],\n",
       "        [ 1.6887e+01],\n",
       "        [ 9.7318e+00],\n",
       "        [ 3.0228e-01],\n",
       "        [ 2.5666e+00],\n",
       "        [-9.0575e+00],\n",
       "        [ 5.9352e-01],\n",
       "        [ 1.1187e+01],\n",
       "        [ 5.6152e+00],\n",
       "        [ 4.7389e-01],\n",
       "        [ 1.3879e+01],\n",
       "        [ 1.7284e+00],\n",
       "        [ 8.2942e-01],\n",
       "        [-7.3225e+00],\n",
       "        [ 2.9350e+00],\n",
       "        [ 4.7754e+00],\n",
       "        [ 7.7851e-01],\n",
       "        [-2.2753e+00],\n",
       "        [ 1.0715e+01],\n",
       "        [ 7.6006e+00],\n",
       "        [ 4.7917e+00],\n",
       "        [ 1.4307e+01],\n",
       "        [ 6.1563e+00],\n",
       "        [ 6.8157e+00],\n",
       "        [-5.5919e+00],\n",
       "        [-5.3209e+00],\n",
       "        [ 5.1971e+00],\n",
       "        [-1.5570e-01],\n",
       "        [ 9.3120e+00],\n",
       "        [-8.9720e+00],\n",
       "        [ 7.0830e+00],\n",
       "        [-1.5202e+00],\n",
       "        [-1.3925e+00],\n",
       "        [ 2.0611e+01],\n",
       "        [ 6.9438e+00],\n",
       "        [-1.5738e+00],\n",
       "        [-2.7774e+00],\n",
       "        [ 1.4480e+01],\n",
       "        [ 1.0138e+01],\n",
       "        [ 1.1406e+01],\n",
       "        [ 8.6084e+00],\n",
       "        [ 1.0398e+01],\n",
       "        [ 5.8840e+00],\n",
       "        [ 1.8354e+01],\n",
       "        [ 7.6440e+00],\n",
       "        [ 1.3977e+01],\n",
       "        [-1.2281e+01],\n",
       "        [ 1.6963e+01],\n",
       "        [-1.1788e+00],\n",
       "        [ 1.0689e+01],\n",
       "        [ 5.2257e-03],\n",
       "        [ 3.4940e+00],\n",
       "        [-5.2181e-01],\n",
       "        [ 1.5029e+01],\n",
       "        [-6.5594e+00],\n",
       "        [ 2.3259e+01],\n",
       "        [ 5.4361e-01],\n",
       "        [-4.6186e+00],\n",
       "        [-1.7060e+01],\n",
       "        [-5.5709e+00],\n",
       "        [ 9.5214e+00],\n",
       "        [-7.9763e+00],\n",
       "        [ 4.2252e+00],\n",
       "        [ 1.5092e+00],\n",
       "        [ 7.0865e+00],\n",
       "        [ 9.0257e+00],\n",
       "        [ 7.0669e+00],\n",
       "        [ 2.4924e+00],\n",
       "        [ 1.2331e+00],\n",
       "        [ 3.7890e+00],\n",
       "        [ 1.7030e+01],\n",
       "        [ 2.2109e+01],\n",
       "        [ 7.1882e+00],\n",
       "        [-5.2052e+00],\n",
       "        [ 5.0795e+00],\n",
       "        [ 7.2834e+00],\n",
       "        [ 1.2444e+01],\n",
       "        [ 1.4443e+01],\n",
       "        [ 1.8640e+00],\n",
       "        [ 1.5246e+01],\n",
       "        [-1.0635e+00],\n",
       "        [ 1.4088e+00],\n",
       "        [ 2.8884e+01],\n",
       "        [-6.2733e-01],\n",
       "        [-1.9599e+00],\n",
       "        [ 6.5011e+00],\n",
       "        [ 1.3949e+00],\n",
       "        [ 2.6366e+00],\n",
       "        [-5.8401e+00]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = y.reshape((-1, 1))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4fa52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd2f8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arrays = (X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d26f5ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f8949d7f7f0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.TensorDataset(*data_arrays)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1bd3b8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f8949d7ef80>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3482cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4741,  0.0645, -0.2747],\n",
      "        [ 1.1765,  0.0767,  0.7029],\n",
      "        [-0.1647,  0.7800, -0.7397],\n",
      "        [ 0.9177, -0.3356, -1.5822],\n",
      "        [ 0.7624,  0.7372, -0.3704],\n",
      "        [-0.4355,  0.0917, -1.1242],\n",
      "        [ 1.8802, -0.6526,  0.3868],\n",
      "        [ 1.1768, -1.3929,  0.1586],\n",
      "        [-0.0452, -0.5718,  0.1165],\n",
      "        [ 0.6459,  0.6444, -0.4780]]) tensor([[ 0.8407],\n",
      "        [11.9224],\n",
      "        [-4.6837],\n",
      "        [-5.4909],\n",
      "        [ 0.2721],\n",
      "        [-5.9651],\n",
      "        [13.2642],\n",
      "        [12.5562],\n",
      "        [ 6.9896],\n",
      "        [-0.5261]])\n",
      "tensor([[ 1.0635,  0.4535, -2.1084],\n",
      "        [-0.8982,  1.2297, -0.2024],\n",
      "        [ 0.2801,  0.2418, -0.3988],\n",
      "        [-0.0743,  1.0724, -0.6607],\n",
      "        [ 2.5289,  2.5730, -1.9285],\n",
      "        [-1.3788, -0.1598,  0.0705],\n",
      "        [ 1.2497,  1.1856, -0.5210],\n",
      "        [-1.3608,  2.4439,  0.4963],\n",
      "        [ 0.0881, -0.4497,  0.9120],\n",
      "        [ 1.2733, -1.2467, -0.3691]]) tensor([[-12.0729],\n",
      "        [ -3.3824],\n",
      "        [  0.7515],\n",
      "        [ -4.8782],\n",
      "        [-14.9111],\n",
      "        [  2.5498],\n",
      "        [ -1.5003],\n",
      "        [ -2.8696],\n",
      "        [ 13.2100],\n",
      "        [  8.0338]])\n",
      "tensor([[ 0.4041,  0.0491, -0.0550],\n",
      "        [ 0.4883, -0.3607, -0.4352],\n",
      "        [-0.8821,  0.7723,  0.6139],\n",
      "        [-2.0936, -0.1589,  1.1179],\n",
      "        [ 1.9686,  0.2384,  0.4716],\n",
      "        [-1.5104, -0.4103, -0.6435],\n",
      "        [ 0.6755,  0.1372,  0.5905],\n",
      "        [ 0.1445,  0.2693,  0.1110],\n",
      "        [ 0.0614, -1.9995,  0.8815],\n",
      "        [-0.4741,  0.7381,  0.6824]]) tensor([[ 4.3992],\n",
      "        [ 2.9237],\n",
      "        [ 4.7244],\n",
      "        [ 9.4918],\n",
      "        [11.0844],\n",
      "        [-2.5771],\n",
      "        [ 9.8014],\n",
      "        [ 4.4602],\n",
      "        [18.1727],\n",
      "        [ 6.1987]])\n",
      "tensor([[ 1.5031,  0.5808, -0.2110],\n",
      "        [ 0.1146, -0.9996, -1.1717],\n",
      "        [ 0.9244, -1.6803,  0.8692],\n",
      "        [ 0.3932, -0.6580, -1.3530],\n",
      "        [-0.5807,  0.7998, -1.4105],\n",
      "        [-0.8193,  0.2486, -1.3396],\n",
      "        [-0.7052,  0.7371,  0.4243],\n",
      "        [-0.0244,  0.3646, -0.0385],\n",
      "        [-0.2672,  0.4276, -1.2282],\n",
      "        [-1.1384, -1.5192, -0.7185]]) tensor([[  3.5527],\n",
      "        [ -1.5405],\n",
      "        [ 18.7210],\n",
      "        [ -3.6017],\n",
      "        [-10.9778],\n",
      "        [ -8.9979],\n",
      "        [  3.6854],\n",
      "        [  2.6064],\n",
      "        [ -7.6018],\n",
      "        [  1.3492]])\n",
      "tensor([[-0.1745,  0.0758, -0.3880],\n",
      "        [ 0.8799, -1.5440,  0.7604],\n",
      "        [-0.6381,  1.2729, -0.2008],\n",
      "        [ 0.2701, -0.8094, -0.1077],\n",
      "        [ 0.1669, -2.1641,  0.8737],\n",
      "        [ 0.1323, -0.9691,  0.2085],\n",
      "        [ 0.1694, -0.2636,  0.0377],\n",
      "        [-1.1261, -1.2635,  0.0054],\n",
      "        [-0.4862,  0.5647, -0.7726],\n",
      "        [-1.6460,  0.9825, -0.4898]]) tensor([[ 0.4799],\n",
      "        [17.2961],\n",
      "        [-3.0204],\n",
      "        [ 6.6368],\n",
      "        [18.8715],\n",
      "        [ 9.4265],\n",
      "        [ 5.7424],\n",
      "        [ 6.2871],\n",
      "        [-4.8967],\n",
      "        [-6.3578]])\n",
      "tensor([[-0.3311,  1.4601,  2.0913],\n",
      "        [ 1.4532, -1.1955,  1.3946],\n",
      "        [ 1.4055, -0.1576,  1.6127],\n",
      "        [-0.7826, -0.8797,  1.2848],\n",
      "        [ 2.3854,  0.2206,  0.3268],\n",
      "        [ 0.0423,  0.2157,  0.0097],\n",
      "        [ 0.0472,  0.3625, -0.7417],\n",
      "        [ 1.3760,  0.0865, -0.6063],\n",
      "        [-0.5417,  0.3632,  1.7842],\n",
      "        [ 1.1246,  0.2206,  0.3202]]) tensor([[15.3025],\n",
      "        [22.3361],\n",
      "        [20.4559],\n",
      "        [15.8851],\n",
      "        [10.8399],\n",
      "        [ 3.6172],\n",
      "        [-2.8761],\n",
      "        [ 1.8053],\n",
      "        [16.1514],\n",
      "        [ 8.2547]])\n",
      "tensor([[ 0.0168,  0.2083,  1.9224],\n",
      "        [ 0.4389, -1.0756,  0.5109],\n",
      "        [-0.6889,  1.3279, -1.1096],\n",
      "        [-0.7307, -1.0804,  1.4829],\n",
      "        [-1.7672, -0.5906, -0.1936],\n",
      "        [ 0.3857, -1.4798,  1.3846],\n",
      "        [ 0.1040, -0.9204,  0.1222],\n",
      "        [ 0.0732, -0.5299, -0.4627],\n",
      "        [-2.2363,  0.0754, -1.2249],\n",
      "        [ 0.9042,  1.4456, -1.0692]]) tensor([[ 18.8951],\n",
      "        [ 12.8244],\n",
      "        [-10.5731],\n",
      "        [ 18.2772],\n",
      "        [  1.1272],\n",
      "        [ 21.0747],\n",
      "        [  8.5060],\n",
      "        [  2.4436],\n",
      "        [-10.3533],\n",
      "        [ -7.4651]])\n",
      "tensor([[ 0.9584,  0.3898, -0.2219],\n",
      "        [ 0.3578, -0.0820,  0.5644],\n",
      "        [-1.3841,  1.1296,  0.8260],\n",
      "        [-1.8243, -0.3132,  0.1420],\n",
      "        [ 0.2290,  0.6890, -0.4778],\n",
      "        [ 0.6697,  0.8256,  0.4716],\n",
      "        [-0.0874,  1.2363,  0.7240],\n",
      "        [-0.3858,  1.4511, -0.3617],\n",
      "        [-0.2431,  1.5711, -1.6574],\n",
      "        [ 0.7819, -0.5023, -3.5054]]) tensor([[  3.0145],\n",
      "        [  9.7221],\n",
      "        [  4.2076],\n",
      "        [  2.7161],\n",
      "        [ -1.5084],\n",
      "        [  6.5037],\n",
      "        [  5.6091],\n",
      "        [ -4.3981],\n",
      "        [-14.8816],\n",
      "        [-20.5613]])\n",
      "tensor([[ 0.3311,  0.1183, -0.6477],\n",
      "        [-1.4320, -1.4606, -0.2012],\n",
      "        [-0.7159,  0.0836, -0.6192],\n",
      "        [ 0.3889,  0.3143,  0.2797],\n",
      "        [ 1.1245, -1.2821, -0.4528],\n",
      "        [-1.5564, -0.3158, -1.4377],\n",
      "        [-0.4597,  0.0689,  2.0930],\n",
      "        [ 0.0102, -0.1998,  0.8459],\n",
      "        [-1.2822,  0.9821, -1.0718],\n",
      "        [ 2.0344, -0.9753, -0.4011]]) tensor([[ -0.7222],\n",
      "        [  4.6808],\n",
      "        [ -2.4597],\n",
      "        [  6.1438],\n",
      "        [  7.1968],\n",
      "        [ -9.3439],\n",
      "        [ 19.7876],\n",
      "        [ 11.6679],\n",
      "        [-10.2745],\n",
      "        [  8.3694]])\n",
      "tensor([[-0.1850, -0.5509, -0.2536],\n",
      "        [ 0.8317,  0.7316,  2.0511],\n",
      "        [ 0.8169, -1.5967, -0.8513],\n",
      "        [-0.4856, -0.9008, -0.1214],\n",
      "        [ 0.7487,  0.6938, -0.5076],\n",
      "        [ 0.9752, -0.7320,  0.0872],\n",
      "        [ 0.5173,  0.2513,  1.3890],\n",
      "        [-0.3664, -0.3942,  0.1424],\n",
      "        [-0.4938,  1.6206,  0.6557],\n",
      "        [ 0.9566, -0.7557, -0.3937]]) tensor([[ 3.6837],\n",
      "        [19.7708],\n",
      "        [ 4.4553],\n",
      "        [ 5.3139],\n",
      "        [-0.7306],\n",
      "        [ 9.3331],\n",
      "        [15.4828],\n",
      "        [ 5.9458],\n",
      "        [ 2.9683],\n",
      "        [ 5.5271]])\n",
      "tensor([[-0.6368, -0.4433, -0.1476],\n",
      "        [-0.3976, -0.7645, -1.5008],\n",
      "        [ 1.9277,  0.0634,  2.1618],\n",
      "        [-0.2644,  1.0337, -0.8442],\n",
      "        [-0.7935, -0.1621, -0.4689],\n",
      "        [-1.1837, -2.0563, -1.0794],\n",
      "        [ 1.8153, -0.3839, -0.6036],\n",
      "        [ 0.9253, -2.2247, -1.2177],\n",
      "        [-1.0339,  0.2436, -0.3611],\n",
      "        [-0.7130, -0.1228, -0.1866]]) tensor([[ 3.2477],\n",
      "        [-5.9998],\n",
      "        [25.1375],\n",
      "        [-6.5965],\n",
      "        [-0.5775],\n",
      "        [ 0.1989],\n",
      "        [ 4.3095],\n",
      "        [ 3.8670],\n",
      "        [-1.5787],\n",
      "        [ 1.7147]])\n",
      "tensor([[-0.3177, -0.9514, -3.1578],\n",
      "        [-0.5169,  2.7027, -0.0707],\n",
      "        [-0.2365, -0.8615,  1.5598],\n",
      "        [-0.5891, -1.1776,  1.3168],\n",
      "        [-1.5139,  0.0939,  0.5022],\n",
      "        [ 0.5547,  0.7236,  1.7680],\n",
      "        [ 0.6341,  0.0687,  1.3599],\n",
      "        [-1.8790, -0.1228, -1.0877],\n",
      "        [-0.5141, -1.2536, -0.3905],\n",
      "        [-1.5642, -0.5467,  0.2053]]) tensor([[-18.4421],\n",
      "        [ -6.6034],\n",
      "        [ 19.1411],\n",
      "        [ 17.5668],\n",
      "        [  4.8649],\n",
      "        [ 17.0038],\n",
      "        [ 16.1134],\n",
      "        [ -7.8527],\n",
      "        [  4.3133],\n",
      "        [  4.5589]])\n",
      "tensor([[-0.9344, -0.3518,  2.1907],\n",
      "        [ 0.8248, -0.0826,  1.5034],\n",
      "        [-1.4325,  0.6003,  1.5040],\n",
      "        [ 0.3141, -1.7126,  1.3030],\n",
      "        [-0.9460,  0.3483, -0.2151],\n",
      "        [-1.3164, -0.0954, -1.2924],\n",
      "        [-0.8678,  0.7954,  0.3624],\n",
      "        [ 1.2861, -0.1302, -0.8388],\n",
      "        [ 0.5546,  1.8674, -0.6394],\n",
      "        [-1.0695,  2.3615, -0.2984]]) tensor([[21.0561],\n",
      "        [18.1684],\n",
      "        [11.3203],\n",
      "        [21.0907],\n",
      "        [-0.6055],\n",
      "        [-8.4516],\n",
      "        [ 2.6672],\n",
      "        [ 0.4792],\n",
      "        [-6.1444],\n",
      "        [-8.3722]])\n",
      "tensor([[ 0.4222, -0.3037,  1.1029],\n",
      "        [ 0.4914, -1.4725, -1.4017],\n",
      "        [ 0.4173,  0.5664,  0.6168],\n",
      "        [ 0.1673,  1.6207, -0.0658],\n",
      "        [ 1.4558, -0.9361,  0.0882],\n",
      "        [ 0.4263, -0.9680,  0.4443],\n",
      "        [-0.0896,  0.3697, -0.3382],\n",
      "        [-0.3003,  0.3852, -0.5902],\n",
      "        [-0.7472,  0.7432, -0.9878],\n",
      "        [-0.4796,  0.6680, -0.2852]]) tensor([[14.9078],\n",
      "        [-1.0056],\n",
      "        [ 8.0619],\n",
      "        [-1.5000],\n",
      "        [10.9784],\n",
      "        [11.9012],\n",
      "        [ 0.0429],\n",
      "        [-2.4372],\n",
      "        [-7.7170],\n",
      "        [-1.3057]])\n",
      "tensor([[-1.0279e+00,  7.5267e-01,  3.2746e-01],\n",
      "        [ 2.8155e-01, -8.5928e-02, -1.1825e-01],\n",
      "        [ 1.0805e+00,  6.6820e-01,  1.0015e+00],\n",
      "        [ 6.2148e-01, -2.8109e-01, -9.9460e-01],\n",
      "        [ 8.4375e-01,  9.0999e-01, -3.3566e-01],\n",
      "        [-7.7081e-01,  6.2308e-01,  6.1875e-02],\n",
      "        [-3.0551e-01,  4.2469e-02,  2.3390e-01],\n",
      "        [-4.4434e-01, -4.8935e-01,  5.2932e-01],\n",
      "        [-2.4868e+00, -7.5233e-01, -8.3988e-01],\n",
      "        [-1.2390e+00,  8.5203e-04,  1.7862e+00]]) tensor([[ 2.2004],\n",
      "        [ 4.1232],\n",
      "        [12.1137],\n",
      "        [-1.5755],\n",
      "        [ 0.1042],\n",
      "        [ 1.0475],\n",
      "        [ 5.3081],\n",
      "        [ 9.2119],\n",
      "        [-4.9342],\n",
      "        [16.0011]])\n",
      "tensor([[-1.2707e+00,  1.4681e-01, -1.0533e-01],\n",
      "        [ 5.9245e-01,  3.8710e-01, -3.4353e-01],\n",
      "        [ 6.1579e-01,  1.4668e+00, -1.2478e+00],\n",
      "        [-9.4807e-01,  7.4086e-01, -2.1961e-01],\n",
      "        [ 3.2072e-01, -2.6920e-01,  2.6364e-01],\n",
      "        [ 5.7419e-01, -3.6292e-01, -1.1369e-01],\n",
      "        [-1.5653e+00, -4.6619e-01,  9.4160e-01],\n",
      "        [-1.0773e+00, -3.0326e-01,  7.0133e-01],\n",
      "        [ 9.3377e-01, -1.3813e+00,  2.3084e-04],\n",
      "        [-7.9813e-01,  1.1368e+00, -9.9027e-01]]) tensor([[ 0.3030],\n",
      "        [ 1.3243],\n",
      "        [-9.5449],\n",
      "        [-1.9831],\n",
      "        [ 7.8850],\n",
      "        [ 5.6724],\n",
      "        [10.1771],\n",
      "        [ 8.6933],\n",
      "        [10.7667],\n",
      "        [-9.1903]])\n",
      "tensor([[-1.7043, -1.1492, -1.8234],\n",
      "        [ 1.1459,  0.8706, -0.7110],\n",
      "        [ 0.6292,  1.0678,  0.7865],\n",
      "        [ 0.4735,  0.7685, -0.2403],\n",
      "        [ 1.5848, -1.8165,  0.9159],\n",
      "        [-0.4129, -0.4257, -0.1015],\n",
      "        [ 0.5457, -0.7605, -0.6500],\n",
      "        [ 0.1506,  0.5158,  0.2962],\n",
      "        [ 1.4940,  1.4104,  0.2064],\n",
      "        [ 0.4609, -0.4964, -1.5431]]) tensor([[-9.8997],\n",
      "        [-2.1544],\n",
      "        [ 8.1214],\n",
      "        [ 0.5936],\n",
      "        [20.8727],\n",
      "        [ 4.0181],\n",
      "        [ 2.6823],\n",
      "        [ 5.0941],\n",
      "        [ 4.0452],\n",
      "        [-5.5348]])\n",
      "tensor([[ 0.4440,  0.1946,  0.0513],\n",
      "        [-0.1821, -1.2626,  0.0322],\n",
      "        [ 1.1460, -0.3986, -1.0911],\n",
      "        [-0.7493, -0.9795, -0.9044],\n",
      "        [-0.0140,  1.0785,  0.5319],\n",
      "        [ 0.6085,  0.7595, -1.1528],\n",
      "        [ 0.5288, -0.5039,  0.6042],\n",
      "        [ 0.3017,  0.0841,  0.3353],\n",
      "        [-0.0099,  0.7017,  1.0472],\n",
      "        [ 1.6686, -1.3914,  0.3792]]) tensor([[ 4.8399],\n",
      "        [ 8.3771],\n",
      "        [-0.8837],\n",
      "        [-1.2107],\n",
      "        [ 4.7647],\n",
      "        [-6.4006],\n",
      "        [11.8095],\n",
      "        [ 7.2122],\n",
      "        [10.1923],\n",
      "        [15.3140]])\n",
      "tensor([[ 9.5145e-01, -2.0586e+00, -1.7822e+00],\n",
      "        [-6.3575e-01, -6.1017e-01,  1.2864e+00],\n",
      "        [-5.3141e-01,  8.7481e-02,  7.4041e-01],\n",
      "        [-2.9504e-01, -6.6592e-01,  5.5584e-01],\n",
      "        [-8.2387e-01,  1.2548e+00, -9.3452e-01],\n",
      "        [ 1.2518e+00,  1.0203e+00, -1.8897e+00],\n",
      "        [-2.9817e-02,  6.7659e-01, -1.7726e-01],\n",
      "        [-1.7688e-01,  4.4640e-01,  3.5070e-01],\n",
      "        [-1.7957e-03,  1.1493e+00, -8.3204e-01],\n",
      "        [-3.0788e-01,  3.0392e-01, -3.8311e-01]]) tensor([[ -1.1499],\n",
      "        [ 15.2936],\n",
      "        [  8.7572],\n",
      "        [ 10.3244],\n",
      "        [ -9.1752],\n",
      "        [-11.8725],\n",
      "        [  0.4136],\n",
      "        [  5.1208],\n",
      "        [ -6.3669],\n",
      "        [ -0.5153]])\n",
      "tensor([[ 0.5078,  1.5300, -1.2263],\n",
      "        [ 1.3927,  0.8307, -1.8142],\n",
      "        [ 0.8570, -0.6438, -0.2425],\n",
      "        [ 1.5877,  0.4611,  0.3999],\n",
      "        [-0.6490, -1.8536, -1.4432],\n",
      "        [ 0.6859,  0.8519, -0.5962],\n",
      "        [ 0.7095, -1.4409,  0.2374],\n",
      "        [-0.2444, -1.1220,  0.5056],\n",
      "        [ 0.1659, -1.1669, -2.3247],\n",
      "        [-0.9729, -1.6951,  1.6827]]) tensor([[ -9.7960],\n",
      "        [-10.3542],\n",
      "        [  6.1595],\n",
      "        [  9.0006],\n",
      "        [ -2.3354],\n",
      "        [ -2.1062],\n",
      "        [ 12.4211],\n",
      "        [ 11.5647],\n",
      "        [-10.0931],\n",
      "        [ 21.4672]])\n",
      "tensor([[ 0.8707, -1.0289,  1.2001],\n",
      "        [ 0.1609, -0.0112, -0.8018],\n",
      "        [-0.1170, -0.6442, -0.1941],\n",
      "        [-0.1531,  1.5628, -0.5669],\n",
      "        [-0.7946,  0.7646, -1.0849],\n",
      "        [ 1.3266,  0.1931,  0.9818],\n",
      "        [ 0.8168, -1.9562, -0.6898],\n",
      "        [ 0.7160,  0.3978, -0.1640],\n",
      "        [-1.0972, -1.1612, -1.1656],\n",
      "        [ 2.3101, -0.7348, -0.8405]]) tensor([[19.0597],\n",
      "        [-1.8666],\n",
      "        [ 4.6038],\n",
      "        [-5.9429],\n",
      "        [-8.6668],\n",
      "        [14.0541],\n",
      "        [ 6.9701],\n",
      "        [ 2.9728],\n",
      "        [-3.3859],\n",
      "        [ 4.5799]])\n",
      "tensor([[-0.7448,  0.2038,  1.9694],\n",
      "        [ 1.7649,  1.3589,  0.3371],\n",
      "        [ 0.7178,  0.6469,  0.4517],\n",
      "        [-0.0226, -1.1530,  1.6667],\n",
      "        [ 1.1354,  1.5405,  1.2896],\n",
      "        [ 0.4713, -0.4250,  1.4711],\n",
      "        [ 1.5904,  0.7891,  0.7947],\n",
      "        [ 1.4727, -1.7199, -0.4064],\n",
      "        [ 0.2359, -0.4277, -0.8002],\n",
      "        [ 1.2002, -0.0237, -0.5686]]) tensor([[17.7860],\n",
      "        [ 5.8033],\n",
      "        [ 7.0463],\n",
      "        [21.4106],\n",
      "        [11.5572],\n",
      "        [18.3608],\n",
      "        [11.0782],\n",
      "        [ 9.7325],\n",
      "        [-0.2845],\n",
      "        [ 2.1332]])\n",
      "tensor([[-0.5192,  0.4501,  0.1154],\n",
      "        [ 2.1706, -0.1347, -0.1882],\n",
      "        [-1.5768, -0.2139, -0.6241],\n",
      "        [-1.2775,  0.5416, -1.6555],\n",
      "        [ 0.4902, -0.1571,  1.3450],\n",
      "        [ 0.5760, -0.4226,  0.2293],\n",
      "        [ 0.1907, -0.0879,  0.3172],\n",
      "        [-0.5227, -1.2501, -0.2646],\n",
      "        [-0.0778, -3.0816,  1.3442],\n",
      "        [ 0.6771, -0.8018,  0.3598]]) tensor([[  2.5586],\n",
      "        [  7.4968],\n",
      "        [ -3.2293],\n",
      "        [-13.4459],\n",
      "        [ 16.5093],\n",
      "        [  8.6220],\n",
      "        [  7.4114],\n",
      "        [  5.2880],\n",
      "        [ 25.2710],\n",
      "        [ 11.1678]])\n",
      "tensor([[-0.7549, -1.3611, -2.3603],\n",
      "        [ 1.1992, -2.6745, -0.0462],\n",
      "        [-0.7089, -0.2613, -0.1099],\n",
      "        [-1.5054,  0.4983,  0.3026],\n",
      "        [ 1.5157,  0.9985,  0.0410],\n",
      "        [ 1.1560,  1.2189, -1.8276],\n",
      "        [-0.5908, -0.7372,  1.9853],\n",
      "        [ 1.5913, -0.4965, -0.2463],\n",
      "        [ 0.5723, -0.9807,  0.3960],\n",
      "        [-0.5347,  0.4405, -0.4946]]) tensor([[-11.5590],\n",
      "        [ 15.3107],\n",
      "        [  2.8055],\n",
      "        [  1.9171],\n",
      "        [  4.1596],\n",
      "        [-12.2802],\n",
      "        [ 21.4059],\n",
      "        [  7.1046],\n",
      "        [ 11.8594],\n",
      "        [ -2.3333]])\n",
      "tensor([[ 2.3235, -1.8612,  0.1031],\n",
      "        [-1.7134,  0.5841, -1.3893],\n",
      "        [-0.4518,  0.6559,  1.7585],\n",
      "        [-1.2007,  1.7714, -2.3237],\n",
      "        [-0.5811,  0.8026,  0.1971],\n",
      "        [-0.1753,  2.6765, -0.9989],\n",
      "        [-0.6683,  0.4649, -0.2145],\n",
      "        [ 0.9613, -0.4850, -2.0285],\n",
      "        [ 0.7613,  2.3369, -0.1459],\n",
      "        [-0.8752, -0.4033, -2.0064]]) tensor([[ 16.0129],\n",
      "        [-12.3204],\n",
      "        [ 15.1322],\n",
      "        [-22.8149],\n",
      "        [  1.8963],\n",
      "        [-13.2366],\n",
      "        [ -0.4293],\n",
      "        [ -8.4395],\n",
      "        [ -3.3799],\n",
      "        [-12.2147]])\n",
      "tensor([[ 0.2492,  0.1134, -0.9290],\n",
      "        [ 0.1833, -0.4444, -0.5910],\n",
      "        [-0.7470,  0.1184,  0.1912],\n",
      "        [-0.8463, -2.7005,  1.0593],\n",
      "        [-0.4982, -2.5614, -1.3492],\n",
      "        [ 1.2534, -1.0493,  0.3597],\n",
      "        [-0.0478,  0.4581,  1.8958],\n",
      "        [-1.3299,  0.6880, -0.1426],\n",
      "        [ 0.0456,  1.2367,  1.8669],\n",
      "        [-0.5940,  0.6423, -0.4559]]) tensor([[-3.1204],\n",
      "        [ 1.3441],\n",
      "        [ 3.8291],\n",
      "        [20.1783],\n",
      "        [ 1.1126],\n",
      "        [13.1735],\n",
      "        [17.7070],\n",
      "        [-1.9406],\n",
      "        [15.0143],\n",
      "        [-2.8084]])\n",
      "tensor([[ 0.6976, -0.4842, -1.6660],\n",
      "        [-2.2493, -0.1093, -0.9912],\n",
      "        [ 0.7546, -0.8336, -0.6958],\n",
      "        [-0.1753,  1.4471, -0.0229],\n",
      "        [ 0.7130,  0.4518,  0.4889],\n",
      "        [-0.3869,  0.6986, -0.2143],\n",
      "        [-1.0243,  0.9412, -0.4945],\n",
      "        [ 1.2709,  0.6559, -0.1075],\n",
      "        [-0.5948, -0.3285, -1.0974],\n",
      "        [ 0.2686,  1.0536, -0.9170]]) tensor([[-6.0857],\n",
      "        [-7.8440],\n",
      "        [ 2.9855],\n",
      "        [-1.2593],\n",
      "        [ 8.0138],\n",
      "        [-0.6627],\n",
      "        [-5.0026],\n",
      "        [ 3.6535],\n",
      "        [-4.6462],\n",
      "        [-6.1911]])\n",
      "tensor([[-0.7925,  1.3374,  1.9542],\n",
      "        [ 0.2206,  0.2752, -0.1340],\n",
      "        [-0.9323,  0.0251, -0.6248],\n",
      "        [-0.7662, -0.8430, -2.9145],\n",
      "        [ 0.5024, -0.1574, -0.9036],\n",
      "        [-0.0475, -0.1525, -0.0168],\n",
      "        [ 2.4878,  0.5717,  0.8701],\n",
      "        [-1.3174,  2.0375,  0.4763],\n",
      "        [-1.1099, -0.1579,  1.3397],\n",
      "        [ 0.0507, -0.6251,  0.9605]]) tensor([[ 13.7079],\n",
      "        [  2.6398],\n",
      "        [ -2.7604],\n",
      "        [-17.7683],\n",
      "        [ -1.4767],\n",
      "        [  4.5020],\n",
      "        [ 14.2156],\n",
      "        [ -1.5502],\n",
      "        [ 13.2289],\n",
      "        [ 14.1217]])\n",
      "tensor([[-0.7202,  0.4177,  1.0422],\n",
      "        [-1.8818, -1.2584, -0.7192],\n",
      "        [ 1.1487,  0.9226, -0.4794],\n",
      "        [ 0.9149,  0.7753, -0.2914],\n",
      "        [ 1.0325,  1.2714,  0.8727],\n",
      "        [ 0.1146,  0.3504, -0.6076],\n",
      "        [-0.8842, -1.2303, -0.2375],\n",
      "        [ 2.1499, -1.7357, -1.0138],\n",
      "        [ 0.4598, -0.8868,  0.0734],\n",
      "        [ 0.5848, -0.2917,  1.6120]]) tensor([[ 9.6785],\n",
      "        [-1.0499],\n",
      "        [-0.4854],\n",
      "        [ 1.0567],\n",
      "        [ 8.9381],\n",
      "        [-1.6415],\n",
      "        [ 4.7112],\n",
      "        [ 6.2837],\n",
      "        [ 8.7108],\n",
      "        [19.2511]])\n",
      "tensor([[ 2.2783,  0.5955,  0.2390],\n",
      "        [ 1.1899,  0.7076,  0.4060],\n",
      "        [-0.1127,  0.2307,  0.7532],\n",
      "        [ 1.0378,  0.8373, -0.5548],\n",
      "        [ 0.8488,  1.5538,  1.0215],\n",
      "        [-0.6395,  0.9236,  1.3834],\n",
      "        [-0.7747, -1.4492,  0.0211],\n",
      "        [ 0.0257,  0.2618,  0.7339],\n",
      "        [-0.7276, -0.4878, -0.4706],\n",
      "        [-1.2298,  2.0943, -0.3492]]) tensor([[ 8.6431],\n",
      "        [ 7.4099],\n",
      "        [ 9.2215],\n",
      "        [-0.9997],\n",
      "        [ 8.7944],\n",
      "        [10.8594],\n",
      "        [ 7.7497],\n",
      "        [ 9.2237],\n",
      "        [ 0.6324],\n",
      "        [-8.1867]])\n",
      "tensor([[ 0.9245, -1.0439, -1.0164],\n",
      "        [ 0.4320, -0.0490, -0.6457],\n",
      "        [ 1.4357, -0.5626,  1.9733],\n",
      "        [-1.0972,  0.6823,  1.1774],\n",
      "        [-2.3837, -0.2362, -0.3858],\n",
      "        [ 0.4364,  0.7611, -0.3668],\n",
      "        [ 1.2257, -0.5878, -1.4502],\n",
      "        [ 1.3717,  0.5936,  0.1335],\n",
      "        [ 0.6670,  0.1114,  2.4118],\n",
      "        [-1.5764,  0.0095,  0.0582]]) tensor([[ 1.4505],\n",
      "        [ 0.0553],\n",
      "        [24.7720],\n",
      "        [ 9.1228],\n",
      "        [-2.8501],\n",
      "        [-0.4633],\n",
      "        [-2.9516],\n",
      "        [ 5.9949],\n",
      "        [24.4538],\n",
      "        [ 1.4707]])\n",
      "tensor([[ 0.1134,  0.1160, -0.6303],\n",
      "        [-0.1498,  0.7149, -0.1724],\n",
      "        [ 1.5229,  0.2645,  1.7155],\n",
      "        [-0.2214,  2.7953, -0.7872],\n",
      "        [ 1.0915, -0.2361,  0.3922],\n",
      "        [ 0.1426,  0.2805,  0.6576],\n",
      "        [-2.8811, -0.9143, -0.5819],\n",
      "        [-0.4870,  0.5904,  0.8621],\n",
      "        [ 0.8914, -1.1278,  0.0339],\n",
      "        [-1.2590, -0.9420, -0.3804]]) tensor([[ -1.0229],\n",
      "        [  0.0967],\n",
      "        [ 20.0677],\n",
      "        [-12.0320],\n",
      "        [ 10.3119],\n",
      "        [  8.7865],\n",
      "        [ -3.1081],\n",
      "        [  8.1245],\n",
      "        [ 10.0954],\n",
      "        [  1.8552]])\n",
      "tensor([[ 0.4569,  0.0476,  0.3222],\n",
      "        [-0.1189,  1.2708,  1.0957],\n",
      "        [-0.1859, -1.5840,  0.3033],\n",
      "        [ 1.7717,  0.7244,  0.3865],\n",
      "        [ 0.3789, -0.4894, -2.3594],\n",
      "        [-1.8788,  0.5861, -0.9575],\n",
      "        [-1.2069, -0.6114, -0.0899],\n",
      "        [-0.6626,  0.3396, -0.8069],\n",
      "        [-0.1308,  2.2479, -0.2293],\n",
      "        [ 1.2761,  0.3431, -0.2670]]) tensor([[  7.5221],\n",
      "        [  8.3986],\n",
      "        [ 11.6458],\n",
      "        [  8.4007],\n",
      "        [-12.2554],\n",
      "        [ -9.2348],\n",
      "        [  3.1516],\n",
      "        [ -4.7380],\n",
      "        [ -5.5292],\n",
      "        [  3.4531]])\n",
      "tensor([[ 1.5144,  1.9855, -2.7830],\n",
      "        [-0.5324, -0.5650, -0.4389],\n",
      "        [-0.3257,  0.6086,  0.0400],\n",
      "        [ 0.1059, -0.1381,  0.3112],\n",
      "        [ 0.1023,  1.4309,  0.5409],\n",
      "        [ 1.1517, -0.7384, -1.3156],\n",
      "        [ 0.7948, -0.5148, -0.6238],\n",
      "        [-0.9653,  2.2755,  0.7736],\n",
      "        [ 0.7567, -1.1930, -0.7554],\n",
      "        [-0.2917, -0.9465, -1.1496]]) tensor([[-21.7873],\n",
      "        [  1.5336],\n",
      "        [  1.8010],\n",
      "        [  7.3839],\n",
      "        [  3.8710],\n",
      "        [ -1.5139],\n",
      "        [  2.5494],\n",
      "        [  0.7159],\n",
      "        [  3.7164],\n",
      "        [ -2.3554]])\n",
      "tensor([[ 2.4873, -0.6766,  0.4400],\n",
      "        [ 0.3763, -0.6747,  0.0044],\n",
      "        [-0.3104,  0.6234,  2.0279],\n",
      "        [ 0.5203,  1.8798,  0.9779],\n",
      "        [ 1.1360, -0.6318, -1.3140],\n",
      "        [-0.0515, -0.2373,  0.0551],\n",
      "        [ 0.0406,  1.1463, -1.1662],\n",
      "        [-1.8243, -0.7761,  1.4030],\n",
      "        [ 0.3040, -0.2683, -1.2491],\n",
      "        [ 1.0368, -0.2864,  0.9377]]) tensor([[15.0023],\n",
      "        [ 7.2758],\n",
      "        [17.6998],\n",
      "        [ 6.6955],\n",
      "        [-1.8892],\n",
      "        [ 5.3568],\n",
      "        [-8.9542],\n",
      "        [14.4097],\n",
      "        [-4.2807],\n",
      "        [14.7538]])\n",
      "tensor([[ 1.4004,  0.2116,  0.8732],\n",
      "        [-0.4787, -1.0420, -0.0711],\n",
      "        [-2.0499,  1.0068, -0.3589],\n",
      "        [-0.6104, -0.5908, -0.3040],\n",
      "        [-1.1130,  0.8364, -0.5410],\n",
      "        [-0.3188, -1.3436,  2.2420],\n",
      "        [-2.0351, -0.2755, -0.1509],\n",
      "        [-0.3224,  1.5565, -2.0602],\n",
      "        [-1.9028, -0.8713,  0.4981],\n",
      "        [-0.3417,  0.6954,  1.9297]]) tensor([[ 13.2620],\n",
      "        [  6.2251],\n",
      "        [ -6.1937],\n",
      "        [  2.5445],\n",
      "        [ -5.1908],\n",
      "        [ 26.0652],\n",
      "        [ -0.1539],\n",
      "        [-18.2261],\n",
      "        [  7.3311],\n",
      "        [ 16.6063]])\n",
      "tensor([[ 0.1037,  1.8890, -0.7844],\n",
      "        [-1.4482, -1.9719,  0.5757],\n",
      "        [-0.4691, -0.3070, -0.3987],\n",
      "        [-0.3756, -1.9729, -1.1931],\n",
      "        [-1.5592, -0.2812, -0.4813],\n",
      "        [-0.3190, -0.4193,  0.2027],\n",
      "        [-1.4404,  0.8576, -0.0483],\n",
      "        [ 0.3531, -0.5342, -1.5559],\n",
      "        [-1.2813, -2.3251, -0.6319],\n",
      "        [ 0.2425,  0.0893,  0.6434]]) tensor([[-8.2876],\n",
      "        [12.6027],\n",
      "        [ 1.1099],\n",
      "        [ 0.6263],\n",
      "        [-1.8240],\n",
      "        [ 6.6195],\n",
      "        [-1.9848],\n",
      "        [-5.7069],\n",
      "        [ 4.4805],\n",
      "        [ 9.5299]])\n",
      "tensor([[ 0.8591, -0.4890, -0.8425],\n",
      "        [-1.5972, -0.3843, -1.1937],\n",
      "        [ 0.5646,  1.0474, -1.2570],\n",
      "        [ 0.7818,  1.6315, -0.5317],\n",
      "        [-0.0040, -0.6796,  1.9217],\n",
      "        [ 1.9815,  0.0976, -1.1103],\n",
      "        [-0.0274, -3.5697,  0.3177],\n",
      "        [-0.8633,  1.5304, -1.4527],\n",
      "        [ 1.1048,  1.3211,  0.8469],\n",
      "        [-0.8532, -0.5630, -0.2759]]) tensor([[  0.8413],\n",
      "        [ -7.2291],\n",
      "        [ -8.2985],\n",
      "        [ -4.0404],\n",
      "        [ 21.8897],\n",
      "        [ -1.0541],\n",
      "        [ 18.8173],\n",
      "        [-14.3437],\n",
      "        [  8.7073],\n",
      "        [  2.2092]])\n",
      "tensor([[-0.7095,  0.7649, -1.0261],\n",
      "        [-0.1977,  0.3058,  0.4852],\n",
      "        [ 0.6258,  0.1238,  1.1628],\n",
      "        [-0.9119,  1.6745, -0.8981],\n",
      "        [ 0.6657,  1.9955, -0.2951],\n",
      "        [-0.4780,  0.2831, -0.9373],\n",
      "        [ 0.2880,  0.2231, -0.2280],\n",
      "        [-0.4029, -1.1619,  0.0979],\n",
      "        [ 1.3607,  0.0543,  0.2311],\n",
      "        [-1.1804,  0.5148, -0.5313]]) tensor([[ -8.0419],\n",
      "        [  6.6466],\n",
      "        [ 14.3410],\n",
      "        [-10.4984],\n",
      "        [ -3.6183],\n",
      "        [ -5.2191],\n",
      "        [  2.1722],\n",
      "        [  8.1229],\n",
      "        [  8.5879],\n",
      "        [ -4.1730]])\n",
      "tensor([[ 0.3261, -0.6522, -0.0138],\n",
      "        [-0.2612,  0.5108,  0.3438],\n",
      "        [-0.3894,  0.7555, -1.3607],\n",
      "        [-0.0467, -0.6306,  0.4417],\n",
      "        [-0.4574, -1.6230, -0.2014],\n",
      "        [-1.3232, -1.5043,  0.7818],\n",
      "        [-0.4924,  1.1271,  0.0554],\n",
      "        [-0.4324,  0.4049, -0.3483],\n",
      "        [-1.7873, -0.6478,  0.2476],\n",
      "        [ 0.1061,  0.3695,  0.5584]]) tensor([[  6.9670],\n",
      "        [  4.7028],\n",
      "        [-10.0374],\n",
      "        [  9.7779],\n",
      "        [  7.1899],\n",
      "        [ 12.9208],\n",
      "        [ -0.1749],\n",
      "        [ -0.8226],\n",
      "        [  4.8035],\n",
      "        [  7.6005]])\n",
      "tensor([[ 0.1408, -0.2226, -0.3808],\n",
      "        [ 0.0179,  1.3296,  0.8342],\n",
      "        [ 0.7588,  0.3561, -0.8854],\n",
      "        [ 1.2010, -0.1103,  1.7728],\n",
      "        [-0.3499, -0.2871, -0.1644],\n",
      "        [-0.1635, -1.8247,  1.3815],\n",
      "        [ 0.2094, -1.0167, -0.5020],\n",
      "        [ 0.7039,  0.0239, -0.1714],\n",
      "        [ 1.2907, -1.1689, -0.8875],\n",
      "        [-0.4276, -0.1071,  0.2084]]) tensor([[ 2.1982],\n",
      "        [ 6.3912],\n",
      "        [-2.5678],\n",
      "        [21.1538],\n",
      "        [ 3.1732],\n",
      "        [21.1225],\n",
      "        [ 4.0462],\n",
      "        [ 4.1583],\n",
      "        [ 3.6579],\n",
      "        [ 5.3845]])\n",
      "tensor([[-1.4997, -1.6879, -0.1364],\n",
      "        [ 0.9043,  1.1295,  0.9548],\n",
      "        [ 0.6372,  0.7760, -0.7526],\n",
      "        [-0.0799,  2.0039,  0.0849],\n",
      "        [ 0.4254,  1.6994,  1.3674],\n",
      "        [-1.2001, -0.0991, -0.9171],\n",
      "        [ 1.0063,  0.8309,  1.2911],\n",
      "        [ 1.3656,  0.7070,  1.3021],\n",
      "        [-0.7225, -2.0189,  0.3976],\n",
      "        [-1.5766,  1.6516, -0.2495]]) tensor([[ 5.8373],\n",
      "        [ 9.7962],\n",
      "        [-3.2039],\n",
      "        [-2.1037],\n",
      "        [10.2253],\n",
      "        [-5.2022],\n",
      "        [13.7123],\n",
      "        [14.9600],\n",
      "        [12.7832],\n",
      "        [-6.5712]])\n",
      "tensor([[ 1.3227, -0.1885,  0.8696],\n",
      "        [-0.7565,  1.0787, -0.1598],\n",
      "        [ 1.4504,  1.9150,  1.4399],\n",
      "        [-2.1790,  0.0461,  1.0412],\n",
      "        [-0.6853,  1.4323,  1.4790],\n",
      "        [ 0.6994, -1.9481,  1.0578],\n",
      "        [-1.2822, -0.2956, -1.0795],\n",
      "        [ 0.2290,  0.1773,  0.8589],\n",
      "        [-0.3849,  0.4597, -0.0931],\n",
      "        [-0.3495, -0.5284,  0.3403]]) tensor([[14.4371],\n",
      "        [-2.2267],\n",
      "        [12.1038],\n",
      "        [ 8.0087],\n",
      "        [ 9.7781],\n",
      "        [20.6698],\n",
      "        [-5.9973],\n",
      "        [10.9265],\n",
      "        [ 1.1186],\n",
      "        [ 8.0298]])\n",
      "tensor([[ 1.1583,  1.6001, -0.0907],\n",
      "        [-0.0467, -0.2170, -0.4629],\n",
      "        [ 0.6358, -0.6582,  0.4366],\n",
      "        [ 2.5771,  0.5774, -1.2718],\n",
      "        [-1.5101,  0.2555,  1.1252],\n",
      "        [ 0.9372,  0.5091,  0.8952],\n",
      "        [-0.2905, -1.1464, -0.7902],\n",
      "        [-0.5372, -0.5529,  1.3165],\n",
      "        [-1.1394,  0.6529, -1.3020],\n",
      "        [ 0.8387, -0.4873,  0.1103]]) tensor([[  0.3444],\n",
      "        [  1.1391],\n",
      "        [ 11.1823],\n",
      "        [ -2.7845],\n",
      "        [  9.3125],\n",
      "        [ 11.5129],\n",
      "        [  1.2054],\n",
      "        [ 15.5417],\n",
      "        [-10.7124],\n",
      "        [  8.4162]])\n",
      "tensor([[ 0.8149,  0.1829, -0.5063],\n",
      "        [-1.1118,  0.1718, -0.9893],\n",
      "        [-0.0776,  0.2332,  1.5461],\n",
      "        [ 1.1014,  0.1101,  2.1176],\n",
      "        [-0.8160,  0.1430, -0.4229],\n",
      "        [-0.7553, -1.2595, -0.5308],\n",
      "        [-0.1493, -0.2081,  0.6363],\n",
      "        [-1.6543, -0.5342, -1.5251],\n",
      "        [-0.5575,  0.0963,  0.3178],\n",
      "        [ 0.6242,  0.3475, -0.9078]]) tensor([[ 1.1742],\n",
      "        [-6.5180],\n",
      "        [15.6285],\n",
      "        [22.9632],\n",
      "        [-1.3255],\n",
      "        [ 2.7159],\n",
      "        [ 9.7071],\n",
      "        [-9.5076],\n",
      "        [ 5.2901],\n",
      "        [-2.9813]])\n",
      "tensor([[ 0.3150, -0.2067, -0.7175],\n",
      "        [ 0.1306, -0.7822,  0.4494],\n",
      "        [-0.2884,  0.2536,  0.0452],\n",
      "        [-1.6799, -0.3145, -0.4572],\n",
      "        [ 3.4603, -0.3154, -0.7179],\n",
      "        [ 1.4362,  0.5012,  0.3581],\n",
      "        [ 1.5152, -0.1755,  0.3891],\n",
      "        [-0.2919, -2.1206,  0.3026],\n",
      "        [-0.3946, -0.8969, -1.0124],\n",
      "        [ 1.1187, -0.3508, -1.4212]]) tensor([[-0.1973],\n",
      "        [10.7204],\n",
      "        [ 3.1174],\n",
      "        [-1.7497],\n",
      "        [ 6.4465],\n",
      "        [ 8.2306],\n",
      "        [10.9427],\n",
      "        [13.2525],\n",
      "        [-1.6470],\n",
      "        [-3.7364]])\n",
      "tensor([[-0.8443,  0.8626,  0.3437],\n",
      "        [ 0.1300, -1.2364, -0.5960],\n",
      "        [ 0.0573, -0.5365, -0.4285],\n",
      "        [ 2.3443,  0.2049,  1.3177],\n",
      "        [-0.5902, -0.0390,  0.9303],\n",
      "        [-0.4235, -0.9168, -1.9199],\n",
      "        [ 0.3214, -0.3984, -1.6137],\n",
      "        [-0.3300, -0.6045,  1.8792],\n",
      "        [ 0.8484,  0.9149, -0.4109],\n",
      "        [ 0.5894, -0.1995, -0.2825]]) tensor([[ 2.3171],\n",
      "        [ 3.8995],\n",
      "        [ 2.6960],\n",
      "        [18.7500],\n",
      "        [10.5937],\n",
      "        [-8.8928],\n",
      "        [-6.7236],\n",
      "        [20.6255],\n",
      "        [-0.4993],\n",
      "        [ 3.8016]])\n",
      "tensor([[ 1.4137, -0.4351,  0.7382],\n",
      "        [ 2.3529,  1.0090,  0.9990],\n",
      "        [-0.4760, -0.5819,  0.8639],\n",
      "        [-0.9459,  0.1736,  0.4805],\n",
      "        [ 1.9201, -0.3665,  0.8441],\n",
      "        [-1.9459,  0.3715, -0.1065],\n",
      "        [-0.8056,  0.3676,  0.5995],\n",
      "        [-1.3129,  1.2429, -0.1835],\n",
      "        [-0.9816,  0.0368,  1.4228],\n",
      "        [ 0.6955, -0.6587, -0.0781]]) tensor([[14.4080],\n",
      "        [13.4722],\n",
      "        [12.1254],\n",
      "        [ 5.5678],\n",
      "        [16.0536],\n",
      "        [-1.8046],\n",
      "        [ 6.1251],\n",
      "        [-4.1111],\n",
      "        [13.4864],\n",
      "        [ 7.2173]])\n",
      "tensor([[-1.2419,  0.6259, -1.4631],\n",
      "        [-1.6016,  1.5707,  0.2559],\n",
      "        [-0.9295,  0.6391,  1.1627],\n",
      "        [ 0.7024, -0.6645, -0.7330],\n",
      "        [-0.4501,  0.7709, -0.4376],\n",
      "        [ 1.2010,  0.0177,  0.6333],\n",
      "        [ 0.0662, -0.1737, -0.0319],\n",
      "        [-1.3442,  0.1329,  0.0405],\n",
      "        [ 1.0844, -0.8576, -1.2600],\n",
      "        [-0.5234, -1.0868, -1.5606]]) tensor([[-12.0976],\n",
      "        [ -2.3052],\n",
      "        [  9.4692],\n",
      "        [  1.9974],\n",
      "        [ -2.8144],\n",
      "        [ 11.5904],\n",
      "        [  4.6739],\n",
      "        [  1.3857],\n",
      "        [ -0.7851],\n",
      "        [ -5.6352]])\n",
      "tensor([[-0.9074,  1.2549,  0.1135],\n",
      "        [ 1.2772,  0.7415,  0.9955],\n",
      "        [ 0.2283,  0.7457,  0.0420],\n",
      "        [ 1.7789,  0.0291,  1.1006],\n",
      "        [-1.0118, -0.8792, -1.3560],\n",
      "        [-0.5820,  0.9975,  1.2328],\n",
      "        [-1.5172,  0.1701,  0.0036],\n",
      "        [ 0.7054, -0.4602,  0.2756],\n",
      "        [-0.5454, -1.4548, -0.5346],\n",
      "        [-0.0533, -0.2931,  0.3614]]) tensor([[-0.9637],\n",
      "        [12.1877],\n",
      "        [ 2.4566],\n",
      "        [16.4653],\n",
      "        [-5.6819],\n",
      "        [ 9.4883],\n",
      "        [ 0.6192],\n",
      "        [ 9.3693],\n",
      "        [ 3.7850],\n",
      "        [ 7.9735]])\n",
      "tensor([[ 0.8383,  1.0171, -1.1319],\n",
      "        [-1.9791,  0.6184, -0.2749],\n",
      "        [ 0.1151, -1.3343, -2.9533],\n",
      "        [ 2.2424, -0.5456, -1.0312],\n",
      "        [-0.3892, -0.3468,  0.0139],\n",
      "        [ 0.3416,  1.1043, -0.9278],\n",
      "        [-0.7010,  0.8702, -0.0296],\n",
      "        [ 0.4260,  0.0865, -0.3298],\n",
      "        [ 0.5125, -0.2720, -0.2897],\n",
      "        [-0.3681,  0.0626,  0.1218]]) tensor([[ -6.6312],\n",
      "        [ -4.0490],\n",
      "        [-14.6615],\n",
      "        [  2.2759],\n",
      "        [  4.7152],\n",
      "        [ -6.2974],\n",
      "        [ -0.3946],\n",
      "        [  2.1109],\n",
      "        [  3.8309],\n",
      "        [  4.2394]])\n",
      "tensor([[-0.5784,  1.1818,  0.7680],\n",
      "        [ 0.3960,  0.3351,  1.0993],\n",
      "        [ 1.4412, -0.4229,  1.7416],\n",
      "        [-1.0655, -0.9124, -0.3662],\n",
      "        [-0.3166,  0.2333,  0.7499],\n",
      "        [ 0.3525, -1.9074, -0.8103],\n",
      "        [ 0.4183, -0.0595,  0.0799],\n",
      "        [ 1.2304, -0.5642, -0.2701],\n",
      "        [-1.4346,  0.6679, -0.9024],\n",
      "        [-0.1175, -0.7945, -2.0230]]) tensor([[ 5.1584],\n",
      "        [12.6396],\n",
      "        [22.4647],\n",
      "        [ 2.2205],\n",
      "        [ 8.7803],\n",
      "        [ 4.9045],\n",
      "        [ 5.8738],\n",
      "        [ 6.4018],\n",
      "        [-8.1590],\n",
      "        [-9.5226]])\n",
      "tensor([[ 1.2975, -0.5573, -0.0056],\n",
      "        [-0.7588,  0.4300,  0.7311],\n",
      "        [ 2.5874,  1.1584,  0.0945],\n",
      "        [-0.5825, -0.8841, -0.0761],\n",
      "        [-0.3831,  0.1448, -0.8926],\n",
      "        [-0.1084,  0.0195,  0.2850],\n",
      "        [ 0.6513, -0.1371, -1.5437],\n",
      "        [ 0.3048, -0.1064, -0.1282],\n",
      "        [ 0.6568, -0.1023,  0.2260],\n",
      "        [-0.3165,  1.5197, -1.1153]]) tensor([[  8.6622],\n",
      "        [  7.0535],\n",
      "        [  6.1915],\n",
      "        [  5.4126],\n",
      "        [ -4.1727],\n",
      "        [  6.1968],\n",
      "        [ -6.4002],\n",
      "        [  4.1432],\n",
      "        [  7.6654],\n",
      "        [-10.5054]])\n",
      "tensor([[-0.0750, -0.7030, -0.5787],\n",
      "        [ 0.1930, -0.3596,  0.6916],\n",
      "        [-0.5202, -0.1929,  1.3784],\n",
      "        [ 0.4346,  2.3427, -1.9545],\n",
      "        [ 0.4696, -0.2179,  1.7316],\n",
      "        [-0.5135, -0.3750,  2.2284],\n",
      "        [ 2.4411,  0.4634,  1.1110],\n",
      "        [-1.2844, -0.7360,  0.4927],\n",
      "        [ 0.3964, -1.1251,  0.8666],\n",
      "        [-0.0512,  0.4433, -0.5032]]) tensor([[  1.7949],\n",
      "        [ 11.3488],\n",
      "        [ 14.8411],\n",
      "        [-18.5283],\n",
      "        [ 19.7562],\n",
      "        [ 22.2738],\n",
      "        [ 16.3986],\n",
      "        [  8.0897],\n",
      "        [ 15.7348],\n",
      "        [ -1.4188]])\n",
      "tensor([[-0.5754, -0.9881, -1.6287],\n",
      "        [ 0.1290,  0.4757,  0.4568],\n",
      "        [-0.5461,  0.7940, -0.1954],\n",
      "        [-0.4366,  1.9434, -0.2072],\n",
      "        [ 0.5694,  1.2808,  0.6021],\n",
      "        [ 0.1146,  1.1982,  0.0577],\n",
      "        [ 0.4352,  0.4125, -1.6486],\n",
      "        [ 2.2384, -1.4299, -0.5814],\n",
      "        [ 0.1500,  1.4044, -2.0266],\n",
      "        [ 1.4750,  0.5085,  0.8891]]) tensor([[ -6.6159],\n",
      "        [  6.4861],\n",
      "        [ -1.1465],\n",
      "        [ -4.9375],\n",
      "        [  5.8125],\n",
      "        [  0.8502],\n",
      "        [ -9.5113],\n",
      "        [  8.8806],\n",
      "        [-16.5225],\n",
      "        [ 12.5413]])\n",
      "tensor([[-1.6495, -0.8310, -0.0896],\n",
      "        [-1.1664,  0.5900,  0.4080],\n",
      "        [ 0.3574, -0.2872, -0.4282],\n",
      "        [ 2.3919, -0.4854,  0.8800],\n",
      "        [-0.2924, -1.4312,  0.0616],\n",
      "        [-0.5603,  1.4013,  1.1440],\n",
      "        [-1.3706,  0.1708, -0.6849],\n",
      "        [-0.1032,  0.3878,  0.6824],\n",
      "        [-0.6620, -0.3507, -0.1492],\n",
      "        [-0.3328,  0.0794,  0.1235]]) tensor([[ 3.0196],\n",
      "        [ 3.1136],\n",
      "        [ 2.4797],\n",
      "        [17.6849],\n",
      "        [ 8.9723],\n",
      "        [ 7.4661],\n",
      "        [-4.6100],\n",
      "        [ 8.1468],\n",
      "        [ 2.8718],\n",
      "        [ 4.2568]])\n",
      "tensor([[-0.1547, -1.1823,  0.3208],\n",
      "        [-0.5465,  0.8078, -0.5833],\n",
      "        [ 0.6140,  1.3981,  0.3390],\n",
      "        [ 0.7865,  0.3512, -1.9094],\n",
      "        [-0.2192,  1.1323, -0.6215],\n",
      "        [-0.0625, -0.3695,  0.6783],\n",
      "        [-0.3246, -1.0522,  0.0931],\n",
      "        [-0.0774,  0.3206, -0.5475],\n",
      "        [ 0.3459,  2.3851, -0.8127],\n",
      "        [ 0.6545,  1.1896,  0.1580]]) tensor([[ 10.4912],\n",
      "        [ -4.3106],\n",
      "        [  3.3792],\n",
      "        [-10.6988],\n",
      "        [ -5.0767],\n",
      "        [ 10.7535],\n",
      "        [  7.8693],\n",
      "        [ -1.4160],\n",
      "        [ -9.7200],\n",
      "        [  2.7388]])\n",
      "tensor([[-3.6562e-01, -1.5625e+00,  8.3460e-01],\n",
      "        [-3.2527e-01, -3.5964e-01, -6.2854e-01],\n",
      "        [-8.4559e-01,  1.7807e-01,  1.2459e+00],\n",
      "        [ 8.2004e-01, -7.0716e-04,  1.2772e+00],\n",
      "        [-3.0200e-01,  4.4073e-01, -1.6121e+00],\n",
      "        [ 5.0938e-01, -3.7623e-01, -5.5773e-01],\n",
      "        [-1.3704e+00, -4.8801e-01,  1.2777e+00],\n",
      "        [ 1.7469e+00,  7.2037e-01,  4.7745e-01],\n",
      "        [-2.9629e-01, -1.0240e+00,  1.0654e+00],\n",
      "        [-1.3615e+00,  1.1337e-01,  1.3800e+00]]) tensor([[ 15.4548],\n",
      "        [ -0.2631],\n",
      "        [ 11.8877],\n",
      "        [ 16.0653],\n",
      "        [-10.8051],\n",
      "        [  2.0329],\n",
      "        [ 13.3406],\n",
      "        [  9.0542],\n",
      "        [ 15.6031],\n",
      "        [ 12.1184]])\n",
      "tensor([[-0.7346,  2.2316,  1.3863],\n",
      "        [ 0.1772, -0.5206,  1.6154],\n",
      "        [-1.1286,  0.1461, -0.3138],\n",
      "        [-0.9132,  0.1593,  1.2713],\n",
      "        [-0.2944,  0.4562,  0.0229],\n",
      "        [-1.0843,  0.4302, -0.0899],\n",
      "        [ 0.3436,  1.0614,  1.1179],\n",
      "        [ 0.2494,  0.0501,  0.4710],\n",
      "        [-0.0826,  2.4583,  0.7278],\n",
      "        [-1.1447, -0.5780, -1.3182]]) tensor([[ 6.2171],\n",
      "        [19.2483],\n",
      "        [-1.0621],\n",
      "        [11.9860],\n",
      "        [ 2.2519],\n",
      "        [-0.1535],\n",
      "        [10.2229],\n",
      "        [ 8.3051],\n",
      "        [ 1.4944],\n",
      "        [-6.6806]])\n",
      "tensor([[-1.4557,  0.7716,  0.4476],\n",
      "        [ 1.5996, -0.9380,  1.0539],\n",
      "        [-0.7822, -0.8946, -0.3377],\n",
      "        [ 1.9988,  1.4660, -0.0820],\n",
      "        [-2.1675, -0.3226,  0.3644],\n",
      "        [ 0.4348, -0.6489,  1.2002],\n",
      "        [-1.1335, -0.6468, -1.5941],\n",
      "        [-0.2155, -0.1919,  0.3992],\n",
      "        [-0.8619,  1.2503,  1.8594],\n",
      "        [ 1.1005, -1.1596, -2.8019]]) tensor([[  2.2491],\n",
      "        [ 19.0181],\n",
      "        [  2.9707],\n",
      "        [  2.5661],\n",
      "        [  3.8816],\n",
      "        [ 16.8845],\n",
      "        [ -8.6439],\n",
      "        [  7.6161],\n",
      "        [ 13.0849],\n",
      "        [-12.0662]])\n",
      "tensor([[ 0.5384,  0.2976, -1.2682],\n",
      "        [-1.0645,  0.2661,  1.1458],\n",
      "        [-0.5862,  0.1061,  1.4697],\n",
      "        [ 0.4342,  1.2952,  1.0420],\n",
      "        [-0.5985,  0.2378,  0.4733],\n",
      "        [-1.7695, -1.0164, -0.6592],\n",
      "        [ 0.5181,  0.3469,  1.6882],\n",
      "        [ 1.4304,  1.0067,  0.5823],\n",
      "        [-0.6203, -1.6258, -0.2955],\n",
      "        [-0.8822, -0.8384, -0.8438]]) tensor([[-5.8857],\n",
      "        [10.3329],\n",
      "        [14.4234],\n",
      "        [ 9.0046],\n",
      "        [ 5.9823],\n",
      "        [-1.1649],\n",
      "        [17.5784],\n",
      "        [ 8.2884],\n",
      "        [ 6.1214],\n",
      "        [-1.4644]])\n",
      "tensor([[ 0.6015,  0.4265,  2.0681],\n",
      "        [-1.9608,  0.0510,  0.2560],\n",
      "        [ 0.1869, -0.0146,  0.9628],\n",
      "        [-0.0574,  1.6413,  1.4385],\n",
      "        [-0.0371, -0.4011,  2.4105],\n",
      "        [ 0.5087, -0.1716,  0.6358],\n",
      "        [-0.8271, -1.0670, -0.8951],\n",
      "        [ 0.3096, -0.1292, -1.5617],\n",
      "        [-0.0840, -0.6615, -1.2519],\n",
      "        [-0.1426,  1.9617,  0.9585]]) tensor([[20.4876],\n",
      "        [ 2.1589],\n",
      "        [12.3045],\n",
      "        [10.0188],\n",
      "        [24.7710],\n",
      "        [10.8721],\n",
      "        [-0.9854],\n",
      "        [-7.2435],\n",
      "        [-3.7212],\n",
      "        [ 4.9165]])\n",
      "tensor([[-0.9123,  0.7940, -0.2133],\n",
      "        [ 0.1472, -0.7646, -0.0239],\n",
      "        [-0.2083, -0.4534,  0.4332],\n",
      "        [-1.1923,  2.3460, -0.0193],\n",
      "        [ 1.4336, -1.2695, -0.7018],\n",
      "        [-0.8177,  1.1173,  0.4315],\n",
      "        [-0.6247,  1.6034,  1.5134],\n",
      "        [ 0.5480,  0.7317, -1.7344],\n",
      "        [-2.1180,  1.1637,  0.3789],\n",
      "        [-0.5238, -1.2175, -2.2584]]) tensor([[ -2.0320],\n",
      "        [  6.9204],\n",
      "        [  8.7908],\n",
      "        [ -6.3114],\n",
      "        [  5.7605],\n",
      "        [  2.2159],\n",
      "        [  9.6266],\n",
      "        [-11.0653],\n",
      "        [ -0.9570],\n",
      "        [-10.7842]])\n",
      "tensor([[ 0.8288,  0.0119,  1.4708],\n",
      "        [ 1.4938, -0.6940,  0.9277],\n",
      "        [-2.4067, -0.3105,  0.6052],\n",
      "        [-0.6599,  0.1305, -0.6354],\n",
      "        [-1.9399,  0.6306, -0.4909],\n",
      "        [-0.8952, -1.5353, -0.5353],\n",
      "        [ 0.6697, -0.3736, -0.9999],\n",
      "        [ 1.0559, -0.2162,  0.0869],\n",
      "        [-0.6120,  0.7743,  0.6352],\n",
      "        [ 1.2557, -1.4929, -2.6695]]) tensor([[17.5829],\n",
      "        [16.9805],\n",
      "        [ 5.2976],\n",
      "        [-2.6576],\n",
      "        [-5.7506],\n",
      "        [ 3.3452],\n",
      "        [-1.1819],\n",
      "        [ 7.7403],\n",
      "        [ 5.4223],\n",
      "        [-9.5554]])\n",
      "tensor([[-1.1840, -0.1044,  0.2085],\n",
      "        [ 1.2721, -0.9868,  0.4793],\n",
      "        [ 0.5369, -0.7062, -0.1738],\n",
      "        [-0.9916, -0.3728, -1.1678],\n",
      "        [-1.3558, -0.5259,  0.5249],\n",
      "        [-1.0399, -0.2457,  0.5930],\n",
      "        [-0.5664, -0.0102,  0.4224],\n",
      "        [-0.0330, -2.3939, -0.2852],\n",
      "        [-0.3306,  0.4144,  0.3721],\n",
      "        [-1.6545,  0.1662, -0.3019]]) tensor([[ 3.8613],\n",
      "        [13.9196],\n",
      "        [ 6.2859],\n",
      "        [-5.8623],\n",
      "        [ 7.4703],\n",
      "        [ 7.6970],\n",
      "        [ 6.4818],\n",
      "        [ 9.9948],\n",
      "        [ 5.0862],\n",
      "        [-2.0743]])\n",
      "tensor([[-0.0429, -1.3380, -1.2291],\n",
      "        [-0.1761, -1.4937, -0.7163],\n",
      "        [-0.6657,  0.4794,  0.7602],\n",
      "        [ 0.0932, -1.0845, -0.1542],\n",
      "        [-1.4760, -2.0888, -1.0024],\n",
      "        [ 0.2258, -0.9646, -1.3970],\n",
      "        [ 0.7045,  1.5546,  0.4560],\n",
      "        [ 0.0983, -0.4456, -0.3455],\n",
      "        [ 0.0406,  0.3570,  1.3659],\n",
      "        [-1.8005,  1.8916,  0.1285]]) tensor([[-1.1752],\n",
      "        [ 3.2121],\n",
      "        [ 7.3195],\n",
      "        [ 6.8496],\n",
      "        [ 0.3343],\n",
      "        [-3.2480],\n",
      "        [ 3.9812],\n",
      "        [ 3.1587],\n",
      "        [13.9911],\n",
      "        [-4.7996]])\n",
      "tensor([[-0.4287, -1.0515,  1.5868],\n",
      "        [-0.6831, -1.3444,  0.7226],\n",
      "        [-0.9312,  0.1243, -2.5361],\n",
      "        [-0.8179, -0.1450,  0.8819],\n",
      "        [ 1.3584,  0.7599,  1.0950],\n",
      "        [-1.0282,  0.1608,  1.6084],\n",
      "        [ 0.1204, -1.4182, -0.8058],\n",
      "        [ 0.3902, -0.0726,  0.8962],\n",
      "        [-0.3914,  0.4293, -0.3035],\n",
      "        [ 0.2206,  0.0356,  0.9676]]) tensor([[ 19.6037],\n",
      "        [ 13.1823],\n",
      "        [-18.3699],\n",
      "        [ 10.1248],\n",
      "        [ 13.1124],\n",
      "        [ 14.4471],\n",
      "        [  2.8298],\n",
      "        [ 12.4058],\n",
      "        [ -0.4827],\n",
      "        [ 12.2632]])\n",
      "tensor([[-0.2509,  0.5528,  0.7334],\n",
      "        [-0.1186, -0.4357, -2.3129],\n",
      "        [-0.6067,  0.4742, -0.2057],\n",
      "        [ 0.3560,  1.2507,  1.4536],\n",
      "        [-0.2948, -0.7009,  0.0987],\n",
      "        [ 1.2678, -0.4494, -0.7104],\n",
      "        [ 1.2031,  0.1176,  1.3345],\n",
      "        [-0.1468, -0.1198, -0.5905],\n",
      "        [ 0.6995, -0.6604, -0.2339],\n",
      "        [-0.3794, -0.4446,  0.0324]]) tensor([[  7.6824],\n",
      "        [-13.0645],\n",
      "        [ -0.2664],\n",
      "        [ 12.2870],\n",
      "        [  6.7911],\n",
      "        [  2.5659],\n",
      "        [ 16.8766],\n",
      "        [ -0.4094],\n",
      "        [  5.9791],\n",
      "        [  5.2056]])\n",
      "tensor([[ 0.0637,  0.9555,  0.8647],\n",
      "        [-0.0395, -0.2527,  1.5706],\n",
      "        [-1.1948, -0.1912, -0.7126],\n",
      "        [ 0.2533, -0.2445, -0.1563],\n",
      "        [ 0.6025, -0.1846,  0.1749],\n",
      "        [-1.0694,  1.4796,  0.3807],\n",
      "        [-2.2584,  0.8198,  0.6665],\n",
      "        [-0.0724, -0.3815,  0.5691],\n",
      "        [ 0.1155, -0.7425,  1.1164],\n",
      "        [ 0.4303,  0.3648, -1.9091]]) tensor([[  7.9938],\n",
      "        [ 17.5319],\n",
      "        [ -3.2405],\n",
      "        [  4.2830],\n",
      "        [  7.4568],\n",
      "        [  0.0972],\n",
      "        [  2.2279],\n",
      "        [  9.9170],\n",
      "        [ 15.8796],\n",
      "        [-11.4487]])\n",
      "tensor([[-0.4047,  0.8541,  0.1564],\n",
      "        [ 2.1414, -0.2648, -0.6813],\n",
      "        [-0.7074,  1.1390, -0.6223],\n",
      "        [-1.1534, -0.7581, -0.7470],\n",
      "        [-0.1900,  0.7819, -0.6189],\n",
      "        [-0.7098,  0.0484,  1.5891],\n",
      "        [-1.0647,  2.4139,  2.5714],\n",
      "        [ 0.5447, -0.3679, -0.8466],\n",
      "        [-1.5126,  1.2967,  0.5601],\n",
      "        [-0.7663, -2.7803, -0.7306]]) tensor([[ 1.7501],\n",
      "        [ 3.9263],\n",
      "        [-6.0586],\n",
      "        [-1.5294],\n",
      "        [-3.7915],\n",
      "        [15.3264],\n",
      "        [14.4185],\n",
      "        [-0.2370],\n",
      "        [ 1.2632],\n",
      "        [ 6.2821]])\n",
      "tensor([[-1.1384, -1.8007, -0.7034],\n",
      "        [ 0.7621, -0.2465, -0.6547],\n",
      "        [-0.3193,  0.4677,  0.2437],\n",
      "        [-0.1642,  0.3419, -0.0503],\n",
      "        [ 1.4810, -1.1702,  0.2158],\n",
      "        [-0.1971, -1.1044, -0.3540],\n",
      "        [ 0.9142, -0.7095,  0.7310],\n",
      "        [-0.6094,  0.5727,  0.7100],\n",
      "        [ 1.8813,  0.0274,  0.6926],\n",
      "        [ 0.6984, -1.1070, -0.7711]]) tensor([[ 2.4130],\n",
      "        [ 1.3092],\n",
      "        [ 3.9259],\n",
      "        [ 2.3144],\n",
      "        [12.8764],\n",
      "        [ 4.7433],\n",
      "        [14.2932],\n",
      "        [ 6.7127],\n",
      "        [13.3972],\n",
      "        [ 3.1917]])\n",
      "tensor([[ 1.2876, -0.4435, -0.8388],\n",
      "        [ 0.9830, -0.3548,  0.2992],\n",
      "        [-0.4081,  1.4496,  0.2930],\n",
      "        [-1.4879,  0.0875,  0.5738],\n",
      "        [-0.3515,  1.5633, -0.4104],\n",
      "        [-1.6272,  0.9667,  0.6200],\n",
      "        [-0.3656,  0.1164,  0.0806],\n",
      "        [-0.1476, -0.3553, -1.2258],\n",
      "        [-3.0419, -0.5725,  0.3231],\n",
      "        [ 0.3460, -0.2464, -0.3390]]) tensor([[ 1.5833],\n",
      "        [ 9.7654],\n",
      "        [ 0.8140],\n",
      "        [ 5.5400],\n",
      "        [-5.0861],\n",
      "        [ 2.6139],\n",
      "        [ 3.7202],\n",
      "        [-4.6904],\n",
      "        [ 2.6502],\n",
      "        [ 3.0353]])\n",
      "tensor([[ 5.8490e-04, -1.7101e+00, -8.5858e-02],\n",
      "        [-2.1055e+00, -2.4145e-01,  1.3545e+00],\n",
      "        [-7.9333e-01, -1.0587e+00,  2.6945e+00],\n",
      "        [ 1.8524e-01, -1.0019e-01,  5.2422e-01],\n",
      "        [-9.6360e-01, -1.2454e-01, -9.6343e-02],\n",
      "        [-5.1510e-03,  4.0147e-01,  9.0258e-01],\n",
      "        [ 9.5818e-01,  1.4259e-01, -1.3131e-01],\n",
      "        [-1.0893e+00, -3.9959e-01, -6.1155e-01],\n",
      "        [-1.8723e+00,  9.5141e-01,  7.9847e-01],\n",
      "        [-3.7345e-01, -8.5919e-01, -2.2240e+00]]) tensor([[  9.3306],\n",
      "        [ 11.6395],\n",
      "        [ 27.7588],\n",
      "        [  9.1016],\n",
      "        [  1.9359],\n",
      "        [ 10.0535],\n",
      "        [  4.5886],\n",
      "        [ -1.4964],\n",
      "        [  3.6027],\n",
      "        [-11.4222]])\n",
      "tensor([[ 2.2450,  1.5468,  0.0515],\n",
      "        [ 1.5952, -0.8597, -0.9905],\n",
      "        [ 0.8008,  0.0192,  0.5114],\n",
      "        [-0.3043, -0.7317, -0.0999],\n",
      "        [-0.0835, -0.5211,  1.8366],\n",
      "        [ 0.4598, -0.2360,  0.6652],\n",
      "        [ 0.8500, -2.0362,  0.1138],\n",
      "        [-0.1691, -0.2734,  0.3874],\n",
      "        [-0.6521, -0.9910,  0.3111],\n",
      "        [-0.4683, -0.2815, -0.8198]]) tensor([[ 3.8444],\n",
      "        [ 2.4136],\n",
      "        [ 9.8129],\n",
      "        [ 5.2502],\n",
      "        [20.4946],\n",
      "        [11.2377],\n",
      "        [13.7238],\n",
      "        [ 7.8981],\n",
      "        [ 8.7386],\n",
      "        [-2.3214]])\n",
      "tensor([[ 7.5542e-01,  2.4922e-01,  1.2086e+00],\n",
      "        [ 2.4825e-03,  9.2762e-01,  1.0170e+00],\n",
      "        [-2.5808e-01, -4.4318e-01, -1.7971e+00],\n",
      "        [-5.9316e-01, -1.7038e-01, -1.2256e+00],\n",
      "        [ 1.9226e+00, -5.8302e-02, -7.6841e-01],\n",
      "        [ 7.0318e-01,  2.0907e+00, -1.0766e+00],\n",
      "        [-1.0012e+00,  8.5021e-01, -7.3232e-02],\n",
      "        [-4.8135e-01, -1.8187e-01,  3.8130e-01],\n",
      "        [ 4.4068e-01, -6.4159e-01,  2.3159e-01],\n",
      "        [ 2.7041e+00, -5.5763e-01,  1.9745e+00]]) tensor([[ 14.5409],\n",
      "        [  9.2077],\n",
      "        [ -9.1954],\n",
      "        [ -6.2139],\n",
      "        [  2.1030],\n",
      "        [-10.1216],\n",
      "        [ -1.2825],\n",
      "        [  6.9069],\n",
      "        [  9.1095],\n",
      "        [ 27.3003]])\n",
      "tensor([[-0.0195, -0.4283,  1.0456],\n",
      "        [-0.3837, -0.1753,  1.4855],\n",
      "        [-0.3244, -1.0369, -0.9441],\n",
      "        [-0.4661,  0.2242, -1.0702],\n",
      "        [ 0.1224, -0.9048, -1.1185],\n",
      "        [-2.0271, -0.7312,  0.6901],\n",
      "        [ 0.3936, -1.1118, -0.7773],\n",
      "        [ 0.6034, -1.1041, -0.5871],\n",
      "        [ 0.7895, -0.9869,  1.7507],\n",
      "        [ 1.9826,  0.3625, -1.5953]]) tensor([[13.9866],\n",
      "        [15.9087],\n",
      "        [-0.4855],\n",
      "        [-6.0347],\n",
      "        [-1.4180],\n",
      "        [ 8.1509],\n",
      "        [ 2.5377],\n",
      "        [ 4.4654],\n",
      "        [23.1270],\n",
      "        [-5.8374]])\n",
      "tensor([[-0.0026,  0.2194, -1.2718],\n",
      "        [ 0.4707, -0.8697,  1.8624],\n",
      "        [-0.1564, -0.6858,  0.5211],\n",
      "        [-1.5075, -0.6363,  0.3202],\n",
      "        [-0.8426, -0.2772,  2.4178],\n",
      "        [-0.6733, -1.9436,  0.7270],\n",
      "        [-1.4194, -0.2539, -0.6016],\n",
      "        [-0.5195, -0.4871,  2.1789],\n",
      "        [ 1.4578,  0.5553,  0.9995],\n",
      "        [-0.9894, -0.0106, -0.9349]]) tensor([[-6.7347],\n",
      "        [22.9900],\n",
      "        [10.3875],\n",
      "        [ 5.9074],\n",
      "        [22.8160],\n",
      "        [15.2754],\n",
      "        [-2.5873],\n",
      "        [22.2411],\n",
      "        [13.2381],\n",
      "        [-5.2122]])\n",
      "tensor([[ 0.7107, -0.8830, -0.0138],\n",
      "        [ 1.2686,  1.1020,  0.0142],\n",
      "        [-0.4131, -1.3635,  0.4767],\n",
      "        [-1.3094, -0.6508, -2.2014],\n",
      "        [-0.7398, -0.9228, -0.0154],\n",
      "        [-1.8141, -0.6128, -0.6721],\n",
      "        [-1.5086,  0.9417, -1.3663],\n",
      "        [-2.3768, -1.0600, -1.4407],\n",
      "        [-0.0818, -0.8098, -0.0622],\n",
      "        [ 1.7185, -0.2307, -1.7303]]) tensor([[  8.5011],\n",
      "        [  3.0919],\n",
      "        [ 11.8240],\n",
      "        [-13.8117],\n",
      "        [  5.7387],\n",
      "        [ -2.7219],\n",
      "        [-12.9538],\n",
      "        [ -8.4739],\n",
      "        [  6.2858],\n",
      "        [ -5.4091]])\n",
      "tensor([[-0.3627, -0.7889, -0.2781],\n",
      "        [ 0.3623, -0.2260, -1.9572],\n",
      "        [ 0.5169,  0.1527,  0.0618],\n",
      "        [-0.1449, -0.6518,  0.2778],\n",
      "        [-0.8075, -1.2031,  0.2563],\n",
      "        [-0.6195, -1.3214, -0.7163],\n",
      "        [ 0.2357,  1.0681,  0.5348],\n",
      "        [ 1.0327, -0.2838,  0.6717],\n",
      "        [ 0.8293, -0.0077, -1.1041],\n",
      "        [-0.6747,  1.2690, -0.3365]]) tensor([[ 3.9257],\n",
      "        [-9.9643],\n",
      "        [ 5.2242],\n",
      "        [ 8.3619],\n",
      "        [ 8.7598],\n",
      "        [ 1.7179],\n",
      "        [ 5.3538],\n",
      "        [12.6069],\n",
      "        [-2.9623],\n",
      "        [-4.1435]])\n",
      "tensor([[-0.8229,  1.2191,  0.9396],\n",
      "        [-1.0738,  0.6730,  1.2564],\n",
      "        [ 1.1382, -1.2100, -2.1938],\n",
      "        [-0.8113,  1.4890,  0.3087],\n",
      "        [-1.0292,  0.1944,  0.8901],\n",
      "        [ 0.3270, -0.1537,  0.0325],\n",
      "        [-0.7123, -0.5487,  0.6221],\n",
      "        [ 0.9147,  0.9078, -0.9660],\n",
      "        [-2.0977, -1.0385,  0.1553],\n",
      "        [ 0.9085,  1.0364, -0.2130]]) tensor([[ 5.9210],\n",
      "        [ 9.8150],\n",
      "        [-6.9614],\n",
      "        [-0.0242],\n",
      "        [ 8.5911],\n",
      "        [ 5.6407],\n",
      "        [ 9.6203],\n",
      "        [-4.7865],\n",
      "        [ 4.7831],\n",
      "        [ 0.7773]])\n",
      "tensor([[ 0.7678,  0.7452,  0.0750],\n",
      "        [-0.1140, -1.9913, -0.3476],\n",
      "        [-2.8362, -0.1732, -0.1891],\n",
      "        [-0.6643, -0.3045,  1.0186],\n",
      "        [ 1.1135, -0.6703, -0.3019],\n",
      "        [ 0.0836, -0.1347, -0.1848],\n",
      "        [ 0.5571, -1.7937,  0.0985],\n",
      "        [-0.2228, -0.0589, -2.9727],\n",
      "        [ 0.4507, -0.6617, -0.8034],\n",
      "        [-0.6911,  0.4576, -0.3383]]) tensor([[  3.7777],\n",
      "        [  7.9667],\n",
      "        [ -2.3967],\n",
      "        [ 12.0521],\n",
      "        [  6.2885],\n",
      "        [  3.3456],\n",
      "        [ 12.2121],\n",
      "        [-19.8362],\n",
      "        [  0.9200],\n",
      "        [ -1.4532]])\n",
      "tensor([[ 0.5851, -0.2099,  0.2435],\n",
      "        [-1.5283,  0.8705, -0.2198],\n",
      "        [-0.0970,  1.3590,  1.6752],\n",
      "        [-0.7315, -0.5952,  0.8199],\n",
      "        [-0.3157,  0.4606,  0.1937],\n",
      "        [ 0.9757,  1.0800,  0.9089],\n",
      "        [-1.2072,  0.3574,  0.0945],\n",
      "        [-0.8306,  1.4800, -0.1332],\n",
      "        [ 0.4866, -1.0282,  0.5558],\n",
      "        [ 1.1437, -0.5266, -1.4846]]) tensor([[ 8.0385],\n",
      "        [-3.5721],\n",
      "        [12.7913],\n",
      "        [11.3030],\n",
      "        [ 3.5537],\n",
      "        [ 9.7252],\n",
      "        [ 1.3295],\n",
      "        [-3.5573],\n",
      "        [13.1245],\n",
      "        [-3.5953]])\n",
      "tensor([[-1.6342,  0.6155, -1.1606],\n",
      "        [ 0.8284, -1.8045,  0.2471],\n",
      "        [ 0.5624, -0.2607,  1.0468],\n",
      "        [-2.4674, -1.1637,  0.6043],\n",
      "        [ 1.3198,  0.1282,  0.6429],\n",
      "        [ 0.5258, -0.7709, -1.2453],\n",
      "        [-0.4742, -0.6537,  2.2024],\n",
      "        [ 0.2416, -1.8770, -0.3502],\n",
      "        [-1.0125, -1.1518,  0.2320],\n",
      "        [ 1.8493, -1.0156, -0.6740]]) tensor([[-10.4500],\n",
      "        [ 13.9530],\n",
      "        [ 14.5819],\n",
      "        [  8.0398],\n",
      "        [ 11.5515],\n",
      "        [ -2.0728],\n",
      "        [ 23.0814],\n",
      "        [  8.2554],\n",
      "        [  7.9309],\n",
      "        [  5.9665]])\n",
      "tensor([[ 1.6194,  0.0724, -1.2996],\n",
      "        [-0.4149, -0.1029,  0.3311],\n",
      "        [ 0.1736,  0.5772,  1.7547],\n",
      "        [ 1.4521,  0.3786, -1.7527],\n",
      "        [-1.6284, -0.8352, -0.4954],\n",
      "        [ 2.0837,  1.0308,  0.5821],\n",
      "        [-0.0867,  1.6088, -0.3956],\n",
      "        [-0.4928, -0.1474, -0.3900],\n",
      "        [-0.3535, -1.0530, -0.2511],\n",
      "        [ 1.3949,  1.4783, -0.2902]]) tensor([[-3.1926],\n",
      "        [ 6.3695],\n",
      "        [16.6276],\n",
      "        [-8.2063],\n",
      "        [-0.1893],\n",
      "        [ 9.5144],\n",
      "        [-4.6239],\n",
      "        [ 0.6038],\n",
      "        [ 5.0582],\n",
      "        [-0.3579]])\n",
      "tensor([[-3.8375e-01,  1.1288e+00, -1.5657e+00],\n",
      "        [-2.1110e-01, -1.0304e+00, -7.1466e-01],\n",
      "        [-9.4727e-01, -9.8433e-02, -8.2606e-01],\n",
      "        [-2.6887e-01, -1.2984e+00, -1.2379e+00],\n",
      "        [-9.5756e-01, -1.2810e-03, -2.4714e-01],\n",
      "        [-8.7920e-01,  7.3020e-01, -1.7431e+00],\n",
      "        [ 3.0207e+00, -7.9059e-01, -9.5463e-01],\n",
      "        [-1.3361e+00,  4.4014e-01, -1.4849e-01],\n",
      "        [-3.8489e-01,  1.9593e-01, -9.5708e-01],\n",
      "        [-3.8739e-01,  3.5684e-01,  7.5488e-02]]) tensor([[-12.9355],\n",
      "        [  1.5739],\n",
      "        [ -3.9558],\n",
      "        [ -1.8293],\n",
      "        [  0.3050],\n",
      "        [-13.9723],\n",
      "        [  5.2899],\n",
      "        [ -1.1690],\n",
      "        [ -4.8961],\n",
      "        [  2.8244]])\n",
      "tensor([[ 0.8630,  1.9825, -0.8582],\n",
      "        [ 0.4567, -2.6020, -0.1510],\n",
      "        [-0.1274,  1.7780, -0.3435],\n",
      "        [-0.6882, -0.6967,  0.9150],\n",
      "        [-0.4101,  1.0817,  0.2343],\n",
      "        [-1.3742, -0.9370,  0.4412],\n",
      "        [-0.4546, -0.7635, -1.5435],\n",
      "        [ 0.7985,  0.2472, -0.9533],\n",
      "        [ 0.0429,  0.1112,  0.1073],\n",
      "        [-0.8700, -0.4843, -0.4462]]) tensor([[-7.6775],\n",
      "        [12.7552],\n",
      "        [-4.8487],\n",
      "        [12.5073],\n",
      "        [ 1.5703],\n",
      "        [ 8.1576],\n",
      "        [-6.4629],\n",
      "        [-2.6627],\n",
      "        [ 4.7405],\n",
      "        [ 0.5405]])\n",
      "tensor([[-0.0965,  0.1832, -2.4420],\n",
      "        [-0.3330, -0.9915,  0.2304],\n",
      "        [-0.5471,  1.8155,  1.8667],\n",
      "        [-0.7687,  1.4894, -1.0890],\n",
      "        [-0.3558, -1.9699, -0.3038],\n",
      "        [-1.0644,  1.5036, -0.6524],\n",
      "        [-0.4679,  0.5420, -0.3888],\n",
      "        [ 0.3714,  0.0386, -0.0444],\n",
      "        [-0.9335, -0.5745, -0.0233],\n",
      "        [-1.1873, -0.0163, -0.7301]]) tensor([[-16.1497],\n",
      "        [  8.7492],\n",
      "        [ 11.8677],\n",
      "        [-11.1274],\n",
      "        [  7.7569],\n",
      "        [ -8.2721],\n",
      "        [ -1.6885],\n",
      "        [  4.4612],\n",
      "        [  4.0872],\n",
      "        [ -3.9580]])\n",
      "tensor([[ 0.6647, -0.3757,  0.5384],\n",
      "        [-1.6809,  0.1728,  0.9434],\n",
      "        [-1.2153,  1.7381,  0.1913],\n",
      "        [-1.0803,  0.6017, -0.1431],\n",
      "        [ 0.4330,  0.0955,  0.4198],\n",
      "        [-1.4286, -1.4754,  0.1529],\n",
      "        [ 0.3475,  1.6447,  1.5188],\n",
      "        [-0.9650, -0.9567, -0.0065],\n",
      "        [-0.0782,  0.1703, -0.5905],\n",
      "        [ 1.5020,  0.3749,  1.1562]]) tensor([[11.1349],\n",
      "        [ 7.8064],\n",
      "        [-2.5995],\n",
      "        [-1.1386],\n",
      "        [ 8.0957],\n",
      "        [ 7.5792],\n",
      "        [11.4427],\n",
      "        [ 5.4745],\n",
      "        [-1.2604],\n",
      "        [15.1767]])\n",
      "tensor([[-1.9181, -1.0973,  0.9480],\n",
      "        [-0.7305, -0.4470, -0.8150],\n",
      "        [-0.1584,  1.3733,  0.7763],\n",
      "        [-1.6823,  1.3853,  0.3085],\n",
      "        [-1.0241,  0.4386, -0.6645],\n",
      "        [ 0.5151,  1.0274,  0.4273],\n",
      "        [-0.2103,  1.6232,  0.0479],\n",
      "        [-0.5485, -1.8946, -0.4258],\n",
      "        [-1.0137,  1.4076,  1.2818],\n",
      "        [-1.6385, -1.2969,  0.7957]]) tensor([[11.6754],\n",
      "        [-2.2584],\n",
      "        [ 5.4357],\n",
      "        [-1.4119],\n",
      "        [-4.6690],\n",
      "        [ 5.1462],\n",
      "        [-1.3636],\n",
      "        [ 6.1252],\n",
      "        [ 7.6176],\n",
      "        [11.7080]])\n",
      "tensor([[-1.3274,  0.5009,  1.2001],\n",
      "        [ 0.1438, -0.1762,  1.9818],\n",
      "        [ 0.5403, -0.3681,  1.3613],\n",
      "        [-0.1240, -1.2716, -0.3126],\n",
      "        [-0.0895, -0.1733, -1.2110],\n",
      "        [-0.2098,  0.1140, -0.6935],\n",
      "        [-1.0612,  1.4590, -1.2231],\n",
      "        [ 0.0116, -0.1396, -0.6942],\n",
      "        [-1.1700,  0.0079, -1.2027],\n",
      "        [-1.4159, -0.3834, -1.5050]]) tensor([[  9.4479],\n",
      "        [ 20.9214],\n",
      "        [ 17.4292],\n",
      "        [  5.7858],\n",
      "        [ -5.0693],\n",
      "        [ -2.1755],\n",
      "        [-12.6645],\n",
      "        [ -0.8556],\n",
      "        [ -7.7826],\n",
      "        [ -9.3653]])\n",
      "tensor([[ 0.6301, -0.2066, -0.8188],\n",
      "        [ 0.3929, -1.0934,  0.9171],\n",
      "        [ 0.5664, -1.1062,  2.2176],\n",
      "        [-1.2687, -1.6847, -0.7607],\n",
      "        [-0.4264,  1.0771, -0.7583],\n",
      "        [-2.1029,  1.2002,  1.7610],\n",
      "        [-0.0244,  0.6464, -0.9014],\n",
      "        [-0.6036,  2.0689, -0.4678],\n",
      "        [-0.4749, -0.8230, -0.5483],\n",
      "        [-1.1360, -1.4017, -0.4835]]) tensor([[-0.3895],\n",
      "        [16.0225],\n",
      "        [26.8453],\n",
      "        [ 1.2933],\n",
      "        [-6.3646],\n",
      "        [10.0031],\n",
      "        [-5.2613],\n",
      "        [-7.7882],\n",
      "        [ 1.6558],\n",
      "        [ 2.8293]])\n",
      "tensor([[ 0.2296,  1.8124,  1.8126],\n",
      "        [ 2.5329,  0.0260,  0.3143],\n",
      "        [ 1.2400, -1.0311, -0.1978],\n",
      "        [-1.1193,  1.2649,  0.0908],\n",
      "        [ 1.6209,  0.1685,  0.7907],\n",
      "        [ 0.7862,  0.6970, -0.4496],\n",
      "        [-1.4676,  1.2253,  0.2221],\n",
      "        [-0.6475,  1.1390, -0.0269],\n",
      "        [-1.3647, -0.8628,  0.6844],\n",
      "        [ 0.3387, -0.6581, -0.8973]]) tensor([[12.9809],\n",
      "        [11.6982],\n",
      "        [ 8.6174],\n",
      "        [-1.6107],\n",
      "        [13.1887],\n",
      "        [-0.1944],\n",
      "        [-1.1225],\n",
      "        [-1.1837],\n",
      "        [ 9.8888],\n",
      "        [-0.0535]])\n",
      "tensor([[ 0.2974, -0.7291, -0.8498],\n",
      "        [ 1.4347,  1.9750,  0.6571],\n",
      "        [-0.6950, -2.1946,  0.9224],\n",
      "        [ 0.4256, -0.3278, -0.6559],\n",
      "        [ 0.5237, -1.1928,  0.6213],\n",
      "        [-0.2502, -0.4247, -1.6591],\n",
      "        [-0.6569,  0.5287,  0.2565],\n",
      "        [-1.1186,  0.2455,  0.6715],\n",
      "        [ 0.3782,  0.3269, -0.3198],\n",
      "        [ 0.0835,  1.4248,  1.2783]]) tensor([[ 0.4878],\n",
      "        [ 5.6195],\n",
      "        [17.6693],\n",
      "        [ 0.9288],\n",
      "        [14.2778],\n",
      "        [-8.1292],\n",
      "        [ 3.1365],\n",
      "        [ 6.5057],\n",
      "        [ 1.2844],\n",
      "        [ 9.7513]])\n",
      "tensor([[ 1.0017, -1.2952,  0.6431],\n",
      "        [ 1.3081, -0.2684, -0.1122],\n",
      "        [ 0.4180, -0.7710, -0.2470],\n",
      "        [-2.4392,  0.4406, -0.4313],\n",
      "        [ 0.8062,  0.3151,  0.3668],\n",
      "        [-1.1032, -0.6369, -1.1600],\n",
      "        [-0.3867,  1.8489,  0.0673],\n",
      "        [ 0.1449, -0.1465, -0.7277],\n",
      "        [-0.0530, -0.5914,  0.5547],\n",
      "        [ 1.1833,  0.1791, -1.4324]]) tensor([[15.7537],\n",
      "        [ 6.8447],\n",
      "        [ 5.6829],\n",
      "        [-5.6076],\n",
      "        [ 7.6580],\n",
      "        [-5.1135],\n",
      "        [-2.3110],\n",
      "        [-0.8454],\n",
      "        [10.5462],\n",
      "        [-5.5085]])\n",
      "tensor([[-0.5180,  0.3735, -0.4040],\n",
      "        [ 1.6765, -0.3050, -1.8199],\n",
      "        [ 0.7122,  1.2955, -0.2143],\n",
      "        [-0.1397,  0.3415,  1.2242],\n",
      "        [-0.5856,  1.2797,  0.3098],\n",
      "        [-0.4782, -0.4892,  0.4768],\n",
      "        [-0.5215, -0.2489,  0.6584],\n",
      "        [-1.0731,  2.2543,  2.0251],\n",
      "        [ 1.8253, -0.7602,  0.8978],\n",
      "        [ 1.5446,  0.8410, -0.2695]]) tensor([[-1.3527],\n",
      "        [-5.9671],\n",
      "        [-0.4882],\n",
      "        [12.5607],\n",
      "        [ 1.1463],\n",
      "        [ 8.7268],\n",
      "        [ 9.2673],\n",
      "        [10.5888],\n",
      "        [17.6255],\n",
      "        [ 2.2582]])\n",
      "tensor([[ 0.6145, -0.0135,  1.5963],\n",
      "        [ 1.0146,  1.7659,  1.1342],\n",
      "        [-1.4429,  0.0671, -0.5700],\n",
      "        [-0.1100, -1.1715, -0.4825],\n",
      "        [ 0.6540,  0.7789,  1.3744],\n",
      "        [-0.2217, -0.0199,  0.8010],\n",
      "        [-0.1680,  0.0147,  1.0644],\n",
      "        [-0.3728, -1.0428, -0.3453],\n",
      "        [ 1.1870, -1.2001, -0.3714],\n",
      "        [-0.4620,  1.0929, -0.1754]]) tensor([[18.2269],\n",
      "        [ 9.2998],\n",
      "        [-3.4718],\n",
      "        [ 4.1105],\n",
      "        [13.8446],\n",
      "        [10.2252],\n",
      "        [12.3357],\n",
      "        [ 4.2296],\n",
      "        [ 7.6910],\n",
      "        [-1.8506]])\n",
      "tensor([[ 0.1539,  0.6119,  0.6964],\n",
      "        [ 1.2464,  0.1492,  0.8994],\n",
      "        [ 0.8979,  0.6682,  1.0306],\n",
      "        [ 0.5906, -0.1517,  1.8420],\n",
      "        [ 0.5383, -0.7994,  1.5276],\n",
      "        [-0.1833, -1.0287, -2.0343],\n",
      "        [ 0.9497,  1.1195, -0.1450],\n",
      "        [-0.2452, -1.2450,  1.3162],\n",
      "        [-0.2865,  0.1276, -1.2871],\n",
      "        [-0.4064, -1.9217, -0.0651]]) tensor([[ 7.9822],\n",
      "        [13.3979],\n",
      "        [11.9603],\n",
      "        [20.6336],\n",
      "        [20.2295],\n",
      "        [-8.9416],\n",
      "        [ 1.1254],\n",
      "        [18.4836],\n",
      "        [-7.0857],\n",
      "        [ 9.4036]])\n",
      "tensor([[-0.5356,  2.0234, -0.8821],\n",
      "        [-0.5172, -0.4667,  0.3174],\n",
      "        [-0.9279, -1.3752, -1.2381],\n",
      "        [-2.0002,  1.7952, -0.6583],\n",
      "        [-1.1368,  0.6762, -0.6175],\n",
      "        [ 0.3750, -0.9197,  0.5567],\n",
      "        [-0.0716, -0.1249,  1.6969],\n",
      "        [ 1.7533, -1.0445, -0.9420],\n",
      "        [ 0.5182, -0.5561, -0.2598],\n",
      "        [-2.3428,  0.1303, -0.6198]]) tensor([[-10.7981],\n",
      "        [  7.2893],\n",
      "        [ -2.8872],\n",
      "        [-11.1787],\n",
      "        [ -5.3066],\n",
      "        [ 12.5186],\n",
      "        [ 18.0591],\n",
      "        [  3.7221],\n",
      "        [  5.0433],\n",
      "        [ -5.8874]])\n",
      "tensor([[ 0.0161, -1.0206,  1.3631],\n",
      "        [-0.6180,  0.7542,  1.2961],\n",
      "        [-0.1105,  1.0267, -0.4343],\n",
      "        [ 0.4494, -1.2456, -1.0425],\n",
      "        [-1.3056, -0.1987,  0.8365],\n",
      "        [ 1.3463,  1.5325, -1.1034],\n",
      "        [ 0.6284, -1.6585,  1.9343],\n",
      "        [-0.8610,  0.5122,  0.1495],\n",
      "        [-0.1034, -0.4745,  1.2901],\n",
      "        [ 0.3830, -1.4006,  0.8716]]) tensor([[18.6160],\n",
      "        [10.7639],\n",
      "        [-2.9936],\n",
      "        [ 0.9866],\n",
      "        [ 8.9644],\n",
      "        [-7.1480],\n",
      "        [26.5749],\n",
      "        [ 1.9287],\n",
      "        [15.9445],\n",
      "        [16.6982]])\n",
      "tensor([[-2.0478,  0.6983,  0.3734],\n",
      "        [-0.9496,  0.5585,  0.3975],\n",
      "        [-0.3877, -0.4861,  0.2872],\n",
      "        [-0.8314,  0.5523,  0.9527],\n",
      "        [ 2.2235,  0.8915, -0.2811],\n",
      "        [-1.4511, -0.0236, -0.5836],\n",
      "        [-0.7801,  0.3239, -0.6370],\n",
      "        [ 0.7107, -0.4503,  0.2929],\n",
      "        [-1.3945, -0.6339, -0.5454],\n",
      "        [ 0.7259, -0.7746, -1.6369]]) tensor([[ 0.7057],\n",
      "        [ 3.5724],\n",
      "        [ 7.3836],\n",
      "        [ 8.2586],\n",
      "        [ 3.3658],\n",
      "        [-3.2893],\n",
      "        [-3.5486],\n",
      "        [ 9.4778],\n",
      "        [-0.7768],\n",
      "        [-4.8124]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20124507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0150],\n",
      "        [-0.0072],\n",
      "        [-0.0017],\n",
      "        [ 0.0181],\n",
      "        [-0.0161],\n",
      "        [ 0.0237],\n",
      "        [-0.0078],\n",
      "        [-0.0154],\n",
      "        [ 0.0058],\n",
      "        [-0.0037]], grad_fn=<AddmmBackward0>) tensor([[-0.3895],\n",
      "        [ 8.0897],\n",
      "        [-1.3057],\n",
      "        [ 2.1030],\n",
      "        [10.1771],\n",
      "        [ 1.4505],\n",
      "        [ 1.3295],\n",
      "        [ 5.2976],\n",
      "        [ 5.6724],\n",
      "        [15.4548]])\n",
      "tensor([[-0.0250],\n",
      "        [-0.0084],\n",
      "        [-0.0066],\n",
      "        [ 0.0022],\n",
      "        [ 0.0204],\n",
      "        [-0.0006],\n",
      "        [ 0.0040],\n",
      "        [ 0.0150],\n",
      "        [ 0.0020],\n",
      "        [-0.0013]], grad_fn=<AddmmBackward0>) tensor([[  1.4944],\n",
      "        [ -6.1937],\n",
      "        [  3.5537],\n",
      "        [ 11.1678],\n",
      "        [ -5.6819],\n",
      "        [  8.3619],\n",
      "        [  8.1229],\n",
      "        [-18.5283],\n",
      "        [  4.3992],\n",
      "        [  3.6172]])\n",
      "tensor([[ 0.0029],\n",
      "        [-0.0060],\n",
      "        [-0.0235],\n",
      "        [ 0.0039],\n",
      "        [-0.0224],\n",
      "        [-0.0015],\n",
      "        [ 0.0015],\n",
      "        [ 0.0168],\n",
      "        [ 0.0085],\n",
      "        [-0.0055]], grad_fn=<AddmmBackward0>) tensor([[  2.1722],\n",
      "        [ 11.9224],\n",
      "        [ 25.1375],\n",
      "        [  1.2844],\n",
      "        [ 26.8453],\n",
      "        [ -9.7200],\n",
      "        [  9.7654],\n",
      "        [-13.9723],\n",
      "        [-10.3533],\n",
      "        [  8.7268]])\n",
      "tensor([[ 0.0184],\n",
      "        [-0.0100],\n",
      "        [ 0.0048],\n",
      "        [-0.0077],\n",
      "        [ 0.0282],\n",
      "        [-0.0091],\n",
      "        [-0.0280],\n",
      "        [ 0.0496],\n",
      "        [ 0.0410],\n",
      "        [-0.0024]], grad_fn=<AddmmBackward0>) tensor([[ -9.5076],\n",
      "        [ 11.0782],\n",
      "        [  4.1583],\n",
      "        [ -3.3824],\n",
      "        [ -2.9516],\n",
      "        [ 21.1225],\n",
      "        [ 18.8951],\n",
      "        [-14.6615],\n",
      "        [-19.8362],\n",
      "        [ -5.0026]])\n",
      "tensor([[ 0.0130],\n",
      "        [ 0.0012],\n",
      "        [ 0.0021],\n",
      "        [ 0.0050],\n",
      "        [-0.0061],\n",
      "        [-0.0157],\n",
      "        [-0.0055],\n",
      "        [ 0.0020],\n",
      "        [-0.0123],\n",
      "        [ 0.0077]], grad_fn=<AddmmBackward0>) tensor([[ 1.8053],\n",
      "        [-5.0767],\n",
      "        [-1.3255],\n",
      "        [-0.1944],\n",
      "        [ 9.2119],\n",
      "        [23.1270],\n",
      "        [ 6.3695],\n",
      "        [10.4912],\n",
      "        [-0.9637],\n",
      "        [-6.2974]])\n",
      "tensor([[-0.0313],\n",
      "        [ 0.0068],\n",
      "        [-0.0196],\n",
      "        [ 0.0045],\n",
      "        [ 0.0014],\n",
      "        [-0.0129],\n",
      "        [ 0.0121],\n",
      "        [ 0.0154],\n",
      "        [ 0.0076],\n",
      "        [-0.0137]], grad_fn=<AddmmBackward0>) tensor([[ 19.7876],\n",
      "        [ -1.6415],\n",
      "        [ -4.7996],\n",
      "        [-10.2745],\n",
      "        [  9.3693],\n",
      "        [  3.6854],\n",
      "        [  2.7159],\n",
      "        [ -1.4767],\n",
      "        [  1.1391],\n",
      "        [ -8.3722]])\n",
      "tensor([[-0.0055],\n",
      "        [ 0.0121],\n",
      "        [ 0.0227],\n",
      "        [-0.0006],\n",
      "        [ 0.0087],\n",
      "        [ 0.0027],\n",
      "        [-0.0036],\n",
      "        [ 0.0055],\n",
      "        [-0.0173],\n",
      "        [-0.0011]], grad_fn=<AddmmBackward0>) tensor([[-5.6076],\n",
      "        [-5.9973],\n",
      "        [-1.5405],\n",
      "        [-1.0621],\n",
      "        [-6.5180],\n",
      "        [ 3.1732],\n",
      "        [ 7.2893],\n",
      "        [ 2.5445],\n",
      "        [ 8.5911],\n",
      "        [15.2754]])\n",
      "tensor([[ 4.8183e-03],\n",
      "        [-1.4997e-02],\n",
      "        [ 5.3180e-03],\n",
      "        [ 8.4192e-03],\n",
      "        [-1.6671e-02],\n",
      "        [-1.3628e-02],\n",
      "        [-2.2867e-02],\n",
      "        [-3.1902e-02],\n",
      "        [ 9.6896e-05],\n",
      "        [ 2.3257e-02]], grad_fn=<AddmmBackward0>) tensor([[-1.5003],\n",
      "        [10.0535],\n",
      "        [13.2642],\n",
      "        [-0.4094],\n",
      "        [15.2936],\n",
      "        [12.1877],\n",
      "        [20.4946],\n",
      "        [24.4538],\n",
      "        [13.1245],\n",
      "        [-5.5085]])\n",
      "tensor([[ 0.0042],\n",
      "        [ 0.0067],\n",
      "        [ 0.0333],\n",
      "        [-0.0156],\n",
      "        [-0.0226],\n",
      "        [ 0.0059],\n",
      "        [-0.0188],\n",
      "        [-0.0062],\n",
      "        [ 0.0113],\n",
      "        [-0.0062]], grad_fn=<AddmmBackward0>) tensor([[-3.2293],\n",
      "        [-7.7170],\n",
      "        [-5.9671],\n",
      "        [ 3.8710],\n",
      "        [ 9.2998],\n",
      "        [-2.5771],\n",
      "        [19.2483],\n",
      "        [ 5.9074],\n",
      "        [ 7.4968],\n",
      "        [11.2377]])\n",
      "tensor([[ 0.0229],\n",
      "        [-0.0308],\n",
      "        [ 0.0078],\n",
      "        [-0.0197],\n",
      "        [ 0.0344],\n",
      "        [ 0.0064],\n",
      "        [-0.0245],\n",
      "        [ 0.0047],\n",
      "        [ 0.0096],\n",
      "        [-0.0297]], grad_fn=<AddmmBackward0>) tensor([[  0.1989],\n",
      "        [ 22.2738],\n",
      "        [  3.1587],\n",
      "        [  9.6785],\n",
      "        [-13.0645],\n",
      "        [  3.4531],\n",
      "        [ 26.0652],\n",
      "        [ -2.5873],\n",
      "        [ -0.7222],\n",
      "        [ 11.4427]])\n",
      "tensor([[ 0.0044],\n",
      "        [ 0.0220],\n",
      "        [ 0.0199],\n",
      "        [-0.0063],\n",
      "        [-0.0087],\n",
      "        [ 0.0179],\n",
      "        [ 0.0080],\n",
      "        [-0.0133],\n",
      "        [ 0.0275],\n",
      "        [-0.0032]], grad_fn=<AddmmBackward0>) tensor([[  2.2582],\n",
      "        [ -8.6439],\n",
      "        [  3.1917],\n",
      "        [  5.8033],\n",
      "        [  6.4861],\n",
      "        [ -5.8857],\n",
      "        [  8.5011],\n",
      "        [ -2.3110],\n",
      "        [-10.6988],\n",
      "        [  8.4007]])\n",
      "tensor([[-0.0149],\n",
      "        [ 0.0274],\n",
      "        [ 0.0061],\n",
      "        [ 0.0180],\n",
      "        [ 0.0176],\n",
      "        [ 0.0257],\n",
      "        [ 0.0039],\n",
      "        [ 0.0025],\n",
      "        [ 0.0119],\n",
      "        [ 0.0107]], grad_fn=<AddmmBackward0>) tensor([[ 16.8766],\n",
      "        [ -5.4909],\n",
      "        [  3.6837],\n",
      "        [ -1.6470],\n",
      "        [-22.8149],\n",
      "        [  3.7221],\n",
      "        [  7.7403],\n",
      "        [  2.9728],\n",
      "        [  2.0329],\n",
      "        [  7.1899]])\n",
      "tensor([[ 0.0205],\n",
      "        [ 0.0041],\n",
      "        [ 0.0055],\n",
      "        [-0.0352],\n",
      "        [-0.0028],\n",
      "        [-0.0050],\n",
      "        [-0.0156],\n",
      "        [ 0.0005],\n",
      "        [-0.0248],\n",
      "        [ 0.0033]], grad_fn=<AddmmBackward0>) tensor([[-16.5225],\n",
      "        [  2.2092],\n",
      "        [  7.7497],\n",
      "        [  6.2171],\n",
      "        [ -2.0743],\n",
      "        [ -6.3578],\n",
      "        [ 12.3357],\n",
      "        [ -5.3066],\n",
      "        [ 10.7639],\n",
      "        [  9.4265]])\n",
      "tensor([[-0.0159],\n",
      "        [ 0.0042],\n",
      "        [ 0.0102],\n",
      "        [ 0.0033],\n",
      "        [-0.0015],\n",
      "        [ 0.0263],\n",
      "        [-0.0031],\n",
      "        [ 0.0054],\n",
      "        [ 0.0005],\n",
      "        [-0.0229]], grad_fn=<AddmmBackward0>) tensor([[12.6396],\n",
      "        [ 5.4126],\n",
      "        [13.9530],\n",
      "        [-3.7915],\n",
      "        [ 6.6195],\n",
      "        [-5.6352],\n",
      "        [ 3.7202],\n",
      "        [ 6.9204],\n",
      "        [ 0.5936],\n",
      "        [ 6.6955]])\n",
      "tensor([[ 0.0017],\n",
      "        [-0.0301],\n",
      "        [-0.0203],\n",
      "        [-0.0278],\n",
      "        [ 0.0116],\n",
      "        [-0.0195],\n",
      "        [ 0.0023],\n",
      "        [-0.0204],\n",
      "        [ 0.0306],\n",
      "        [ 0.0017]], grad_fn=<AddmmBackward0>) tensor([[  4.6739],\n",
      "        [ 15.1322],\n",
      "        [  7.8064],\n",
      "        [  0.7159],\n",
      "        [  6.4018],\n",
      "        [  5.4357],\n",
      "        [ -2.3333],\n",
      "        [  8.7944],\n",
      "        [-12.0729],\n",
      "        [  4.4612]])\n",
      "tensor([[-0.0123],\n",
      "        [-0.0094],\n",
      "        [-0.0061],\n",
      "        [ 0.0120],\n",
      "        [-0.0002],\n",
      "        [-0.0111],\n",
      "        [-0.0053],\n",
      "        [-0.0156],\n",
      "        [-0.0099],\n",
      "        [-0.0149]], grad_fn=<AddmmBackward0>) tensor([[ 9.2215],\n",
      "        [11.7080],\n",
      "        [ 9.7221],\n",
      "        [ 1.7949],\n",
      "        [ 2.5661],\n",
      "        [18.7500],\n",
      "        [-3.6183],\n",
      "        [ 2.2159],\n",
      "        [15.6031],\n",
      "        [17.4292]])\n",
      "tensor([[ 0.0107],\n",
      "        [-0.0019],\n",
      "        [ 0.0148],\n",
      "        [-0.0073],\n",
      "        [ 0.0222],\n",
      "        [ 0.0184],\n",
      "        [ 0.0054],\n",
      "        [-0.0082],\n",
      "        [-0.0030],\n",
      "        [ 0.0088]], grad_fn=<AddmmBackward0>) tensor([[ -1.5294],\n",
      "        [ -5.9429],\n",
      "        [ -2.6627],\n",
      "        [ -0.3946],\n",
      "        [ -9.5113],\n",
      "        [-18.2261],\n",
      "        [  6.2251],\n",
      "        [  5.1208],\n",
      "        [ 13.3972],\n",
      "        [ -1.1649]])\n",
      "tensor([[ 0.0188],\n",
      "        [ 0.0128],\n",
      "        [-0.0271],\n",
      "        [ 0.0187],\n",
      "        [ 0.0016],\n",
      "        [-0.0203],\n",
      "        [ 0.0023],\n",
      "        [-0.0165],\n",
      "        [-0.0067],\n",
      "        [-0.0111]], grad_fn=<AddmmBackward0>) tensor([[  8.3694],\n",
      "        [-10.9778],\n",
      "        [ 10.8594],\n",
      "        [ -4.6904],\n",
      "        [  5.6407],\n",
      "        [  2.6139],\n",
      "        [  3.6535],\n",
      "        [ 21.4106],\n",
      "        [ -2.3967],\n",
      "        [  3.8816]])\n",
      "tensor([[-0.0318],\n",
      "        [-0.0156],\n",
      "        [-0.0013],\n",
      "        [-0.0234],\n",
      "        [ 0.0097],\n",
      "        [-0.0020],\n",
      "        [-0.0140],\n",
      "        [ 0.0071],\n",
      "        [ 0.0064],\n",
      "        [-0.0171]], grad_fn=<AddmmBackward0>) tensor([[12.7913],\n",
      "        [14.5409],\n",
      "        [11.5647],\n",
      "        [ 9.4692],\n",
      "        [-5.2191],\n",
      "        [ 4.7405],\n",
      "        [ 5.5400],\n",
      "        [-4.9342],\n",
      "        [ 8.3771],\n",
      "        [15.5417]])\n",
      "tensor([[-0.0343],\n",
      "        [ 0.0157],\n",
      "        [ 0.0272],\n",
      "        [-0.0057],\n",
      "        [ 0.0059],\n",
      "        [ 0.0022],\n",
      "        [ 0.0002],\n",
      "        [-0.0014],\n",
      "        [ 0.0045],\n",
      "        [-0.0128]], grad_fn=<AddmmBackward0>) tensor([[ 27.7588],\n",
      "        [ -1.2107],\n",
      "        [-12.2147],\n",
      "        [ -1.8506],\n",
      "        [ -0.1893],\n",
      "        [  9.1095],\n",
      "        [  3.0196],\n",
      "        [ 17.6255],\n",
      "        [  0.6038],\n",
      "        [  2.2004]])\n",
      "tensor([[-0.0089],\n",
      "        [ 0.0135],\n",
      "        [ 0.0046],\n",
      "        [-0.0197],\n",
      "        [-0.0365],\n",
      "        [ 0.0237],\n",
      "        [-0.0068],\n",
      "        [-0.0060],\n",
      "        [-0.0078],\n",
      "        [ 0.0073]], grad_fn=<AddmmBackward0>) tensor([[  5.0862],\n",
      "        [ -1.4644],\n",
      "        [-12.6645],\n",
      "        [  9.2077],\n",
      "        [ 13.0849],\n",
      "        [ -2.7845],\n",
      "        [ 12.9208],\n",
      "        [  9.9170],\n",
      "        [ -1.8046],\n",
      "        [ 13.2525]])\n",
      "tensor([[ 0.0078],\n",
      "        [ 0.0075],\n",
      "        [ 0.0017],\n",
      "        [ 0.0022],\n",
      "        [-0.0031],\n",
      "        [ 0.0136],\n",
      "        [-0.0009],\n",
      "        [-0.0033],\n",
      "        [-0.0122],\n",
      "        [ 0.0260]], grad_fn=<AddmmBackward0>) tensor([[12.4211],\n",
      "        [ 7.2173],\n",
      "        [ 0.8407],\n",
      "        [ 0.0429],\n",
      "        [ 7.3839],\n",
      "        [-7.6018],\n",
      "        [ 8.7386],\n",
      "        [19.0181],\n",
      "        [ 8.1468],\n",
      "        [-9.8997]])\n",
      "tensor([[ 0.0064],\n",
      "        [-0.0153],\n",
      "        [ 0.0096],\n",
      "        [ 0.0057],\n",
      "        [-0.0206],\n",
      "        [ 0.0262],\n",
      "        [ 0.0046],\n",
      "        [ 0.0163],\n",
      "        [ 0.0220],\n",
      "        [ 0.0055]], grad_fn=<AddmmBackward0>) tensor([[ 5.8373],\n",
      "        [ 8.9644],\n",
      "        [10.9784],\n",
      "        [-4.8967],\n",
      "        [ 9.0046],\n",
      "        [-1.8892],\n",
      "        [ 5.2502],\n",
      "        [-9.3439],\n",
      "        [-2.8872],\n",
      "        [-1.4160]])\n",
      "tensor([[-0.0233],\n",
      "        [ 0.0008],\n",
      "        [ 0.0108],\n",
      "        [-0.0129],\n",
      "        [-0.0149],\n",
      "        [-0.0049],\n",
      "        [ 0.0004],\n",
      "        [-0.0112],\n",
      "        [-0.0129],\n",
      "        [ 0.0115]], grad_fn=<AddmmBackward0>) tensor([[14.4234],\n",
      "        [ 5.2056],\n",
      "        [ 4.7433],\n",
      "        [18.6160],\n",
      "        [26.5749],\n",
      "        [10.3244],\n",
      "        [-2.8084],\n",
      "        [12.5073],\n",
      "        [ 5.3538],\n",
      "        [-4.7865]])\n",
      "tensor([[ 0.0236],\n",
      "        [-0.0027],\n",
      "        [-0.0017],\n",
      "        [-0.0224],\n",
      "        [-0.0016],\n",
      "        [-0.0034],\n",
      "        [ 0.0032],\n",
      "        [-0.0131],\n",
      "        [-0.0198],\n",
      "        [ 0.0138]], grad_fn=<AddmmBackward0>) tensor([[  0.9866],\n",
      "        [  8.2306],\n",
      "        [ 12.6027],\n",
      "        [  2.2279],\n",
      "        [-10.7981],\n",
      "        [  4.2568],\n",
      "        [  4.1232],\n",
      "        [  4.8649],\n",
      "        [  5.1584],\n",
      "        [ -8.4516]])\n",
      "tensor([[ 0.0222],\n",
      "        [-0.0043],\n",
      "        [-0.0139],\n",
      "        [ 0.0043],\n",
      "        [ 0.0066],\n",
      "        [ 0.0156],\n",
      "        [-0.0066],\n",
      "        [-0.0119],\n",
      "        [-0.0128],\n",
      "        [ 0.0163]], grad_fn=<AddmmBackward0>) tensor([[ -1.0541],\n",
      "        [  6.1438],\n",
      "        [  4.7647],\n",
      "        [  0.4799],\n",
      "        [-10.4500],\n",
      "        [  2.6823],\n",
      "        [  9.8014],\n",
      "        [ 10.2252],\n",
      "        [  8.7572],\n",
      "        [  2.4130]])\n",
      "tensor([[-0.0095],\n",
      "        [-0.0169],\n",
      "        [ 0.0313],\n",
      "        [ 0.0132],\n",
      "        [ 0.0151],\n",
      "        [ 0.0178],\n",
      "        [ 0.0125],\n",
      "        [ 0.0147],\n",
      "        [ 0.0071],\n",
      "        [ 0.0239]], grad_fn=<AddmmBackward0>) tensor([[ 14.1217],\n",
      "        [ -6.6034],\n",
      "        [-18.3699],\n",
      "        [ -3.1204],\n",
      "        [ -4.6462],\n",
      "        [  0.8413],\n",
      "        [ -7.7826],\n",
      "        [  2.5494],\n",
      "        [  2.1982],\n",
      "        [ -2.0728]])\n",
      "tensor([[-0.0129],\n",
      "        [-0.0122],\n",
      "        [ 0.0003],\n",
      "        [ 0.0024],\n",
      "        [ 0.0301],\n",
      "        [-0.0025],\n",
      "        [-0.0032],\n",
      "        [-0.0233],\n",
      "        [ 0.0300],\n",
      "        [ 0.0126]], grad_fn=<AddmmBackward0>) tensor([[ 2.6672],\n",
      "        [10.9265],\n",
      "        [14.2778],\n",
      "        [ 0.1042],\n",
      "        [-4.8124],\n",
      "        [-0.6055],\n",
      "        [ 3.1174],\n",
      "        [ 4.2076],\n",
      "        [-9.9643],\n",
      "        [ 0.9288]])\n",
      "tensor([[-0.0251],\n",
      "        [-0.0196],\n",
      "        [ 0.0245],\n",
      "        [-0.0069],\n",
      "        [ 0.0095],\n",
      "        [ 0.0160],\n",
      "        [-0.0034],\n",
      "        [-0.0048],\n",
      "        [-0.0233],\n",
      "        [ 0.0190]], grad_fn=<AddmmBackward0>) tensor([[15.3264],\n",
      "        [12.5607],\n",
      "        [ 6.4465],\n",
      "        [ 2.7388],\n",
      "        [ 5.6829],\n",
      "        [-0.2370],\n",
      "        [16.9805],\n",
      "        [ 8.0957],\n",
      "        [ 5.9210],\n",
      "        [ 1.5833]])\n",
      "tensor([[ 0.0037],\n",
      "        [-0.0077],\n",
      "        [-0.0314],\n",
      "        [-0.0031],\n",
      "        [ 0.0065],\n",
      "        [ 0.0082],\n",
      "        [ 0.0258],\n",
      "        [-0.0069],\n",
      "        [ 0.0093],\n",
      "        [ 0.0318]], grad_fn=<AddmmBackward0>) tensor([[20.8727],\n",
      "        [-3.5721],\n",
      "        [24.7710],\n",
      "        [ 7.5221],\n",
      "        [ 8.9723],\n",
      "        [-3.2039],\n",
      "        [ 2.2759],\n",
      "        [21.0907],\n",
      "        [12.8764],\n",
      "        [-5.4091]])\n",
      "tensor([[ 0.0236],\n",
      "        [-0.0071],\n",
      "        [-0.0037],\n",
      "        [-0.0142],\n",
      "        [-0.0056],\n",
      "        [ 0.0022],\n",
      "        [ 0.0004],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [ 0.0240]], grad_fn=<AddmmBackward0>) tensor([[-3.1926],\n",
      "        [-3.0204],\n",
      "        [-8.2721],\n",
      "        [ 0.8140],\n",
      "        [ 8.1576],\n",
      "        [ 5.4745],\n",
      "        [-0.3579],\n",
      "        [10.5462],\n",
      "        [ 7.8981],\n",
      "        [-1.8293]])\n",
      "tensor([[-0.0041],\n",
      "        [ 0.0017],\n",
      "        [-0.0148],\n",
      "        [ 0.0172],\n",
      "        [ 0.0242],\n",
      "        [-0.0008],\n",
      "        [ 0.0247],\n",
      "        [-0.0007],\n",
      "        [-0.0083],\n",
      "        [ 0.0153]], grad_fn=<AddmmBackward0>) tensor([[  7.2122],\n",
      "        [  2.8718],\n",
      "        [ 16.0653],\n",
      "        [  0.4792],\n",
      "        [ -3.6017],\n",
      "        [ 11.0844],\n",
      "        [  8.8806],\n",
      "        [ 20.6698],\n",
      "        [ 13.2620],\n",
      "        [-13.4459]])\n",
      "tensor([[-0.0012],\n",
      "        [ 0.0138],\n",
      "        [ 0.0046],\n",
      "        [ 0.0180],\n",
      "        [-0.0025],\n",
      "        [-0.0175],\n",
      "        [ 0.0011],\n",
      "        [-0.0299],\n",
      "        [ 0.0053],\n",
      "        [ 0.0262]], grad_fn=<AddmmBackward0>) tensor([[ 10.7204],\n",
      "        [  4.0462],\n",
      "        [ -0.5775],\n",
      "        [  7.1968],\n",
      "        [-13.2366],\n",
      "        [ 19.1411],\n",
      "        [ 11.9012],\n",
      "        [ 19.7708],\n",
      "        [  5.3139],\n",
      "        [ -5.5348]])\n",
      "tensor([[-1.3996e-02],\n",
      "        [-4.6279e-03],\n",
      "        [-9.8351e-05],\n",
      "        [ 3.3822e-02],\n",
      "        [-3.3136e-02],\n",
      "        [-4.5566e-03],\n",
      "        [ 2.6205e-03],\n",
      "        [ 2.6100e-03],\n",
      "        [-2.6105e-02],\n",
      "        [ 8.8080e-03]], grad_fn=<AddmmBackward0>) tensor([[12.1137],\n",
      "        [13.1823],\n",
      "        [10.3119],\n",
      "        [-8.9416],\n",
      "        [17.6998],\n",
      "        [ 9.0542],\n",
      "        [-9.1752],\n",
      "        [-4.8782],\n",
      "        [20.9214],\n",
      "        [ 5.0433]])\n",
      "tensor([[ 0.0036],\n",
      "        [ 0.0042],\n",
      "        [-0.0019],\n",
      "        [-0.0110],\n",
      "        [ 0.0012],\n",
      "        [ 0.0114],\n",
      "        [ 0.0116],\n",
      "        [ 0.0245],\n",
      "        [ 0.0146],\n",
      "        [ 0.0130]], grad_fn=<AddmmBackward0>) tensor([[  0.2721],\n",
      "        [ -1.4188],\n",
      "        [ 20.1783],\n",
      "        [ -1.3636],\n",
      "        [ 18.7210],\n",
      "        [ -2.2584],\n",
      "        [ 10.7667],\n",
      "        [  4.5799],\n",
      "        [  7.7569],\n",
      "        [-14.8816]])\n",
      "tensor([[ 0.0135],\n",
      "        [ 0.0164],\n",
      "        [-0.0007],\n",
      "        [-0.0016],\n",
      "        [-0.0159],\n",
      "        [ 0.0160],\n",
      "        [ 0.0014],\n",
      "        [-0.0040],\n",
      "        [ 0.0239],\n",
      "        [-0.0292]], grad_fn=<AddmmBackward0>) tensor([[ 5.5271],\n",
      "        [-6.7347],\n",
      "        [-5.8874],\n",
      "        [ 0.4136],\n",
      "        [ 8.9381],\n",
      "        [ 1.2933],\n",
      "        [ 8.7492],\n",
      "        [15.7348],\n",
      "        [ 6.2821],\n",
      "        [20.4876]])\n",
      "tensor([[ 0.0486],\n",
      "        [-0.0082],\n",
      "        [ 0.0002],\n",
      "        [ 0.0500],\n",
      "        [-0.0127],\n",
      "        [-0.0245],\n",
      "        [ 0.0097],\n",
      "        [ 0.0014],\n",
      "        [ 0.0133],\n",
      "        [-0.0060]], grad_fn=<AddmmBackward0>) tensor([[-18.4421],\n",
      "        [  9.7071],\n",
      "        [  0.7773],\n",
      "        [-12.0662],\n",
      "        [  1.9171],\n",
      "        [  9.1228],\n",
      "        [-12.3204],\n",
      "        [  8.5879],\n",
      "        [  4.1105],\n",
      "        [  6.9069]])\n",
      "tensor([[-0.0049],\n",
      "        [ 0.0008],\n",
      "        [-0.0010],\n",
      "        [ 0.0003],\n",
      "        [-0.0090],\n",
      "        [ 0.0041],\n",
      "        [ 0.0094],\n",
      "        [ 0.0130],\n",
      "        [-0.0043],\n",
      "        [ 0.0096]], grad_fn=<AddmmBackward0>) tensor([[11.5515],\n",
      "        [ 7.4568],\n",
      "        [ 5.9458],\n",
      "        [-0.4827],\n",
      "        [-3.3799],\n",
      "        [-3.5486],\n",
      "        [ 2.6960],\n",
      "        [-2.5678],\n",
      "        [ 9.8129],\n",
      "        [ 4.2296]])\n",
      "tensor([[ 0.0045],\n",
      "        [-0.0156],\n",
      "        [-0.0102],\n",
      "        [-0.0228],\n",
      "        [-0.0128],\n",
      "        [ 0.0047],\n",
      "        [ 0.0131],\n",
      "        [ 0.0072],\n",
      "        [-0.0190],\n",
      "        [-0.0165]], grad_fn=<AddmmBackward0>) tensor([[ 11.6458],\n",
      "        [  8.7073],\n",
      "        [ -4.9375],\n",
      "        [ 21.8897],\n",
      "        [  7.9822],\n",
      "        [ 11.6982],\n",
      "        [-10.0374],\n",
      "        [ -8.0419],\n",
      "        [ 24.7720],\n",
      "        [ 20.4559]])\n",
      "tensor([[ 0.0037],\n",
      "        [ 0.0037],\n",
      "        [ 0.0138],\n",
      "        [-0.0144],\n",
      "        [ 0.0260],\n",
      "        [-0.0077],\n",
      "        [-0.0166],\n",
      "        [ 0.0301],\n",
      "        [-0.0239],\n",
      "        [-0.0017]], grad_fn=<AddmmBackward0>) tensor([[ 7.8693],\n",
      "        [ 3.3456],\n",
      "        [-6.4006],\n",
      "        [ 7.6824],\n",
      "        [-3.7364],\n",
      "        [-1.2825],\n",
      "        [22.4647],\n",
      "        [-1.0056],\n",
      "        [20.6255],\n",
      "        [ 3.8444]])\n",
      "tensor([[-0.0083],\n",
      "        [ 0.0021],\n",
      "        [-0.0051],\n",
      "        [-0.0060],\n",
      "        [-0.0246],\n",
      "        [ 0.0106],\n",
      "        [ 0.0051],\n",
      "        [-0.0021],\n",
      "        [-0.0063],\n",
      "        [ 0.0182]], grad_fn=<AddmmBackward0>) tensor([[  1.9287],\n",
      "        [ -1.7497],\n",
      "        [  2.5498],\n",
      "        [  8.3051],\n",
      "        [  9.4479],\n",
      "        [ -0.8556],\n",
      "        [-10.5731],\n",
      "        [ -0.2664],\n",
      "        [  1.3857],\n",
      "        [  3.2121]])\n",
      "tensor([[-0.0352],\n",
      "        [-0.0034],\n",
      "        [ 0.0085],\n",
      "        [ 0.0368],\n",
      "        [ 0.0141],\n",
      "        [ 0.0162],\n",
      "        [-0.0210],\n",
      "        [-0.0061],\n",
      "        [ 0.0149],\n",
      "        [-0.0075]], grad_fn=<AddmmBackward0>) tensor([[ 22.8160],\n",
      "        [  4.2394],\n",
      "        [ -1.0229],\n",
      "        [-10.7842],\n",
      "        [  3.7850],\n",
      "        [ -7.0857],\n",
      "        [ 13.9911],\n",
      "        [  3.8291],\n",
      "        [  1.3492],\n",
      "        [ 10.7535]])\n",
      "tensor([[ 0.0181],\n",
      "        [-0.0156],\n",
      "        [ 0.0092],\n",
      "        [ 0.0052],\n",
      "        [ 0.0185],\n",
      "        [ 0.0248],\n",
      "        [ 0.0225],\n",
      "        [ 0.0262],\n",
      "        [-0.0187],\n",
      "        [ 0.0035]], grad_fn=<AddmmBackward0>) tensor([[-9.3653],\n",
      "        [15.9445],\n",
      "        [ 5.2880],\n",
      "        [-2.7604],\n",
      "        [-2.9623],\n",
      "        [-8.1292],\n",
      "        [ 5.7605],\n",
      "        [-5.7069],\n",
      "        [-2.3052],\n",
      "        [ 4.1432]])\n",
      "tensor([[ 0.0054],\n",
      "        [ 0.0176],\n",
      "        [ 0.0097],\n",
      "        [ 0.0168],\n",
      "        [ 0.0024],\n",
      "        [-0.0263],\n",
      "        [ 0.0158],\n",
      "        [ 0.0086],\n",
      "        [ 0.0099],\n",
      "        [-0.0052]], grad_fn=<AddmmBackward0>) tensor([[-10.5054],\n",
      "        [ -5.0693],\n",
      "        [  5.9791],\n",
      "        [  0.9200],\n",
      "        [ 11.8594],\n",
      "        [  7.4661],\n",
      "        [ -0.9854],\n",
      "        [  6.2859],\n",
      "        [ -9.7960],\n",
      "        [  7.6161]])\n",
      "tensor([[-0.0128],\n",
      "        [ 0.0325],\n",
      "        [ 0.0335],\n",
      "        [-0.0269],\n",
      "        [ 0.0173],\n",
      "        [-0.0122],\n",
      "        [ 0.0110],\n",
      "        [-0.0043],\n",
      "        [-0.0106],\n",
      "        [-0.0001]], grad_fn=<AddmmBackward0>) tensor([[-1.6107],\n",
      "        [-9.5226],\n",
      "        [ 3.8670],\n",
      "        [17.0038],\n",
      "        [ 0.4878],\n",
      "        [ 2.6502],\n",
      "        [-9.5449],\n",
      "        [-4.6239],\n",
      "        [11.3030],\n",
      "        [ 7.9309]])\n",
      "tensor([[ 0.0047],\n",
      "        [ 0.0006],\n",
      "        [ 0.0287],\n",
      "        [-0.0260],\n",
      "        [-0.0249],\n",
      "        [-0.0066],\n",
      "        [ 0.0008],\n",
      "        [ 0.0206],\n",
      "        [-0.0223],\n",
      "        [-0.0032]], grad_fn=<AddmmBackward0>) tensor([[ 1.3243],\n",
      "        [-4.0404],\n",
      "        [-2.3354],\n",
      "        [ 9.7513],\n",
      "        [12.1184],\n",
      "        [ 5.0941],\n",
      "        [12.8244],\n",
      "        [-2.3554],\n",
      "        [ 9.4918],\n",
      "        [ 7.4114]])\n",
      "tensor([[ 0.0005],\n",
      "        [ 0.0122],\n",
      "        [ 0.0066],\n",
      "        [ 0.0038],\n",
      "        [-0.0090],\n",
      "        [ 0.0274],\n",
      "        [ 0.0024],\n",
      "        [ 0.0030],\n",
      "        [-0.0053],\n",
      "        [-0.0014]], grad_fn=<AddmmBackward0>) tensor([[ -1.6885],\n",
      "        [-12.0976],\n",
      "        [  2.2205],\n",
      "        [ 13.9196],\n",
      "        [  6.5037],\n",
      "        [ -5.8374],\n",
      "        [ -0.5153],\n",
      "        [ -3.2893],\n",
      "        [ -4.1435],\n",
      "        [  1.9359]])\n",
      "tensor([[-0.0066],\n",
      "        [-0.0180],\n",
      "        [-0.0150],\n",
      "        [ 0.0049],\n",
      "        [ 0.0024],\n",
      "        [-0.0120],\n",
      "        [-0.0149],\n",
      "        [-0.0264],\n",
      "        [ 0.0009],\n",
      "        [ 0.0134]], grad_fn=<AddmmBackward0>) tensor([[ 0.6192],\n",
      "        [ 0.0972],\n",
      "        [ 8.1214],\n",
      "        [-2.4372],\n",
      "        [ 4.0181],\n",
      "        [-8.1867],\n",
      "        [ 6.5057],\n",
      "        [12.2870],\n",
      "        [-0.8226],\n",
      "        [-8.2985]])\n",
      "tensor([[-0.0273],\n",
      "        [ 0.0052],\n",
      "        [ 0.0209],\n",
      "        [-0.0049],\n",
      "        [ 0.0007],\n",
      "        [-0.0237],\n",
      "        [-0.0135],\n",
      "        [-0.0096],\n",
      "        [-0.0007],\n",
      "        [ 0.0160]], grad_fn=<AddmmBackward0>) tensor([[ 16.6276],\n",
      "        [  0.7515],\n",
      "        [-14.9111],\n",
      "        [ 16.0225],\n",
      "        [  1.7147],\n",
      "        [ 13.4864],\n",
      "        [  6.1251],\n",
      "        [  9.2673],\n",
      "        [-10.4984],\n",
      "        [ -6.2139]])\n",
      "tensor([[ 0.0322],\n",
      "        [-0.0066],\n",
      "        [ 0.0161],\n",
      "        [ 0.0070],\n",
      "        [-0.0175],\n",
      "        [-0.0100],\n",
      "        [-0.0064],\n",
      "        [-0.0103],\n",
      "        [-0.0046],\n",
      "        [ 0.0113]], grad_fn=<AddmmBackward0>) tensor([[  1.1126],\n",
      "        [  9.5144],\n",
      "        [  3.8995],\n",
      "        [ -1.2604],\n",
      "        [ 19.6037],\n",
      "        [ 14.0541],\n",
      "        [-12.0320],\n",
      "        [  8.7865],\n",
      "        [  5.3081],\n",
      "        [ 12.2121]])\n",
      "tensor([[ 0.0001],\n",
      "        [ 0.0181],\n",
      "        [-0.0215],\n",
      "        [-0.0098],\n",
      "        [ 0.0210],\n",
      "        [ 0.0067],\n",
      "        [ 0.0028],\n",
      "        [-0.0106],\n",
      "        [ 0.0023],\n",
      "        [-0.0068]], grad_fn=<AddmmBackward0>) tensor([[ 5.2242],\n",
      "        [-0.4855],\n",
      "        [10.3329],\n",
      "        [13.2100],\n",
      "        [ 0.3343],\n",
      "        [-3.2405],\n",
      "        [10.8399],\n",
      "        [ 7.6970],\n",
      "        [15.7537],\n",
      "        [11.3488]])\n",
      "tensor([[ 0.0027],\n",
      "        [ 0.0090],\n",
      "        [ 0.0076],\n",
      "        [ 0.0047],\n",
      "        [-0.0233],\n",
      "        [ 0.0102],\n",
      "        [-0.0329],\n",
      "        [-0.0070],\n",
      "        [ 0.0079],\n",
      "        [-0.0171]], grad_fn=<AddmmBackward0>) tensor([[ -6.3646],\n",
      "        [ -2.1544],\n",
      "        [ -6.1911],\n",
      "        [ -6.5965],\n",
      "        [ 15.6285],\n",
      "        [-10.7124],\n",
      "        [  9.6266],\n",
      "        [ -4.0490],\n",
      "        [  6.8447],\n",
      "        [ 16.1134]])\n",
      "tensor([[ 0.0084],\n",
      "        [ 0.0082],\n",
      "        [ 0.0022],\n",
      "        [ 0.0011],\n",
      "        [-0.0073],\n",
      "        [ 0.0087],\n",
      "        [-0.0168],\n",
      "        [ 0.0044],\n",
      "        [ 0.0041],\n",
      "        [-0.0087]], grad_fn=<AddmmBackward0>) tensor([[ 5.0582],\n",
      "        [-2.1755],\n",
      "        [-0.4633],\n",
      "        [10.9427],\n",
      "        [ 3.9259],\n",
      "        [-5.2613],\n",
      "        [ 0.7057],\n",
      "        [ 8.4162],\n",
      "        [ 8.5060],\n",
      "        [ 1.7501]])\n",
      "tensor([[ 0.0113],\n",
      "        [-0.0089],\n",
      "        [-0.0100],\n",
      "        [-0.0113],\n",
      "        [ 0.0400],\n",
      "        [-0.0196],\n",
      "        [-0.0040],\n",
      "        [ 0.0247],\n",
      "        [-0.0394],\n",
      "        [-0.0276]], grad_fn=<AddmmBackward0>) tensor([[  9.3306],\n",
      "        [ 13.3979],\n",
      "        [ 12.5413],\n",
      "        [ 13.4722],\n",
      "        [-10.0931],\n",
      "        [  8.2586],\n",
      "        [ -1.1465],\n",
      "        [  2.4136],\n",
      "        [ 10.0031],\n",
      "        [ 10.2253]])\n",
      "tensor([[ 0.0125],\n",
      "        [-0.0186],\n",
      "        [ 0.0162],\n",
      "        [ 0.0062],\n",
      "        [-0.0104],\n",
      "        [-0.0076],\n",
      "        [-0.0134],\n",
      "        [ 0.0068],\n",
      "        [-0.0011],\n",
      "        [-0.0130]], grad_fn=<AddmmBackward0>) tensor([[ 2.1332],\n",
      "        [-1.4119],\n",
      "        [ 7.9667],\n",
      "        [ 4.6808],\n",
      "        [ 8.0619],\n",
      "        [14.7538],\n",
      "        [ 3.1136],\n",
      "        [ 3.3658],\n",
      "        [ 1.1254],\n",
      "        [ 8.7803]])\n",
      "tensor([[-0.0390],\n",
      "        [-0.0037],\n",
      "        [ 0.0268],\n",
      "        [ 0.0134],\n",
      "        [ 0.0058],\n",
      "        [ 0.0122],\n",
      "        [-0.0029],\n",
      "        [ 0.0173],\n",
      "        [-0.0541],\n",
      "        [ 0.0211]], grad_fn=<AddmmBackward0>) tensor([[15.3025],\n",
      "        [-0.1539],\n",
      "        [-9.1954],\n",
      "        [ 8.6174],\n",
      "        [13.1735],\n",
      "        [ 7.1046],\n",
      "        [ 8.0298],\n",
      "        [ 4.3095],\n",
      "        [14.4185],\n",
      "        [-3.7212]])\n",
      "tensor([[ 0.0042],\n",
      "        [ 0.0103],\n",
      "        [-0.0174],\n",
      "        [-0.0236],\n",
      "        [ 0.0348],\n",
      "        [ 0.0109],\n",
      "        [ 0.0008],\n",
      "        [ 0.0097],\n",
      "        [-0.0026],\n",
      "        [-0.0254]], grad_fn=<AddmmBackward0>) tensor([[ -9.1903],\n",
      "        [  6.1595],\n",
      "        [ -2.5995],\n",
      "        [  3.6027],\n",
      "        [-11.4222],\n",
      "        [  0.0553],\n",
      "        [  5.8738],\n",
      "        [ -7.4651],\n",
      "        [  4.4602],\n",
      "        [  9.8150]])\n",
      "tensor([[ 0.0068],\n",
      "        [ 0.0168],\n",
      "        [-0.0021],\n",
      "        [-0.0137],\n",
      "        [-0.0106],\n",
      "        [ 0.0060],\n",
      "        [ 0.0063],\n",
      "        [-0.0092],\n",
      "        [-0.0058],\n",
      "        [ 0.0247]], grad_fn=<AddmmBackward0>) tensor([[ 0.6324],\n",
      "        [ 1.2054],\n",
      "        [-0.4882],\n",
      "        [11.6754],\n",
      "        [ 8.0398],\n",
      "        [-3.9580],\n",
      "        [-7.8440],\n",
      "        [-0.1749],\n",
      "        [ 4.0452],\n",
      "        [-6.4002]])\n",
      "tensor([[ 0.0043],\n",
      "        [-0.0194],\n",
      "        [-0.0175],\n",
      "        [ 0.0006],\n",
      "        [ 0.0090],\n",
      "        [ 0.0016],\n",
      "        [-0.0147],\n",
      "        [-0.0093],\n",
      "        [ 0.0298],\n",
      "        [-0.0255]], grad_fn=<AddmmBackward0>) tensor([[  3.0145],\n",
      "        [  6.3912],\n",
      "        [ 18.1684],\n",
      "        [  8.7598],\n",
      "        [  1.1742],\n",
      "        [  6.9896],\n",
      "        [ 14.3410],\n",
      "        [  6.6466],\n",
      "        [-13.8117],\n",
      "        [  4.9165]])\n",
      "tensor([[ 4.5533e-03],\n",
      "        [ 2.8017e-02],\n",
      "        [ 7.5236e-03],\n",
      "        [-2.8243e-03],\n",
      "        [-1.1186e-02],\n",
      "        [-9.6470e-05],\n",
      "        [ 2.2165e-02],\n",
      "        [ 1.0801e-02],\n",
      "        [-7.9028e-03],\n",
      "        [-5.5154e-03]], grad_fn=<AddmmBackward0>) tensor([[ 4.2830],\n",
      "        [-3.5953],\n",
      "        [ 3.8309],\n",
      "        [ 1.1186],\n",
      "        [ 5.5678],\n",
      "        [-6.1444],\n",
      "        [ 5.9665],\n",
      "        [-4.8961],\n",
      "        [ 6.4818],\n",
      "        [ 7.4099]])\n",
      "tensor([[ 0.0067],\n",
      "        [ 0.0255],\n",
      "        [ 0.0001],\n",
      "        [-0.0294],\n",
      "        [ 0.0048],\n",
      "        [ 0.0057],\n",
      "        [ 0.0239],\n",
      "        [-0.0069],\n",
      "        [ 0.0014],\n",
      "        [-0.0149]], grad_fn=<AddmmBackward0>) tensor([[  9.3331],\n",
      "        [-10.3542],\n",
      "        [ 11.1823],\n",
      "        [ 17.7070],\n",
      "        [ -6.3669],\n",
      "        [ -2.6576],\n",
      "        [  4.9045],\n",
      "        [  8.0138],\n",
      "        [  8.6220],\n",
      "        [ 10.5937]])\n",
      "tensor([[-5.3377e-03],\n",
      "        [-2.4776e-04],\n",
      "        [-6.1253e-03],\n",
      "        [-1.8995e-02],\n",
      "        [-3.4167e-05],\n",
      "        [ 1.7202e-02],\n",
      "        [ 1.3832e-03],\n",
      "        [-7.0404e-03],\n",
      "        [-2.6144e-02],\n",
      "        [ 8.3839e-03]], grad_fn=<AddmmBackward0>) tensor([[ 4.5589],\n",
      "        [ 4.8399],\n",
      "        [13.1887],\n",
      "        [15.4828],\n",
      "        [ 0.3050],\n",
      "        [ 2.5659],\n",
      "        [ 7.5792],\n",
      "        [ 5.2901],\n",
      "        [12.1038],\n",
      "        [-2.8761]])\n",
      "tensor([[-0.0164],\n",
      "        [ 0.0015],\n",
      "        [-0.0040],\n",
      "        [ 0.0029],\n",
      "        [ 0.0429],\n",
      "        [-0.0006],\n",
      "        [ 0.0059],\n",
      "        [-0.0096],\n",
      "        [-0.0008],\n",
      "        [-0.0155]], grad_fn=<AddmmBackward0>) tensor([[  4.7244],\n",
      "        [ -1.3527],\n",
      "        [  0.3444],\n",
      "        [ -4.6690],\n",
      "        [-17.7683],\n",
      "        [ -6.0586],\n",
      "        [  0.5405],\n",
      "        [ -4.1111],\n",
      "        [ 25.2710],\n",
      "        [  7.0535]])\n",
      "tensor([[-0.0161],\n",
      "        [ 0.0108],\n",
      "        [-0.0455],\n",
      "        [-0.0220],\n",
      "        [ 0.0010],\n",
      "        [ 0.0034],\n",
      "        [-0.0099],\n",
      "        [ 0.0017],\n",
      "        [ 0.0004],\n",
      "        [ 0.0204]], grad_fn=<AddmmBackward0>) tensor([[16.5093],\n",
      "        [ 9.4036],\n",
      "        [10.5888],\n",
      "        [11.9860],\n",
      "        [ 2.6398],\n",
      "        [-7.6775],\n",
      "        [-3.5573],\n",
      "        [17.2961],\n",
      "        [ 5.3568],\n",
      "        [ 3.7164]])\n",
      "tensor([[ 0.0240],\n",
      "        [ 0.0153],\n",
      "        [-0.0041],\n",
      "        [ 0.0201],\n",
      "        [ 0.0054],\n",
      "        [-0.0089],\n",
      "        [ 0.0136],\n",
      "        [-0.0156],\n",
      "        [-0.0262],\n",
      "        [ 0.0038]], grad_fn=<AddmmBackward0>) tensor([[ 3.6579],\n",
      "        [ 1.5739],\n",
      "        [ 8.7908],\n",
      "        [ 2.8298],\n",
      "        [-0.4854],\n",
      "        [ 8.2884],\n",
      "        [-5.9651],\n",
      "        [15.8851],\n",
      "        [22.9632],\n",
      "        [12.7832]])\n",
      "tensor([[-2.7159e-02],\n",
      "        [-9.2302e-05],\n",
      "        [-1.4831e-02],\n",
      "        [-8.6276e-03],\n",
      "        [ 8.9079e-03],\n",
      "        [-1.7017e-02],\n",
      "        [-1.7495e-02],\n",
      "        [ 6.9308e-03],\n",
      "        [ 1.6615e-02],\n",
      "        [-2.0545e-02]], grad_fn=<AddmmBackward0>) tensor([[14.4471],\n",
      "        [-2.8144],\n",
      "        [13.1124],\n",
      "        [ 9.5299],\n",
      "        [ 6.8496],\n",
      "        [21.4672],\n",
      "        [ 7.9938],\n",
      "        [15.0023],\n",
      "        [ 7.6910],\n",
      "        [ 2.9683]])\n",
      "tensor([[ 0.0114],\n",
      "        [ 0.0091],\n",
      "        [-0.0024],\n",
      "        [ 0.0287],\n",
      "        [-0.0046],\n",
      "        [-0.0075],\n",
      "        [-0.0027],\n",
      "        [ 0.0178],\n",
      "        [-0.0075],\n",
      "        [-0.0163]], grad_fn=<AddmmBackward0>) tensor([[ 5.7858],\n",
      "        [-7.8527],\n",
      "        [ 0.0967],\n",
      "        [-6.0857],\n",
      "        [ 2.8244],\n",
      "        [ 0.8502],\n",
      "        [14.2932],\n",
      "        [-1.5755],\n",
      "        [ 7.0463],\n",
      "        [18.3608]])\n",
      "tensor([[-0.0136],\n",
      "        [-0.0005],\n",
      "        [-0.0117],\n",
      "        [-0.0127],\n",
      "        [-0.0191],\n",
      "        [-0.0129],\n",
      "        [ 0.0179],\n",
      "        [-0.0079],\n",
      "        [-0.0295],\n",
      "        [-0.0199]], grad_fn=<AddmmBackward0>) tensor([[17.5668],\n",
      "        [-1.4532],\n",
      "        [ 9.2237],\n",
      "        [ 8.1509],\n",
      "        [22.9900],\n",
      "        [12.2632],\n",
      "        [ 4.4805],\n",
      "        [-7.7882],\n",
      "        [16.0011],\n",
      "        [-0.9570]])\n",
      "tensor([[-0.0069],\n",
      "        [-0.0097],\n",
      "        [ 0.0017],\n",
      "        [ 0.0189],\n",
      "        [ 0.0172],\n",
      "        [ 0.0030],\n",
      "        [ 0.0208],\n",
      "        [ 0.0102],\n",
      "        [ 0.0149],\n",
      "        [ 0.0244]], grad_fn=<AddmmBackward0>) tensor([[-1.9406],\n",
      "        [-1.9848],\n",
      "        [ 6.7911],\n",
      "        [ 2.5377],\n",
      "        [ 8.0338],\n",
      "        [ 5.7387],\n",
      "        [15.3107],\n",
      "        [-4.1727],\n",
      "        [-5.8623],\n",
      "        [-6.4629]])\n",
      "tensor([[-0.0094],\n",
      "        [-0.0002],\n",
      "        [ 0.0266],\n",
      "        [-0.0040],\n",
      "        [ 0.0075],\n",
      "        [-0.0119],\n",
      "        [ 0.0095],\n",
      "        [ 0.0189],\n",
      "        [ 0.0034],\n",
      "        [-0.0026]], grad_fn=<AddmmBackward0>) tensor([[ 9.8888],\n",
      "        [-1.5787],\n",
      "        [-0.7851],\n",
      "        [ 0.3030],\n",
      "        [ 1.5336],\n",
      "        [13.2381],\n",
      "        [-5.2122],\n",
      "        [ 3.9263],\n",
      "        [-0.4993],\n",
      "        [ 9.7779]])\n",
      "tensor([[-0.0200],\n",
      "        [ 0.0090],\n",
      "        [ 0.0265],\n",
      "        [-0.0300],\n",
      "        [-0.0094],\n",
      "        [ 0.0017],\n",
      "        [-0.0110],\n",
      "        [-0.0049],\n",
      "        [-0.0381],\n",
      "        [ 0.0054]], grad_fn=<AddmmBackward0>) tensor([[18.2269],\n",
      "        [-5.2022],\n",
      "        [-6.6159],\n",
      "        [10.0188],\n",
      "        [16.3986],\n",
      "        [ 5.7424],\n",
      "        [14.5819],\n",
      "        [-4.3981],\n",
      "        [13.7079],\n",
      "        [ 6.2858]])\n",
      "tensor([[-0.0046],\n",
      "        [ 0.0033],\n",
      "        [-0.0148],\n",
      "        [ 0.0548],\n",
      "        [ 0.0383],\n",
      "        [-0.0170],\n",
      "        [-0.0314],\n",
      "        [-0.0081],\n",
      "        [ 0.0249],\n",
      "        [-0.0176]], grad_fn=<AddmmBackward0>) tensor([[ 11.5904],\n",
      "        [  6.2871],\n",
      "        [ 12.0521],\n",
      "        [-20.5613],\n",
      "        [-11.5590],\n",
      "        [ 18.2772],\n",
      "        [ 17.7860],\n",
      "        [ -1.5000],\n",
      "        [ -1.1752],\n",
      "        [ 17.5829]])\n",
      "tensor([[ 1.1555e-02],\n",
      "        [-1.0593e-02],\n",
      "        [-9.5957e-03],\n",
      "        [ 8.9819e-03],\n",
      "        [ 9.9919e-03],\n",
      "        [-1.9964e-02],\n",
      "        [ 1.8024e-02],\n",
      "        [ 1.3380e-02],\n",
      "        [ 6.6884e-05],\n",
      "        [-9.1054e-03]], grad_fn=<AddmmBackward0>) tensor([[-0.8454],\n",
      "        [11.6679],\n",
      "        [ 7.6005],\n",
      "        [ 2.4797],\n",
      "        [ 2.9237],\n",
      "        [20.0677],\n",
      "        [ 9.9948],\n",
      "        [ 1.3092],\n",
      "        [-4.1730],\n",
      "        [ 3.1365]])\n",
      "tensor([[ 0.0290],\n",
      "        [ 0.0094],\n",
      "        [-0.0167],\n",
      "        [-0.0054],\n",
      "        [-0.0087],\n",
      "        [-0.0206],\n",
      "        [-0.0299],\n",
      "        [-0.0038],\n",
      "        [-0.0255],\n",
      "        [ 0.0131]], grad_fn=<AddmmBackward0>) tensor([[ 5.2899],\n",
      "        [10.0954],\n",
      "        [ 9.7962],\n",
      "        [-1.1690],\n",
      "        [-1.1837],\n",
      "        [17.5319],\n",
      "        [ 7.6176],\n",
      "        [ 5.3845],\n",
      "        [21.4059],\n",
      "        [-7.2291]])\n",
      "tensor([[-4.0458e-03],\n",
      "        [-4.1660e-03],\n",
      "        [-2.4144e-05],\n",
      "        [-8.7744e-03],\n",
      "        [-2.5558e-04],\n",
      "        [-9.1719e-03],\n",
      "        [ 5.2399e-03],\n",
      "        [ 1.6582e-02],\n",
      "        [-2.4858e-04],\n",
      "        [-2.6140e-03]], grad_fn=<AddmmBackward0>) tensor([[ 7.6580],\n",
      "        [ 2.4566],\n",
      "        [ 8.0385],\n",
      "        [ 4.7028],\n",
      "        [18.1727],\n",
      "        [21.0747],\n",
      "        [ 6.9670],\n",
      "        [18.8173],\n",
      "        [ 1.1272],\n",
      "        [16.0536]])\n",
      "tensor([[-0.0087],\n",
      "        [-0.0127],\n",
      "        [ 0.0152],\n",
      "        [ 0.0036],\n",
      "        [-0.0062],\n",
      "        [-0.0129],\n",
      "        [-0.0017],\n",
      "        [-0.0009],\n",
      "        [-0.0048],\n",
      "        [-0.0038]], grad_fn=<AddmmBackward0>) tensor([[-11.1787],\n",
      "        [ 12.3045],\n",
      "        [  6.1252],\n",
      "        [-11.1274],\n",
      "        [  2.5586],\n",
      "        [ 15.1767],\n",
      "        [  8.2547],\n",
      "        [  7.8850],\n",
      "        [ -1.9831],\n",
      "        [ 10.3875]])\n",
      "tensor([[-0.0096],\n",
      "        [-0.0037],\n",
      "        [-0.0159],\n",
      "        [-0.0119],\n",
      "        [ 0.0097],\n",
      "        [ 0.0133],\n",
      "        [ 0.0103],\n",
      "        [ 0.0225],\n",
      "        [-0.0233],\n",
      "        [ 0.0077]], grad_fn=<AddmmBackward0>) tensor([[  1.8963],\n",
      "        [  4.7831],\n",
      "        [  7.3195],\n",
      "        [ 18.4836],\n",
      "        [ -8.9542],\n",
      "        [  3.3452],\n",
      "        [ 12.5562],\n",
      "        [-12.2802],\n",
      "        [  8.3986],\n",
      "        [ -8.6668]])\n",
      "tensor([[-0.0144],\n",
      "        [ 0.0081],\n",
      "        [ 0.0201],\n",
      "        [ 0.0326],\n",
      "        [-0.0017],\n",
      "        [ 0.0167],\n",
      "        [ 0.0068],\n",
      "        [ 0.0219],\n",
      "        [ 0.0080],\n",
      "        [ 0.0212]], grad_fn=<AddmmBackward0>) tensor([[ 10.1248],\n",
      "        [-14.3437],\n",
      "        [ -4.2807],\n",
      "        [-21.7873],\n",
      "        [  2.6064],\n",
      "        [  1.9974],\n",
      "        [ -4.7380],\n",
      "        [-11.0653],\n",
      "        [-12.9538],\n",
      "        [  9.7325]])\n",
      "tensor([[-0.0123],\n",
      "        [ 0.0087],\n",
      "        [-0.0230],\n",
      "        [-0.0062],\n",
      "        [-0.0027],\n",
      "        [-0.0119],\n",
      "        [ 0.0030],\n",
      "        [-0.0002],\n",
      "        [-0.0107],\n",
      "        [-0.0332]], grad_fn=<AddmmBackward0>) tensor([[ 3.5724],\n",
      "        [-3.9558],\n",
      "        [11.5572],\n",
      "        [14.4371],\n",
      "        [ 3.7777],\n",
      "        [ 8.6933],\n",
      "        [-9.2348],\n",
      "        [ 7.6654],\n",
      "        [12.4058],\n",
      "        [15.0143]])\n",
      "tensor([[ 0.0058],\n",
      "        [ 0.0014],\n",
      "        [ 0.0050],\n",
      "        [ 0.0114],\n",
      "        [ 0.0073],\n",
      "        [ 0.0142],\n",
      "        [ 0.0055],\n",
      "        [ 0.0146],\n",
      "        [-0.0215],\n",
      "        [ 0.0109]], grad_fn=<AddmmBackward0>) tensor([[-2.1062],\n",
      "        [ 8.6431],\n",
      "        [ 3.5527],\n",
      "        [-2.3214],\n",
      "        [ 3.8016],\n",
      "        [-8.9979],\n",
      "        [-2.4597],\n",
      "        [-0.2845],\n",
      "        [11.8877],\n",
      "        [ 2.8293]])\n",
      "tensor([[ 0.0188],\n",
      "        [-0.0161],\n",
      "        [-0.0068],\n",
      "        [-0.0019],\n",
      "        [-0.0188],\n",
      "        [-0.0197],\n",
      "        [-0.0228],\n",
      "        [-0.0217],\n",
      "        [-0.0041],\n",
      "        [-0.0206]], grad_fn=<AddmmBackward0>) tensor([[-10.8051],\n",
      "        [  2.2491],\n",
      "        [  2.7161],\n",
      "        [ -2.8501],\n",
      "        [ 10.1923],\n",
      "        [ 21.1538],\n",
      "        [  8.0087],\n",
      "        [ 14.4097],\n",
      "        [  2.2519],\n",
      "        [ 10.2229]])\n",
      "tensor([[ 0.0116],\n",
      "        [-0.0062],\n",
      "        [-0.0015],\n",
      "        [-0.0252],\n",
      "        [ 0.0218],\n",
      "        [-0.0146],\n",
      "        [ 0.0261],\n",
      "        [ 0.0061],\n",
      "        [ 0.0059],\n",
      "        [ 0.0057]], grad_fn=<AddmmBackward0>) tensor([[  1.3441],\n",
      "        [ -4.8487],\n",
      "        [ -5.1908],\n",
      "        [ 11.6395],\n",
      "        [ -0.8837],\n",
      "        [ 20.2295],\n",
      "        [-11.4487],\n",
      "        [  4.6038],\n",
      "        [  8.7108],\n",
      "        [ -0.7306]])\n",
      "tensor([[ 0.0075],\n",
      "        [-0.0021],\n",
      "        [ 0.0052],\n",
      "        [-0.0108],\n",
      "        [ 0.0024],\n",
      "        [ 0.0053],\n",
      "        [ 0.0327],\n",
      "        [-0.0133],\n",
      "        [ 0.0012],\n",
      "        [-0.0264]], grad_fn=<AddmmBackward0>) tensor([[  3.0353],\n",
      "        [  3.0919],\n",
      "        [-10.1216],\n",
      "        [ 15.8796],\n",
      "        [  3.2477],\n",
      "        [  7.2758],\n",
      "        [-16.1497],\n",
      "        [ -2.1037],\n",
      "        [ 18.8715],\n",
      "        [ -2.8696]])\n",
      "tensor([[ 0.0004],\n",
      "        [-0.0104],\n",
      "        [ 0.0419],\n",
      "        [-0.0035],\n",
      "        [ 0.0191],\n",
      "        [ 0.0034],\n",
      "        [-0.0019],\n",
      "        [ 0.0260],\n",
      "        [ 0.0156],\n",
      "        [ 0.0507]], grad_fn=<AddmmBackward0>) tensor([[ 4.7152],\n",
      "        [12.1254],\n",
      "        [-6.9614],\n",
      "        [ 7.9735],\n",
      "        [-3.3859],\n",
      "        [-1.5084],\n",
      "        [ 2.3144],\n",
      "        [-3.2480],\n",
      "        [ 1.7179],\n",
      "        [-9.5554]])\n",
      "tensor([[-0.0294],\n",
      "        [-0.0066],\n",
      "        [ 0.0270],\n",
      "        [-0.0352],\n",
      "        [ 0.0045],\n",
      "        [-0.0065],\n",
      "        [-0.0025],\n",
      "        [-0.0080],\n",
      "        [ 0.0249],\n",
      "        [ 0.0027]], grad_fn=<AddmmBackward0>) tensor([[ 22.2411],\n",
      "        [  3.8613],\n",
      "        [  0.6263],\n",
      "        [ 12.9809],\n",
      "        [  4.5886],\n",
      "        [ 14.2156],\n",
      "        [  7.3836],\n",
      "        [  9.6203],\n",
      "        [-11.8725],\n",
      "        [ -1.8240]])\n",
      "tensor([[-0.0025],\n",
      "        [-0.0087],\n",
      "        [ 0.0237],\n",
      "        [-0.0052],\n",
      "        [-0.0029],\n",
      "        [ 0.0128],\n",
      "        [-0.0214],\n",
      "        [-0.0050],\n",
      "        [-0.0323],\n",
      "        [-0.0186]], grad_fn=<AddmmBackward0>) tensor([[ 9.0006],\n",
      "        [ 7.3311],\n",
      "        [-7.2435],\n",
      "        [-0.1535],\n",
      "        [11.1349],\n",
      "        [-6.6312],\n",
      "        [13.8446],\n",
      "        [-2.0320],\n",
      "        [16.6063],\n",
      "        [19.2511]])\n",
      "tensor([[-0.0177],\n",
      "        [ 0.0169],\n",
      "        [-0.0069],\n",
      "        [-0.0120],\n",
      "        [ 0.0169],\n",
      "        [-0.0010],\n",
      "        [-0.0211],\n",
      "        [-0.0055],\n",
      "        [-0.0156],\n",
      "        [ 0.0012]], grad_fn=<AddmmBackward0>) tensor([[ 5.6091],\n",
      "        [ 8.2554],\n",
      "        [-2.2267],\n",
      "        [-6.5712],\n",
      "        [ 4.4654],\n",
      "        [12.5186],\n",
      "        [15.9087],\n",
      "        [-1.1386],\n",
      "        [ 6.1987],\n",
      "        [ 9.4778]])\n",
      "tensor([[-0.0210],\n",
      "        [ 0.0074],\n",
      "        [-0.0290],\n",
      "        [-0.0316],\n",
      "        [ 0.0261],\n",
      "        [-0.0161],\n",
      "        [ 0.0097],\n",
      "        [ 0.0005],\n",
      "        [ 0.0005],\n",
      "        [-0.0112]], grad_fn=<AddmmBackward0>) tensor([[ 1.2632],\n",
      "        [ 4.7112],\n",
      "        [16.1514],\n",
      "        [ 9.7781],\n",
      "        [-6.7236],\n",
      "        [-0.0242],\n",
      "        [-0.2631],\n",
      "        [ 2.8055],\n",
      "        [ 3.1516],\n",
      "        [ 1.5703]])\n",
      "tensor([[-0.0010],\n",
      "        [-0.0004],\n",
      "        [-0.0140],\n",
      "        [-0.0102],\n",
      "        [ 0.0052],\n",
      "        [-0.0157],\n",
      "        [-0.0121],\n",
      "        [ 0.0243],\n",
      "        [ 0.0192],\n",
      "        [ 0.0124]], grad_fn=<AddmmBackward0>) tensor([[ 4.1596],\n",
      "        [-2.9936],\n",
      "        [ 1.1463],\n",
      "        [ 5.1462],\n",
      "        [-0.5261],\n",
      "        [ 5.4223],\n",
      "        [11.5129],\n",
      "        [ 4.4553],\n",
      "        [12.7552],\n",
      "        [-0.1973]])\n",
      "tensor([[-0.0180],\n",
      "        [-0.0252],\n",
      "        [ 0.0073],\n",
      "        [ 0.0214],\n",
      "        [-0.0035],\n",
      "        [ 0.0057],\n",
      "        [-0.0113],\n",
      "        [-0.0200],\n",
      "        [ 0.0242],\n",
      "        [-0.0007]], grad_fn=<AddmmBackward0>) tensor([[-6.3114],\n",
      "        [ 9.4883],\n",
      "        [ 6.6368],\n",
      "        [-1.4180],\n",
      "        [11.8095],\n",
      "        [ 1.1099],\n",
      "        [16.8845],\n",
      "        [13.3406],\n",
      "        [ 6.9701],\n",
      "        [17.6849]])\n",
      "tensor([[-0.0121],\n",
      "        [-0.0102],\n",
      "        [ 0.0003],\n",
      "        [ 0.0014],\n",
      "        [-0.0174],\n",
      "        [ 0.0186],\n",
      "        [ 0.0034],\n",
      "        [-0.0110],\n",
      "        [ 0.0159],\n",
      "        [-0.0061]], grad_fn=<AddmmBackward0>) tensor([[14.9078],\n",
      "        [ 5.9823],\n",
      "        [ 4.0872],\n",
      "        [-4.3106],\n",
      "        [14.9600],\n",
      "        [-1.1819],\n",
      "        [-8.1590],\n",
      "        [ 2.1589],\n",
      "        [-5.1135],\n",
      "        [ 9.1016]])\n",
      "tensor([[ 0.0069],\n",
      "        [ 0.0180],\n",
      "        [-0.0151],\n",
      "        [ 0.0030],\n",
      "        [-0.0227],\n",
      "        [ 0.0405],\n",
      "        [ 0.0064],\n",
      "        [-0.0388],\n",
      "        [-0.0091],\n",
      "        [-0.0039]], grad_fn=<AddmmBackward0>) tensor([[-1.4964],\n",
      "        [16.0129],\n",
      "        [11.9603],\n",
      "        [-3.1081],\n",
      "        [ 9.3125],\n",
      "        [-1.1499],\n",
      "        [-2.7219],\n",
      "        [11.8677],\n",
      "        [16.4653],\n",
      "        [12.6069]])\n",
      "tensor([[ 0.0028],\n",
      "        [-0.0061],\n",
      "        [ 0.0122],\n",
      "        [ 0.0056],\n",
      "        [-0.0074],\n",
      "        [-0.0139],\n",
      "        [ 0.0174],\n",
      "        [ 0.0323],\n",
      "        [ 0.0177],\n",
      "        [ 0.0036]], grad_fn=<AddmmBackward0>) tensor([[ 1.0567],\n",
      "        [ 4.8035],\n",
      "        [ 6.2885],\n",
      "        [ 2.1109],\n",
      "        [ 1.0475],\n",
      "        [ 5.8125],\n",
      "        [ 2.9855],\n",
      "        [ 6.2837],\n",
      "        [-0.0535],\n",
      "        [-4.6100]])\n",
      "tensor([[-0.0026],\n",
      "        [-0.0040],\n",
      "        [ 0.0110],\n",
      "        [-0.0071],\n",
      "        [ 0.0118],\n",
      "        [ 0.0138],\n",
      "        [-0.0025],\n",
      "        [-0.0004],\n",
      "        [ 0.0113],\n",
      "        [ 0.0063]], grad_fn=<AddmmBackward0>) tensor([[ -0.6627],\n",
      "        [ -5.7506],\n",
      "        [  4.3133],\n",
      "        [ 22.3361],\n",
      "        [ -1.8666],\n",
      "        [-12.9355],\n",
      "        [ 16.6982],\n",
      "        [  5.9949],\n",
      "        [ -7.1480],\n",
      "        [ -0.7768]])\n",
      "tensor([[-0.0089],\n",
      "        [ 0.0072],\n",
      "        [-0.0130],\n",
      "        [ 0.0063],\n",
      "        [ 0.0013],\n",
      "        [-0.0092],\n",
      "        [ 0.0307],\n",
      "        [-0.0121],\n",
      "        [-0.0173],\n",
      "        [ 0.0090]], grad_fn=<AddmmBackward0>) tensor([[-1.2593],\n",
      "        [ 2.9707],\n",
      "        [ 2.3171],\n",
      "        [ 1.8552],\n",
      "        [ 6.1915],\n",
      "        [ 7.4703],\n",
      "        [-8.8928],\n",
      "        [13.9866],\n",
      "        [ 8.1245],\n",
      "        [15.3140]])\n",
      "tensor([[ 0.0051],\n",
      "        [-0.0108],\n",
      "        [ 0.0177],\n",
      "        [ 0.0081],\n",
      "        [ 0.0136],\n",
      "        [-0.0106],\n",
      "        [ 0.0119],\n",
      "        [ 0.0023],\n",
      "        [-0.0232],\n",
      "        [ 0.0269]], grad_fn=<AddmmBackward0>) tensor([[-4.6837],\n",
      "        [ 3.3792],\n",
      "        [-8.4739],\n",
      "        [ 8.6622],\n",
      "        [13.7238],\n",
      "        [-5.5292],\n",
      "        [-6.0347],\n",
      "        [-3.4718],\n",
      "        [18.0591],\n",
      "        [-1.5139]])\n",
      "tensor([[ 0.0106],\n",
      "        [-0.0237],\n",
      "        [-0.0235],\n",
      "        [-0.0286],\n",
      "        [-0.0156],\n",
      "        [-0.0155],\n",
      "        [-0.0193],\n",
      "        [-0.0022],\n",
      "        [-0.0053],\n",
      "        [ 0.0372]], grad_fn=<AddmmBackward0>) tensor([[ -1.0499],\n",
      "        [ 17.5784],\n",
      "        [ -1.5502],\n",
      "        [ 23.0814],\n",
      "        [  5.6195],\n",
      "        [  9.7252],\n",
      "        [ 13.7123],\n",
      "        [ -0.4293],\n",
      "        [  1.8010],\n",
      "        [-12.2554]])\n",
      "tensor([[-1.4408e-02],\n",
      "        [-1.2994e-02],\n",
      "        [-2.0003e-02],\n",
      "        [ 2.4027e-02],\n",
      "        [-2.1177e-02],\n",
      "        [-9.6972e-05],\n",
      "        [-2.2669e-02],\n",
      "        [-4.4895e-03],\n",
      "        [ 6.5786e-03],\n",
      "        [ 3.4700e-02]], grad_fn=<AddmmBackward0>) tensor([[27.3003],\n",
      "        [ 3.9812],\n",
      "        [14.8411],\n",
      "        [-5.9998],\n",
      "        [19.7562],\n",
      "        [11.8240],\n",
      "        [20.6336],\n",
      "        [ 6.1968],\n",
      "        [-0.9997],\n",
      "        [-8.4395]])\n",
      "tensor([[-0.0319],\n",
      "        [-0.0075],\n",
      "        [ 0.0002],\n",
      "        [-0.0060],\n",
      "        [ 0.0177],\n",
      "        [ 0.0129],\n",
      "        [-0.0298],\n",
      "        [ 0.0010],\n",
      "        [ 0.0099],\n",
      "        [ 0.0108]], grad_fn=<AddmmBackward0>) tensor([[21.0561],\n",
      "        [19.0597],\n",
      "        [-8.2876],\n",
      "        [10.8721],\n",
      "        [-6.6806],\n",
      "        [-2.9813],\n",
      "        [11.3203],\n",
      "        [ 4.5020],\n",
      "        [ 2.4436],\n",
      "        [ 1.6558]])\n",
      "tensor([[ 0.0072],\n",
      "        [-0.0157],\n",
      "        [ 0.0275],\n",
      "        [-0.0066],\n",
      "        [-0.0024],\n",
      "        [ 0.0115],\n",
      "        [-0.0026],\n",
      "        [-0.0218],\n",
      "        [-0.0155],\n",
      "        [-0.0048]], grad_fn=<AddmmBackward0>) tensor([[ 3.9257],\n",
      "        [-1.1225],\n",
      "        [-8.2063],\n",
      "        [ 1.4707],\n",
      "        [17.6693],\n",
      "        [ 6.1214],\n",
      "        [14.4080],\n",
      "        [13.2289],\n",
      "        [ 6.7127],\n",
      "        [-5.0861]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(net(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de7f78e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step4: Define model &amp;amp;amp; initialization\n",
    " \n",
    "# Create a single layer feed-forward network with 2 inputs and 1 outputs.\n",
    " \n",
    "net = nn.Linear(3, 1)\n",
    " \n",
    "\n",
    " \n",
    "#Initialize model params\n",
    " \n",
    "net.weight.data.normal_(0, 0.01)\n",
    " \n",
    "net.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eeab26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01c3a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "#Step 6: Define optimization algorithm\n",
    "# implements a stochastic gradient descent optimization method\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "57d21fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# back propagation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# parameter update\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(net(\u001b[43mfeatures\u001b[49m), labels)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    " \n",
    "    for X, y in data_iter:\n",
    " \n",
    "        l = loss(net(X) ,y)\n",
    " \n",
    "        trainer.zero_grad() #sets gradients to zero\n",
    " \n",
    "    l.backward() # back propagation\n",
    " \n",
    "    trainer.step() # parameter update\n",
    " \n",
    "    l = loss(net(features), labels)\n",
    " \n",
    "print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ab21e",
   "metadata": {},
   "source": [
    "# batch \n",
    "* https://deeplizard.com/learn/video/U4WB9p6ODjM\n",
    "* https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/\n",
    "* https://www.baeldung.com/cs/epoch-vs-batch-vs-mini-batch\n",
    "* https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "* https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/\n",
    "* https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n",
    "* https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf587501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
