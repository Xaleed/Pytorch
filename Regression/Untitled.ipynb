{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 681,
   "id": "2e3dd01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "8e13f56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179300"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7200+55600+68600+47900"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa28f42e",
   "metadata": {},
   "source": [
    "# Create a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "id": "144d8bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.random.normal(0, 1, size=(100, 1)) \n",
    "X2 = np.random.normal(0, 1, size=(100, 1)) \n",
    "X3 = np.random.normal(0,1 , size=(100, 1)) \n",
    "Y = 1*X1+2*X2+4*X3+3 + np.random.normal(0,1 , size=(100, 1))\n",
    "X = np.hstack((X1,X2, X3))\n",
    "X_Train = Variable(torch.Tensor(X))\n",
    "Y_Train = Variable(torch.Tensor(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "id": "25f967fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.796653</td>\n",
       "      <td>0.261292</td>\n",
       "      <td>0.707335</td>\n",
       "      <td>6.246750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.012962</td>\n",
       "      <td>0.015452</td>\n",
       "      <td>-0.232989</td>\n",
       "      <td>1.496483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.692559</td>\n",
       "      <td>-0.163414</td>\n",
       "      <td>-1.929627</td>\n",
       "      <td>-1.429067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.367617</td>\n",
       "      <td>-0.252074</td>\n",
       "      <td>0.522062</td>\n",
       "      <td>5.764367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.141039</td>\n",
       "      <td>-0.686807</td>\n",
       "      <td>-0.892543</td>\n",
       "      <td>-2.969211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-1.702592</td>\n",
       "      <td>-0.196430</td>\n",
       "      <td>0.896199</td>\n",
       "      <td>4.547389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.290724</td>\n",
       "      <td>0.319295</td>\n",
       "      <td>-0.887759</td>\n",
       "      <td>-1.776310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-0.848191</td>\n",
       "      <td>0.523350</td>\n",
       "      <td>-0.114807</td>\n",
       "      <td>3.020802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-0.782181</td>\n",
       "      <td>-1.282353</td>\n",
       "      <td>-2.565802</td>\n",
       "      <td>-11.334153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.401314</td>\n",
       "      <td>-1.975148</td>\n",
       "      <td>0.064807</td>\n",
       "      <td>-0.466198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          X1        X2        X3          Y\n",
       "0  -0.796653  0.261292  0.707335   6.246750\n",
       "1  -0.012962  0.015452 -0.232989   1.496483\n",
       "2   0.692559 -0.163414 -1.929627  -1.429067\n",
       "3   0.367617 -0.252074  0.522062   5.764367\n",
       "4  -0.141039 -0.686807 -0.892543  -2.969211\n",
       "..       ...       ...       ...        ...\n",
       "95 -1.702592 -0.196430  0.896199   4.547389\n",
       "96  0.290724  0.319295 -0.887759  -1.776310\n",
       "97 -0.848191  0.523350 -0.114807   3.020802\n",
       "98 -0.782181 -1.282353 -2.565802 -11.334153\n",
       "99  0.401314 -1.975148  0.064807  -0.466198\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\"X1\" : X1[:,0],\"X2\" : X2[:,0],\"X3\" : X3[:,0], \"Y\":Y[:,0]}\n",
    "df = pd.DataFrame(data)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "id": "4d94308f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.904996</td>\n",
       "      <td>1.601225</td>\n",
       "      <td>-1.160352</td>\n",
       "      <td>0.656045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.408843</td>\n",
       "      <td>0.557574</td>\n",
       "      <td>0.589575</td>\n",
       "      <td>6.064606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.573054</td>\n",
       "      <td>0.939472</td>\n",
       "      <td>0.345655</td>\n",
       "      <td>6.834617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.081524</td>\n",
       "      <td>0.292687</td>\n",
       "      <td>-0.205934</td>\n",
       "      <td>1.680111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.427468</td>\n",
       "      <td>0.362836</td>\n",
       "      <td>1.505525</td>\n",
       "      <td>9.320303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.830238</td>\n",
       "      <td>0.831841</td>\n",
       "      <td>1.301149</td>\n",
       "      <td>9.038044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.264081</td>\n",
       "      <td>0.148189</td>\n",
       "      <td>-1.074924</td>\n",
       "      <td>1.260763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.999624</td>\n",
       "      <td>0.353115</td>\n",
       "      <td>-0.603923</td>\n",
       "      <td>3.290163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.744615</td>\n",
       "      <td>1.324343</td>\n",
       "      <td>-0.352554</td>\n",
       "      <td>4.983086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.454596</td>\n",
       "      <td>1.939948</td>\n",
       "      <td>0.498064</td>\n",
       "      <td>9.326749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X1        X2        X3         Y\n",
       "0   -0.904996  1.601225 -1.160352  0.656045\n",
       "1   -0.408843  0.557574  0.589575  6.064606\n",
       "2    0.573054  0.939472  0.345655  6.834617\n",
       "3   -1.081524  0.292687 -0.205934  1.680111\n",
       "4   -0.427468  0.362836  1.505525  9.320303\n",
       "..        ...       ...       ...       ...\n",
       "995 -0.830238  0.831841  1.301149  9.038044\n",
       "996  2.264081  0.148189 -1.074924  1.260763\n",
       "997  1.999624  0.353115 -0.603923  3.290163\n",
       "998  0.744615  1.324343 -0.352554  4.983086\n",
       "999  0.454596  1.939948  0.498064  9.326749\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = torch.normal(0, 1, (1000, 3))\n",
    "y = torch.matmul(X, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0, torch.Size([1000]))/1000000\n",
    "############\n",
    "Y = y.reshape((-1, 1))\n",
    "X_Train = X\n",
    "Y_Train = Y\n",
    "data = {\"X1\" : X.numpy()[:,0],\"X2\" : X.numpy()[:,1],\"X3\" : X.numpy()[:,2], \"Y\":y}\n",
    "df = pd.DataFrame(data)  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "id": "e25f267e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train  = torch.normal(0, 1, (1000, 3))\n",
    "y = torch.matmul(X, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0, torch.Size([1000]))/100000\n",
    "############\n",
    "Y_Train = y.reshape((-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31273ef0",
   "metadata": {},
   "source": [
    "# Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "id": "b8311728",
   "metadata": {},
   "outputs": [],
   "source": [
    "InputDim = 3\n",
    "OutputDim = 1\n",
    "class LinearRegression(torch.nn.Module):\n",
    "    def __init__(self): \n",
    "        super(LinearRegression, self).__init__() \n",
    "        self.linear = torch.nn.Linear(InputDim, OutputDim)  \n",
    "    def forward(self, x): \n",
    "        predict_y = self.linear(x) \n",
    "        return predict_y \n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c055deb",
   "metadata": {},
   "source": [
    "# Define the Loss Function and an Optimization Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "id": "8ab3babf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define_criterion = torch.nn.MSELoss(size_average=False) replace with:\n",
    "criterion = torch.nn.MSELoss( reduction='sum')\n",
    "Optimizer = torch.optim.SGD(linear_model.parameters(), lr=0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "7507bf7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss function 29134.08203125\n",
      "epoch 1, loss function 29108.859375\n",
      "epoch 2, loss function 29083.73828125\n",
      "epoch 3, loss function 29058.716796875\n",
      "epoch 4, loss function 29033.794921875\n",
      "epoch 5, loss function 29008.97265625\n",
      "epoch 6, loss function 28984.248046875\n",
      "epoch 7, loss function 28959.625\n",
      "epoch 8, loss function 28935.095703125\n",
      "epoch 9, loss function 28910.66796875\n",
      "epoch 10, loss function 28886.33203125\n",
      "epoch 11, loss function 28862.09765625\n",
      "epoch 12, loss function 28837.958984375\n",
      "epoch 13, loss function 28813.9140625\n",
      "epoch 14, loss function 28789.96484375\n",
      "epoch 15, loss function 28766.11328125\n",
      "epoch 16, loss function 28742.357421875\n",
      "epoch 17, loss function 28718.693359375\n",
      "epoch 18, loss function 28695.125\n",
      "epoch 19, loss function 28671.650390625\n",
      "epoch 20, loss function 28648.271484375\n",
      "epoch 21, loss function 28624.984375\n",
      "epoch 22, loss function 28601.783203125\n",
      "epoch 23, loss function 28578.6796875\n",
      "epoch 24, loss function 28555.669921875\n",
      "epoch 25, loss function 28532.75\n",
      "epoch 26, loss function 28509.919921875\n",
      "epoch 27, loss function 28487.18359375\n",
      "epoch 28, loss function 28464.53515625\n",
      "epoch 29, loss function 28441.978515625\n",
      "epoch 30, loss function 28419.509765625\n",
      "epoch 31, loss function 28397.13671875\n",
      "epoch 32, loss function 28374.84375\n",
      "epoch 33, loss function 28352.640625\n",
      "epoch 34, loss function 28330.529296875\n",
      "epoch 35, loss function 28308.505859375\n",
      "epoch 36, loss function 28286.5703125\n",
      "epoch 37, loss function 28264.720703125\n",
      "epoch 38, loss function 28242.95703125\n",
      "epoch 39, loss function 28221.28125\n",
      "epoch 40, loss function 28199.69140625\n",
      "epoch 41, loss function 28178.185546875\n",
      "epoch 42, loss function 28156.76953125\n",
      "epoch 43, loss function 28135.43359375\n",
      "epoch 44, loss function 28114.1875\n",
      "epoch 45, loss function 28093.021484375\n",
      "epoch 46, loss function 28071.94140625\n",
      "epoch 47, loss function 28050.943359375\n",
      "epoch 48, loss function 28030.03515625\n",
      "epoch 49, loss function 28009.205078125\n",
      "epoch 50, loss function 27988.45703125\n",
      "epoch 51, loss function 27967.79296875\n",
      "epoch 52, loss function 27947.2109375\n",
      "epoch 53, loss function 27926.7109375\n",
      "epoch 54, loss function 27906.29296875\n",
      "epoch 55, loss function 27885.953125\n",
      "epoch 56, loss function 27865.697265625\n",
      "epoch 57, loss function 27845.521484375\n",
      "epoch 58, loss function 27825.423828125\n",
      "epoch 59, loss function 27805.40625\n",
      "epoch 60, loss function 27785.46875\n",
      "epoch 61, loss function 27765.61328125\n",
      "epoch 62, loss function 27745.833984375\n",
      "epoch 63, loss function 27726.134765625\n",
      "epoch 64, loss function 27706.509765625\n",
      "epoch 65, loss function 27686.96875\n",
      "epoch 66, loss function 27667.501953125\n",
      "epoch 67, loss function 27648.11328125\n",
      "epoch 68, loss function 27628.802734375\n",
      "epoch 69, loss function 27609.568359375\n",
      "epoch 70, loss function 27590.412109375\n",
      "epoch 71, loss function 27571.328125\n",
      "epoch 72, loss function 27552.318359375\n",
      "epoch 73, loss function 27533.390625\n",
      "epoch 74, loss function 27514.533203125\n",
      "epoch 75, loss function 27495.751953125\n",
      "epoch 76, loss function 27477.046875\n",
      "epoch 77, loss function 27458.41015625\n",
      "epoch 78, loss function 27439.85546875\n",
      "epoch 79, loss function 27421.37109375\n",
      "epoch 80, loss function 27402.95703125\n",
      "epoch 81, loss function 27384.62109375\n",
      "epoch 82, loss function 27366.35546875\n",
      "epoch 83, loss function 27348.1640625\n",
      "epoch 84, loss function 27330.041015625\n",
      "epoch 85, loss function 27311.998046875\n",
      "epoch 86, loss function 27294.01953125\n",
      "epoch 87, loss function 27276.111328125\n",
      "epoch 88, loss function 27258.27734375\n",
      "epoch 89, loss function 27240.515625\n",
      "epoch 90, loss function 27222.822265625\n",
      "epoch 91, loss function 27205.19921875\n",
      "epoch 92, loss function 27187.646484375\n",
      "epoch 93, loss function 27170.162109375\n",
      "epoch 94, loss function 27152.75\n",
      "epoch 95, loss function 27135.40625\n",
      "epoch 96, loss function 27118.12890625\n",
      "epoch 97, loss function 27100.921875\n",
      "epoch 98, loss function 27083.783203125\n",
      "epoch 99, loss function 27066.71484375\n",
      "epoch 100, loss function 27049.7109375\n",
      "epoch 101, loss function 27032.775390625\n",
      "epoch 102, loss function 27015.904296875\n",
      "epoch 103, loss function 26999.103515625\n",
      "epoch 104, loss function 26982.369140625\n",
      "epoch 105, loss function 26965.701171875\n",
      "epoch 106, loss function 26949.09765625\n",
      "epoch 107, loss function 26932.560546875\n",
      "epoch 108, loss function 26916.091796875\n",
      "epoch 109, loss function 26899.685546875\n",
      "epoch 110, loss function 26883.34765625\n",
      "epoch 111, loss function 26867.0703125\n",
      "epoch 112, loss function 26850.859375\n",
      "epoch 113, loss function 26834.712890625\n",
      "epoch 114, loss function 26818.630859375\n",
      "epoch 115, loss function 26802.611328125\n",
      "epoch 116, loss function 26786.65625\n",
      "epoch 117, loss function 26770.763671875\n",
      "epoch 118, loss function 26754.9375\n",
      "epoch 119, loss function 26739.171875\n",
      "epoch 120, loss function 26723.466796875\n",
      "epoch 121, loss function 26707.82421875\n",
      "epoch 122, loss function 26692.24609375\n",
      "epoch 123, loss function 26676.728515625\n",
      "epoch 124, loss function 26661.2734375\n",
      "epoch 125, loss function 26645.87890625\n",
      "epoch 126, loss function 26630.544921875\n",
      "epoch 127, loss function 26615.2734375\n",
      "epoch 128, loss function 26600.05859375\n",
      "epoch 129, loss function 26584.908203125\n",
      "epoch 130, loss function 26569.814453125\n",
      "epoch 131, loss function 26554.78515625\n",
      "epoch 132, loss function 26539.8125\n",
      "epoch 133, loss function 26524.90234375\n",
      "epoch 134, loss function 26510.044921875\n",
      "epoch 135, loss function 26495.25\n",
      "epoch 136, loss function 26480.515625\n",
      "epoch 137, loss function 26465.837890625\n",
      "epoch 138, loss function 26451.21484375\n",
      "epoch 139, loss function 26436.65625\n",
      "epoch 140, loss function 26422.15234375\n",
      "epoch 141, loss function 26407.703125\n",
      "epoch 142, loss function 26393.314453125\n",
      "epoch 143, loss function 26378.982421875\n",
      "epoch 144, loss function 26364.70703125\n",
      "epoch 145, loss function 26350.48828125\n",
      "epoch 146, loss function 26336.328125\n",
      "epoch 147, loss function 26322.220703125\n",
      "epoch 148, loss function 26308.16796875\n",
      "epoch 149, loss function 26294.17578125\n",
      "epoch 150, loss function 26280.236328125\n",
      "epoch 151, loss function 26266.353515625\n",
      "epoch 152, loss function 26252.5234375\n",
      "epoch 153, loss function 26238.75\n",
      "epoch 154, loss function 26225.02734375\n",
      "epoch 155, loss function 26211.36328125\n",
      "epoch 156, loss function 26197.75390625\n",
      "epoch 157, loss function 26184.1953125\n",
      "epoch 158, loss function 26170.69140625\n",
      "epoch 159, loss function 26157.2421875\n",
      "epoch 160, loss function 26143.845703125\n",
      "epoch 161, loss function 26130.5\n",
      "epoch 162, loss function 26117.208984375\n",
      "epoch 163, loss function 26103.97265625\n",
      "epoch 164, loss function 26090.787109375\n",
      "epoch 165, loss function 26077.65234375\n",
      "epoch 166, loss function 26064.5703125\n",
      "epoch 167, loss function 26051.5390625\n",
      "epoch 168, loss function 26038.5625\n",
      "epoch 169, loss function 26025.63671875\n",
      "epoch 170, loss function 26012.7578125\n",
      "epoch 171, loss function 25999.935546875\n",
      "epoch 172, loss function 25987.162109375\n",
      "epoch 173, loss function 25974.4375\n",
      "epoch 174, loss function 25961.765625\n",
      "epoch 175, loss function 25949.140625\n",
      "epoch 176, loss function 25936.568359375\n",
      "epoch 177, loss function 25924.048828125\n",
      "epoch 178, loss function 25911.572265625\n",
      "epoch 179, loss function 25899.15234375\n",
      "epoch 180, loss function 25886.775390625\n",
      "epoch 181, loss function 25874.44921875\n",
      "epoch 182, loss function 25862.171875\n",
      "epoch 183, loss function 25849.9453125\n",
      "epoch 184, loss function 25837.763671875\n",
      "epoch 185, loss function 25825.630859375\n",
      "epoch 186, loss function 25813.548828125\n",
      "epoch 187, loss function 25801.513671875\n",
      "epoch 188, loss function 25789.525390625\n",
      "epoch 189, loss function 25777.583984375\n",
      "epoch 190, loss function 25765.6875\n",
      "epoch 191, loss function 25753.84375\n",
      "epoch 192, loss function 25742.041015625\n",
      "epoch 193, loss function 25730.2890625\n",
      "epoch 194, loss function 25718.583984375\n",
      "epoch 195, loss function 25706.923828125\n",
      "epoch 196, loss function 25695.310546875\n",
      "epoch 197, loss function 25683.7421875\n",
      "epoch 198, loss function 25672.220703125\n",
      "epoch 199, loss function 25660.7421875\n",
      "epoch 200, loss function 25649.310546875\n",
      "epoch 201, loss function 25637.923828125\n",
      "epoch 202, loss function 25626.58203125\n",
      "epoch 203, loss function 25615.287109375\n",
      "epoch 204, loss function 25604.03515625\n",
      "epoch 205, loss function 25592.828125\n",
      "epoch 206, loss function 25581.66796875\n",
      "epoch 207, loss function 25570.546875\n",
      "epoch 208, loss function 25559.47265625\n",
      "epoch 209, loss function 25548.443359375\n",
      "epoch 210, loss function 25537.455078125\n",
      "epoch 211, loss function 25526.51171875\n",
      "epoch 212, loss function 25515.611328125\n",
      "epoch 213, loss function 25504.75390625\n",
      "epoch 214, loss function 25493.939453125\n",
      "epoch 215, loss function 25483.166015625\n",
      "epoch 216, loss function 25472.44140625\n",
      "epoch 217, loss function 25461.75390625\n",
      "epoch 218, loss function 25451.109375\n",
      "epoch 219, loss function 25440.505859375\n",
      "epoch 220, loss function 25429.9453125\n",
      "epoch 221, loss function 25419.42578125\n",
      "epoch 222, loss function 25408.94921875\n",
      "epoch 223, loss function 25398.51171875\n",
      "epoch 224, loss function 25388.12109375\n",
      "epoch 225, loss function 25377.765625\n",
      "epoch 226, loss function 25367.45703125\n",
      "epoch 227, loss function 25357.181640625\n",
      "epoch 228, loss function 25346.953125\n",
      "epoch 229, loss function 25336.763671875\n",
      "epoch 230, loss function 25326.609375\n",
      "epoch 231, loss function 25316.501953125\n",
      "epoch 232, loss function 25306.431640625\n",
      "epoch 233, loss function 25296.400390625\n",
      "epoch 234, loss function 25286.408203125\n",
      "epoch 235, loss function 25276.45703125\n",
      "epoch 236, loss function 25266.548828125\n",
      "epoch 237, loss function 25256.67578125\n",
      "epoch 238, loss function 25246.83984375\n",
      "epoch 239, loss function 25237.046875\n",
      "epoch 240, loss function 25227.2890625\n",
      "epoch 241, loss function 25217.5703125\n",
      "epoch 242, loss function 25207.892578125\n",
      "epoch 243, loss function 25198.25390625\n",
      "epoch 244, loss function 25188.650390625\n",
      "epoch 245, loss function 25179.083984375\n",
      "epoch 246, loss function 25169.556640625\n",
      "epoch 247, loss function 25160.068359375\n",
      "epoch 248, loss function 25150.6171875\n",
      "epoch 249, loss function 25141.201171875\n",
      "epoch 250, loss function 25131.82421875\n",
      "epoch 251, loss function 25122.482421875\n",
      "epoch 252, loss function 25113.1796875\n",
      "epoch 253, loss function 25103.9140625\n",
      "epoch 254, loss function 25094.68359375\n",
      "epoch 255, loss function 25085.48828125\n",
      "epoch 256, loss function 25076.330078125\n",
      "epoch 257, loss function 25067.2109375\n",
      "epoch 258, loss function 25058.12109375\n",
      "epoch 259, loss function 25049.07421875\n",
      "epoch 260, loss function 25040.060546875\n",
      "epoch 261, loss function 25031.08203125\n",
      "epoch 262, loss function 25022.140625\n",
      "epoch 263, loss function 25013.234375\n",
      "epoch 264, loss function 25004.361328125\n",
      "epoch 265, loss function 24995.525390625\n",
      "epoch 266, loss function 24986.720703125\n",
      "epoch 267, loss function 24977.953125\n",
      "epoch 268, loss function 24969.22265625\n",
      "epoch 269, loss function 24960.5234375\n",
      "epoch 270, loss function 24951.859375\n",
      "epoch 271, loss function 24943.228515625\n",
      "epoch 272, loss function 24934.6328125\n",
      "epoch 273, loss function 24926.072265625\n",
      "epoch 274, loss function 24917.54296875\n",
      "epoch 275, loss function 24909.048828125\n",
      "epoch 276, loss function 24900.587890625\n",
      "epoch 277, loss function 24892.16015625\n",
      "epoch 278, loss function 24883.763671875\n",
      "epoch 279, loss function 24875.404296875\n",
      "epoch 280, loss function 24867.076171875\n",
      "epoch 281, loss function 24858.783203125\n",
      "epoch 282, loss function 24850.51953125\n",
      "epoch 283, loss function 24842.2890625\n",
      "epoch 284, loss function 24834.091796875\n",
      "epoch 285, loss function 24825.927734375\n",
      "epoch 286, loss function 24817.79296875\n",
      "epoch 287, loss function 24809.693359375\n",
      "epoch 288, loss function 24801.623046875\n",
      "epoch 289, loss function 24793.5859375\n",
      "epoch 290, loss function 24785.580078125\n",
      "epoch 291, loss function 24777.607421875\n",
      "epoch 292, loss function 24769.6640625\n",
      "epoch 293, loss function 24761.75390625\n",
      "epoch 294, loss function 24753.875\n",
      "epoch 295, loss function 24746.025390625\n",
      "epoch 296, loss function 24738.20703125\n",
      "epoch 297, loss function 24730.421875\n",
      "epoch 298, loss function 24722.662109375\n",
      "epoch 299, loss function 24714.9375\n",
      "epoch 300, loss function 24707.2421875\n",
      "epoch 301, loss function 24699.580078125\n",
      "epoch 302, loss function 24691.9453125\n",
      "epoch 303, loss function 24684.341796875\n",
      "epoch 304, loss function 24676.765625\n",
      "epoch 305, loss function 24669.220703125\n",
      "epoch 306, loss function 24661.70703125\n",
      "epoch 307, loss function 24654.22265625\n",
      "epoch 308, loss function 24646.763671875\n",
      "epoch 309, loss function 24639.337890625\n",
      "epoch 310, loss function 24631.943359375\n",
      "epoch 311, loss function 24624.576171875\n",
      "epoch 312, loss function 24617.234375\n",
      "epoch 313, loss function 24609.923828125\n",
      "epoch 314, loss function 24602.64453125\n",
      "epoch 315, loss function 24595.390625\n",
      "epoch 316, loss function 24588.16796875\n",
      "epoch 317, loss function 24580.97265625\n",
      "epoch 318, loss function 24573.8046875\n",
      "epoch 319, loss function 24566.666015625\n",
      "epoch 320, loss function 24559.556640625\n",
      "epoch 321, loss function 24552.470703125\n",
      "epoch 322, loss function 24545.416015625\n",
      "epoch 323, loss function 24538.392578125\n",
      "epoch 324, loss function 24531.390625\n",
      "epoch 325, loss function 24524.421875\n",
      "epoch 326, loss function 24517.4765625\n",
      "epoch 327, loss function 24510.55859375\n",
      "epoch 328, loss function 24503.671875\n",
      "epoch 329, loss function 24496.806640625\n",
      "epoch 330, loss function 24489.97265625\n",
      "epoch 331, loss function 24483.166015625\n",
      "epoch 332, loss function 24476.3828125\n",
      "epoch 333, loss function 24469.626953125\n",
      "epoch 334, loss function 24462.8984375\n",
      "epoch 335, loss function 24456.197265625\n",
      "epoch 336, loss function 24449.5234375\n",
      "epoch 337, loss function 24442.873046875\n",
      "epoch 338, loss function 24436.25\n",
      "epoch 339, loss function 24429.65234375\n",
      "epoch 340, loss function 24423.083984375\n",
      "epoch 341, loss function 24416.5390625\n",
      "epoch 342, loss function 24410.01953125\n",
      "epoch 343, loss function 24403.52734375\n",
      "epoch 344, loss function 24397.05859375\n",
      "epoch 345, loss function 24390.61328125\n",
      "epoch 346, loss function 24384.197265625\n",
      "epoch 347, loss function 24377.806640625\n",
      "epoch 348, loss function 24371.439453125\n",
      "epoch 349, loss function 24365.09765625\n",
      "epoch 350, loss function 24358.78125\n",
      "epoch 351, loss function 24352.48828125\n",
      "epoch 352, loss function 24346.22265625\n",
      "epoch 353, loss function 24339.98046875\n",
      "epoch 354, loss function 24333.76171875\n",
      "epoch 355, loss function 24327.568359375\n",
      "epoch 356, loss function 24321.400390625\n",
      "epoch 357, loss function 24315.2578125\n",
      "epoch 358, loss function 24309.13671875\n",
      "epoch 359, loss function 24303.0390625\n",
      "epoch 360, loss function 24296.96875\n",
      "epoch 361, loss function 24290.91796875\n",
      "epoch 362, loss function 24284.892578125\n",
      "epoch 363, loss function 24278.89453125\n",
      "epoch 364, loss function 24272.91796875\n",
      "epoch 365, loss function 24266.962890625\n",
      "epoch 366, loss function 24261.033203125\n",
      "epoch 367, loss function 24255.125\n",
      "epoch 368, loss function 24249.240234375\n",
      "epoch 369, loss function 24243.380859375\n",
      "epoch 370, loss function 24237.54296875\n",
      "epoch 371, loss function 24231.728515625\n",
      "epoch 372, loss function 24225.9375\n",
      "epoch 373, loss function 24220.169921875\n",
      "epoch 374, loss function 24214.419921875\n",
      "epoch 375, loss function 24208.69921875\n",
      "epoch 376, loss function 24202.99609375\n",
      "epoch 377, loss function 24197.31640625\n",
      "epoch 378, loss function 24191.662109375\n",
      "epoch 379, loss function 24186.029296875\n",
      "epoch 380, loss function 24180.4140625\n",
      "epoch 381, loss function 24174.826171875\n",
      "epoch 382, loss function 24169.2578125\n",
      "epoch 383, loss function 24163.71484375\n",
      "epoch 384, loss function 24158.189453125\n",
      "epoch 385, loss function 24152.68359375\n",
      "epoch 386, loss function 24147.203125\n",
      "epoch 387, loss function 24141.748046875\n",
      "epoch 388, loss function 24136.30859375\n",
      "epoch 389, loss function 24130.892578125\n",
      "epoch 390, loss function 24125.5\n",
      "epoch 391, loss function 24120.12109375\n",
      "epoch 392, loss function 24114.771484375\n",
      "epoch 393, loss function 24109.4375\n",
      "epoch 394, loss function 24104.125\n",
      "epoch 395, loss function 24098.837890625\n",
      "epoch 396, loss function 24093.5703125\n",
      "epoch 397, loss function 24088.3203125\n",
      "epoch 398, loss function 24083.09375\n",
      "epoch 399, loss function 24077.884765625\n",
      "epoch 400, loss function 24072.69921875\n",
      "epoch 401, loss function 24067.53515625\n",
      "epoch 402, loss function 24062.38671875\n",
      "epoch 403, loss function 24057.259765625\n",
      "epoch 404, loss function 24052.15625\n",
      "epoch 405, loss function 24047.0703125\n",
      "epoch 406, loss function 24042.00390625\n",
      "epoch 407, loss function 24036.958984375\n",
      "epoch 408, loss function 24031.935546875\n",
      "epoch 409, loss function 24026.927734375\n",
      "epoch 410, loss function 24021.939453125\n",
      "epoch 411, loss function 24016.97265625\n",
      "epoch 412, loss function 24012.025390625\n",
      "epoch 413, loss function 24007.099609375\n",
      "epoch 414, loss function 24002.19140625\n",
      "epoch 415, loss function 23997.30078125\n",
      "epoch 416, loss function 23992.431640625\n",
      "epoch 417, loss function 23987.580078125\n",
      "epoch 418, loss function 23982.75\n",
      "epoch 419, loss function 23977.93359375\n",
      "epoch 420, loss function 23973.142578125\n",
      "epoch 421, loss function 23968.3671875\n",
      "epoch 422, loss function 23963.611328125\n",
      "epoch 423, loss function 23958.875\n",
      "epoch 424, loss function 23954.154296875\n",
      "epoch 425, loss function 23949.455078125\n",
      "epoch 426, loss function 23944.771484375\n",
      "epoch 427, loss function 23940.109375\n",
      "epoch 428, loss function 23935.462890625\n",
      "epoch 429, loss function 23930.8359375\n",
      "epoch 430, loss function 23926.2265625\n",
      "epoch 431, loss function 23921.63671875\n",
      "epoch 432, loss function 23917.064453125\n",
      "epoch 433, loss function 23912.5078125\n",
      "epoch 434, loss function 23907.97265625\n",
      "epoch 435, loss function 23903.455078125\n",
      "epoch 436, loss function 23898.953125\n",
      "epoch 437, loss function 23894.46484375\n",
      "epoch 438, loss function 23890.0\n",
      "epoch 439, loss function 23885.5546875\n",
      "epoch 440, loss function 23881.12109375\n",
      "epoch 441, loss function 23876.70703125\n",
      "epoch 442, loss function 23872.3125\n",
      "epoch 443, loss function 23867.93359375\n",
      "epoch 444, loss function 23863.572265625\n",
      "epoch 445, loss function 23859.2265625\n",
      "epoch 446, loss function 23854.8984375\n",
      "epoch 447, loss function 23850.587890625\n",
      "epoch 448, loss function 23846.29296875\n",
      "epoch 449, loss function 23842.017578125\n",
      "epoch 450, loss function 23837.7578125\n",
      "epoch 451, loss function 23833.513671875\n",
      "epoch 452, loss function 23829.287109375\n",
      "epoch 453, loss function 23825.078125\n",
      "epoch 454, loss function 23820.8828125\n",
      "epoch 455, loss function 23816.70703125\n",
      "epoch 456, loss function 23812.544921875\n",
      "epoch 457, loss function 23808.400390625\n",
      "epoch 458, loss function 23804.275390625\n",
      "epoch 459, loss function 23800.16015625\n",
      "epoch 460, loss function 23796.064453125\n",
      "epoch 461, loss function 23791.982421875\n",
      "epoch 462, loss function 23787.919921875\n",
      "epoch 463, loss function 23783.87109375\n",
      "epoch 464, loss function 23779.83984375\n",
      "epoch 465, loss function 23775.826171875\n",
      "epoch 466, loss function 23771.82421875\n",
      "epoch 467, loss function 23767.837890625\n",
      "epoch 468, loss function 23763.87109375\n",
      "epoch 469, loss function 23759.91796875\n",
      "epoch 470, loss function 23755.978515625\n",
      "epoch 471, loss function 23752.0546875\n",
      "epoch 472, loss function 23748.1484375\n",
      "epoch 473, loss function 23744.255859375\n",
      "epoch 474, loss function 23740.380859375\n",
      "epoch 475, loss function 23736.517578125\n",
      "epoch 476, loss function 23732.671875\n",
      "epoch 477, loss function 23728.841796875\n",
      "epoch 478, loss function 23725.025390625\n",
      "epoch 479, loss function 23721.224609375\n",
      "epoch 480, loss function 23717.435546875\n",
      "epoch 481, loss function 23713.666015625\n",
      "epoch 482, loss function 23709.908203125\n",
      "epoch 483, loss function 23706.16796875\n",
      "epoch 484, loss function 23702.44140625\n",
      "epoch 485, loss function 23698.7265625\n",
      "epoch 486, loss function 23695.029296875\n",
      "epoch 487, loss function 23691.345703125\n",
      "epoch 488, loss function 23687.67578125\n",
      "epoch 489, loss function 23684.0234375\n",
      "epoch 490, loss function 23680.380859375\n",
      "epoch 491, loss function 23676.755859375\n",
      "epoch 492, loss function 23673.14453125\n",
      "epoch 493, loss function 23669.548828125\n",
      "epoch 494, loss function 23665.9609375\n",
      "epoch 495, loss function 23662.392578125\n",
      "epoch 496, loss function 23658.8359375\n",
      "epoch 497, loss function 23655.294921875\n",
      "epoch 498, loss function 23651.765625\n",
      "epoch 499, loss function 23648.25390625\n",
      "epoch 500, loss function 23644.75390625\n",
      "epoch 501, loss function 23641.265625\n",
      "epoch 502, loss function 23637.79296875\n",
      "epoch 503, loss function 23634.33203125\n",
      "epoch 504, loss function 23630.888671875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 505, loss function 23627.455078125\n",
      "epoch 506, loss function 23624.03515625\n",
      "epoch 507, loss function 23620.630859375\n",
      "epoch 508, loss function 23617.240234375\n",
      "epoch 509, loss function 23613.859375\n",
      "epoch 510, loss function 23610.49609375\n",
      "epoch 511, loss function 23607.140625\n",
      "epoch 512, loss function 23603.802734375\n",
      "epoch 513, loss function 23600.4765625\n",
      "epoch 514, loss function 23597.1640625\n",
      "epoch 515, loss function 23593.86328125\n",
      "epoch 516, loss function 23590.576171875\n",
      "epoch 517, loss function 23587.30078125\n",
      "epoch 518, loss function 23584.0390625\n",
      "epoch 519, loss function 23580.791015625\n",
      "epoch 520, loss function 23577.5546875\n",
      "epoch 521, loss function 23574.33203125\n",
      "epoch 522, loss function 23571.12109375\n",
      "epoch 523, loss function 23567.921875\n",
      "epoch 524, loss function 23564.73828125\n",
      "epoch 525, loss function 23561.564453125\n",
      "epoch 526, loss function 23558.40234375\n",
      "epoch 527, loss function 23555.255859375\n",
      "epoch 528, loss function 23552.119140625\n",
      "epoch 529, loss function 23548.99609375\n",
      "epoch 530, loss function 23545.88671875\n",
      "epoch 531, loss function 23542.787109375\n",
      "epoch 532, loss function 23539.69921875\n",
      "epoch 533, loss function 23536.623046875\n",
      "epoch 534, loss function 23533.560546875\n",
      "epoch 535, loss function 23530.5078125\n",
      "epoch 536, loss function 23527.470703125\n",
      "epoch 537, loss function 23524.443359375\n",
      "epoch 538, loss function 23521.42578125\n",
      "epoch 539, loss function 23518.42578125\n",
      "epoch 540, loss function 23515.431640625\n",
      "epoch 541, loss function 23512.451171875\n",
      "epoch 542, loss function 23509.484375\n",
      "epoch 543, loss function 23506.52734375\n",
      "epoch 544, loss function 23503.58203125\n",
      "epoch 545, loss function 23500.6484375\n",
      "epoch 546, loss function 23497.7265625\n",
      "epoch 547, loss function 23494.8125\n",
      "epoch 548, loss function 23491.91796875\n",
      "epoch 549, loss function 23489.02734375\n",
      "epoch 550, loss function 23486.150390625\n",
      "epoch 551, loss function 23483.28515625\n",
      "epoch 552, loss function 23480.4296875\n",
      "epoch 553, loss function 23477.5859375\n",
      "epoch 554, loss function 23474.75390625\n",
      "epoch 555, loss function 23471.93359375\n",
      "epoch 556, loss function 23469.123046875\n",
      "epoch 557, loss function 23466.32421875\n",
      "epoch 558, loss function 23463.53515625\n",
      "epoch 559, loss function 23460.7578125\n",
      "epoch 560, loss function 23457.994140625\n",
      "epoch 561, loss function 23455.23828125\n",
      "epoch 562, loss function 23452.4921875\n",
      "epoch 563, loss function 23449.7578125\n",
      "epoch 564, loss function 23447.037109375\n",
      "epoch 565, loss function 23444.322265625\n",
      "epoch 566, loss function 23441.623046875\n",
      "epoch 567, loss function 23438.9296875\n",
      "epoch 568, loss function 23436.25\n",
      "epoch 569, loss function 23433.578125\n",
      "epoch 570, loss function 23430.91796875\n",
      "epoch 571, loss function 23428.26953125\n",
      "epoch 572, loss function 23425.62890625\n",
      "epoch 573, loss function 23423.001953125\n",
      "epoch 574, loss function 23420.384765625\n",
      "epoch 575, loss function 23417.775390625\n",
      "epoch 576, loss function 23415.177734375\n",
      "epoch 577, loss function 23412.5859375\n",
      "epoch 578, loss function 23410.009765625\n",
      "epoch 579, loss function 23407.443359375\n",
      "epoch 580, loss function 23404.884765625\n",
      "epoch 581, loss function 23402.337890625\n",
      "epoch 582, loss function 23399.80078125\n",
      "epoch 583, loss function 23397.2734375\n",
      "epoch 584, loss function 23394.75390625\n",
      "epoch 585, loss function 23392.24609375\n",
      "epoch 586, loss function 23389.74609375\n",
      "epoch 587, loss function 23387.2578125\n",
      "epoch 588, loss function 23384.77734375\n",
      "epoch 589, loss function 23382.30859375\n",
      "epoch 590, loss function 23379.849609375\n",
      "epoch 591, loss function 23377.400390625\n",
      "epoch 592, loss function 23374.9609375\n",
      "epoch 593, loss function 23372.52734375\n",
      "epoch 594, loss function 23370.107421875\n",
      "epoch 595, loss function 23367.6953125\n",
      "epoch 596, loss function 23365.29296875\n",
      "epoch 597, loss function 23362.900390625\n",
      "epoch 598, loss function 23360.515625\n",
      "epoch 599, loss function 23358.140625\n",
      "epoch 600, loss function 23355.775390625\n",
      "epoch 601, loss function 23353.419921875\n",
      "epoch 602, loss function 23351.076171875\n",
      "epoch 603, loss function 23348.73828125\n",
      "epoch 604, loss function 23346.408203125\n",
      "epoch 605, loss function 23344.087890625\n",
      "epoch 606, loss function 23341.77734375\n",
      "epoch 607, loss function 23339.478515625\n",
      "epoch 608, loss function 23337.1875\n",
      "epoch 609, loss function 23334.900390625\n",
      "epoch 610, loss function 23332.626953125\n",
      "epoch 611, loss function 23330.36328125\n",
      "epoch 612, loss function 23328.107421875\n",
      "epoch 613, loss function 23325.859375\n",
      "epoch 614, loss function 23323.619140625\n",
      "epoch 615, loss function 23321.388671875\n",
      "epoch 616, loss function 23319.166015625\n",
      "epoch 617, loss function 23316.953125\n",
      "epoch 618, loss function 23314.751953125\n",
      "epoch 619, loss function 23312.5546875\n",
      "epoch 620, loss function 23310.3671875\n",
      "epoch 621, loss function 23308.1875\n",
      "epoch 622, loss function 23306.01953125\n",
      "epoch 623, loss function 23303.857421875\n",
      "epoch 624, loss function 23301.705078125\n",
      "epoch 625, loss function 23299.55859375\n",
      "epoch 626, loss function 23297.421875\n",
      "epoch 627, loss function 23295.294921875\n",
      "epoch 628, loss function 23293.173828125\n",
      "epoch 629, loss function 23291.064453125\n",
      "epoch 630, loss function 23288.9609375\n",
      "epoch 631, loss function 23286.8671875\n",
      "epoch 632, loss function 23284.779296875\n",
      "epoch 633, loss function 23282.69921875\n",
      "epoch 634, loss function 23280.62890625\n",
      "epoch 635, loss function 23278.56640625\n",
      "epoch 636, loss function 23276.515625\n",
      "epoch 637, loss function 23274.466796875\n",
      "epoch 638, loss function 23272.42578125\n",
      "epoch 639, loss function 23270.396484375\n",
      "epoch 640, loss function 23268.375\n",
      "epoch 641, loss function 23266.359375\n",
      "epoch 642, loss function 23264.353515625\n",
      "epoch 643, loss function 23262.353515625\n",
      "epoch 644, loss function 23260.365234375\n",
      "epoch 645, loss function 23258.37890625\n",
      "epoch 646, loss function 23256.404296875\n",
      "epoch 647, loss function 23254.43359375\n",
      "epoch 648, loss function 23252.474609375\n",
      "epoch 649, loss function 23250.5234375\n",
      "epoch 650, loss function 23248.578125\n",
      "epoch 651, loss function 23246.640625\n",
      "epoch 652, loss function 23244.7109375\n",
      "epoch 653, loss function 23242.787109375\n",
      "epoch 654, loss function 23240.873046875\n",
      "epoch 655, loss function 23238.96484375\n",
      "epoch 656, loss function 23237.06640625\n",
      "epoch 657, loss function 23235.17578125\n",
      "epoch 658, loss function 23233.287109375\n",
      "epoch 659, loss function 23231.41015625\n",
      "epoch 660, loss function 23229.5390625\n",
      "epoch 661, loss function 23227.67578125\n",
      "epoch 662, loss function 23225.8203125\n",
      "epoch 663, loss function 23223.96875\n",
      "epoch 664, loss function 23222.130859375\n",
      "epoch 665, loss function 23220.294921875\n",
      "epoch 666, loss function 23218.466796875\n",
      "epoch 667, loss function 23216.6484375\n",
      "epoch 668, loss function 23214.833984375\n",
      "epoch 669, loss function 23213.02734375\n",
      "epoch 670, loss function 23211.23046875\n",
      "epoch 671, loss function 23209.4375\n",
      "epoch 672, loss function 23207.65234375\n",
      "epoch 673, loss function 23205.875\n",
      "epoch 674, loss function 23204.103515625\n",
      "epoch 675, loss function 23202.33984375\n",
      "epoch 676, loss function 23200.58203125\n",
      "epoch 677, loss function 23198.83203125\n",
      "epoch 678, loss function 23197.08984375\n",
      "epoch 679, loss function 23195.3515625\n",
      "epoch 680, loss function 23193.62109375\n",
      "epoch 681, loss function 23191.8984375\n",
      "epoch 682, loss function 23190.1796875\n",
      "epoch 683, loss function 23188.47265625\n",
      "epoch 684, loss function 23186.771484375\n",
      "epoch 685, loss function 23185.072265625\n",
      "epoch 686, loss function 23183.3828125\n",
      "epoch 687, loss function 23181.697265625\n",
      "epoch 688, loss function 23180.01953125\n",
      "epoch 689, loss function 23178.3515625\n",
      "epoch 690, loss function 23176.6875\n",
      "epoch 691, loss function 23175.03125\n",
      "epoch 692, loss function 23173.37890625\n",
      "epoch 693, loss function 23171.736328125\n",
      "epoch 694, loss function 23170.09765625\n",
      "epoch 695, loss function 23168.466796875\n",
      "epoch 696, loss function 23166.83984375\n",
      "epoch 697, loss function 23165.21875\n",
      "epoch 698, loss function 23163.60546875\n",
      "epoch 699, loss function 23162.00390625\n",
      "epoch 700, loss function 23160.404296875\n",
      "epoch 701, loss function 23158.80859375\n",
      "epoch 702, loss function 23157.22265625\n",
      "epoch 703, loss function 23155.640625\n",
      "epoch 704, loss function 23154.064453125\n",
      "epoch 705, loss function 23152.49609375\n",
      "epoch 706, loss function 23150.931640625\n",
      "epoch 707, loss function 23149.375\n",
      "epoch 708, loss function 23147.822265625\n",
      "epoch 709, loss function 23146.279296875\n",
      "epoch 710, loss function 23144.73828125\n",
      "epoch 711, loss function 23143.20703125\n",
      "epoch 712, loss function 23141.6796875\n",
      "epoch 713, loss function 23140.158203125\n",
      "epoch 714, loss function 23138.64453125\n",
      "epoch 715, loss function 23137.13671875\n",
      "epoch 716, loss function 23135.6328125\n",
      "epoch 717, loss function 23134.1328125\n",
      "epoch 718, loss function 23132.642578125\n",
      "epoch 719, loss function 23131.15625\n",
      "epoch 720, loss function 23129.67578125\n",
      "epoch 721, loss function 23128.205078125\n",
      "epoch 722, loss function 23126.734375\n",
      "epoch 723, loss function 23125.26953125\n",
      "epoch 724, loss function 23123.8125\n",
      "epoch 725, loss function 23122.361328125\n",
      "epoch 726, loss function 23120.91796875\n",
      "epoch 727, loss function 23119.4765625\n",
      "epoch 728, loss function 23118.04296875\n",
      "epoch 729, loss function 23116.61328125\n",
      "epoch 730, loss function 23115.189453125\n",
      "epoch 731, loss function 23113.7734375\n",
      "epoch 732, loss function 23112.359375\n",
      "epoch 733, loss function 23110.953125\n",
      "epoch 734, loss function 23109.55078125\n",
      "epoch 735, loss function 23108.154296875\n",
      "epoch 736, loss function 23106.763671875\n",
      "epoch 737, loss function 23105.37890625\n",
      "epoch 738, loss function 23104.0\n",
      "epoch 739, loss function 23102.625\n",
      "epoch 740, loss function 23101.2578125\n",
      "epoch 741, loss function 23099.89453125\n",
      "epoch 742, loss function 23098.53515625\n",
      "epoch 743, loss function 23097.18359375\n",
      "epoch 744, loss function 23095.833984375\n",
      "epoch 745, loss function 23094.490234375\n",
      "epoch 746, loss function 23093.15234375\n",
      "epoch 747, loss function 23091.8203125\n",
      "epoch 748, loss function 23090.494140625\n",
      "epoch 749, loss function 23089.171875\n",
      "epoch 750, loss function 23087.85546875\n",
      "epoch 751, loss function 23086.54296875\n",
      "epoch 752, loss function 23085.23828125\n",
      "epoch 753, loss function 23083.9375\n",
      "epoch 754, loss function 23082.640625\n",
      "epoch 755, loss function 23081.34765625\n",
      "epoch 756, loss function 23080.0625\n",
      "epoch 757, loss function 23078.78125\n",
      "epoch 758, loss function 23077.50390625\n",
      "epoch 759, loss function 23076.234375\n",
      "epoch 760, loss function 23074.966796875\n",
      "epoch 761, loss function 23073.705078125\n",
      "epoch 762, loss function 23072.451171875\n",
      "epoch 763, loss function 23071.19921875\n",
      "epoch 764, loss function 23069.94921875\n",
      "epoch 765, loss function 23068.708984375\n",
      "epoch 766, loss function 23067.47265625\n",
      "epoch 767, loss function 23066.240234375\n",
      "epoch 768, loss function 23065.013671875\n",
      "epoch 769, loss function 23063.7890625\n",
      "epoch 770, loss function 23062.5703125\n",
      "epoch 771, loss function 23061.357421875\n",
      "epoch 772, loss function 23060.1484375\n",
      "epoch 773, loss function 23058.9453125\n",
      "epoch 774, loss function 23057.74609375\n",
      "epoch 775, loss function 23056.552734375\n",
      "epoch 776, loss function 23055.361328125\n",
      "epoch 777, loss function 23054.17578125\n",
      "epoch 778, loss function 23052.99609375\n",
      "epoch 779, loss function 23051.8203125\n",
      "epoch 780, loss function 23050.646484375\n",
      "epoch 781, loss function 23049.48046875\n",
      "epoch 782, loss function 23048.318359375\n",
      "epoch 783, loss function 23047.16015625\n",
      "epoch 784, loss function 23046.0078125\n",
      "epoch 785, loss function 23044.859375\n",
      "epoch 786, loss function 23043.71484375\n",
      "epoch 787, loss function 23042.57421875\n",
      "epoch 788, loss function 23041.4375\n",
      "epoch 789, loss function 23040.30859375\n",
      "epoch 790, loss function 23039.1796875\n",
      "epoch 791, loss function 23038.056640625\n",
      "epoch 792, loss function 23036.939453125\n",
      "epoch 793, loss function 23035.82421875\n",
      "epoch 794, loss function 23034.716796875\n",
      "epoch 795, loss function 23033.611328125\n",
      "epoch 796, loss function 23032.509765625\n",
      "epoch 797, loss function 23031.416015625\n",
      "epoch 798, loss function 23030.322265625\n",
      "epoch 799, loss function 23029.234375\n",
      "epoch 800, loss function 23028.150390625\n",
      "epoch 801, loss function 23027.0703125\n",
      "epoch 802, loss function 23025.99609375\n",
      "epoch 803, loss function 23024.921875\n",
      "epoch 804, loss function 23023.85546875\n",
      "epoch 805, loss function 23022.79296875\n",
      "epoch 806, loss function 23021.734375\n",
      "epoch 807, loss function 23020.6796875\n",
      "epoch 808, loss function 23019.630859375\n",
      "epoch 809, loss function 23018.583984375\n",
      "epoch 810, loss function 23017.54296875\n",
      "epoch 811, loss function 23016.501953125\n",
      "epoch 812, loss function 23015.46875\n",
      "epoch 813, loss function 23014.4375\n",
      "epoch 814, loss function 23013.412109375\n",
      "epoch 815, loss function 23012.388671875\n",
      "epoch 816, loss function 23011.37109375\n",
      "epoch 817, loss function 23010.357421875\n",
      "epoch 818, loss function 23009.345703125\n",
      "epoch 819, loss function 23008.337890625\n",
      "epoch 820, loss function 23007.3359375\n",
      "epoch 821, loss function 23006.337890625\n",
      "epoch 822, loss function 23005.341796875\n",
      "epoch 823, loss function 23004.3515625\n",
      "epoch 824, loss function 23003.365234375\n",
      "epoch 825, loss function 23002.380859375\n",
      "epoch 826, loss function 23001.400390625\n",
      "epoch 827, loss function 23000.42578125\n",
      "epoch 828, loss function 22999.451171875\n",
      "epoch 829, loss function 22998.484375\n",
      "epoch 830, loss function 22997.51953125\n",
      "epoch 831, loss function 22996.55859375\n",
      "epoch 832, loss function 22995.6015625\n",
      "epoch 833, loss function 22994.646484375\n",
      "epoch 834, loss function 22993.69921875\n",
      "epoch 835, loss function 22992.75390625\n",
      "epoch 836, loss function 22991.810546875\n",
      "epoch 837, loss function 22990.873046875\n",
      "epoch 838, loss function 22989.9375\n",
      "epoch 839, loss function 22989.005859375\n",
      "epoch 840, loss function 22988.076171875\n",
      "epoch 841, loss function 22987.154296875\n",
      "epoch 842, loss function 22986.232421875\n",
      "epoch 843, loss function 22985.31640625\n",
      "epoch 844, loss function 22984.40234375\n",
      "epoch 845, loss function 22983.4921875\n",
      "epoch 846, loss function 22982.5859375\n",
      "epoch 847, loss function 22981.685546875\n",
      "epoch 848, loss function 22980.783203125\n",
      "epoch 849, loss function 22979.88671875\n",
      "epoch 850, loss function 22978.99609375\n",
      "epoch 851, loss function 22978.109375\n",
      "epoch 852, loss function 22977.22265625\n",
      "epoch 853, loss function 22976.33984375\n",
      "epoch 854, loss function 22975.458984375\n",
      "epoch 855, loss function 22974.583984375\n",
      "epoch 856, loss function 22973.71484375\n",
      "epoch 857, loss function 22972.845703125\n",
      "epoch 858, loss function 22971.98046875\n",
      "epoch 859, loss function 22971.1171875\n",
      "epoch 860, loss function 22970.26171875\n",
      "epoch 861, loss function 22969.40625\n",
      "epoch 862, loss function 22968.552734375\n",
      "epoch 863, loss function 22967.705078125\n",
      "epoch 864, loss function 22966.859375\n",
      "epoch 865, loss function 22966.01953125\n",
      "epoch 866, loss function 22965.1796875\n",
      "epoch 867, loss function 22964.34375\n",
      "epoch 868, loss function 22963.51171875\n",
      "epoch 869, loss function 22962.68359375\n",
      "epoch 870, loss function 22961.857421875\n",
      "epoch 871, loss function 22961.03515625\n",
      "epoch 872, loss function 22960.21484375\n",
      "epoch 873, loss function 22959.400390625\n",
      "epoch 874, loss function 22958.5859375\n",
      "epoch 875, loss function 22957.775390625\n",
      "epoch 876, loss function 22956.970703125\n",
      "epoch 877, loss function 22956.16796875\n",
      "epoch 878, loss function 22955.365234375\n",
      "epoch 879, loss function 22954.568359375\n",
      "epoch 880, loss function 22953.7734375\n",
      "epoch 881, loss function 22952.982421875\n",
      "epoch 882, loss function 22952.193359375\n",
      "epoch 883, loss function 22951.408203125\n",
      "epoch 884, loss function 22950.626953125\n",
      "epoch 885, loss function 22949.84765625\n",
      "epoch 886, loss function 22949.072265625\n",
      "epoch 887, loss function 22948.298828125\n",
      "epoch 888, loss function 22947.529296875\n",
      "epoch 889, loss function 22946.76171875\n",
      "epoch 890, loss function 22945.998046875\n",
      "epoch 891, loss function 22945.23828125\n",
      "epoch 892, loss function 22944.478515625\n",
      "epoch 893, loss function 22943.72265625\n",
      "epoch 894, loss function 22942.97265625\n",
      "epoch 895, loss function 22942.21875\n",
      "epoch 896, loss function 22941.4765625\n",
      "epoch 897, loss function 22940.732421875\n",
      "epoch 898, loss function 22939.9921875\n",
      "epoch 899, loss function 22939.25390625\n",
      "epoch 900, loss function 22938.51953125\n",
      "epoch 901, loss function 22937.78515625\n",
      "epoch 902, loss function 22937.05859375\n",
      "epoch 903, loss function 22936.330078125\n",
      "epoch 904, loss function 22935.60546875\n",
      "epoch 905, loss function 22934.88671875\n",
      "epoch 906, loss function 22934.169921875\n",
      "epoch 907, loss function 22933.451171875\n",
      "epoch 908, loss function 22932.740234375\n",
      "epoch 909, loss function 22932.03125\n",
      "epoch 910, loss function 22931.32421875\n",
      "epoch 911, loss function 22930.619140625\n",
      "epoch 912, loss function 22929.91796875\n",
      "epoch 913, loss function 22929.21875\n",
      "epoch 914, loss function 22928.521484375\n",
      "epoch 915, loss function 22927.830078125\n",
      "epoch 916, loss function 22927.138671875\n",
      "epoch 917, loss function 22926.451171875\n",
      "epoch 918, loss function 22925.765625\n",
      "epoch 919, loss function 22925.080078125\n",
      "epoch 920, loss function 22924.40234375\n",
      "epoch 921, loss function 22923.724609375\n",
      "epoch 922, loss function 22923.05078125\n",
      "epoch 923, loss function 22922.37890625\n",
      "epoch 924, loss function 22921.70703125\n",
      "epoch 925, loss function 22921.0390625\n",
      "epoch 926, loss function 22920.375\n",
      "epoch 927, loss function 22919.71484375\n",
      "epoch 928, loss function 22919.052734375\n",
      "epoch 929, loss function 22918.3984375\n",
      "epoch 930, loss function 22917.7421875\n",
      "epoch 931, loss function 22917.091796875\n",
      "epoch 932, loss function 22916.443359375\n",
      "epoch 933, loss function 22915.796875\n",
      "epoch 934, loss function 22915.15234375\n",
      "epoch 935, loss function 22914.51171875\n",
      "epoch 936, loss function 22913.87109375\n",
      "epoch 937, loss function 22913.234375\n",
      "epoch 938, loss function 22912.599609375\n",
      "epoch 939, loss function 22911.96875\n",
      "epoch 940, loss function 22911.33984375\n",
      "epoch 941, loss function 22910.7109375\n",
      "epoch 942, loss function 22910.0859375\n",
      "epoch 943, loss function 22909.46484375\n",
      "epoch 944, loss function 22908.84375\n",
      "epoch 945, loss function 22908.2265625\n",
      "epoch 946, loss function 22907.61328125\n",
      "epoch 947, loss function 22907.0\n",
      "epoch 948, loss function 22906.390625\n",
      "epoch 949, loss function 22905.78125\n",
      "epoch 950, loss function 22905.177734375\n",
      "epoch 951, loss function 22904.572265625\n",
      "epoch 952, loss function 22903.970703125\n",
      "epoch 953, loss function 22903.373046875\n",
      "epoch 954, loss function 22902.77734375\n",
      "epoch 955, loss function 22902.18359375\n",
      "epoch 956, loss function 22901.591796875\n",
      "epoch 957, loss function 22901.001953125\n",
      "epoch 958, loss function 22900.4140625\n",
      "epoch 959, loss function 22899.830078125\n",
      "epoch 960, loss function 22899.24609375\n",
      "epoch 961, loss function 22898.66796875\n",
      "epoch 962, loss function 22898.08984375\n",
      "epoch 963, loss function 22897.513671875\n",
      "epoch 964, loss function 22896.939453125\n",
      "epoch 965, loss function 22896.3671875\n",
      "epoch 966, loss function 22895.80078125\n",
      "epoch 967, loss function 22895.23046875\n",
      "epoch 968, loss function 22894.666015625\n",
      "epoch 969, loss function 22894.10546875\n",
      "epoch 970, loss function 22893.544921875\n",
      "epoch 971, loss function 22892.986328125\n",
      "epoch 972, loss function 22892.431640625\n",
      "epoch 973, loss function 22891.876953125\n",
      "epoch 974, loss function 22891.32421875\n",
      "epoch 975, loss function 22890.775390625\n",
      "epoch 976, loss function 22890.228515625\n",
      "epoch 977, loss function 22889.68359375\n",
      "epoch 978, loss function 22889.138671875\n",
      "epoch 979, loss function 22888.59765625\n",
      "epoch 980, loss function 22888.060546875\n",
      "epoch 981, loss function 22887.521484375\n",
      "epoch 982, loss function 22886.98828125\n",
      "epoch 983, loss function 22886.451171875\n",
      "epoch 984, loss function 22885.921875\n",
      "epoch 985, loss function 22885.39453125\n",
      "epoch 986, loss function 22884.8671875\n",
      "epoch 987, loss function 22884.341796875\n",
      "epoch 988, loss function 22883.818359375\n",
      "epoch 989, loss function 22883.298828125\n",
      "epoch 990, loss function 22882.779296875\n",
      "epoch 991, loss function 22882.263671875\n",
      "epoch 992, loss function 22881.748046875\n",
      "epoch 993, loss function 22881.234375\n",
      "epoch 994, loss function 22880.724609375\n",
      "epoch 995, loss function 22880.216796875\n",
      "epoch 996, loss function 22879.708984375\n",
      "epoch 997, loss function 22879.203125\n",
      "epoch 998, loss function 22878.701171875\n",
      "epoch 999, loss function 22878.19921875\n",
      "epoch 1000, loss function 22877.703125\n",
      "epoch 1001, loss function 22877.205078125\n",
      "epoch 1002, loss function 22876.708984375\n",
      "epoch 1003, loss function 22876.21484375\n",
      "epoch 1004, loss function 22875.7265625\n",
      "epoch 1005, loss function 22875.234375\n",
      "epoch 1006, loss function 22874.74609375\n",
      "epoch 1007, loss function 22874.263671875\n",
      "epoch 1008, loss function 22873.77734375\n",
      "epoch 1009, loss function 22873.296875\n",
      "epoch 1010, loss function 22872.81640625\n",
      "epoch 1011, loss function 22872.33984375\n",
      "epoch 1012, loss function 22871.861328125\n",
      "epoch 1013, loss function 22871.388671875\n",
      "epoch 1014, loss function 22870.9140625\n",
      "epoch 1015, loss function 22870.443359375\n",
      "epoch 1016, loss function 22869.974609375\n",
      "epoch 1017, loss function 22869.505859375\n",
      "epoch 1018, loss function 22869.04296875\n",
      "epoch 1019, loss function 22868.578125\n",
      "epoch 1020, loss function 22868.1171875\n",
      "epoch 1021, loss function 22867.65625\n",
      "epoch 1022, loss function 22867.197265625\n",
      "epoch 1023, loss function 22866.7421875\n",
      "epoch 1024, loss function 22866.287109375\n",
      "epoch 1025, loss function 22865.83203125\n",
      "epoch 1026, loss function 22865.3828125\n",
      "epoch 1027, loss function 22864.93359375\n",
      "epoch 1028, loss function 22864.484375\n",
      "epoch 1029, loss function 22864.0390625\n",
      "epoch 1030, loss function 22863.59375\n",
      "epoch 1031, loss function 22863.150390625\n",
      "epoch 1032, loss function 22862.7109375\n",
      "epoch 1033, loss function 22862.26953125\n",
      "epoch 1034, loss function 22861.83203125\n",
      "epoch 1035, loss function 22861.3984375\n",
      "epoch 1036, loss function 22860.96484375\n",
      "epoch 1037, loss function 22860.53125\n",
      "epoch 1038, loss function 22860.1015625\n",
      "epoch 1039, loss function 22859.671875\n",
      "epoch 1040, loss function 22859.2421875\n",
      "epoch 1041, loss function 22858.814453125\n",
      "epoch 1042, loss function 22858.392578125\n",
      "epoch 1043, loss function 22857.96875\n",
      "epoch 1044, loss function 22857.55078125\n",
      "epoch 1045, loss function 22857.130859375\n",
      "epoch 1046, loss function 22856.7109375\n",
      "epoch 1047, loss function 22856.296875\n",
      "epoch 1048, loss function 22855.880859375\n",
      "epoch 1049, loss function 22855.46875\n",
      "epoch 1050, loss function 22855.056640625\n",
      "epoch 1051, loss function 22854.646484375\n",
      "epoch 1052, loss function 22854.23828125\n",
      "epoch 1053, loss function 22853.83203125\n",
      "epoch 1054, loss function 22853.427734375\n",
      "epoch 1055, loss function 22853.0234375\n",
      "epoch 1056, loss function 22852.623046875\n",
      "epoch 1057, loss function 22852.22265625\n",
      "epoch 1058, loss function 22851.822265625\n",
      "epoch 1059, loss function 22851.42578125\n",
      "epoch 1060, loss function 22851.02734375\n",
      "epoch 1061, loss function 22850.634765625\n",
      "epoch 1062, loss function 22850.244140625\n",
      "epoch 1063, loss function 22849.8515625\n",
      "epoch 1064, loss function 22849.4609375\n",
      "epoch 1065, loss function 22849.072265625\n",
      "epoch 1066, loss function 22848.6875\n",
      "epoch 1067, loss function 22848.302734375\n",
      "epoch 1068, loss function 22847.919921875\n",
      "epoch 1069, loss function 22847.53515625\n",
      "epoch 1070, loss function 22847.154296875\n",
      "epoch 1071, loss function 22846.775390625\n",
      "epoch 1072, loss function 22846.3984375\n",
      "epoch 1073, loss function 22846.021484375\n",
      "epoch 1074, loss function 22845.646484375\n",
      "epoch 1075, loss function 22845.2734375\n",
      "epoch 1076, loss function 22844.90234375\n",
      "epoch 1077, loss function 22844.53125\n",
      "epoch 1078, loss function 22844.16015625\n",
      "epoch 1079, loss function 22843.79296875\n",
      "epoch 1080, loss function 22843.42578125\n",
      "epoch 1081, loss function 22843.0625\n",
      "epoch 1082, loss function 22842.697265625\n",
      "epoch 1083, loss function 22842.337890625\n",
      "epoch 1084, loss function 22841.974609375\n",
      "epoch 1085, loss function 22841.6171875\n",
      "epoch 1086, loss function 22841.255859375\n",
      "epoch 1087, loss function 22840.90234375\n",
      "epoch 1088, loss function 22840.544921875\n",
      "epoch 1089, loss function 22840.193359375\n",
      "epoch 1090, loss function 22839.83984375\n",
      "epoch 1091, loss function 22839.48828125\n",
      "epoch 1092, loss function 22839.138671875\n",
      "epoch 1093, loss function 22838.7890625\n",
      "epoch 1094, loss function 22838.44140625\n",
      "epoch 1095, loss function 22838.095703125\n",
      "epoch 1096, loss function 22837.751953125\n",
      "epoch 1097, loss function 22837.408203125\n",
      "epoch 1098, loss function 22837.068359375\n",
      "epoch 1099, loss function 22836.7265625\n",
      "epoch 1100, loss function 22836.38671875\n",
      "epoch 1101, loss function 22836.05078125\n",
      "epoch 1102, loss function 22835.712890625\n",
      "epoch 1103, loss function 22835.37890625\n",
      "epoch 1104, loss function 22835.04296875\n",
      "epoch 1105, loss function 22834.7109375\n",
      "epoch 1106, loss function 22834.37890625\n",
      "epoch 1107, loss function 22834.048828125\n",
      "epoch 1108, loss function 22833.72265625\n",
      "epoch 1109, loss function 22833.39453125\n",
      "epoch 1110, loss function 22833.068359375\n",
      "epoch 1111, loss function 22832.7421875\n",
      "epoch 1112, loss function 22832.41796875\n",
      "epoch 1113, loss function 22832.09375\n",
      "epoch 1114, loss function 22831.7734375\n",
      "epoch 1115, loss function 22831.453125\n",
      "epoch 1116, loss function 22831.13671875\n",
      "epoch 1117, loss function 22830.81640625\n",
      "epoch 1118, loss function 22830.498046875\n",
      "epoch 1119, loss function 22830.185546875\n",
      "epoch 1120, loss function 22829.873046875\n",
      "epoch 1121, loss function 22829.55859375\n",
      "epoch 1122, loss function 22829.24609375\n",
      "epoch 1123, loss function 22828.9375\n",
      "epoch 1124, loss function 22828.62890625\n",
      "epoch 1125, loss function 22828.318359375\n",
      "epoch 1126, loss function 22828.01171875\n",
      "epoch 1127, loss function 22827.70703125\n",
      "epoch 1128, loss function 22827.400390625\n",
      "epoch 1129, loss function 22827.09765625\n",
      "epoch 1130, loss function 22826.796875\n",
      "epoch 1131, loss function 22826.49609375\n",
      "epoch 1132, loss function 22826.1953125\n",
      "epoch 1133, loss function 22825.896484375\n",
      "epoch 1134, loss function 22825.59765625\n",
      "epoch 1135, loss function 22825.3046875\n",
      "epoch 1136, loss function 22825.009765625\n",
      "epoch 1137, loss function 22824.712890625\n",
      "epoch 1138, loss function 22824.421875\n",
      "epoch 1139, loss function 22824.12890625\n",
      "epoch 1140, loss function 22823.837890625\n",
      "epoch 1141, loss function 22823.546875\n",
      "epoch 1142, loss function 22823.259765625\n",
      "epoch 1143, loss function 22822.97265625\n",
      "epoch 1144, loss function 22822.6875\n",
      "epoch 1145, loss function 22822.3984375\n",
      "epoch 1146, loss function 22822.115234375\n",
      "epoch 1147, loss function 22821.833984375\n",
      "epoch 1148, loss function 22821.552734375\n",
      "epoch 1149, loss function 22821.26953125\n",
      "epoch 1150, loss function 22820.9921875\n",
      "epoch 1151, loss function 22820.7109375\n",
      "epoch 1152, loss function 22820.435546875\n",
      "epoch 1153, loss function 22820.16015625\n",
      "epoch 1154, loss function 22819.8828125\n",
      "epoch 1155, loss function 22819.609375\n",
      "epoch 1156, loss function 22819.333984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1157, loss function 22819.0625\n",
      "epoch 1158, loss function 22818.791015625\n",
      "epoch 1159, loss function 22818.521484375\n",
      "epoch 1160, loss function 22818.251953125\n",
      "epoch 1161, loss function 22817.984375\n",
      "epoch 1162, loss function 22817.716796875\n",
      "epoch 1163, loss function 22817.44921875\n",
      "epoch 1164, loss function 22817.185546875\n",
      "epoch 1165, loss function 22816.921875\n",
      "epoch 1166, loss function 22816.66015625\n",
      "epoch 1167, loss function 22816.396484375\n",
      "epoch 1168, loss function 22816.134765625\n",
      "epoch 1169, loss function 22815.875\n",
      "epoch 1170, loss function 22815.615234375\n",
      "epoch 1171, loss function 22815.359375\n",
      "epoch 1172, loss function 22815.099609375\n",
      "epoch 1173, loss function 22814.845703125\n",
      "epoch 1174, loss function 22814.587890625\n",
      "epoch 1175, loss function 22814.3359375\n",
      "epoch 1176, loss function 22814.08203125\n",
      "epoch 1177, loss function 22813.830078125\n",
      "epoch 1178, loss function 22813.578125\n",
      "epoch 1179, loss function 22813.328125\n",
      "epoch 1180, loss function 22813.080078125\n",
      "epoch 1181, loss function 22812.83203125\n",
      "epoch 1182, loss function 22812.583984375\n",
      "epoch 1183, loss function 22812.33984375\n",
      "epoch 1184, loss function 22812.09375\n",
      "epoch 1185, loss function 22811.84765625\n",
      "epoch 1186, loss function 22811.60546875\n",
      "epoch 1187, loss function 22811.361328125\n",
      "epoch 1188, loss function 22811.119140625\n",
      "epoch 1189, loss function 22810.87890625\n",
      "epoch 1190, loss function 22810.640625\n",
      "epoch 1191, loss function 22810.400390625\n",
      "epoch 1192, loss function 22810.162109375\n",
      "epoch 1193, loss function 22809.92578125\n",
      "epoch 1194, loss function 22809.6875\n",
      "epoch 1195, loss function 22809.453125\n",
      "epoch 1196, loss function 22809.21875\n",
      "epoch 1197, loss function 22808.986328125\n",
      "epoch 1198, loss function 22808.751953125\n",
      "epoch 1199, loss function 22808.521484375\n",
      "epoch 1200, loss function 22808.291015625\n",
      "epoch 1201, loss function 22808.060546875\n",
      "epoch 1202, loss function 22807.830078125\n",
      "epoch 1203, loss function 22807.603515625\n",
      "epoch 1204, loss function 22807.376953125\n",
      "epoch 1205, loss function 22807.1484375\n",
      "epoch 1206, loss function 22806.923828125\n",
      "epoch 1207, loss function 22806.69921875\n",
      "epoch 1208, loss function 22806.4765625\n",
      "epoch 1209, loss function 22806.251953125\n",
      "epoch 1210, loss function 22806.03125\n",
      "epoch 1211, loss function 22805.810546875\n",
      "epoch 1212, loss function 22805.58984375\n",
      "epoch 1213, loss function 22805.369140625\n",
      "epoch 1214, loss function 22805.1484375\n",
      "epoch 1215, loss function 22804.931640625\n",
      "epoch 1216, loss function 22804.71484375\n",
      "epoch 1217, loss function 22804.5\n",
      "epoch 1218, loss function 22804.283203125\n",
      "epoch 1219, loss function 22804.0703125\n",
      "epoch 1220, loss function 22803.85546875\n",
      "epoch 1221, loss function 22803.64453125\n",
      "epoch 1222, loss function 22803.4296875\n",
      "epoch 1223, loss function 22803.21875\n",
      "epoch 1224, loss function 22803.009765625\n",
      "epoch 1225, loss function 22802.796875\n",
      "epoch 1226, loss function 22802.58984375\n",
      "epoch 1227, loss function 22802.3828125\n",
      "epoch 1228, loss function 22802.17578125\n",
      "epoch 1229, loss function 22801.96875\n",
      "epoch 1230, loss function 22801.763671875\n",
      "epoch 1231, loss function 22801.556640625\n",
      "epoch 1232, loss function 22801.353515625\n",
      "epoch 1233, loss function 22801.150390625\n",
      "epoch 1234, loss function 22800.947265625\n",
      "epoch 1235, loss function 22800.748046875\n",
      "epoch 1236, loss function 22800.546875\n",
      "epoch 1237, loss function 22800.345703125\n",
      "epoch 1238, loss function 22800.14453125\n",
      "epoch 1239, loss function 22799.947265625\n",
      "epoch 1240, loss function 22799.75\n",
      "epoch 1241, loss function 22799.55078125\n",
      "epoch 1242, loss function 22799.35546875\n",
      "epoch 1243, loss function 22799.16015625\n",
      "epoch 1244, loss function 22798.96484375\n",
      "epoch 1245, loss function 22798.76953125\n",
      "epoch 1246, loss function 22798.576171875\n",
      "epoch 1247, loss function 22798.384765625\n",
      "epoch 1248, loss function 22798.19140625\n",
      "epoch 1249, loss function 22798.001953125\n",
      "epoch 1250, loss function 22797.810546875\n",
      "epoch 1251, loss function 22797.62109375\n",
      "epoch 1252, loss function 22797.43359375\n",
      "epoch 1253, loss function 22797.244140625\n",
      "epoch 1254, loss function 22797.056640625\n",
      "epoch 1255, loss function 22796.869140625\n",
      "epoch 1256, loss function 22796.68359375\n",
      "epoch 1257, loss function 22796.49609375\n",
      "epoch 1258, loss function 22796.3125\n",
      "epoch 1259, loss function 22796.12890625\n",
      "epoch 1260, loss function 22795.9453125\n",
      "epoch 1261, loss function 22795.763671875\n",
      "epoch 1262, loss function 22795.58203125\n",
      "epoch 1263, loss function 22795.400390625\n",
      "epoch 1264, loss function 22795.220703125\n",
      "epoch 1265, loss function 22795.0390625\n",
      "epoch 1266, loss function 22794.861328125\n",
      "epoch 1267, loss function 22794.68359375\n",
      "epoch 1268, loss function 22794.501953125\n",
      "epoch 1269, loss function 22794.328125\n",
      "epoch 1270, loss function 22794.150390625\n",
      "epoch 1271, loss function 22793.974609375\n",
      "epoch 1272, loss function 22793.80078125\n",
      "epoch 1273, loss function 22793.625\n",
      "epoch 1274, loss function 22793.453125\n",
      "epoch 1275, loss function 22793.27734375\n",
      "epoch 1276, loss function 22793.10546875\n",
      "epoch 1277, loss function 22792.935546875\n",
      "epoch 1278, loss function 22792.763671875\n",
      "epoch 1279, loss function 22792.59375\n",
      "epoch 1280, loss function 22792.423828125\n",
      "epoch 1281, loss function 22792.25390625\n",
      "epoch 1282, loss function 22792.0859375\n",
      "epoch 1283, loss function 22791.916015625\n",
      "epoch 1284, loss function 22791.751953125\n",
      "epoch 1285, loss function 22791.583984375\n",
      "epoch 1286, loss function 22791.41796875\n",
      "epoch 1287, loss function 22791.25390625\n",
      "epoch 1288, loss function 22791.087890625\n",
      "epoch 1289, loss function 22790.923828125\n",
      "epoch 1290, loss function 22790.76171875\n",
      "epoch 1291, loss function 22790.59765625\n",
      "epoch 1292, loss function 22790.435546875\n",
      "epoch 1293, loss function 22790.2734375\n",
      "epoch 1294, loss function 22790.115234375\n",
      "epoch 1295, loss function 22789.953125\n",
      "epoch 1296, loss function 22789.794921875\n",
      "epoch 1297, loss function 22789.63671875\n",
      "epoch 1298, loss function 22789.4765625\n",
      "epoch 1299, loss function 22789.318359375\n",
      "epoch 1300, loss function 22789.16015625\n",
      "epoch 1301, loss function 22789.00390625\n",
      "epoch 1302, loss function 22788.849609375\n",
      "epoch 1303, loss function 22788.693359375\n",
      "epoch 1304, loss function 22788.5390625\n",
      "epoch 1305, loss function 22788.3828125\n",
      "epoch 1306, loss function 22788.23046875\n",
      "epoch 1307, loss function 22788.078125\n",
      "epoch 1308, loss function 22787.92578125\n",
      "epoch 1309, loss function 22787.7734375\n",
      "epoch 1310, loss function 22787.62109375\n",
      "epoch 1311, loss function 22787.47265625\n",
      "epoch 1312, loss function 22787.3203125\n",
      "epoch 1313, loss function 22787.169921875\n",
      "epoch 1314, loss function 22787.021484375\n",
      "epoch 1315, loss function 22786.873046875\n",
      "epoch 1316, loss function 22786.7265625\n",
      "epoch 1317, loss function 22786.576171875\n",
      "epoch 1318, loss function 22786.4296875\n",
      "epoch 1319, loss function 22786.28515625\n",
      "epoch 1320, loss function 22786.140625\n",
      "epoch 1321, loss function 22785.994140625\n",
      "epoch 1322, loss function 22785.8515625\n",
      "epoch 1323, loss function 22785.70703125\n",
      "epoch 1324, loss function 22785.564453125\n",
      "epoch 1325, loss function 22785.419921875\n",
      "epoch 1326, loss function 22785.27734375\n",
      "epoch 1327, loss function 22785.134765625\n",
      "epoch 1328, loss function 22784.994140625\n",
      "epoch 1329, loss function 22784.853515625\n",
      "epoch 1330, loss function 22784.71484375\n",
      "epoch 1331, loss function 22784.57421875\n",
      "epoch 1332, loss function 22784.435546875\n",
      "epoch 1333, loss function 22784.296875\n",
      "epoch 1334, loss function 22784.15625\n",
      "epoch 1335, loss function 22784.021484375\n",
      "epoch 1336, loss function 22783.8828125\n",
      "epoch 1337, loss function 22783.748046875\n",
      "epoch 1338, loss function 22783.609375\n",
      "epoch 1339, loss function 22783.4765625\n",
      "epoch 1340, loss function 22783.33984375\n",
      "epoch 1341, loss function 22783.20703125\n",
      "epoch 1342, loss function 22783.072265625\n",
      "epoch 1343, loss function 22782.94140625\n",
      "epoch 1344, loss function 22782.806640625\n",
      "epoch 1345, loss function 22782.671875\n",
      "epoch 1346, loss function 22782.54296875\n",
      "epoch 1347, loss function 22782.41015625\n",
      "epoch 1348, loss function 22782.279296875\n",
      "epoch 1349, loss function 22782.1484375\n",
      "epoch 1350, loss function 22782.021484375\n",
      "epoch 1351, loss function 22781.892578125\n",
      "epoch 1352, loss function 22781.76171875\n",
      "epoch 1353, loss function 22781.634765625\n",
      "epoch 1354, loss function 22781.505859375\n",
      "epoch 1355, loss function 22781.37890625\n",
      "epoch 1356, loss function 22781.251953125\n",
      "epoch 1357, loss function 22781.125\n",
      "epoch 1358, loss function 22781.0\n",
      "epoch 1359, loss function 22780.875\n",
      "epoch 1360, loss function 22780.748046875\n",
      "epoch 1361, loss function 22780.625\n",
      "epoch 1362, loss function 22780.5\n",
      "epoch 1363, loss function 22780.376953125\n",
      "epoch 1364, loss function 22780.25390625\n",
      "epoch 1365, loss function 22780.12890625\n",
      "epoch 1366, loss function 22780.009765625\n",
      "epoch 1367, loss function 22779.88671875\n",
      "epoch 1368, loss function 22779.765625\n",
      "epoch 1369, loss function 22779.646484375\n",
      "epoch 1370, loss function 22779.525390625\n",
      "epoch 1371, loss function 22779.40625\n",
      "epoch 1372, loss function 22779.287109375\n",
      "epoch 1373, loss function 22779.16796875\n",
      "epoch 1374, loss function 22779.05078125\n",
      "epoch 1375, loss function 22778.931640625\n",
      "epoch 1376, loss function 22778.8125\n",
      "epoch 1377, loss function 22778.6953125\n",
      "epoch 1378, loss function 22778.580078125\n",
      "epoch 1379, loss function 22778.462890625\n",
      "epoch 1380, loss function 22778.34765625\n",
      "epoch 1381, loss function 22778.232421875\n",
      "epoch 1382, loss function 22778.1171875\n",
      "epoch 1383, loss function 22778.00390625\n",
      "epoch 1384, loss function 22777.888671875\n",
      "epoch 1385, loss function 22777.775390625\n",
      "epoch 1386, loss function 22777.662109375\n",
      "epoch 1387, loss function 22777.548828125\n",
      "epoch 1388, loss function 22777.4375\n",
      "epoch 1389, loss function 22777.328125\n",
      "epoch 1390, loss function 22777.212890625\n",
      "epoch 1391, loss function 22777.1015625\n",
      "epoch 1392, loss function 22776.9921875\n",
      "epoch 1393, loss function 22776.8828125\n",
      "epoch 1394, loss function 22776.771484375\n",
      "epoch 1395, loss function 22776.6640625\n",
      "epoch 1396, loss function 22776.5546875\n",
      "epoch 1397, loss function 22776.447265625\n",
      "epoch 1398, loss function 22776.337890625\n",
      "epoch 1399, loss function 22776.232421875\n",
      "epoch 1400, loss function 22776.123046875\n",
      "epoch 1401, loss function 22776.015625\n",
      "epoch 1402, loss function 22775.91015625\n",
      "epoch 1403, loss function 22775.8046875\n",
      "epoch 1404, loss function 22775.69921875\n",
      "epoch 1405, loss function 22775.591796875\n",
      "epoch 1406, loss function 22775.486328125\n",
      "epoch 1407, loss function 22775.3828125\n",
      "epoch 1408, loss function 22775.28125\n",
      "epoch 1409, loss function 22775.17578125\n",
      "epoch 1410, loss function 22775.0703125\n",
      "epoch 1411, loss function 22774.970703125\n",
      "epoch 1412, loss function 22774.8671875\n",
      "epoch 1413, loss function 22774.763671875\n",
      "epoch 1414, loss function 22774.6640625\n",
      "epoch 1415, loss function 22774.5625\n",
      "epoch 1416, loss function 22774.4609375\n",
      "epoch 1417, loss function 22774.361328125\n",
      "epoch 1418, loss function 22774.259765625\n",
      "epoch 1419, loss function 22774.162109375\n",
      "epoch 1420, loss function 22774.0625\n",
      "epoch 1421, loss function 22773.96484375\n",
      "epoch 1422, loss function 22773.865234375\n",
      "epoch 1423, loss function 22773.767578125\n",
      "epoch 1424, loss function 22773.671875\n",
      "epoch 1425, loss function 22773.5703125\n",
      "epoch 1426, loss function 22773.474609375\n",
      "epoch 1427, loss function 22773.376953125\n",
      "epoch 1428, loss function 22773.283203125\n",
      "epoch 1429, loss function 22773.185546875\n",
      "epoch 1430, loss function 22773.08984375\n",
      "epoch 1431, loss function 22772.9921875\n",
      "epoch 1432, loss function 22772.8984375\n",
      "epoch 1433, loss function 22772.8046875\n",
      "epoch 1434, loss function 22772.7109375\n",
      "epoch 1435, loss function 22772.6171875\n",
      "epoch 1436, loss function 22772.5234375\n",
      "epoch 1437, loss function 22772.4296875\n",
      "epoch 1438, loss function 22772.337890625\n",
      "epoch 1439, loss function 22772.244140625\n",
      "epoch 1440, loss function 22772.154296875\n",
      "epoch 1441, loss function 22772.0625\n",
      "epoch 1442, loss function 22771.96875\n",
      "epoch 1443, loss function 22771.880859375\n",
      "epoch 1444, loss function 22771.7890625\n",
      "epoch 1445, loss function 22771.697265625\n",
      "epoch 1446, loss function 22771.607421875\n",
      "epoch 1447, loss function 22771.51953125\n",
      "epoch 1448, loss function 22771.4296875\n",
      "epoch 1449, loss function 22771.33984375\n",
      "epoch 1450, loss function 22771.251953125\n",
      "epoch 1451, loss function 22771.1640625\n",
      "epoch 1452, loss function 22771.07421875\n",
      "epoch 1453, loss function 22770.98828125\n",
      "epoch 1454, loss function 22770.90234375\n",
      "epoch 1455, loss function 22770.814453125\n",
      "epoch 1456, loss function 22770.728515625\n",
      "epoch 1457, loss function 22770.640625\n",
      "epoch 1458, loss function 22770.5546875\n",
      "epoch 1459, loss function 22770.46875\n",
      "epoch 1460, loss function 22770.384765625\n",
      "epoch 1461, loss function 22770.30078125\n",
      "epoch 1462, loss function 22770.21484375\n",
      "epoch 1463, loss function 22770.12890625\n",
      "epoch 1464, loss function 22770.044921875\n",
      "epoch 1465, loss function 22769.962890625\n",
      "epoch 1466, loss function 22769.87890625\n",
      "epoch 1467, loss function 22769.796875\n",
      "epoch 1468, loss function 22769.71484375\n",
      "epoch 1469, loss function 22769.6328125\n",
      "epoch 1470, loss function 22769.548828125\n",
      "epoch 1471, loss function 22769.46875\n",
      "epoch 1472, loss function 22769.384765625\n",
      "epoch 1473, loss function 22769.306640625\n",
      "epoch 1474, loss function 22769.22265625\n",
      "epoch 1475, loss function 22769.14453125\n",
      "epoch 1476, loss function 22769.0625\n",
      "epoch 1477, loss function 22768.984375\n",
      "epoch 1478, loss function 22768.904296875\n",
      "epoch 1479, loss function 22768.82421875\n",
      "epoch 1480, loss function 22768.74609375\n",
      "epoch 1481, loss function 22768.666015625\n",
      "epoch 1482, loss function 22768.58984375\n",
      "epoch 1483, loss function 22768.509765625\n",
      "epoch 1484, loss function 22768.431640625\n",
      "epoch 1485, loss function 22768.35546875\n",
      "epoch 1486, loss function 22768.27734375\n",
      "epoch 1487, loss function 22768.201171875\n",
      "epoch 1488, loss function 22768.123046875\n",
      "epoch 1489, loss function 22768.048828125\n",
      "epoch 1490, loss function 22767.970703125\n",
      "epoch 1491, loss function 22767.89453125\n",
      "epoch 1492, loss function 22767.822265625\n",
      "epoch 1493, loss function 22767.74609375\n",
      "epoch 1494, loss function 22767.669921875\n",
      "epoch 1495, loss function 22767.595703125\n",
      "epoch 1496, loss function 22767.5234375\n",
      "epoch 1497, loss function 22767.447265625\n",
      "epoch 1498, loss function 22767.373046875\n",
      "epoch 1499, loss function 22767.298828125\n",
      "epoch 1500, loss function 22767.2265625\n",
      "epoch 1501, loss function 22767.15625\n",
      "epoch 1502, loss function 22767.083984375\n",
      "epoch 1503, loss function 22767.009765625\n",
      "epoch 1504, loss function 22766.9375\n",
      "epoch 1505, loss function 22766.865234375\n",
      "epoch 1506, loss function 22766.79296875\n",
      "epoch 1507, loss function 22766.72265625\n",
      "epoch 1508, loss function 22766.65234375\n",
      "epoch 1509, loss function 22766.580078125\n",
      "epoch 1510, loss function 22766.509765625\n",
      "epoch 1511, loss function 22766.439453125\n",
      "epoch 1512, loss function 22766.369140625\n",
      "epoch 1513, loss function 22766.30078125\n",
      "epoch 1514, loss function 22766.23046875\n",
      "epoch 1515, loss function 22766.1640625\n",
      "epoch 1516, loss function 22766.091796875\n",
      "epoch 1517, loss function 22766.0234375\n",
      "epoch 1518, loss function 22765.955078125\n",
      "epoch 1519, loss function 22765.88671875\n",
      "epoch 1520, loss function 22765.8203125\n",
      "epoch 1521, loss function 22765.751953125\n",
      "epoch 1522, loss function 22765.685546875\n",
      "epoch 1523, loss function 22765.619140625\n",
      "epoch 1524, loss function 22765.552734375\n",
      "epoch 1525, loss function 22765.486328125\n",
      "epoch 1526, loss function 22765.41796875\n",
      "epoch 1527, loss function 22765.353515625\n",
      "epoch 1528, loss function 22765.287109375\n",
      "epoch 1529, loss function 22765.22265625\n",
      "epoch 1530, loss function 22765.15625\n",
      "epoch 1531, loss function 22765.091796875\n",
      "epoch 1532, loss function 22765.025390625\n",
      "epoch 1533, loss function 22764.962890625\n",
      "epoch 1534, loss function 22764.896484375\n",
      "epoch 1535, loss function 22764.833984375\n",
      "epoch 1536, loss function 22764.76953125\n",
      "epoch 1537, loss function 22764.703125\n",
      "epoch 1538, loss function 22764.642578125\n",
      "epoch 1539, loss function 22764.580078125\n",
      "epoch 1540, loss function 22764.517578125\n",
      "epoch 1541, loss function 22764.455078125\n",
      "epoch 1542, loss function 22764.390625\n",
      "epoch 1543, loss function 22764.328125\n",
      "epoch 1544, loss function 22764.267578125\n",
      "epoch 1545, loss function 22764.20703125\n",
      "epoch 1546, loss function 22764.14453125\n",
      "epoch 1547, loss function 22764.083984375\n",
      "epoch 1548, loss function 22764.0234375\n",
      "epoch 1549, loss function 22763.9609375\n",
      "epoch 1550, loss function 22763.900390625\n",
      "epoch 1551, loss function 22763.83984375\n",
      "epoch 1552, loss function 22763.78125\n",
      "epoch 1553, loss function 22763.720703125\n",
      "epoch 1554, loss function 22763.662109375\n",
      "epoch 1555, loss function 22763.6015625\n",
      "epoch 1556, loss function 22763.544921875\n",
      "epoch 1557, loss function 22763.484375\n",
      "epoch 1558, loss function 22763.42578125\n",
      "epoch 1559, loss function 22763.365234375\n",
      "epoch 1560, loss function 22763.30859375\n",
      "epoch 1561, loss function 22763.25\n",
      "epoch 1562, loss function 22763.1953125\n",
      "epoch 1563, loss function 22763.134765625\n",
      "epoch 1564, loss function 22763.078125\n",
      "epoch 1565, loss function 22763.01953125\n",
      "epoch 1566, loss function 22762.96484375\n",
      "epoch 1567, loss function 22762.90625\n",
      "epoch 1568, loss function 22762.8515625\n",
      "epoch 1569, loss function 22762.794921875\n",
      "epoch 1570, loss function 22762.73828125\n",
      "epoch 1571, loss function 22762.681640625\n",
      "epoch 1572, loss function 22762.626953125\n",
      "epoch 1573, loss function 22762.572265625\n",
      "epoch 1574, loss function 22762.515625\n",
      "epoch 1575, loss function 22762.4609375\n",
      "epoch 1576, loss function 22762.40625\n",
      "epoch 1577, loss function 22762.3515625\n",
      "epoch 1578, loss function 22762.298828125\n",
      "epoch 1579, loss function 22762.2421875\n",
      "epoch 1580, loss function 22762.1875\n",
      "epoch 1581, loss function 22762.134765625\n",
      "epoch 1582, loss function 22762.08203125\n",
      "epoch 1583, loss function 22762.03125\n",
      "epoch 1584, loss function 22761.974609375\n",
      "epoch 1585, loss function 22761.921875\n",
      "epoch 1586, loss function 22761.8671875\n",
      "epoch 1587, loss function 22761.818359375\n",
      "epoch 1588, loss function 22761.765625\n",
      "epoch 1589, loss function 22761.712890625\n",
      "epoch 1590, loss function 22761.662109375\n",
      "epoch 1591, loss function 22761.609375\n",
      "epoch 1592, loss function 22761.556640625\n",
      "epoch 1593, loss function 22761.505859375\n",
      "epoch 1594, loss function 22761.45703125\n",
      "epoch 1595, loss function 22761.404296875\n",
      "epoch 1596, loss function 22761.3515625\n",
      "epoch 1597, loss function 22761.30078125\n",
      "epoch 1598, loss function 22761.251953125\n",
      "epoch 1599, loss function 22761.201171875\n",
      "epoch 1600, loss function 22761.150390625\n",
      "epoch 1601, loss function 22761.1015625\n",
      "epoch 1602, loss function 22761.05078125\n",
      "epoch 1603, loss function 22761.001953125\n",
      "epoch 1604, loss function 22760.953125\n",
      "epoch 1605, loss function 22760.904296875\n",
      "epoch 1606, loss function 22760.85546875\n",
      "epoch 1607, loss function 22760.806640625\n",
      "epoch 1608, loss function 22760.755859375\n",
      "epoch 1609, loss function 22760.708984375\n",
      "epoch 1610, loss function 22760.662109375\n",
      "epoch 1611, loss function 22760.61328125\n",
      "epoch 1612, loss function 22760.56640625\n",
      "epoch 1613, loss function 22760.515625\n",
      "epoch 1614, loss function 22760.46875\n",
      "epoch 1615, loss function 22760.421875\n",
      "epoch 1616, loss function 22760.376953125\n",
      "epoch 1617, loss function 22760.328125\n",
      "epoch 1618, loss function 22760.283203125\n",
      "epoch 1619, loss function 22760.236328125\n",
      "epoch 1620, loss function 22760.189453125\n",
      "epoch 1621, loss function 22760.14453125\n",
      "epoch 1622, loss function 22760.09765625\n",
      "epoch 1623, loss function 22760.052734375\n",
      "epoch 1624, loss function 22760.0078125\n",
      "epoch 1625, loss function 22759.9609375\n",
      "epoch 1626, loss function 22759.916015625\n",
      "epoch 1627, loss function 22759.869140625\n",
      "epoch 1628, loss function 22759.826171875\n",
      "epoch 1629, loss function 22759.78125\n",
      "epoch 1630, loss function 22759.736328125\n",
      "epoch 1631, loss function 22759.69140625\n",
      "epoch 1632, loss function 22759.646484375\n",
      "epoch 1633, loss function 22759.6015625\n",
      "epoch 1634, loss function 22759.55859375\n",
      "epoch 1635, loss function 22759.515625\n",
      "epoch 1636, loss function 22759.470703125\n",
      "epoch 1637, loss function 22759.427734375\n",
      "epoch 1638, loss function 22759.384765625\n",
      "epoch 1639, loss function 22759.33984375\n",
      "epoch 1640, loss function 22759.298828125\n",
      "epoch 1641, loss function 22759.2578125\n",
      "epoch 1642, loss function 22759.21484375\n",
      "epoch 1643, loss function 22759.169921875\n",
      "epoch 1644, loss function 22759.12890625\n",
      "epoch 1645, loss function 22759.0859375\n",
      "epoch 1646, loss function 22759.044921875\n",
      "epoch 1647, loss function 22759.00390625\n",
      "epoch 1648, loss function 22758.9609375\n",
      "epoch 1649, loss function 22758.919921875\n",
      "epoch 1650, loss function 22758.87890625\n",
      "epoch 1651, loss function 22758.8359375\n",
      "epoch 1652, loss function 22758.796875\n",
      "epoch 1653, loss function 22758.755859375\n",
      "epoch 1654, loss function 22758.71484375\n",
      "epoch 1655, loss function 22758.673828125\n",
      "epoch 1656, loss function 22758.6328125\n",
      "epoch 1657, loss function 22758.591796875\n",
      "epoch 1658, loss function 22758.55078125\n",
      "epoch 1659, loss function 22758.51171875\n",
      "epoch 1660, loss function 22758.474609375\n",
      "epoch 1661, loss function 22758.43359375\n",
      "epoch 1662, loss function 22758.39453125\n",
      "epoch 1663, loss function 22758.353515625\n",
      "epoch 1664, loss function 22758.31640625\n",
      "epoch 1665, loss function 22758.275390625\n",
      "epoch 1666, loss function 22758.23828125\n",
      "epoch 1667, loss function 22758.19921875\n",
      "epoch 1668, loss function 22758.16015625\n",
      "epoch 1669, loss function 22758.12109375\n",
      "epoch 1670, loss function 22758.08203125\n",
      "epoch 1671, loss function 22758.04296875\n",
      "epoch 1672, loss function 22758.0078125\n",
      "epoch 1673, loss function 22757.96875\n",
      "epoch 1674, loss function 22757.9296875\n",
      "epoch 1675, loss function 22757.89453125\n",
      "epoch 1676, loss function 22757.85546875\n",
      "epoch 1677, loss function 22757.818359375\n",
      "epoch 1678, loss function 22757.78125\n",
      "epoch 1679, loss function 22757.744140625\n",
      "epoch 1680, loss function 22757.70703125\n",
      "epoch 1681, loss function 22757.671875\n",
      "epoch 1682, loss function 22757.634765625\n",
      "epoch 1683, loss function 22757.595703125\n",
      "epoch 1684, loss function 22757.560546875\n",
      "epoch 1685, loss function 22757.5234375\n",
      "epoch 1686, loss function 22757.48828125\n",
      "epoch 1687, loss function 22757.453125\n",
      "epoch 1688, loss function 22757.41796875\n",
      "epoch 1689, loss function 22757.380859375\n",
      "epoch 1690, loss function 22757.34375\n",
      "epoch 1691, loss function 22757.30859375\n",
      "epoch 1692, loss function 22757.275390625\n",
      "epoch 1693, loss function 22757.240234375\n",
      "epoch 1694, loss function 22757.205078125\n",
      "epoch 1695, loss function 22757.171875\n",
      "epoch 1696, loss function 22757.134765625\n",
      "epoch 1697, loss function 22757.099609375\n",
      "epoch 1698, loss function 22757.06640625\n",
      "epoch 1699, loss function 22757.03125\n",
      "epoch 1700, loss function 22756.99609375\n",
      "epoch 1701, loss function 22756.96484375\n",
      "epoch 1702, loss function 22756.927734375\n",
      "epoch 1703, loss function 22756.896484375\n",
      "epoch 1704, loss function 22756.86328125\n",
      "epoch 1705, loss function 22756.828125\n",
      "epoch 1706, loss function 22756.79296875\n",
      "epoch 1707, loss function 22756.76171875\n",
      "epoch 1708, loss function 22756.7265625\n",
      "epoch 1709, loss function 22756.6953125\n",
      "epoch 1710, loss function 22756.662109375\n",
      "epoch 1711, loss function 22756.62890625\n",
      "epoch 1712, loss function 22756.59765625\n",
      "epoch 1713, loss function 22756.564453125\n",
      "epoch 1714, loss function 22756.53125\n",
      "epoch 1715, loss function 22756.5\n",
      "epoch 1716, loss function 22756.466796875\n",
      "epoch 1717, loss function 22756.435546875\n",
      "epoch 1718, loss function 22756.40234375\n",
      "epoch 1719, loss function 22756.373046875\n",
      "epoch 1720, loss function 22756.337890625\n",
      "epoch 1721, loss function 22756.30859375\n",
      "epoch 1722, loss function 22756.275390625\n",
      "epoch 1723, loss function 22756.24609375\n",
      "epoch 1724, loss function 22756.212890625\n",
      "epoch 1725, loss function 22756.18359375\n",
      "epoch 1726, loss function 22756.15234375\n",
      "epoch 1727, loss function 22756.123046875\n",
      "epoch 1728, loss function 22756.087890625\n",
      "epoch 1729, loss function 22756.05859375\n",
      "epoch 1730, loss function 22756.029296875\n",
      "epoch 1731, loss function 22756.0\n",
      "epoch 1732, loss function 22755.96875\n",
      "epoch 1733, loss function 22755.9375\n",
      "epoch 1734, loss function 22755.908203125\n",
      "epoch 1735, loss function 22755.87890625\n",
      "epoch 1736, loss function 22755.84765625\n",
      "epoch 1737, loss function 22755.8203125\n",
      "epoch 1738, loss function 22755.787109375\n",
      "epoch 1739, loss function 22755.759765625\n",
      "epoch 1740, loss function 22755.73046875\n",
      "epoch 1741, loss function 22755.701171875\n",
      "epoch 1742, loss function 22755.671875\n",
      "epoch 1743, loss function 22755.640625\n",
      "epoch 1744, loss function 22755.61328125\n",
      "epoch 1745, loss function 22755.5859375\n",
      "epoch 1746, loss function 22755.556640625\n",
      "epoch 1747, loss function 22755.52734375\n",
      "epoch 1748, loss function 22755.498046875\n",
      "epoch 1749, loss function 22755.470703125\n",
      "epoch 1750, loss function 22755.44140625\n",
      "epoch 1751, loss function 22755.4140625\n",
      "epoch 1752, loss function 22755.38671875\n",
      "epoch 1753, loss function 22755.359375\n",
      "epoch 1754, loss function 22755.330078125\n",
      "epoch 1755, loss function 22755.3046875\n",
      "epoch 1756, loss function 22755.275390625\n",
      "epoch 1757, loss function 22755.24609375\n",
      "epoch 1758, loss function 22755.21875\n",
      "epoch 1759, loss function 22755.19140625\n",
      "epoch 1760, loss function 22755.166015625\n",
      "epoch 1761, loss function 22755.13671875\n",
      "epoch 1762, loss function 22755.11328125\n",
      "epoch 1763, loss function 22755.083984375\n",
      "epoch 1764, loss function 22755.056640625\n",
      "epoch 1765, loss function 22755.03125\n",
      "epoch 1766, loss function 22755.00390625\n",
      "epoch 1767, loss function 22754.9765625\n",
      "epoch 1768, loss function 22754.953125\n",
      "epoch 1769, loss function 22754.923828125\n",
      "epoch 1770, loss function 22754.8984375\n",
      "epoch 1771, loss function 22754.87109375\n",
      "epoch 1772, loss function 22754.845703125\n",
      "epoch 1773, loss function 22754.818359375\n",
      "epoch 1774, loss function 22754.796875\n",
      "epoch 1775, loss function 22754.76953125\n",
      "epoch 1776, loss function 22754.7421875\n",
      "epoch 1777, loss function 22754.716796875\n",
      "epoch 1778, loss function 22754.69140625\n",
      "epoch 1779, loss function 22754.666015625\n",
      "epoch 1780, loss function 22754.642578125\n",
      "epoch 1781, loss function 22754.615234375\n",
      "epoch 1782, loss function 22754.591796875\n",
      "epoch 1783, loss function 22754.564453125\n",
      "epoch 1784, loss function 22754.54296875\n",
      "epoch 1785, loss function 22754.515625\n",
      "epoch 1786, loss function 22754.4921875\n",
      "epoch 1787, loss function 22754.46875\n",
      "epoch 1788, loss function 22754.443359375\n",
      "epoch 1789, loss function 22754.41796875\n",
      "epoch 1790, loss function 22754.392578125\n",
      "epoch 1791, loss function 22754.369140625\n",
      "epoch 1792, loss function 22754.34375\n",
      "epoch 1793, loss function 22754.3203125\n",
      "epoch 1794, loss function 22754.296875\n",
      "epoch 1795, loss function 22754.2734375\n",
      "epoch 1796, loss function 22754.25\n",
      "epoch 1797, loss function 22754.2265625\n",
      "epoch 1798, loss function 22754.203125\n",
      "epoch 1799, loss function 22754.1796875\n",
      "epoch 1800, loss function 22754.154296875\n",
      "epoch 1801, loss function 22754.130859375\n",
      "epoch 1802, loss function 22754.109375\n",
      "epoch 1803, loss function 22754.0859375\n",
      "epoch 1804, loss function 22754.0625\n",
      "epoch 1805, loss function 22754.0390625\n",
      "epoch 1806, loss function 22754.01953125\n",
      "epoch 1807, loss function 22753.994140625\n",
      "epoch 1808, loss function 22753.96875\n",
      "epoch 1809, loss function 22753.947265625\n",
      "epoch 1810, loss function 22753.92578125\n",
      "epoch 1811, loss function 22753.904296875\n",
      "epoch 1812, loss function 22753.880859375\n",
      "epoch 1813, loss function 22753.859375\n",
      "epoch 1814, loss function 22753.837890625\n",
      "epoch 1815, loss function 22753.8125\n",
      "epoch 1816, loss function 22753.791015625\n",
      "epoch 1817, loss function 22753.76953125\n",
      "epoch 1818, loss function 22753.748046875\n",
      "epoch 1819, loss function 22753.728515625\n",
      "epoch 1820, loss function 22753.705078125\n",
      "epoch 1821, loss function 22753.681640625\n",
      "epoch 1822, loss function 22753.6640625\n",
      "epoch 1823, loss function 22753.640625\n",
      "epoch 1824, loss function 22753.619140625\n",
      "epoch 1825, loss function 22753.59765625\n",
      "epoch 1826, loss function 22753.576171875\n",
      "epoch 1827, loss function 22753.556640625\n",
      "epoch 1828, loss function 22753.533203125\n",
      "epoch 1829, loss function 22753.51171875\n",
      "epoch 1830, loss function 22753.4921875\n",
      "epoch 1831, loss function 22753.470703125\n",
      "epoch 1832, loss function 22753.44921875\n",
      "epoch 1833, loss function 22753.4296875\n",
      "epoch 1834, loss function 22753.41015625\n",
      "epoch 1835, loss function 22753.388671875\n",
      "epoch 1836, loss function 22753.3671875\n",
      "epoch 1837, loss function 22753.34765625\n",
      "epoch 1838, loss function 22753.326171875\n",
      "epoch 1839, loss function 22753.306640625\n",
      "epoch 1840, loss function 22753.2890625\n",
      "epoch 1841, loss function 22753.265625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1842, loss function 22753.24609375\n",
      "epoch 1843, loss function 22753.2265625\n",
      "epoch 1844, loss function 22753.208984375\n",
      "epoch 1845, loss function 22753.1875\n",
      "epoch 1846, loss function 22753.16796875\n",
      "epoch 1847, loss function 22753.1484375\n",
      "epoch 1848, loss function 22753.12890625\n",
      "epoch 1849, loss function 22753.107421875\n",
      "epoch 1850, loss function 22753.08984375\n",
      "epoch 1851, loss function 22753.0703125\n",
      "epoch 1852, loss function 22753.052734375\n",
      "epoch 1853, loss function 22753.03125\n",
      "epoch 1854, loss function 22753.013671875\n",
      "epoch 1855, loss function 22752.994140625\n",
      "epoch 1856, loss function 22752.974609375\n",
      "epoch 1857, loss function 22752.955078125\n",
      "epoch 1858, loss function 22752.9375\n",
      "epoch 1859, loss function 22752.919921875\n",
      "epoch 1860, loss function 22752.8984375\n",
      "epoch 1861, loss function 22752.884765625\n",
      "epoch 1862, loss function 22752.86328125\n",
      "epoch 1863, loss function 22752.84375\n",
      "epoch 1864, loss function 22752.828125\n",
      "epoch 1865, loss function 22752.806640625\n",
      "epoch 1866, loss function 22752.7890625\n",
      "epoch 1867, loss function 22752.771484375\n",
      "epoch 1868, loss function 22752.75390625\n",
      "epoch 1869, loss function 22752.734375\n",
      "epoch 1870, loss function 22752.716796875\n",
      "epoch 1871, loss function 22752.69921875\n",
      "epoch 1872, loss function 22752.681640625\n",
      "epoch 1873, loss function 22752.6640625\n",
      "epoch 1874, loss function 22752.646484375\n",
      "epoch 1875, loss function 22752.62890625\n",
      "epoch 1876, loss function 22752.611328125\n",
      "epoch 1877, loss function 22752.59375\n",
      "epoch 1878, loss function 22752.578125\n",
      "epoch 1879, loss function 22752.55859375\n",
      "epoch 1880, loss function 22752.5390625\n",
      "epoch 1881, loss function 22752.5234375\n",
      "epoch 1882, loss function 22752.5078125\n",
      "epoch 1883, loss function 22752.490234375\n",
      "epoch 1884, loss function 22752.47265625\n",
      "epoch 1885, loss function 22752.455078125\n",
      "epoch 1886, loss function 22752.439453125\n",
      "epoch 1887, loss function 22752.421875\n",
      "epoch 1888, loss function 22752.40625\n",
      "epoch 1889, loss function 22752.390625\n",
      "epoch 1890, loss function 22752.37109375\n",
      "epoch 1891, loss function 22752.35546875\n",
      "epoch 1892, loss function 22752.33984375\n",
      "epoch 1893, loss function 22752.322265625\n",
      "epoch 1894, loss function 22752.3046875\n",
      "epoch 1895, loss function 22752.2890625\n",
      "epoch 1896, loss function 22752.2734375\n",
      "epoch 1897, loss function 22752.255859375\n",
      "epoch 1898, loss function 22752.2421875\n",
      "epoch 1899, loss function 22752.2265625\n",
      "epoch 1900, loss function 22752.2109375\n",
      "epoch 1901, loss function 22752.19140625\n",
      "epoch 1902, loss function 22752.17578125\n",
      "epoch 1903, loss function 22752.16015625\n",
      "epoch 1904, loss function 22752.14453125\n",
      "epoch 1905, loss function 22752.12890625\n",
      "epoch 1906, loss function 22752.11328125\n",
      "epoch 1907, loss function 22752.09765625\n",
      "epoch 1908, loss function 22752.08203125\n",
      "epoch 1909, loss function 22752.06640625\n",
      "epoch 1910, loss function 22752.05078125\n",
      "epoch 1911, loss function 22752.03515625\n",
      "epoch 1912, loss function 22752.01953125\n",
      "epoch 1913, loss function 22752.00390625\n",
      "epoch 1914, loss function 22751.990234375\n",
      "epoch 1915, loss function 22751.974609375\n",
      "epoch 1916, loss function 22751.9609375\n",
      "epoch 1917, loss function 22751.9453125\n",
      "epoch 1918, loss function 22751.9296875\n",
      "epoch 1919, loss function 22751.912109375\n",
      "epoch 1920, loss function 22751.900390625\n",
      "epoch 1921, loss function 22751.884765625\n",
      "epoch 1922, loss function 22751.87109375\n",
      "epoch 1923, loss function 22751.857421875\n",
      "epoch 1924, loss function 22751.83984375\n",
      "epoch 1925, loss function 22751.826171875\n",
      "epoch 1926, loss function 22751.810546875\n",
      "epoch 1927, loss function 22751.796875\n",
      "epoch 1928, loss function 22751.78125\n",
      "epoch 1929, loss function 22751.767578125\n",
      "epoch 1930, loss function 22751.75390625\n",
      "epoch 1931, loss function 22751.740234375\n",
      "epoch 1932, loss function 22751.724609375\n",
      "epoch 1933, loss function 22751.7109375\n",
      "epoch 1934, loss function 22751.697265625\n",
      "epoch 1935, loss function 22751.68359375\n",
      "epoch 1936, loss function 22751.669921875\n",
      "epoch 1937, loss function 22751.654296875\n",
      "epoch 1938, loss function 22751.642578125\n",
      "epoch 1939, loss function 22751.626953125\n",
      "epoch 1940, loss function 22751.61328125\n",
      "epoch 1941, loss function 22751.599609375\n",
      "epoch 1942, loss function 22751.5859375\n",
      "epoch 1943, loss function 22751.572265625\n",
      "epoch 1944, loss function 22751.560546875\n",
      "epoch 1945, loss function 22751.544921875\n",
      "epoch 1946, loss function 22751.533203125\n",
      "epoch 1947, loss function 22751.517578125\n",
      "epoch 1948, loss function 22751.505859375\n",
      "epoch 1949, loss function 22751.4921875\n",
      "epoch 1950, loss function 22751.478515625\n",
      "epoch 1951, loss function 22751.466796875\n",
      "epoch 1952, loss function 22751.453125\n",
      "epoch 1953, loss function 22751.439453125\n",
      "epoch 1954, loss function 22751.42578125\n",
      "epoch 1955, loss function 22751.4140625\n",
      "epoch 1956, loss function 22751.40234375\n",
      "epoch 1957, loss function 22751.388671875\n",
      "epoch 1958, loss function 22751.37109375\n",
      "epoch 1959, loss function 22751.361328125\n",
      "epoch 1960, loss function 22751.34765625\n",
      "epoch 1961, loss function 22751.3359375\n",
      "epoch 1962, loss function 22751.32421875\n",
      "epoch 1963, loss function 22751.310546875\n",
      "epoch 1964, loss function 22751.296875\n",
      "epoch 1965, loss function 22751.28515625\n",
      "epoch 1966, loss function 22751.271484375\n",
      "epoch 1967, loss function 22751.26171875\n",
      "epoch 1968, loss function 22751.248046875\n",
      "epoch 1969, loss function 22751.234375\n",
      "epoch 1970, loss function 22751.22265625\n",
      "epoch 1971, loss function 22751.208984375\n",
      "epoch 1972, loss function 22751.19921875\n",
      "epoch 1973, loss function 22751.185546875\n",
      "epoch 1974, loss function 22751.173828125\n",
      "epoch 1975, loss function 22751.162109375\n",
      "epoch 1976, loss function 22751.150390625\n",
      "epoch 1977, loss function 22751.13671875\n",
      "epoch 1978, loss function 22751.126953125\n",
      "epoch 1979, loss function 22751.115234375\n",
      "epoch 1980, loss function 22751.1015625\n",
      "epoch 1981, loss function 22751.091796875\n",
      "epoch 1982, loss function 22751.078125\n",
      "epoch 1983, loss function 22751.068359375\n",
      "epoch 1984, loss function 22751.0546875\n",
      "epoch 1985, loss function 22751.04296875\n",
      "epoch 1986, loss function 22751.03125\n",
      "epoch 1987, loss function 22751.01953125\n",
      "epoch 1988, loss function 22751.0078125\n",
      "epoch 1989, loss function 22750.998046875\n",
      "epoch 1990, loss function 22750.986328125\n",
      "epoch 1991, loss function 22750.974609375\n",
      "epoch 1992, loss function 22750.96484375\n",
      "epoch 1993, loss function 22750.951171875\n",
      "epoch 1994, loss function 22750.939453125\n",
      "epoch 1995, loss function 22750.9296875\n",
      "epoch 1996, loss function 22750.91796875\n",
      "epoch 1997, loss function 22750.90625\n",
      "epoch 1998, loss function 22750.896484375\n",
      "epoch 1999, loss function 22750.884765625\n",
      "epoch 2000, loss function 22750.873046875\n",
      "epoch 2001, loss function 22750.86328125\n",
      "epoch 2002, loss function 22750.8515625\n",
      "epoch 2003, loss function 22750.83984375\n",
      "epoch 2004, loss function 22750.828125\n",
      "epoch 2005, loss function 22750.8203125\n",
      "epoch 2006, loss function 22750.80859375\n",
      "epoch 2007, loss function 22750.798828125\n",
      "epoch 2008, loss function 22750.787109375\n",
      "epoch 2009, loss function 22750.775390625\n",
      "epoch 2010, loss function 22750.765625\n",
      "epoch 2011, loss function 22750.755859375\n",
      "epoch 2012, loss function 22750.744140625\n",
      "epoch 2013, loss function 22750.734375\n",
      "epoch 2014, loss function 22750.724609375\n",
      "epoch 2015, loss function 22750.71484375\n",
      "epoch 2016, loss function 22750.701171875\n",
      "epoch 2017, loss function 22750.69140625\n",
      "epoch 2018, loss function 22750.68359375\n",
      "epoch 2019, loss function 22750.671875\n",
      "epoch 2020, loss function 22750.662109375\n",
      "epoch 2021, loss function 22750.650390625\n",
      "epoch 2022, loss function 22750.640625\n",
      "epoch 2023, loss function 22750.6328125\n",
      "epoch 2024, loss function 22750.62109375\n",
      "epoch 2025, loss function 22750.611328125\n",
      "epoch 2026, loss function 22750.6015625\n",
      "epoch 2027, loss function 22750.59375\n",
      "epoch 2028, loss function 22750.580078125\n",
      "epoch 2029, loss function 22750.572265625\n",
      "epoch 2030, loss function 22750.5625\n",
      "epoch 2031, loss function 22750.5546875\n",
      "epoch 2032, loss function 22750.54296875\n",
      "epoch 2033, loss function 22750.533203125\n",
      "epoch 2034, loss function 22750.5234375\n",
      "epoch 2035, loss function 22750.51171875\n",
      "epoch 2036, loss function 22750.50390625\n",
      "epoch 2037, loss function 22750.494140625\n",
      "epoch 2038, loss function 22750.484375\n",
      "epoch 2039, loss function 22750.4765625\n",
      "epoch 2040, loss function 22750.46484375\n",
      "epoch 2041, loss function 22750.45703125\n",
      "epoch 2042, loss function 22750.447265625\n",
      "epoch 2043, loss function 22750.4375\n",
      "epoch 2044, loss function 22750.4296875\n",
      "epoch 2045, loss function 22750.41796875\n",
      "epoch 2046, loss function 22750.41015625\n",
      "epoch 2047, loss function 22750.400390625\n",
      "epoch 2048, loss function 22750.392578125\n",
      "epoch 2049, loss function 22750.3828125\n",
      "epoch 2050, loss function 22750.373046875\n",
      "epoch 2051, loss function 22750.36328125\n",
      "epoch 2052, loss function 22750.353515625\n",
      "epoch 2053, loss function 22750.34765625\n",
      "epoch 2054, loss function 22750.3359375\n",
      "epoch 2055, loss function 22750.328125\n",
      "epoch 2056, loss function 22750.3203125\n",
      "epoch 2057, loss function 22750.310546875\n",
      "epoch 2058, loss function 22750.302734375\n",
      "epoch 2059, loss function 22750.29296875\n",
      "epoch 2060, loss function 22750.283203125\n",
      "epoch 2061, loss function 22750.275390625\n",
      "epoch 2062, loss function 22750.265625\n",
      "epoch 2063, loss function 22750.2578125\n",
      "epoch 2064, loss function 22750.25\n",
      "epoch 2065, loss function 22750.240234375\n",
      "epoch 2066, loss function 22750.23046875\n",
      "epoch 2067, loss function 22750.22265625\n",
      "epoch 2068, loss function 22750.21484375\n",
      "epoch 2069, loss function 22750.205078125\n",
      "epoch 2070, loss function 22750.197265625\n",
      "epoch 2071, loss function 22750.189453125\n",
      "epoch 2072, loss function 22750.181640625\n",
      "epoch 2073, loss function 22750.171875\n",
      "epoch 2074, loss function 22750.1640625\n",
      "epoch 2075, loss function 22750.15625\n",
      "epoch 2076, loss function 22750.146484375\n",
      "epoch 2077, loss function 22750.138671875\n",
      "epoch 2078, loss function 22750.130859375\n",
      "epoch 2079, loss function 22750.123046875\n",
      "epoch 2080, loss function 22750.11328125\n",
      "epoch 2081, loss function 22750.107421875\n",
      "epoch 2082, loss function 22750.09765625\n",
      "epoch 2083, loss function 22750.091796875\n",
      "epoch 2084, loss function 22750.08203125\n",
      "epoch 2085, loss function 22750.076171875\n",
      "epoch 2086, loss function 22750.06640625\n",
      "epoch 2087, loss function 22750.05859375\n",
      "epoch 2088, loss function 22750.05078125\n",
      "epoch 2089, loss function 22750.04296875\n",
      "epoch 2090, loss function 22750.033203125\n",
      "epoch 2091, loss function 22750.02734375\n",
      "epoch 2092, loss function 22750.01953125\n",
      "epoch 2093, loss function 22750.01171875\n",
      "epoch 2094, loss function 22750.00390625\n",
      "epoch 2095, loss function 22749.99609375\n",
      "epoch 2096, loss function 22749.98828125\n",
      "epoch 2097, loss function 22749.98046875\n",
      "epoch 2098, loss function 22749.97265625\n",
      "epoch 2099, loss function 22749.966796875\n",
      "epoch 2100, loss function 22749.95703125\n",
      "epoch 2101, loss function 22749.94921875\n",
      "epoch 2102, loss function 22749.943359375\n",
      "epoch 2103, loss function 22749.935546875\n",
      "epoch 2104, loss function 22749.9296875\n",
      "epoch 2105, loss function 22749.919921875\n",
      "epoch 2106, loss function 22749.912109375\n",
      "epoch 2107, loss function 22749.90625\n",
      "epoch 2108, loss function 22749.8984375\n",
      "epoch 2109, loss function 22749.890625\n",
      "epoch 2110, loss function 22749.8828125\n",
      "epoch 2111, loss function 22749.876953125\n",
      "epoch 2112, loss function 22749.869140625\n",
      "epoch 2113, loss function 22749.86328125\n",
      "epoch 2114, loss function 22749.85546875\n",
      "epoch 2115, loss function 22749.84765625\n",
      "epoch 2116, loss function 22749.83984375\n",
      "epoch 2117, loss function 22749.83203125\n",
      "epoch 2118, loss function 22749.826171875\n",
      "epoch 2119, loss function 22749.8203125\n",
      "epoch 2120, loss function 22749.810546875\n",
      "epoch 2121, loss function 22749.8046875\n",
      "epoch 2122, loss function 22749.796875\n",
      "epoch 2123, loss function 22749.791015625\n",
      "epoch 2124, loss function 22749.78515625\n",
      "epoch 2125, loss function 22749.77734375\n",
      "epoch 2126, loss function 22749.7734375\n",
      "epoch 2127, loss function 22749.765625\n",
      "epoch 2128, loss function 22749.7578125\n",
      "epoch 2129, loss function 22749.75\n",
      "epoch 2130, loss function 22749.744140625\n",
      "epoch 2131, loss function 22749.736328125\n",
      "epoch 2132, loss function 22749.728515625\n",
      "epoch 2133, loss function 22749.724609375\n",
      "epoch 2134, loss function 22749.71875\n",
      "epoch 2135, loss function 22749.7109375\n",
      "epoch 2136, loss function 22749.703125\n",
      "epoch 2137, loss function 22749.697265625\n",
      "epoch 2138, loss function 22749.69140625\n",
      "epoch 2139, loss function 22749.68359375\n",
      "epoch 2140, loss function 22749.67578125\n",
      "epoch 2141, loss function 22749.66796875\n",
      "epoch 2142, loss function 22749.666015625\n",
      "epoch 2143, loss function 22749.66015625\n",
      "epoch 2144, loss function 22749.65234375\n",
      "epoch 2145, loss function 22749.646484375\n",
      "epoch 2146, loss function 22749.638671875\n",
      "epoch 2147, loss function 22749.634765625\n",
      "epoch 2148, loss function 22749.626953125\n",
      "epoch 2149, loss function 22749.62109375\n",
      "epoch 2150, loss function 22749.615234375\n",
      "epoch 2151, loss function 22749.609375\n",
      "epoch 2152, loss function 22749.6015625\n",
      "epoch 2153, loss function 22749.595703125\n",
      "epoch 2154, loss function 22749.587890625\n",
      "epoch 2155, loss function 22749.583984375\n",
      "epoch 2156, loss function 22749.578125\n",
      "epoch 2157, loss function 22749.5703125\n",
      "epoch 2158, loss function 22749.564453125\n",
      "epoch 2159, loss function 22749.560546875\n",
      "epoch 2160, loss function 22749.552734375\n",
      "epoch 2161, loss function 22749.546875\n",
      "epoch 2162, loss function 22749.54296875\n",
      "epoch 2163, loss function 22749.53515625\n",
      "epoch 2164, loss function 22749.529296875\n",
      "epoch 2165, loss function 22749.5234375\n",
      "epoch 2166, loss function 22749.517578125\n",
      "epoch 2167, loss function 22749.51171875\n",
      "epoch 2168, loss function 22749.505859375\n",
      "epoch 2169, loss function 22749.5\n",
      "epoch 2170, loss function 22749.4921875\n",
      "epoch 2171, loss function 22749.486328125\n",
      "epoch 2172, loss function 22749.48046875\n",
      "epoch 2173, loss function 22749.4765625\n",
      "epoch 2174, loss function 22749.470703125\n",
      "epoch 2175, loss function 22749.466796875\n",
      "epoch 2176, loss function 22749.45703125\n",
      "epoch 2177, loss function 22749.453125\n",
      "epoch 2178, loss function 22749.447265625\n",
      "epoch 2179, loss function 22749.443359375\n",
      "epoch 2180, loss function 22749.4375\n",
      "epoch 2181, loss function 22749.4296875\n",
      "epoch 2182, loss function 22749.42578125\n",
      "epoch 2183, loss function 22749.41796875\n",
      "epoch 2184, loss function 22749.4140625\n",
      "epoch 2185, loss function 22749.41015625\n",
      "epoch 2186, loss function 22749.404296875\n",
      "epoch 2187, loss function 22749.396484375\n",
      "epoch 2188, loss function 22749.392578125\n",
      "epoch 2189, loss function 22749.38671875\n",
      "epoch 2190, loss function 22749.3828125\n",
      "epoch 2191, loss function 22749.37890625\n",
      "epoch 2192, loss function 22749.37109375\n",
      "epoch 2193, loss function 22749.3671875\n",
      "epoch 2194, loss function 22749.361328125\n",
      "epoch 2195, loss function 22749.35546875\n",
      "epoch 2196, loss function 22749.349609375\n",
      "epoch 2197, loss function 22749.34375\n",
      "epoch 2198, loss function 22749.33984375\n",
      "epoch 2199, loss function 22749.33203125\n",
      "epoch 2200, loss function 22749.328125\n",
      "epoch 2201, loss function 22749.32421875\n",
      "epoch 2202, loss function 22749.31640625\n",
      "epoch 2203, loss function 22749.314453125\n",
      "epoch 2204, loss function 22749.30859375\n",
      "epoch 2205, loss function 22749.3046875\n",
      "epoch 2206, loss function 22749.296875\n",
      "epoch 2207, loss function 22749.29296875\n",
      "epoch 2208, loss function 22749.2890625\n",
      "epoch 2209, loss function 22749.28125\n",
      "epoch 2210, loss function 22749.27734375\n",
      "epoch 2211, loss function 22749.2734375\n",
      "epoch 2212, loss function 22749.267578125\n",
      "epoch 2213, loss function 22749.263671875\n",
      "epoch 2214, loss function 22749.2578125\n",
      "epoch 2215, loss function 22749.25390625\n",
      "epoch 2216, loss function 22749.25\n",
      "epoch 2217, loss function 22749.2421875\n",
      "epoch 2218, loss function 22749.240234375\n",
      "epoch 2219, loss function 22749.232421875\n",
      "epoch 2220, loss function 22749.23046875\n",
      "epoch 2221, loss function 22749.2265625\n",
      "epoch 2222, loss function 22749.220703125\n",
      "epoch 2223, loss function 22749.21484375\n",
      "epoch 2224, loss function 22749.208984375\n",
      "epoch 2225, loss function 22749.205078125\n",
      "epoch 2226, loss function 22749.19921875\n",
      "epoch 2227, loss function 22749.1953125\n",
      "epoch 2228, loss function 22749.19140625\n",
      "epoch 2229, loss function 22749.1875\n",
      "epoch 2230, loss function 22749.18359375\n",
      "epoch 2231, loss function 22749.177734375\n",
      "epoch 2232, loss function 22749.171875\n",
      "epoch 2233, loss function 22749.16796875\n",
      "epoch 2234, loss function 22749.1640625\n",
      "epoch 2235, loss function 22749.16015625\n",
      "epoch 2236, loss function 22749.15625\n",
      "epoch 2237, loss function 22749.150390625\n",
      "epoch 2238, loss function 22749.14453125\n",
      "epoch 2239, loss function 22749.140625\n",
      "epoch 2240, loss function 22749.134765625\n",
      "epoch 2241, loss function 22749.130859375\n",
      "epoch 2242, loss function 22749.126953125\n",
      "epoch 2243, loss function 22749.123046875\n",
      "epoch 2244, loss function 22749.119140625\n",
      "epoch 2245, loss function 22749.11328125\n",
      "epoch 2246, loss function 22749.111328125\n",
      "epoch 2247, loss function 22749.10546875\n",
      "epoch 2248, loss function 22749.1015625\n",
      "epoch 2249, loss function 22749.095703125\n",
      "epoch 2250, loss function 22749.09375\n",
      "epoch 2251, loss function 22749.087890625\n",
      "epoch 2252, loss function 22749.08203125\n",
      "epoch 2253, loss function 22749.080078125\n",
      "epoch 2254, loss function 22749.07421875\n",
      "epoch 2255, loss function 22749.072265625\n",
      "epoch 2256, loss function 22749.06640625\n",
      "epoch 2257, loss function 22749.0625\n",
      "epoch 2258, loss function 22749.060546875\n",
      "epoch 2259, loss function 22749.0546875\n",
      "epoch 2260, loss function 22749.048828125\n",
      "epoch 2261, loss function 22749.046875\n",
      "epoch 2262, loss function 22749.04296875\n",
      "epoch 2263, loss function 22749.0390625\n",
      "epoch 2264, loss function 22749.033203125\n",
      "epoch 2265, loss function 22749.029296875\n",
      "epoch 2266, loss function 22749.025390625\n",
      "epoch 2267, loss function 22749.0234375\n",
      "epoch 2268, loss function 22749.017578125\n",
      "epoch 2269, loss function 22749.013671875\n",
      "epoch 2270, loss function 22749.01171875\n",
      "epoch 2271, loss function 22749.005859375\n",
      "epoch 2272, loss function 22749.001953125\n",
      "epoch 2273, loss function 22748.998046875\n",
      "epoch 2274, loss function 22748.994140625\n",
      "epoch 2275, loss function 22748.990234375\n",
      "epoch 2276, loss function 22748.986328125\n",
      "epoch 2277, loss function 22748.984375\n",
      "epoch 2278, loss function 22748.978515625\n",
      "epoch 2279, loss function 22748.9765625\n",
      "epoch 2280, loss function 22748.970703125\n",
      "epoch 2281, loss function 22748.966796875\n",
      "epoch 2282, loss function 22748.96484375\n",
      "epoch 2283, loss function 22748.958984375\n",
      "epoch 2284, loss function 22748.955078125\n",
      "epoch 2285, loss function 22748.951171875\n",
      "epoch 2286, loss function 22748.947265625\n",
      "epoch 2287, loss function 22748.9453125\n",
      "epoch 2288, loss function 22748.939453125\n",
      "epoch 2289, loss function 22748.9375\n",
      "epoch 2290, loss function 22748.931640625\n",
      "epoch 2291, loss function 22748.9296875\n",
      "epoch 2292, loss function 22748.92578125\n",
      "epoch 2293, loss function 22748.921875\n",
      "epoch 2294, loss function 22748.919921875\n",
      "epoch 2295, loss function 22748.916015625\n",
      "epoch 2296, loss function 22748.91015625\n",
      "epoch 2297, loss function 22748.908203125\n",
      "epoch 2298, loss function 22748.90234375\n",
      "epoch 2299, loss function 22748.90234375\n",
      "epoch 2300, loss function 22748.896484375\n",
      "epoch 2301, loss function 22748.892578125\n",
      "epoch 2302, loss function 22748.890625\n",
      "epoch 2303, loss function 22748.884765625\n",
      "epoch 2304, loss function 22748.8828125\n",
      "epoch 2305, loss function 22748.87890625\n",
      "epoch 2306, loss function 22748.876953125\n",
      "epoch 2307, loss function 22748.87109375\n",
      "epoch 2308, loss function 22748.8671875\n",
      "epoch 2309, loss function 22748.86328125\n",
      "epoch 2310, loss function 22748.861328125\n",
      "epoch 2311, loss function 22748.859375\n",
      "epoch 2312, loss function 22748.85546875\n",
      "epoch 2313, loss function 22748.8515625\n",
      "epoch 2314, loss function 22748.849609375\n",
      "epoch 2315, loss function 22748.845703125\n",
      "epoch 2316, loss function 22748.84375\n",
      "epoch 2317, loss function 22748.837890625\n",
      "epoch 2318, loss function 22748.833984375\n",
      "epoch 2319, loss function 22748.83203125\n",
      "epoch 2320, loss function 22748.828125\n",
      "epoch 2321, loss function 22748.82421875\n",
      "epoch 2322, loss function 22748.822265625\n",
      "epoch 2323, loss function 22748.818359375\n",
      "epoch 2324, loss function 22748.814453125\n",
      "epoch 2325, loss function 22748.810546875\n",
      "epoch 2326, loss function 22748.80859375\n",
      "epoch 2327, loss function 22748.8046875\n",
      "epoch 2328, loss function 22748.802734375\n",
      "epoch 2329, loss function 22748.798828125\n",
      "epoch 2330, loss function 22748.796875\n",
      "epoch 2331, loss function 22748.794921875\n",
      "epoch 2332, loss function 22748.791015625\n",
      "epoch 2333, loss function 22748.787109375\n",
      "epoch 2334, loss function 22748.783203125\n",
      "epoch 2335, loss function 22748.78125\n",
      "epoch 2336, loss function 22748.779296875\n",
      "epoch 2337, loss function 22748.7734375\n",
      "epoch 2338, loss function 22748.76953125\n",
      "epoch 2339, loss function 22748.765625\n",
      "epoch 2340, loss function 22748.763671875\n",
      "epoch 2341, loss function 22748.76171875\n",
      "epoch 2342, loss function 22748.759765625\n",
      "epoch 2343, loss function 22748.755859375\n",
      "epoch 2344, loss function 22748.751953125\n",
      "epoch 2345, loss function 22748.75\n",
      "epoch 2346, loss function 22748.748046875\n",
      "epoch 2347, loss function 22748.7421875\n",
      "epoch 2348, loss function 22748.7421875\n",
      "epoch 2349, loss function 22748.736328125\n",
      "epoch 2350, loss function 22748.734375\n",
      "epoch 2351, loss function 22748.73046875\n",
      "epoch 2352, loss function 22748.728515625\n",
      "epoch 2353, loss function 22748.7265625\n",
      "epoch 2354, loss function 22748.72265625\n",
      "epoch 2355, loss function 22748.71875\n",
      "epoch 2356, loss function 22748.716796875\n",
      "epoch 2357, loss function 22748.712890625\n",
      "epoch 2358, loss function 22748.7109375\n",
      "epoch 2359, loss function 22748.7109375\n",
      "epoch 2360, loss function 22748.70703125\n",
      "epoch 2361, loss function 22748.701171875\n",
      "epoch 2362, loss function 22748.69921875\n",
      "epoch 2363, loss function 22748.6953125\n",
      "epoch 2364, loss function 22748.6953125\n",
      "epoch 2365, loss function 22748.69140625\n",
      "epoch 2366, loss function 22748.6875\n",
      "epoch 2367, loss function 22748.68359375\n",
      "epoch 2368, loss function 22748.68359375\n",
      "epoch 2369, loss function 22748.6796875\n",
      "epoch 2370, loss function 22748.677734375\n",
      "epoch 2371, loss function 22748.673828125\n",
      "epoch 2372, loss function 22748.671875\n",
      "epoch 2373, loss function 22748.669921875\n",
      "epoch 2374, loss function 22748.666015625\n",
      "epoch 2375, loss function 22748.662109375\n",
      "epoch 2376, loss function 22748.662109375\n",
      "epoch 2377, loss function 22748.66015625\n",
      "epoch 2378, loss function 22748.65625\n",
      "epoch 2379, loss function 22748.65234375\n",
      "epoch 2380, loss function 22748.650390625\n",
      "epoch 2381, loss function 22748.6484375\n",
      "epoch 2382, loss function 22748.64453125\n",
      "epoch 2383, loss function 22748.642578125\n",
      "epoch 2384, loss function 22748.640625\n",
      "epoch 2385, loss function 22748.638671875\n",
      "epoch 2386, loss function 22748.634765625\n",
      "epoch 2387, loss function 22748.630859375\n",
      "epoch 2388, loss function 22748.6328125\n",
      "epoch 2389, loss function 22748.625\n",
      "epoch 2390, loss function 22748.625\n",
      "epoch 2391, loss function 22748.623046875\n",
      "epoch 2392, loss function 22748.619140625\n",
      "epoch 2393, loss function 22748.6171875\n",
      "epoch 2394, loss function 22748.615234375\n",
      "epoch 2395, loss function 22748.611328125\n",
      "epoch 2396, loss function 22748.609375\n",
      "epoch 2397, loss function 22748.607421875\n",
      "epoch 2398, loss function 22748.603515625\n",
      "epoch 2399, loss function 22748.6015625\n",
      "epoch 2400, loss function 22748.599609375\n",
      "epoch 2401, loss function 22748.59765625\n",
      "epoch 2402, loss function 22748.59765625\n",
      "epoch 2403, loss function 22748.591796875\n",
      "epoch 2404, loss function 22748.58984375\n",
      "epoch 2405, loss function 22748.58984375\n",
      "epoch 2406, loss function 22748.5859375\n",
      "epoch 2407, loss function 22748.583984375\n",
      "epoch 2408, loss function 22748.578125\n",
      "epoch 2409, loss function 22748.578125\n",
      "epoch 2410, loss function 22748.578125\n",
      "epoch 2411, loss function 22748.57421875\n",
      "epoch 2412, loss function 22748.5703125\n",
      "epoch 2413, loss function 22748.568359375\n",
      "epoch 2414, loss function 22748.56640625\n",
      "epoch 2415, loss function 22748.5625\n",
      "epoch 2416, loss function 22748.5625\n",
      "epoch 2417, loss function 22748.560546875\n",
      "epoch 2418, loss function 22748.556640625\n",
      "epoch 2419, loss function 22748.5546875\n",
      "epoch 2420, loss function 22748.552734375\n",
      "epoch 2421, loss function 22748.55078125\n",
      "epoch 2422, loss function 22748.548828125\n",
      "epoch 2423, loss function 22748.544921875\n",
      "epoch 2424, loss function 22748.54296875\n",
      "epoch 2425, loss function 22748.541015625\n",
      "epoch 2426, loss function 22748.5390625\n",
      "epoch 2427, loss function 22748.537109375\n",
      "epoch 2428, loss function 22748.533203125\n",
      "epoch 2429, loss function 22748.533203125\n",
      "epoch 2430, loss function 22748.529296875\n",
      "epoch 2431, loss function 22748.52734375\n",
      "epoch 2432, loss function 22748.525390625\n",
      "epoch 2433, loss function 22748.5234375\n",
      "epoch 2434, loss function 22748.51953125\n",
      "epoch 2435, loss function 22748.51953125\n",
      "epoch 2436, loss function 22748.515625\n",
      "epoch 2437, loss function 22748.515625\n",
      "epoch 2438, loss function 22748.51171875\n",
      "epoch 2439, loss function 22748.51171875\n",
      "epoch 2440, loss function 22748.5078125\n",
      "epoch 2441, loss function 22748.505859375\n",
      "epoch 2442, loss function 22748.50390625\n",
      "epoch 2443, loss function 22748.5\n",
      "epoch 2444, loss function 22748.5\n",
      "epoch 2445, loss function 22748.498046875\n",
      "epoch 2446, loss function 22748.498046875\n",
      "epoch 2447, loss function 22748.494140625\n",
      "epoch 2448, loss function 22748.4921875\n",
      "epoch 2449, loss function 22748.490234375\n",
      "epoch 2450, loss function 22748.486328125\n",
      "epoch 2451, loss function 22748.486328125\n",
      "epoch 2452, loss function 22748.484375\n",
      "epoch 2453, loss function 22748.48046875\n",
      "epoch 2454, loss function 22748.48046875\n",
      "epoch 2455, loss function 22748.478515625\n",
      "epoch 2456, loss function 22748.4765625\n",
      "epoch 2457, loss function 22748.474609375\n",
      "epoch 2458, loss function 22748.47265625\n",
      "epoch 2459, loss function 22748.46875\n",
      "epoch 2460, loss function 22748.466796875\n",
      "epoch 2461, loss function 22748.46484375\n",
      "epoch 2462, loss function 22748.46484375\n",
      "epoch 2463, loss function 22748.4609375\n",
      "epoch 2464, loss function 22748.4609375\n",
      "epoch 2465, loss function 22748.458984375\n",
      "epoch 2466, loss function 22748.455078125\n",
      "epoch 2467, loss function 22748.453125\n",
      "epoch 2468, loss function 22748.453125\n",
      "epoch 2469, loss function 22748.44921875\n",
      "epoch 2470, loss function 22748.44921875\n",
      "epoch 2471, loss function 22748.447265625\n",
      "epoch 2472, loss function 22748.447265625\n",
      "epoch 2473, loss function 22748.44140625\n",
      "epoch 2474, loss function 22748.44140625\n",
      "epoch 2475, loss function 22748.439453125\n",
      "epoch 2476, loss function 22748.4375\n",
      "epoch 2477, loss function 22748.435546875\n",
      "epoch 2478, loss function 22748.43359375\n",
      "epoch 2479, loss function 22748.431640625\n",
      "epoch 2480, loss function 22748.4296875\n",
      "epoch 2481, loss function 22748.427734375\n",
      "epoch 2482, loss function 22748.42578125\n",
      "epoch 2483, loss function 22748.42578125\n",
      "epoch 2484, loss function 22748.423828125\n",
      "epoch 2485, loss function 22748.421875\n",
      "epoch 2486, loss function 22748.41796875\n",
      "epoch 2487, loss function 22748.41796875\n",
      "epoch 2488, loss function 22748.416015625\n",
      "epoch 2489, loss function 22748.4140625\n",
      "epoch 2490, loss function 22748.412109375\n",
      "epoch 2491, loss function 22748.41015625\n",
      "epoch 2492, loss function 22748.41015625\n",
      "epoch 2493, loss function 22748.408203125\n",
      "epoch 2494, loss function 22748.404296875\n",
      "epoch 2495, loss function 22748.40234375\n",
      "epoch 2496, loss function 22748.40234375\n",
      "epoch 2497, loss function 22748.400390625\n",
      "epoch 2498, loss function 22748.3984375\n",
      "epoch 2499, loss function 22748.396484375\n",
      "epoch 2500, loss function 22748.39453125\n",
      "epoch 2501, loss function 22748.39453125\n",
      "epoch 2502, loss function 22748.392578125\n",
      "epoch 2503, loss function 22748.390625\n",
      "epoch 2504, loss function 22748.38671875\n",
      "epoch 2505, loss function 22748.38671875\n",
      "epoch 2506, loss function 22748.38671875\n",
      "epoch 2507, loss function 22748.3828125\n",
      "epoch 2508, loss function 22748.380859375\n",
      "epoch 2509, loss function 22748.37890625\n",
      "epoch 2510, loss function 22748.376953125\n",
      "epoch 2511, loss function 22748.375\n",
      "epoch 2512, loss function 22748.375\n",
      "epoch 2513, loss function 22748.373046875\n",
      "epoch 2514, loss function 22748.373046875\n",
      "epoch 2515, loss function 22748.369140625\n",
      "epoch 2516, loss function 22748.369140625\n",
      "epoch 2517, loss function 22748.3671875\n",
      "epoch 2518, loss function 22748.36328125\n",
      "epoch 2519, loss function 22748.36328125\n",
      "epoch 2520, loss function 22748.361328125\n",
      "epoch 2521, loss function 22748.361328125\n",
      "epoch 2522, loss function 22748.359375\n",
      "epoch 2523, loss function 22748.357421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2524, loss function 22748.35546875\n",
      "epoch 2525, loss function 22748.35546875\n",
      "epoch 2526, loss function 22748.353515625\n",
      "epoch 2527, loss function 22748.3515625\n",
      "epoch 2528, loss function 22748.349609375\n",
      "epoch 2529, loss function 22748.349609375\n",
      "epoch 2530, loss function 22748.34765625\n",
      "epoch 2531, loss function 22748.345703125\n",
      "epoch 2532, loss function 22748.34375\n",
      "epoch 2533, loss function 22748.341796875\n",
      "epoch 2534, loss function 22748.341796875\n",
      "epoch 2535, loss function 22748.337890625\n",
      "epoch 2536, loss function 22748.337890625\n",
      "epoch 2537, loss function 22748.3359375\n",
      "epoch 2538, loss function 22748.337890625\n",
      "epoch 2539, loss function 22748.333984375\n",
      "epoch 2540, loss function 22748.33203125\n",
      "epoch 2541, loss function 22748.33203125\n",
      "epoch 2542, loss function 22748.330078125\n",
      "epoch 2543, loss function 22748.328125\n",
      "epoch 2544, loss function 22748.326171875\n",
      "epoch 2545, loss function 22748.32421875\n",
      "epoch 2546, loss function 22748.32421875\n",
      "epoch 2547, loss function 22748.322265625\n",
      "epoch 2548, loss function 22748.3203125\n",
      "epoch 2549, loss function 22748.318359375\n",
      "epoch 2550, loss function 22748.31640625\n",
      "epoch 2551, loss function 22748.31640625\n",
      "epoch 2552, loss function 22748.314453125\n",
      "epoch 2553, loss function 22748.3125\n",
      "epoch 2554, loss function 22748.3125\n",
      "epoch 2555, loss function 22748.310546875\n",
      "epoch 2556, loss function 22748.30859375\n",
      "epoch 2557, loss function 22748.30859375\n",
      "epoch 2558, loss function 22748.306640625\n",
      "epoch 2559, loss function 22748.3046875\n",
      "epoch 2560, loss function 22748.3046875\n",
      "epoch 2561, loss function 22748.302734375\n",
      "epoch 2562, loss function 22748.30078125\n",
      "epoch 2563, loss function 22748.298828125\n",
      "epoch 2564, loss function 22748.298828125\n",
      "epoch 2565, loss function 22748.296875\n",
      "epoch 2566, loss function 22748.296875\n",
      "epoch 2567, loss function 22748.29296875\n",
      "epoch 2568, loss function 22748.294921875\n",
      "epoch 2569, loss function 22748.29296875\n",
      "epoch 2570, loss function 22748.29296875\n",
      "epoch 2571, loss function 22748.2890625\n",
      "epoch 2572, loss function 22748.2890625\n",
      "epoch 2573, loss function 22748.2890625\n",
      "epoch 2574, loss function 22748.28515625\n",
      "epoch 2575, loss function 22748.28515625\n",
      "epoch 2576, loss function 22748.283203125\n",
      "epoch 2577, loss function 22748.28125\n",
      "epoch 2578, loss function 22748.28125\n",
      "epoch 2579, loss function 22748.279296875\n",
      "epoch 2580, loss function 22748.279296875\n",
      "epoch 2581, loss function 22748.27734375\n",
      "epoch 2582, loss function 22748.275390625\n",
      "epoch 2583, loss function 22748.275390625\n",
      "epoch 2584, loss function 22748.275390625\n",
      "epoch 2585, loss function 22748.2734375\n",
      "epoch 2586, loss function 22748.26953125\n",
      "epoch 2587, loss function 22748.26953125\n",
      "epoch 2588, loss function 22748.267578125\n",
      "epoch 2589, loss function 22748.265625\n",
      "epoch 2590, loss function 22748.265625\n",
      "epoch 2591, loss function 22748.265625\n",
      "epoch 2592, loss function 22748.263671875\n",
      "epoch 2593, loss function 22748.26171875\n",
      "epoch 2594, loss function 22748.26171875\n",
      "epoch 2595, loss function 22748.259765625\n",
      "epoch 2596, loss function 22748.259765625\n",
      "epoch 2597, loss function 22748.2578125\n",
      "epoch 2598, loss function 22748.255859375\n",
      "epoch 2599, loss function 22748.25390625\n",
      "epoch 2600, loss function 22748.25390625\n",
      "epoch 2601, loss function 22748.251953125\n",
      "epoch 2602, loss function 22748.25\n",
      "epoch 2603, loss function 22748.25\n",
      "epoch 2604, loss function 22748.25\n",
      "epoch 2605, loss function 22748.25\n",
      "epoch 2606, loss function 22748.248046875\n",
      "epoch 2607, loss function 22748.24609375\n",
      "epoch 2608, loss function 22748.244140625\n",
      "epoch 2609, loss function 22748.244140625\n",
      "epoch 2610, loss function 22748.2421875\n",
      "epoch 2611, loss function 22748.240234375\n",
      "epoch 2612, loss function 22748.2421875\n",
      "epoch 2613, loss function 22748.23828125\n",
      "epoch 2614, loss function 22748.23828125\n",
      "epoch 2615, loss function 22748.23828125\n",
      "epoch 2616, loss function 22748.236328125\n",
      "epoch 2617, loss function 22748.234375\n",
      "epoch 2618, loss function 22748.232421875\n",
      "epoch 2619, loss function 22748.232421875\n",
      "epoch 2620, loss function 22748.232421875\n",
      "epoch 2621, loss function 22748.23046875\n",
      "epoch 2622, loss function 22748.23046875\n",
      "epoch 2623, loss function 22748.228515625\n",
      "epoch 2624, loss function 22748.2265625\n",
      "epoch 2625, loss function 22748.2265625\n",
      "epoch 2626, loss function 22748.2265625\n",
      "epoch 2627, loss function 22748.22265625\n",
      "epoch 2628, loss function 22748.224609375\n",
      "epoch 2629, loss function 22748.22265625\n",
      "epoch 2630, loss function 22748.21875\n",
      "epoch 2631, loss function 22748.21875\n",
      "epoch 2632, loss function 22748.21875\n",
      "epoch 2633, loss function 22748.21875\n",
      "epoch 2634, loss function 22748.21484375\n",
      "epoch 2635, loss function 22748.216796875\n",
      "epoch 2636, loss function 22748.21484375\n",
      "epoch 2637, loss function 22748.21484375\n",
      "epoch 2638, loss function 22748.21484375\n",
      "epoch 2639, loss function 22748.2109375\n",
      "epoch 2640, loss function 22748.212890625\n",
      "epoch 2641, loss function 22748.2109375\n",
      "epoch 2642, loss function 22748.208984375\n",
      "epoch 2643, loss function 22748.20703125\n",
      "epoch 2644, loss function 22748.205078125\n",
      "epoch 2645, loss function 22748.20703125\n",
      "epoch 2646, loss function 22748.205078125\n",
      "epoch 2647, loss function 22748.205078125\n",
      "epoch 2648, loss function 22748.203125\n",
      "epoch 2649, loss function 22748.201171875\n",
      "epoch 2650, loss function 22748.201171875\n",
      "epoch 2651, loss function 22748.19921875\n",
      "epoch 2652, loss function 22748.19921875\n",
      "epoch 2653, loss function 22748.197265625\n",
      "epoch 2654, loss function 22748.19921875\n",
      "epoch 2655, loss function 22748.1953125\n",
      "epoch 2656, loss function 22748.1953125\n",
      "epoch 2657, loss function 22748.1953125\n",
      "epoch 2658, loss function 22748.19140625\n",
      "epoch 2659, loss function 22748.193359375\n",
      "epoch 2660, loss function 22748.19140625\n",
      "epoch 2661, loss function 22748.19140625\n",
      "epoch 2662, loss function 22748.189453125\n",
      "epoch 2663, loss function 22748.189453125\n",
      "epoch 2664, loss function 22748.1875\n",
      "epoch 2665, loss function 22748.185546875\n",
      "epoch 2666, loss function 22748.1875\n",
      "epoch 2667, loss function 22748.18359375\n",
      "epoch 2668, loss function 22748.18359375\n",
      "epoch 2669, loss function 22748.185546875\n",
      "epoch 2670, loss function 22748.181640625\n",
      "epoch 2671, loss function 22748.181640625\n",
      "epoch 2672, loss function 22748.1796875\n",
      "epoch 2673, loss function 22748.1796875\n",
      "epoch 2674, loss function 22748.1796875\n",
      "epoch 2675, loss function 22748.177734375\n",
      "epoch 2676, loss function 22748.17578125\n",
      "epoch 2677, loss function 22748.17578125\n",
      "epoch 2678, loss function 22748.17578125\n",
      "epoch 2679, loss function 22748.17578125\n",
      "epoch 2680, loss function 22748.171875\n",
      "epoch 2681, loss function 22748.171875\n",
      "epoch 2682, loss function 22748.171875\n",
      "epoch 2683, loss function 22748.169921875\n",
      "epoch 2684, loss function 22748.169921875\n",
      "epoch 2685, loss function 22748.16796875\n",
      "epoch 2686, loss function 22748.169921875\n",
      "epoch 2687, loss function 22748.16796875\n",
      "epoch 2688, loss function 22748.166015625\n",
      "epoch 2689, loss function 22748.166015625\n",
      "epoch 2690, loss function 22748.1640625\n",
      "epoch 2691, loss function 22748.1640625\n",
      "epoch 2692, loss function 22748.1640625\n",
      "epoch 2693, loss function 22748.162109375\n",
      "epoch 2694, loss function 22748.1640625\n",
      "epoch 2695, loss function 22748.16015625\n",
      "epoch 2696, loss function 22748.16015625\n",
      "epoch 2697, loss function 22748.158203125\n",
      "epoch 2698, loss function 22748.16015625\n",
      "epoch 2699, loss function 22748.15625\n",
      "epoch 2700, loss function 22748.154296875\n",
      "epoch 2701, loss function 22748.154296875\n",
      "epoch 2702, loss function 22748.154296875\n",
      "epoch 2703, loss function 22748.154296875\n",
      "epoch 2704, loss function 22748.15234375\n",
      "epoch 2705, loss function 22748.15234375\n",
      "epoch 2706, loss function 22748.15234375\n",
      "epoch 2707, loss function 22748.15234375\n",
      "epoch 2708, loss function 22748.150390625\n",
      "epoch 2709, loss function 22748.150390625\n",
      "epoch 2710, loss function 22748.1484375\n",
      "epoch 2711, loss function 22748.1484375\n",
      "epoch 2712, loss function 22748.146484375\n",
      "epoch 2713, loss function 22748.146484375\n",
      "epoch 2714, loss function 22748.146484375\n",
      "epoch 2715, loss function 22748.146484375\n",
      "epoch 2716, loss function 22748.14453125\n",
      "epoch 2717, loss function 22748.14453125\n",
      "epoch 2718, loss function 22748.142578125\n",
      "epoch 2719, loss function 22748.142578125\n",
      "epoch 2720, loss function 22748.142578125\n",
      "epoch 2721, loss function 22748.140625\n",
      "epoch 2722, loss function 22748.138671875\n",
      "epoch 2723, loss function 22748.138671875\n",
      "epoch 2724, loss function 22748.138671875\n",
      "epoch 2725, loss function 22748.138671875\n",
      "epoch 2726, loss function 22748.13671875\n",
      "epoch 2727, loss function 22748.138671875\n",
      "epoch 2728, loss function 22748.13671875\n",
      "epoch 2729, loss function 22748.1328125\n",
      "epoch 2730, loss function 22748.134765625\n",
      "epoch 2731, loss function 22748.1328125\n",
      "epoch 2732, loss function 22748.1328125\n",
      "epoch 2733, loss function 22748.1328125\n",
      "epoch 2734, loss function 22748.1328125\n",
      "epoch 2735, loss function 22748.130859375\n",
      "epoch 2736, loss function 22748.130859375\n",
      "epoch 2737, loss function 22748.12890625\n",
      "epoch 2738, loss function 22748.12890625\n",
      "epoch 2739, loss function 22748.12890625\n",
      "epoch 2740, loss function 22748.125\n",
      "epoch 2741, loss function 22748.126953125\n",
      "epoch 2742, loss function 22748.125\n",
      "epoch 2743, loss function 22748.125\n",
      "epoch 2744, loss function 22748.125\n",
      "epoch 2745, loss function 22748.125\n",
      "epoch 2746, loss function 22748.123046875\n",
      "epoch 2747, loss function 22748.125\n",
      "epoch 2748, loss function 22748.123046875\n",
      "epoch 2749, loss function 22748.12109375\n",
      "epoch 2750, loss function 22748.119140625\n",
      "epoch 2751, loss function 22748.119140625\n",
      "epoch 2752, loss function 22748.1171875\n",
      "epoch 2753, loss function 22748.119140625\n",
      "epoch 2754, loss function 22748.1171875\n",
      "epoch 2755, loss function 22748.115234375\n",
      "epoch 2756, loss function 22748.1171875\n",
      "epoch 2757, loss function 22748.1171875\n",
      "epoch 2758, loss function 22748.115234375\n",
      "epoch 2759, loss function 22748.11328125\n",
      "epoch 2760, loss function 22748.11328125\n",
      "epoch 2761, loss function 22748.11328125\n",
      "epoch 2762, loss function 22748.11328125\n",
      "epoch 2763, loss function 22748.111328125\n",
      "epoch 2764, loss function 22748.109375\n",
      "epoch 2765, loss function 22748.111328125\n",
      "epoch 2766, loss function 22748.111328125\n",
      "epoch 2767, loss function 22748.109375\n",
      "epoch 2768, loss function 22748.107421875\n",
      "epoch 2769, loss function 22748.107421875\n",
      "epoch 2770, loss function 22748.107421875\n",
      "epoch 2771, loss function 22748.107421875\n",
      "epoch 2772, loss function 22748.10546875\n",
      "epoch 2773, loss function 22748.10546875\n",
      "epoch 2774, loss function 22748.10546875\n",
      "epoch 2775, loss function 22748.10546875\n",
      "epoch 2776, loss function 22748.10546875\n",
      "epoch 2777, loss function 22748.103515625\n",
      "epoch 2778, loss function 22748.1015625\n",
      "epoch 2779, loss function 22748.1015625\n",
      "epoch 2780, loss function 22748.103515625\n",
      "epoch 2781, loss function 22748.099609375\n",
      "epoch 2782, loss function 22748.099609375\n",
      "epoch 2783, loss function 22748.099609375\n",
      "epoch 2784, loss function 22748.09765625\n",
      "epoch 2785, loss function 22748.099609375\n",
      "epoch 2786, loss function 22748.09765625\n",
      "epoch 2787, loss function 22748.09765625\n",
      "epoch 2788, loss function 22748.09765625\n",
      "epoch 2789, loss function 22748.095703125\n",
      "epoch 2790, loss function 22748.09765625\n",
      "epoch 2791, loss function 22748.095703125\n",
      "epoch 2792, loss function 22748.091796875\n",
      "epoch 2793, loss function 22748.09375\n",
      "epoch 2794, loss function 22748.09375\n",
      "epoch 2795, loss function 22748.09375\n",
      "epoch 2796, loss function 22748.09375\n",
      "epoch 2797, loss function 22748.08984375\n",
      "epoch 2798, loss function 22748.08984375\n",
      "epoch 2799, loss function 22748.08984375\n",
      "epoch 2800, loss function 22748.087890625\n",
      "epoch 2801, loss function 22748.08984375\n",
      "epoch 2802, loss function 22748.08984375\n",
      "epoch 2803, loss function 22748.0859375\n",
      "epoch 2804, loss function 22748.0859375\n",
      "epoch 2805, loss function 22748.087890625\n",
      "epoch 2806, loss function 22748.083984375\n",
      "epoch 2807, loss function 22748.0859375\n",
      "epoch 2808, loss function 22748.0859375\n",
      "epoch 2809, loss function 22748.083984375\n",
      "epoch 2810, loss function 22748.08203125\n",
      "epoch 2811, loss function 22748.0859375\n",
      "epoch 2812, loss function 22748.083984375\n",
      "epoch 2813, loss function 22748.08203125\n",
      "epoch 2814, loss function 22748.08203125\n",
      "epoch 2815, loss function 22748.08203125\n",
      "epoch 2816, loss function 22748.08203125\n",
      "epoch 2817, loss function 22748.080078125\n",
      "epoch 2818, loss function 22748.080078125\n",
      "epoch 2819, loss function 22748.080078125\n",
      "epoch 2820, loss function 22748.080078125\n",
      "epoch 2821, loss function 22748.078125\n",
      "epoch 2822, loss function 22748.078125\n",
      "epoch 2823, loss function 22748.078125\n",
      "epoch 2824, loss function 22748.076171875\n",
      "epoch 2825, loss function 22748.076171875\n",
      "epoch 2826, loss function 22748.076171875\n",
      "epoch 2827, loss function 22748.07421875\n",
      "epoch 2828, loss function 22748.076171875\n",
      "epoch 2829, loss function 22748.07421875\n",
      "epoch 2830, loss function 22748.07421875\n",
      "epoch 2831, loss function 22748.07421875\n",
      "epoch 2832, loss function 22748.07421875\n",
      "epoch 2833, loss function 22748.072265625\n",
      "epoch 2834, loss function 22748.0703125\n",
      "epoch 2835, loss function 22748.0703125\n",
      "epoch 2836, loss function 22748.072265625\n",
      "epoch 2837, loss function 22748.0703125\n",
      "epoch 2838, loss function 22748.0703125\n",
      "epoch 2839, loss function 22748.068359375\n",
      "epoch 2840, loss function 22748.0703125\n",
      "epoch 2841, loss function 22748.0703125\n",
      "epoch 2842, loss function 22748.0703125\n",
      "epoch 2843, loss function 22748.068359375\n",
      "epoch 2844, loss function 22748.068359375\n",
      "epoch 2845, loss function 22748.064453125\n",
      "epoch 2846, loss function 22748.06640625\n",
      "epoch 2847, loss function 22748.06640625\n",
      "epoch 2848, loss function 22748.06640625\n",
      "epoch 2849, loss function 22748.064453125\n",
      "epoch 2850, loss function 22748.064453125\n",
      "epoch 2851, loss function 22748.0625\n",
      "epoch 2852, loss function 22748.064453125\n",
      "epoch 2853, loss function 22748.0625\n",
      "epoch 2854, loss function 22748.060546875\n",
      "epoch 2855, loss function 22748.0625\n",
      "epoch 2856, loss function 22748.0625\n",
      "epoch 2857, loss function 22748.0625\n",
      "epoch 2858, loss function 22748.060546875\n",
      "epoch 2859, loss function 22748.060546875\n",
      "epoch 2860, loss function 22748.060546875\n",
      "epoch 2861, loss function 22748.05859375\n",
      "epoch 2862, loss function 22748.05859375\n",
      "epoch 2863, loss function 22748.05859375\n",
      "epoch 2864, loss function 22748.060546875\n",
      "epoch 2865, loss function 22748.05859375\n",
      "epoch 2866, loss function 22748.05859375\n",
      "epoch 2867, loss function 22748.056640625\n",
      "epoch 2868, loss function 22748.056640625\n",
      "epoch 2869, loss function 22748.056640625\n",
      "epoch 2870, loss function 22748.056640625\n",
      "epoch 2871, loss function 22748.0546875\n",
      "epoch 2872, loss function 22748.056640625\n",
      "epoch 2873, loss function 22748.052734375\n",
      "epoch 2874, loss function 22748.0546875\n",
      "epoch 2875, loss function 22748.052734375\n",
      "epoch 2876, loss function 22748.052734375\n",
      "epoch 2877, loss function 22748.052734375\n",
      "epoch 2878, loss function 22748.05078125\n",
      "epoch 2879, loss function 22748.052734375\n",
      "epoch 2880, loss function 22748.052734375\n",
      "epoch 2881, loss function 22748.05078125\n",
      "epoch 2882, loss function 22748.05078125\n",
      "epoch 2883, loss function 22748.048828125\n",
      "epoch 2884, loss function 22748.048828125\n",
      "epoch 2885, loss function 22748.05078125\n",
      "epoch 2886, loss function 22748.046875\n",
      "epoch 2887, loss function 22748.05078125\n",
      "epoch 2888, loss function 22748.048828125\n",
      "epoch 2889, loss function 22748.048828125\n",
      "epoch 2890, loss function 22748.046875\n",
      "epoch 2891, loss function 22748.046875\n",
      "epoch 2892, loss function 22748.044921875\n",
      "epoch 2893, loss function 22748.044921875\n",
      "epoch 2894, loss function 22748.046875\n",
      "epoch 2895, loss function 22748.044921875\n",
      "epoch 2896, loss function 22748.044921875\n",
      "epoch 2897, loss function 22748.044921875\n",
      "epoch 2898, loss function 22748.044921875\n",
      "epoch 2899, loss function 22748.044921875\n",
      "epoch 2900, loss function 22748.044921875\n",
      "epoch 2901, loss function 22748.04296875\n",
      "epoch 2902, loss function 22748.04296875\n",
      "epoch 2903, loss function 22748.041015625\n",
      "epoch 2904, loss function 22748.04296875\n",
      "epoch 2905, loss function 22748.041015625\n",
      "epoch 2906, loss function 22748.041015625\n",
      "epoch 2907, loss function 22748.041015625\n",
      "epoch 2908, loss function 22748.041015625\n",
      "epoch 2909, loss function 22748.041015625\n",
      "epoch 2910, loss function 22748.041015625\n",
      "epoch 2911, loss function 22748.0390625\n",
      "epoch 2912, loss function 22748.0390625\n",
      "epoch 2913, loss function 22748.0390625\n",
      "epoch 2914, loss function 22748.0390625\n",
      "epoch 2915, loss function 22748.0390625\n",
      "epoch 2916, loss function 22748.037109375\n",
      "epoch 2917, loss function 22748.03515625\n",
      "epoch 2918, loss function 22748.037109375\n",
      "epoch 2919, loss function 22748.037109375\n",
      "epoch 2920, loss function 22748.037109375\n",
      "epoch 2921, loss function 22748.03515625\n",
      "epoch 2922, loss function 22748.03515625\n",
      "epoch 2923, loss function 22748.03515625\n",
      "epoch 2924, loss function 22748.03515625\n",
      "epoch 2925, loss function 22748.033203125\n",
      "epoch 2926, loss function 22748.033203125\n",
      "epoch 2927, loss function 22748.03515625\n",
      "epoch 2928, loss function 22748.03125\n",
      "epoch 2929, loss function 22748.03515625\n",
      "epoch 2930, loss function 22748.03125\n",
      "epoch 2931, loss function 22748.03125\n",
      "epoch 2932, loss function 22748.03125\n",
      "epoch 2933, loss function 22748.03125\n",
      "epoch 2934, loss function 22748.03125\n",
      "epoch 2935, loss function 22748.03125\n",
      "epoch 2936, loss function 22748.03125\n",
      "epoch 2937, loss function 22748.03125\n",
      "epoch 2938, loss function 22748.03125\n",
      "epoch 2939, loss function 22748.03125\n",
      "epoch 2940, loss function 22748.02734375\n",
      "epoch 2941, loss function 22748.03125\n",
      "epoch 2942, loss function 22748.02734375\n",
      "epoch 2943, loss function 22748.02734375\n",
      "epoch 2944, loss function 22748.02734375\n",
      "epoch 2945, loss function 22748.02734375\n",
      "epoch 2946, loss function 22748.02734375\n",
      "epoch 2947, loss function 22748.025390625\n",
      "epoch 2948, loss function 22748.02734375\n",
      "epoch 2949, loss function 22748.02734375\n",
      "epoch 2950, loss function 22748.02734375\n",
      "epoch 2951, loss function 22748.0234375\n",
      "epoch 2952, loss function 22748.02734375\n",
      "epoch 2953, loss function 22748.02734375\n",
      "epoch 2954, loss function 22748.02734375\n",
      "epoch 2955, loss function 22748.0234375\n",
      "epoch 2956, loss function 22748.0234375\n",
      "epoch 2957, loss function 22748.0234375\n",
      "epoch 2958, loss function 22748.0234375\n",
      "epoch 2959, loss function 22748.0234375\n",
      "epoch 2960, loss function 22748.021484375\n",
      "epoch 2961, loss function 22748.021484375\n",
      "epoch 2962, loss function 22748.021484375\n",
      "epoch 2963, loss function 22748.021484375\n",
      "epoch 2964, loss function 22748.021484375\n",
      "epoch 2965, loss function 22748.021484375\n",
      "epoch 2966, loss function 22748.021484375\n",
      "epoch 2967, loss function 22748.01953125\n",
      "epoch 2968, loss function 22748.021484375\n",
      "epoch 2969, loss function 22748.01953125\n",
      "epoch 2970, loss function 22748.01953125\n",
      "epoch 2971, loss function 22748.01953125\n",
      "epoch 2972, loss function 22748.021484375\n",
      "epoch 2973, loss function 22748.01953125\n",
      "epoch 2974, loss function 22748.017578125\n",
      "epoch 2975, loss function 22748.021484375\n",
      "epoch 2976, loss function 22748.01953125\n",
      "epoch 2977, loss function 22748.01953125\n",
      "epoch 2978, loss function 22748.015625\n",
      "epoch 2979, loss function 22748.01953125\n",
      "epoch 2980, loss function 22748.015625\n",
      "epoch 2981, loss function 22748.017578125\n",
      "epoch 2982, loss function 22748.015625\n",
      "epoch 2983, loss function 22748.015625\n",
      "epoch 2984, loss function 22748.017578125\n",
      "epoch 2985, loss function 22748.015625\n",
      "epoch 2986, loss function 22748.015625\n",
      "epoch 2987, loss function 22748.015625\n",
      "epoch 2988, loss function 22748.015625\n",
      "epoch 2989, loss function 22748.015625\n",
      "epoch 2990, loss function 22748.015625\n",
      "epoch 2991, loss function 22748.015625\n",
      "epoch 2992, loss function 22748.015625\n",
      "epoch 2993, loss function 22748.013671875\n",
      "epoch 2994, loss function 22748.013671875\n",
      "epoch 2995, loss function 22748.013671875\n",
      "epoch 2996, loss function 22748.013671875\n",
      "epoch 2997, loss function 22748.01171875\n",
      "epoch 2998, loss function 22748.013671875\n",
      "epoch 2999, loss function 22748.01171875\n",
      "epoch 3000, loss function 22748.01171875\n",
      "epoch 3001, loss function 22748.01171875\n",
      "epoch 3002, loss function 22748.01171875\n",
      "epoch 3003, loss function 22748.009765625\n",
      "epoch 3004, loss function 22748.009765625\n",
      "epoch 3005, loss function 22748.009765625\n",
      "epoch 3006, loss function 22748.009765625\n",
      "epoch 3007, loss function 22748.009765625\n",
      "epoch 3008, loss function 22748.009765625\n",
      "epoch 3009, loss function 22748.009765625\n",
      "epoch 3010, loss function 22748.009765625\n",
      "epoch 3011, loss function 22748.0078125\n",
      "epoch 3012, loss function 22748.0078125\n",
      "epoch 3013, loss function 22748.0078125\n",
      "epoch 3014, loss function 22748.009765625\n",
      "epoch 3015, loss function 22748.0078125\n",
      "epoch 3016, loss function 22748.0078125\n",
      "epoch 3017, loss function 22748.0078125\n",
      "epoch 3018, loss function 22748.0078125\n",
      "epoch 3019, loss function 22748.0078125\n",
      "epoch 3020, loss function 22748.005859375\n",
      "epoch 3021, loss function 22748.005859375\n",
      "epoch 3022, loss function 22748.005859375\n",
      "epoch 3023, loss function 22748.005859375\n",
      "epoch 3024, loss function 22748.005859375\n",
      "epoch 3025, loss function 22748.00390625\n",
      "epoch 3026, loss function 22748.00390625\n",
      "epoch 3027, loss function 22748.005859375\n",
      "epoch 3028, loss function 22748.00390625\n",
      "epoch 3029, loss function 22748.00390625\n",
      "epoch 3030, loss function 22748.00390625\n",
      "epoch 3031, loss function 22748.00390625\n",
      "epoch 3032, loss function 22748.00390625\n",
      "epoch 3033, loss function 22748.00390625\n",
      "epoch 3034, loss function 22748.00390625\n",
      "epoch 3035, loss function 22748.00390625\n",
      "epoch 3036, loss function 22748.001953125\n",
      "epoch 3037, loss function 22748.00390625\n",
      "epoch 3038, loss function 22748.001953125\n",
      "epoch 3039, loss function 22748.001953125\n",
      "epoch 3040, loss function 22748.00390625\n",
      "epoch 3041, loss function 22748.001953125\n",
      "epoch 3042, loss function 22748.001953125\n",
      "epoch 3043, loss function 22748.001953125\n",
      "epoch 3044, loss function 22748.001953125\n",
      "epoch 3045, loss function 22748.0\n",
      "epoch 3046, loss function 22748.0\n",
      "epoch 3047, loss function 22748.0\n",
      "epoch 3048, loss function 22748.0\n",
      "epoch 3049, loss function 22747.998046875\n",
      "epoch 3050, loss function 22748.0\n",
      "epoch 3051, loss function 22748.0\n",
      "epoch 3052, loss function 22748.0\n",
      "epoch 3053, loss function 22748.0\n",
      "epoch 3054, loss function 22747.998046875\n",
      "epoch 3055, loss function 22747.998046875\n",
      "epoch 3056, loss function 22747.998046875\n",
      "epoch 3057, loss function 22748.0\n",
      "epoch 3058, loss function 22747.99609375\n",
      "epoch 3059, loss function 22747.998046875\n",
      "epoch 3060, loss function 22747.998046875\n",
      "epoch 3061, loss function 22747.998046875\n",
      "epoch 3062, loss function 22747.99609375\n",
      "epoch 3063, loss function 22747.99609375\n",
      "epoch 3064, loss function 22747.99609375\n",
      "epoch 3065, loss function 22747.99609375\n",
      "epoch 3066, loss function 22747.99609375\n",
      "epoch 3067, loss function 22747.99609375\n",
      "epoch 3068, loss function 22747.99609375\n",
      "epoch 3069, loss function 22747.994140625\n",
      "epoch 3070, loss function 22747.99609375\n",
      "epoch 3071, loss function 22747.99609375\n",
      "epoch 3072, loss function 22747.99609375\n",
      "epoch 3073, loss function 22747.99609375\n",
      "epoch 3074, loss function 22747.994140625\n",
      "epoch 3075, loss function 22747.994140625\n",
      "epoch 3076, loss function 22747.994140625\n",
      "epoch 3077, loss function 22747.994140625\n",
      "epoch 3078, loss function 22747.9921875\n",
      "epoch 3079, loss function 22747.994140625\n",
      "epoch 3080, loss function 22747.994140625\n",
      "epoch 3081, loss function 22747.994140625\n",
      "epoch 3082, loss function 22747.9921875\n",
      "epoch 3083, loss function 22747.9921875\n",
      "epoch 3084, loss function 22747.994140625\n",
      "epoch 3085, loss function 22747.994140625\n",
      "epoch 3086, loss function 22747.9921875\n",
      "epoch 3087, loss function 22747.990234375\n",
      "epoch 3088, loss function 22747.9921875\n",
      "epoch 3089, loss function 22747.990234375\n",
      "epoch 3090, loss function 22747.9921875\n",
      "epoch 3091, loss function 22747.990234375\n",
      "epoch 3092, loss function 22747.9921875\n",
      "epoch 3093, loss function 22747.990234375\n",
      "epoch 3094, loss function 22747.9921875\n",
      "epoch 3095, loss function 22747.9921875\n",
      "epoch 3096, loss function 22747.990234375\n",
      "epoch 3097, loss function 22747.990234375\n",
      "epoch 3098, loss function 22747.990234375\n",
      "epoch 3099, loss function 22747.98828125\n",
      "epoch 3100, loss function 22747.98828125\n",
      "epoch 3101, loss function 22747.98828125\n",
      "epoch 3102, loss function 22747.990234375\n",
      "epoch 3103, loss function 22747.98828125\n",
      "epoch 3104, loss function 22747.98828125\n",
      "epoch 3105, loss function 22747.98828125\n",
      "epoch 3106, loss function 22747.98828125\n",
      "epoch 3107, loss function 22747.98828125\n",
      "epoch 3108, loss function 22747.986328125\n",
      "epoch 3109, loss function 22747.986328125\n",
      "epoch 3110, loss function 22747.98828125\n",
      "epoch 3111, loss function 22747.986328125\n",
      "epoch 3112, loss function 22747.98828125\n",
      "epoch 3113, loss function 22747.98828125\n",
      "epoch 3114, loss function 22747.98828125\n",
      "epoch 3115, loss function 22747.986328125\n",
      "epoch 3116, loss function 22747.986328125\n",
      "epoch 3117, loss function 22747.986328125\n",
      "epoch 3118, loss function 22747.984375\n",
      "epoch 3119, loss function 22747.986328125\n",
      "epoch 3120, loss function 22747.986328125\n",
      "epoch 3121, loss function 22747.986328125\n",
      "epoch 3122, loss function 22747.984375\n",
      "epoch 3123, loss function 22747.984375\n",
      "epoch 3124, loss function 22747.984375\n",
      "epoch 3125, loss function 22747.98828125\n",
      "epoch 3126, loss function 22747.984375\n",
      "epoch 3127, loss function 22747.984375\n",
      "epoch 3128, loss function 22747.984375\n",
      "epoch 3129, loss function 22747.984375\n",
      "epoch 3130, loss function 22747.984375\n",
      "epoch 3131, loss function 22747.984375\n",
      "epoch 3132, loss function 22747.984375\n",
      "epoch 3133, loss function 22747.982421875\n",
      "epoch 3134, loss function 22747.984375\n",
      "epoch 3135, loss function 22747.982421875\n",
      "epoch 3136, loss function 22747.984375\n",
      "epoch 3137, loss function 22747.982421875\n",
      "epoch 3138, loss function 22747.982421875\n",
      "epoch 3139, loss function 22747.98046875\n",
      "epoch 3140, loss function 22747.984375\n",
      "epoch 3141, loss function 22747.984375\n",
      "epoch 3142, loss function 22747.982421875\n",
      "epoch 3143, loss function 22747.98046875\n",
      "epoch 3144, loss function 22747.982421875\n",
      "epoch 3145, loss function 22747.982421875\n",
      "epoch 3146, loss function 22747.98046875\n",
      "epoch 3147, loss function 22747.982421875\n",
      "epoch 3148, loss function 22747.98046875\n",
      "epoch 3149, loss function 22747.98046875\n",
      "epoch 3150, loss function 22747.98046875\n",
      "epoch 3151, loss function 22747.982421875\n",
      "epoch 3152, loss function 22747.98046875\n",
      "epoch 3153, loss function 22747.98046875\n",
      "epoch 3154, loss function 22747.98046875\n",
      "epoch 3155, loss function 22747.98046875\n",
      "epoch 3156, loss function 22747.98046875\n",
      "epoch 3157, loss function 22747.98046875\n",
      "epoch 3158, loss function 22747.98046875\n",
      "epoch 3159, loss function 22747.98046875\n",
      "epoch 3160, loss function 22747.98046875\n",
      "epoch 3161, loss function 22747.982421875\n",
      "epoch 3162, loss function 22747.978515625\n",
      "epoch 3163, loss function 22747.98046875\n",
      "epoch 3164, loss function 22747.978515625\n",
      "epoch 3165, loss function 22747.978515625\n",
      "epoch 3166, loss function 22747.978515625\n",
      "epoch 3167, loss function 22747.98046875\n",
      "epoch 3168, loss function 22747.978515625\n",
      "epoch 3169, loss function 22747.98046875\n",
      "epoch 3170, loss function 22747.978515625\n",
      "epoch 3171, loss function 22747.978515625\n",
      "epoch 3172, loss function 22747.978515625\n",
      "epoch 3173, loss function 22747.978515625\n",
      "epoch 3174, loss function 22747.9765625\n",
      "epoch 3175, loss function 22747.9765625\n",
      "epoch 3176, loss function 22747.978515625\n",
      "epoch 3177, loss function 22747.9765625\n",
      "epoch 3178, loss function 22747.9765625\n",
      "epoch 3179, loss function 22747.978515625\n",
      "epoch 3180, loss function 22747.9765625\n",
      "epoch 3181, loss function 22747.978515625\n",
      "epoch 3182, loss function 22747.9765625\n",
      "epoch 3183, loss function 22747.9765625\n",
      "epoch 3184, loss function 22747.9765625\n",
      "epoch 3185, loss function 22747.974609375\n",
      "epoch 3186, loss function 22747.974609375\n",
      "epoch 3187, loss function 22747.9765625\n",
      "epoch 3188, loss function 22747.9765625\n",
      "epoch 3189, loss function 22747.974609375\n",
      "epoch 3190, loss function 22747.9765625\n",
      "epoch 3191, loss function 22747.9765625\n",
      "epoch 3192, loss function 22747.974609375\n",
      "epoch 3193, loss function 22747.9765625\n",
      "epoch 3194, loss function 22747.974609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3195, loss function 22747.974609375\n",
      "epoch 3196, loss function 22747.974609375\n",
      "epoch 3197, loss function 22747.974609375\n",
      "epoch 3198, loss function 22747.974609375\n",
      "epoch 3199, loss function 22747.9765625\n",
      "epoch 3200, loss function 22747.974609375\n",
      "epoch 3201, loss function 22747.974609375\n",
      "epoch 3202, loss function 22747.974609375\n",
      "epoch 3203, loss function 22747.974609375\n",
      "epoch 3204, loss function 22747.974609375\n",
      "epoch 3205, loss function 22747.974609375\n",
      "epoch 3206, loss function 22747.974609375\n",
      "epoch 3207, loss function 22747.97265625\n",
      "epoch 3208, loss function 22747.974609375\n",
      "epoch 3209, loss function 22747.97265625\n",
      "epoch 3210, loss function 22747.97265625\n",
      "epoch 3211, loss function 22747.974609375\n",
      "epoch 3212, loss function 22747.97265625\n",
      "epoch 3213, loss function 22747.97265625\n",
      "epoch 3214, loss function 22747.97265625\n",
      "epoch 3215, loss function 22747.970703125\n",
      "epoch 3216, loss function 22747.97265625\n",
      "epoch 3217, loss function 22747.97265625\n",
      "epoch 3218, loss function 22747.970703125\n",
      "epoch 3219, loss function 22747.97265625\n",
      "epoch 3220, loss function 22747.97265625\n",
      "epoch 3221, loss function 22747.97265625\n",
      "epoch 3222, loss function 22747.97265625\n",
      "epoch 3223, loss function 22747.97265625\n",
      "epoch 3224, loss function 22747.970703125\n",
      "epoch 3225, loss function 22747.970703125\n",
      "epoch 3226, loss function 22747.97265625\n",
      "epoch 3227, loss function 22747.970703125\n",
      "epoch 3228, loss function 22747.970703125\n",
      "epoch 3229, loss function 22747.970703125\n",
      "epoch 3230, loss function 22747.97265625\n",
      "epoch 3231, loss function 22747.970703125\n",
      "epoch 3232, loss function 22747.96875\n",
      "epoch 3233, loss function 22747.970703125\n",
      "epoch 3234, loss function 22747.970703125\n",
      "epoch 3235, loss function 22747.970703125\n",
      "epoch 3236, loss function 22747.970703125\n",
      "epoch 3237, loss function 22747.96875\n",
      "epoch 3238, loss function 22747.96875\n",
      "epoch 3239, loss function 22747.970703125\n",
      "epoch 3240, loss function 22747.96875\n",
      "epoch 3241, loss function 22747.970703125\n",
      "epoch 3242, loss function 22747.96875\n",
      "epoch 3243, loss function 22747.96875\n",
      "epoch 3244, loss function 22747.96875\n",
      "epoch 3245, loss function 22747.96875\n",
      "epoch 3246, loss function 22747.970703125\n",
      "epoch 3247, loss function 22747.96875\n",
      "epoch 3248, loss function 22747.970703125\n",
      "epoch 3249, loss function 22747.96875\n",
      "epoch 3250, loss function 22747.96875\n",
      "epoch 3251, loss function 22747.970703125\n",
      "epoch 3252, loss function 22747.96875\n",
      "epoch 3253, loss function 22747.970703125\n",
      "epoch 3254, loss function 22747.966796875\n",
      "epoch 3255, loss function 22747.966796875\n",
      "epoch 3256, loss function 22747.96875\n",
      "epoch 3257, loss function 22747.966796875\n",
      "epoch 3258, loss function 22747.966796875\n",
      "epoch 3259, loss function 22747.966796875\n",
      "epoch 3260, loss function 22747.96875\n",
      "epoch 3261, loss function 22747.966796875\n",
      "epoch 3262, loss function 22747.96875\n",
      "epoch 3263, loss function 22747.96875\n",
      "epoch 3264, loss function 22747.96875\n",
      "epoch 3265, loss function 22747.96875\n",
      "epoch 3266, loss function 22747.966796875\n",
      "epoch 3267, loss function 22747.966796875\n",
      "epoch 3268, loss function 22747.966796875\n",
      "epoch 3269, loss function 22747.966796875\n",
      "epoch 3270, loss function 22747.96484375\n",
      "epoch 3271, loss function 22747.966796875\n",
      "epoch 3272, loss function 22747.96484375\n",
      "epoch 3273, loss function 22747.966796875\n",
      "epoch 3274, loss function 22747.96875\n",
      "epoch 3275, loss function 22747.96484375\n",
      "epoch 3276, loss function 22747.966796875\n",
      "epoch 3277, loss function 22747.966796875\n",
      "epoch 3278, loss function 22747.966796875\n",
      "epoch 3279, loss function 22747.96484375\n",
      "epoch 3280, loss function 22747.966796875\n",
      "epoch 3281, loss function 22747.96484375\n",
      "epoch 3282, loss function 22747.966796875\n",
      "epoch 3283, loss function 22747.96484375\n",
      "epoch 3284, loss function 22747.96484375\n",
      "epoch 3285, loss function 22747.96484375\n",
      "epoch 3286, loss function 22747.96484375\n",
      "epoch 3287, loss function 22747.96484375\n",
      "epoch 3288, loss function 22747.96484375\n",
      "epoch 3289, loss function 22747.96484375\n",
      "epoch 3290, loss function 22747.96484375\n",
      "epoch 3291, loss function 22747.966796875\n",
      "epoch 3292, loss function 22747.96484375\n",
      "epoch 3293, loss function 22747.96484375\n",
      "epoch 3294, loss function 22747.96484375\n",
      "epoch 3295, loss function 22747.96484375\n",
      "epoch 3296, loss function 22747.962890625\n",
      "epoch 3297, loss function 22747.96484375\n",
      "epoch 3298, loss function 22747.9609375\n",
      "epoch 3299, loss function 22747.96484375\n",
      "epoch 3300, loss function 22747.96484375\n",
      "epoch 3301, loss function 22747.96484375\n",
      "epoch 3302, loss function 22747.962890625\n",
      "epoch 3303, loss function 22747.962890625\n",
      "epoch 3304, loss function 22747.96484375\n",
      "epoch 3305, loss function 22747.96484375\n",
      "epoch 3306, loss function 22747.9609375\n",
      "epoch 3307, loss function 22747.962890625\n",
      "epoch 3308, loss function 22747.962890625\n",
      "epoch 3309, loss function 22747.962890625\n",
      "epoch 3310, loss function 22747.962890625\n",
      "epoch 3311, loss function 22747.962890625\n",
      "epoch 3312, loss function 22747.962890625\n",
      "epoch 3313, loss function 22747.962890625\n",
      "epoch 3314, loss function 22747.962890625\n",
      "epoch 3315, loss function 22747.962890625\n",
      "epoch 3316, loss function 22747.962890625\n",
      "epoch 3317, loss function 22747.9609375\n",
      "epoch 3318, loss function 22747.962890625\n",
      "epoch 3319, loss function 22747.962890625\n",
      "epoch 3320, loss function 22747.9609375\n",
      "epoch 3321, loss function 22747.9609375\n",
      "epoch 3322, loss function 22747.962890625\n",
      "epoch 3323, loss function 22747.9609375\n",
      "epoch 3324, loss function 22747.9609375\n",
      "epoch 3325, loss function 22747.9609375\n",
      "epoch 3326, loss function 22747.962890625\n",
      "epoch 3327, loss function 22747.9609375\n",
      "epoch 3328, loss function 22747.9609375\n",
      "epoch 3329, loss function 22747.9609375\n",
      "epoch 3330, loss function 22747.958984375\n",
      "epoch 3331, loss function 22747.962890625\n",
      "epoch 3332, loss function 22747.9609375\n",
      "epoch 3333, loss function 22747.958984375\n",
      "epoch 3334, loss function 22747.962890625\n",
      "epoch 3335, loss function 22747.9609375\n",
      "epoch 3336, loss function 22747.9609375\n",
      "epoch 3337, loss function 22747.9609375\n",
      "epoch 3338, loss function 22747.962890625\n",
      "epoch 3339, loss function 22747.9609375\n",
      "epoch 3340, loss function 22747.9609375\n",
      "epoch 3341, loss function 22747.9609375\n",
      "epoch 3342, loss function 22747.9609375\n",
      "epoch 3343, loss function 22747.9609375\n",
      "epoch 3344, loss function 22747.9609375\n",
      "epoch 3345, loss function 22747.9609375\n",
      "epoch 3346, loss function 22747.9609375\n",
      "epoch 3347, loss function 22747.9609375\n",
      "epoch 3348, loss function 22747.9609375\n",
      "epoch 3349, loss function 22747.958984375\n",
      "epoch 3350, loss function 22747.95703125\n",
      "epoch 3351, loss function 22747.958984375\n",
      "epoch 3352, loss function 22747.9609375\n",
      "epoch 3353, loss function 22747.9609375\n",
      "epoch 3354, loss function 22747.95703125\n",
      "epoch 3355, loss function 22747.958984375\n",
      "epoch 3356, loss function 22747.958984375\n",
      "epoch 3357, loss function 22747.9609375\n",
      "epoch 3358, loss function 22747.95703125\n",
      "epoch 3359, loss function 22747.958984375\n",
      "epoch 3360, loss function 22747.958984375\n",
      "epoch 3361, loss function 22747.958984375\n",
      "epoch 3362, loss function 22747.958984375\n",
      "epoch 3363, loss function 22747.958984375\n",
      "epoch 3364, loss function 22747.958984375\n",
      "epoch 3365, loss function 22747.958984375\n",
      "epoch 3366, loss function 22747.958984375\n",
      "epoch 3367, loss function 22747.958984375\n",
      "epoch 3368, loss function 22747.958984375\n",
      "epoch 3369, loss function 22747.95703125\n",
      "epoch 3370, loss function 22747.958984375\n",
      "epoch 3371, loss function 22747.95703125\n",
      "epoch 3372, loss function 22747.958984375\n",
      "epoch 3373, loss function 22747.95703125\n",
      "epoch 3374, loss function 22747.95703125\n",
      "epoch 3375, loss function 22747.955078125\n",
      "epoch 3376, loss function 22747.95703125\n",
      "epoch 3377, loss function 22747.958984375\n",
      "epoch 3378, loss function 22747.95703125\n",
      "epoch 3379, loss function 22747.95703125\n",
      "epoch 3380, loss function 22747.95703125\n",
      "epoch 3381, loss function 22747.95703125\n",
      "epoch 3382, loss function 22747.95703125\n",
      "epoch 3383, loss function 22747.95703125\n",
      "epoch 3384, loss function 22747.95703125\n",
      "epoch 3385, loss function 22747.958984375\n",
      "epoch 3386, loss function 22747.95703125\n",
      "epoch 3387, loss function 22747.95703125\n",
      "epoch 3388, loss function 22747.95703125\n",
      "epoch 3389, loss function 22747.95703125\n",
      "epoch 3390, loss function 22747.95703125\n",
      "epoch 3391, loss function 22747.95703125\n",
      "epoch 3392, loss function 22747.95703125\n",
      "epoch 3393, loss function 22747.95703125\n",
      "epoch 3394, loss function 22747.95703125\n",
      "epoch 3395, loss function 22747.95703125\n",
      "epoch 3396, loss function 22747.95703125\n",
      "epoch 3397, loss function 22747.95703125\n",
      "epoch 3398, loss function 22747.95703125\n",
      "epoch 3399, loss function 22747.955078125\n",
      "epoch 3400, loss function 22747.955078125\n",
      "epoch 3401, loss function 22747.95703125\n",
      "epoch 3402, loss function 22747.955078125\n",
      "epoch 3403, loss function 22747.95703125\n",
      "epoch 3404, loss function 22747.955078125\n",
      "epoch 3405, loss function 22747.95703125\n",
      "epoch 3406, loss function 22747.95703125\n",
      "epoch 3407, loss function 22747.95703125\n",
      "epoch 3408, loss function 22747.95703125\n",
      "epoch 3409, loss function 22747.955078125\n",
      "epoch 3410, loss function 22747.95703125\n",
      "epoch 3411, loss function 22747.955078125\n",
      "epoch 3412, loss function 22747.95703125\n",
      "epoch 3413, loss function 22747.95703125\n",
      "epoch 3414, loss function 22747.955078125\n",
      "epoch 3415, loss function 22747.95703125\n",
      "epoch 3416, loss function 22747.955078125\n",
      "epoch 3417, loss function 22747.95703125\n",
      "epoch 3418, loss function 22747.955078125\n",
      "epoch 3419, loss function 22747.953125\n",
      "epoch 3420, loss function 22747.955078125\n",
      "epoch 3421, loss function 22747.953125\n",
      "epoch 3422, loss function 22747.955078125\n",
      "epoch 3423, loss function 22747.955078125\n",
      "epoch 3424, loss function 22747.955078125\n",
      "epoch 3425, loss function 22747.955078125\n",
      "epoch 3426, loss function 22747.955078125\n",
      "epoch 3427, loss function 22747.955078125\n",
      "epoch 3428, loss function 22747.953125\n",
      "epoch 3429, loss function 22747.955078125\n",
      "epoch 3430, loss function 22747.955078125\n",
      "epoch 3431, loss function 22747.953125\n",
      "epoch 3432, loss function 22747.955078125\n",
      "epoch 3433, loss function 22747.95703125\n",
      "epoch 3434, loss function 22747.955078125\n",
      "epoch 3435, loss function 22747.953125\n",
      "epoch 3436, loss function 22747.955078125\n",
      "epoch 3437, loss function 22747.955078125\n",
      "epoch 3438, loss function 22747.953125\n",
      "epoch 3439, loss function 22747.953125\n",
      "epoch 3440, loss function 22747.955078125\n",
      "epoch 3441, loss function 22747.953125\n",
      "epoch 3442, loss function 22747.953125\n",
      "epoch 3443, loss function 22747.953125\n",
      "epoch 3444, loss function 22747.953125\n",
      "epoch 3445, loss function 22747.953125\n",
      "epoch 3446, loss function 22747.955078125\n",
      "epoch 3447, loss function 22747.955078125\n",
      "epoch 3448, loss function 22747.953125\n",
      "epoch 3449, loss function 22747.953125\n",
      "epoch 3450, loss function 22747.953125\n",
      "epoch 3451, loss function 22747.955078125\n",
      "epoch 3452, loss function 22747.953125\n",
      "epoch 3453, loss function 22747.953125\n",
      "epoch 3454, loss function 22747.953125\n",
      "epoch 3455, loss function 22747.953125\n",
      "epoch 3456, loss function 22747.953125\n",
      "epoch 3457, loss function 22747.953125\n",
      "epoch 3458, loss function 22747.951171875\n",
      "epoch 3459, loss function 22747.953125\n",
      "epoch 3460, loss function 22747.953125\n",
      "epoch 3461, loss function 22747.953125\n",
      "epoch 3462, loss function 22747.951171875\n",
      "epoch 3463, loss function 22747.953125\n",
      "epoch 3464, loss function 22747.953125\n",
      "epoch 3465, loss function 22747.953125\n",
      "epoch 3466, loss function 22747.953125\n",
      "epoch 3467, loss function 22747.953125\n",
      "epoch 3468, loss function 22747.953125\n",
      "epoch 3469, loss function 22747.953125\n",
      "epoch 3470, loss function 22747.953125\n",
      "epoch 3471, loss function 22747.953125\n",
      "epoch 3472, loss function 22747.953125\n",
      "epoch 3473, loss function 22747.951171875\n",
      "epoch 3474, loss function 22747.953125\n",
      "epoch 3475, loss function 22747.953125\n",
      "epoch 3476, loss function 22747.953125\n",
      "epoch 3477, loss function 22747.953125\n",
      "epoch 3478, loss function 22747.951171875\n",
      "epoch 3479, loss function 22747.953125\n",
      "epoch 3480, loss function 22747.953125\n",
      "epoch 3481, loss function 22747.951171875\n",
      "epoch 3482, loss function 22747.953125\n",
      "epoch 3483, loss function 22747.953125\n",
      "epoch 3484, loss function 22747.951171875\n",
      "epoch 3485, loss function 22747.953125\n",
      "epoch 3486, loss function 22747.951171875\n",
      "epoch 3487, loss function 22747.953125\n",
      "epoch 3488, loss function 22747.951171875\n",
      "epoch 3489, loss function 22747.951171875\n",
      "epoch 3490, loss function 22747.951171875\n",
      "epoch 3491, loss function 22747.951171875\n",
      "epoch 3492, loss function 22747.953125\n",
      "epoch 3493, loss function 22747.951171875\n",
      "epoch 3494, loss function 22747.951171875\n",
      "epoch 3495, loss function 22747.951171875\n",
      "epoch 3496, loss function 22747.953125\n",
      "epoch 3497, loss function 22747.951171875\n",
      "epoch 3498, loss function 22747.953125\n",
      "epoch 3499, loss function 22747.951171875\n",
      "epoch 3500, loss function 22747.953125\n",
      "epoch 3501, loss function 22747.951171875\n",
      "epoch 3502, loss function 22747.951171875\n",
      "epoch 3503, loss function 22747.951171875\n",
      "epoch 3504, loss function 22747.951171875\n",
      "epoch 3505, loss function 22747.951171875\n",
      "epoch 3506, loss function 22747.951171875\n",
      "epoch 3507, loss function 22747.951171875\n",
      "epoch 3508, loss function 22747.953125\n",
      "epoch 3509, loss function 22747.953125\n",
      "epoch 3510, loss function 22747.951171875\n",
      "epoch 3511, loss function 22747.951171875\n",
      "epoch 3512, loss function 22747.953125\n",
      "epoch 3513, loss function 22747.951171875\n",
      "epoch 3514, loss function 22747.94921875\n",
      "epoch 3515, loss function 22747.94921875\n",
      "epoch 3516, loss function 22747.94921875\n",
      "epoch 3517, loss function 22747.951171875\n",
      "epoch 3518, loss function 22747.953125\n",
      "epoch 3519, loss function 22747.951171875\n",
      "epoch 3520, loss function 22747.94921875\n",
      "epoch 3521, loss function 22747.951171875\n",
      "epoch 3522, loss function 22747.94921875\n",
      "epoch 3523, loss function 22747.94921875\n",
      "epoch 3524, loss function 22747.951171875\n",
      "epoch 3525, loss function 22747.951171875\n",
      "epoch 3526, loss function 22747.94921875\n",
      "epoch 3527, loss function 22747.951171875\n",
      "epoch 3528, loss function 22747.94921875\n",
      "epoch 3529, loss function 22747.951171875\n",
      "epoch 3530, loss function 22747.951171875\n",
      "epoch 3531, loss function 22747.94921875\n",
      "epoch 3532, loss function 22747.94921875\n",
      "epoch 3533, loss function 22747.94921875\n",
      "epoch 3534, loss function 22747.94921875\n",
      "epoch 3535, loss function 22747.94921875\n",
      "epoch 3536, loss function 22747.94921875\n",
      "epoch 3537, loss function 22747.94921875\n",
      "epoch 3538, loss function 22747.951171875\n",
      "epoch 3539, loss function 22747.94921875\n",
      "epoch 3540, loss function 22747.94921875\n",
      "epoch 3541, loss function 22747.951171875\n",
      "epoch 3542, loss function 22747.951171875\n",
      "epoch 3543, loss function 22747.94921875\n",
      "epoch 3544, loss function 22747.951171875\n",
      "epoch 3545, loss function 22747.94921875\n",
      "epoch 3546, loss function 22747.947265625\n",
      "epoch 3547, loss function 22747.94921875\n",
      "epoch 3548, loss function 22747.94921875\n",
      "epoch 3549, loss function 22747.94921875\n",
      "epoch 3550, loss function 22747.951171875\n",
      "epoch 3551, loss function 22747.94921875\n",
      "epoch 3552, loss function 22747.94921875\n",
      "epoch 3553, loss function 22747.94921875\n",
      "epoch 3554, loss function 22747.947265625\n",
      "epoch 3555, loss function 22747.94921875\n",
      "epoch 3556, loss function 22747.94921875\n",
      "epoch 3557, loss function 22747.94921875\n",
      "epoch 3558, loss function 22747.947265625\n",
      "epoch 3559, loss function 22747.94921875\n",
      "epoch 3560, loss function 22747.94921875\n",
      "epoch 3561, loss function 22747.94921875\n",
      "epoch 3562, loss function 22747.94921875\n",
      "epoch 3563, loss function 22747.94921875\n",
      "epoch 3564, loss function 22747.94921875\n",
      "epoch 3565, loss function 22747.94921875\n",
      "epoch 3566, loss function 22747.94921875\n",
      "epoch 3567, loss function 22747.94921875\n",
      "epoch 3568, loss function 22747.94921875\n",
      "epoch 3569, loss function 22747.94921875\n",
      "epoch 3570, loss function 22747.94921875\n",
      "epoch 3571, loss function 22747.94921875\n",
      "epoch 3572, loss function 22747.94921875\n",
      "epoch 3573, loss function 22747.94921875\n",
      "epoch 3574, loss function 22747.94921875\n",
      "epoch 3575, loss function 22747.94921875\n",
      "epoch 3576, loss function 22747.947265625\n",
      "epoch 3577, loss function 22747.94921875\n",
      "epoch 3578, loss function 22747.94921875\n",
      "epoch 3579, loss function 22747.94921875\n",
      "epoch 3580, loss function 22747.947265625\n",
      "epoch 3581, loss function 22747.94921875\n",
      "epoch 3582, loss function 22747.94921875\n",
      "epoch 3583, loss function 22747.947265625\n",
      "epoch 3584, loss function 22747.951171875\n",
      "epoch 3585, loss function 22747.94921875\n",
      "epoch 3586, loss function 22747.947265625\n",
      "epoch 3587, loss function 22747.951171875\n",
      "epoch 3588, loss function 22747.947265625\n",
      "epoch 3589, loss function 22747.947265625\n",
      "epoch 3590, loss function 22747.94921875\n",
      "epoch 3591, loss function 22747.94921875\n",
      "epoch 3592, loss function 22747.947265625\n",
      "epoch 3593, loss function 22747.94921875\n",
      "epoch 3594, loss function 22747.94921875\n",
      "epoch 3595, loss function 22747.947265625\n",
      "epoch 3596, loss function 22747.947265625\n",
      "epoch 3597, loss function 22747.94921875\n",
      "epoch 3598, loss function 22747.94921875\n",
      "epoch 3599, loss function 22747.947265625\n",
      "epoch 3600, loss function 22747.94921875\n",
      "epoch 3601, loss function 22747.94921875\n",
      "epoch 3602, loss function 22747.94921875\n",
      "epoch 3603, loss function 22747.947265625\n",
      "epoch 3604, loss function 22747.94921875\n",
      "epoch 3605, loss function 22747.94921875\n",
      "epoch 3606, loss function 22747.9453125\n",
      "epoch 3607, loss function 22747.94921875\n",
      "epoch 3608, loss function 22747.947265625\n",
      "epoch 3609, loss function 22747.947265625\n",
      "epoch 3610, loss function 22747.94921875\n",
      "epoch 3611, loss function 22747.94921875\n",
      "epoch 3612, loss function 22747.9453125\n",
      "epoch 3613, loss function 22747.9453125\n",
      "epoch 3614, loss function 22747.94921875\n",
      "epoch 3615, loss function 22747.947265625\n",
      "epoch 3616, loss function 22747.947265625\n",
      "epoch 3617, loss function 22747.9453125\n",
      "epoch 3618, loss function 22747.947265625\n",
      "epoch 3619, loss function 22747.947265625\n",
      "epoch 3620, loss function 22747.94921875\n",
      "epoch 3621, loss function 22747.947265625\n",
      "epoch 3622, loss function 22747.947265625\n",
      "epoch 3623, loss function 22747.947265625\n",
      "epoch 3624, loss function 22747.94921875\n",
      "epoch 3625, loss function 22747.947265625\n",
      "epoch 3626, loss function 22747.947265625\n",
      "epoch 3627, loss function 22747.94921875\n",
      "epoch 3628, loss function 22747.947265625\n",
      "epoch 3629, loss function 22747.947265625\n",
      "epoch 3630, loss function 22747.9453125\n",
      "epoch 3631, loss function 22747.947265625\n",
      "epoch 3632, loss function 22747.947265625\n",
      "epoch 3633, loss function 22747.9453125\n",
      "epoch 3634, loss function 22747.9453125\n",
      "epoch 3635, loss function 22747.947265625\n",
      "epoch 3636, loss function 22747.947265625\n",
      "epoch 3637, loss function 22747.947265625\n",
      "epoch 3638, loss function 22747.947265625\n",
      "epoch 3639, loss function 22747.947265625\n",
      "epoch 3640, loss function 22747.947265625\n",
      "epoch 3641, loss function 22747.9453125\n",
      "epoch 3642, loss function 22747.947265625\n",
      "epoch 3643, loss function 22747.947265625\n",
      "epoch 3644, loss function 22747.9453125\n",
      "epoch 3645, loss function 22747.947265625\n",
      "epoch 3646, loss function 22747.947265625\n",
      "epoch 3647, loss function 22747.947265625\n",
      "epoch 3648, loss function 22747.9453125\n",
      "epoch 3649, loss function 22747.947265625\n",
      "epoch 3650, loss function 22747.947265625\n",
      "epoch 3651, loss function 22747.9453125\n",
      "epoch 3652, loss function 22747.947265625\n",
      "epoch 3653, loss function 22747.947265625\n",
      "epoch 3654, loss function 22747.9453125\n",
      "epoch 3655, loss function 22747.94921875\n",
      "epoch 3656, loss function 22747.947265625\n",
      "epoch 3657, loss function 22747.947265625\n",
      "epoch 3658, loss function 22747.9453125\n",
      "epoch 3659, loss function 22747.9453125\n",
      "epoch 3660, loss function 22747.947265625\n",
      "epoch 3661, loss function 22747.947265625\n",
      "epoch 3662, loss function 22747.9453125\n",
      "epoch 3663, loss function 22747.9453125\n",
      "epoch 3664, loss function 22747.9453125\n",
      "epoch 3665, loss function 22747.9453125\n",
      "epoch 3666, loss function 22747.9453125\n",
      "epoch 3667, loss function 22747.947265625\n",
      "epoch 3668, loss function 22747.947265625\n",
      "epoch 3669, loss function 22747.9453125\n",
      "epoch 3670, loss function 22747.9453125\n",
      "epoch 3671, loss function 22747.947265625\n",
      "epoch 3672, loss function 22747.947265625\n",
      "epoch 3673, loss function 22747.947265625\n",
      "epoch 3674, loss function 22747.9453125\n",
      "epoch 3675, loss function 22747.947265625\n",
      "epoch 3676, loss function 22747.9453125\n",
      "epoch 3677, loss function 22747.9453125\n",
      "epoch 3678, loss function 22747.9453125\n",
      "epoch 3679, loss function 22747.9453125\n",
      "epoch 3680, loss function 22747.9453125\n",
      "epoch 3681, loss function 22747.9453125\n",
      "epoch 3682, loss function 22747.9453125\n",
      "epoch 3683, loss function 22747.9453125\n",
      "epoch 3684, loss function 22747.9453125\n",
      "epoch 3685, loss function 22747.9453125\n",
      "epoch 3686, loss function 22747.947265625\n",
      "epoch 3687, loss function 22747.947265625\n",
      "epoch 3688, loss function 22747.9453125\n",
      "epoch 3689, loss function 22747.9453125\n",
      "epoch 3690, loss function 22747.947265625\n",
      "epoch 3691, loss function 22747.9453125\n",
      "epoch 3692, loss function 22747.9453125\n",
      "epoch 3693, loss function 22747.9453125\n",
      "epoch 3694, loss function 22747.9453125\n",
      "epoch 3695, loss function 22747.9453125\n",
      "epoch 3696, loss function 22747.9453125\n",
      "epoch 3697, loss function 22747.9453125\n",
      "epoch 3698, loss function 22747.9453125\n",
      "epoch 3699, loss function 22747.9453125\n",
      "epoch 3700, loss function 22747.9453125\n",
      "epoch 3701, loss function 22747.9453125\n",
      "epoch 3702, loss function 22747.9453125\n",
      "epoch 3703, loss function 22747.9453125\n",
      "epoch 3704, loss function 22747.943359375\n",
      "epoch 3705, loss function 22747.947265625\n",
      "epoch 3706, loss function 22747.9453125\n",
      "epoch 3707, loss function 22747.9453125\n",
      "epoch 3708, loss function 22747.9453125\n",
      "epoch 3709, loss function 22747.947265625\n",
      "epoch 3710, loss function 22747.9453125\n",
      "epoch 3711, loss function 22747.943359375\n",
      "epoch 3712, loss function 22747.943359375\n",
      "epoch 3713, loss function 22747.9453125\n",
      "epoch 3714, loss function 22747.9453125\n",
      "epoch 3715, loss function 22747.9453125\n",
      "epoch 3716, loss function 22747.9453125\n",
      "epoch 3717, loss function 22747.947265625\n",
      "epoch 3718, loss function 22747.9453125\n",
      "epoch 3719, loss function 22747.9453125\n",
      "epoch 3720, loss function 22747.9453125\n",
      "epoch 3721, loss function 22747.9453125\n",
      "epoch 3722, loss function 22747.9453125\n",
      "epoch 3723, loss function 22747.9453125\n",
      "epoch 3724, loss function 22747.9453125\n",
      "epoch 3725, loss function 22747.9453125\n",
      "epoch 3726, loss function 22747.947265625\n",
      "epoch 3727, loss function 22747.9453125\n",
      "epoch 3728, loss function 22747.9453125\n",
      "epoch 3729, loss function 22747.9453125\n",
      "epoch 3730, loss function 22747.9453125\n",
      "epoch 3731, loss function 22747.9453125\n",
      "epoch 3732, loss function 22747.9453125\n",
      "epoch 3733, loss function 22747.9453125\n",
      "epoch 3734, loss function 22747.9453125\n",
      "epoch 3735, loss function 22747.9453125\n",
      "epoch 3736, loss function 22747.943359375\n",
      "epoch 3737, loss function 22747.9453125\n",
      "epoch 3738, loss function 22747.9453125\n",
      "epoch 3739, loss function 22747.9453125\n",
      "epoch 3740, loss function 22747.9453125\n",
      "epoch 3741, loss function 22747.943359375\n",
      "epoch 3742, loss function 22747.9453125\n",
      "epoch 3743, loss function 22747.943359375\n",
      "epoch 3744, loss function 22747.9453125\n",
      "epoch 3745, loss function 22747.9453125\n",
      "epoch 3746, loss function 22747.9453125\n",
      "epoch 3747, loss function 22747.9453125\n",
      "epoch 3748, loss function 22747.943359375\n",
      "epoch 3749, loss function 22747.9453125\n",
      "epoch 3750, loss function 22747.9453125\n",
      "epoch 3751, loss function 22747.9453125\n",
      "epoch 3752, loss function 22747.9453125\n",
      "epoch 3753, loss function 22747.9453125\n",
      "epoch 3754, loss function 22747.943359375\n",
      "epoch 3755, loss function 22747.94140625\n",
      "epoch 3756, loss function 22747.9453125\n",
      "epoch 3757, loss function 22747.9453125\n",
      "epoch 3758, loss function 22747.9453125\n",
      "epoch 3759, loss function 22747.943359375\n",
      "epoch 3760, loss function 22747.947265625\n",
      "epoch 3761, loss function 22747.9453125\n",
      "epoch 3762, loss function 22747.943359375\n",
      "epoch 3763, loss function 22747.9453125\n",
      "epoch 3764, loss function 22747.947265625\n",
      "epoch 3765, loss function 22747.9453125\n",
      "epoch 3766, loss function 22747.9453125\n",
      "epoch 3767, loss function 22747.943359375\n",
      "epoch 3768, loss function 22747.9453125\n",
      "epoch 3769, loss function 22747.9453125\n",
      "epoch 3770, loss function 22747.943359375\n",
      "epoch 3771, loss function 22747.943359375\n",
      "epoch 3772, loss function 22747.943359375\n",
      "epoch 3773, loss function 22747.9453125\n",
      "epoch 3774, loss function 22747.943359375\n",
      "epoch 3775, loss function 22747.943359375\n",
      "epoch 3776, loss function 22747.9453125\n",
      "epoch 3777, loss function 22747.9453125\n",
      "epoch 3778, loss function 22747.9453125\n",
      "epoch 3779, loss function 22747.9453125\n",
      "epoch 3780, loss function 22747.943359375\n",
      "epoch 3781, loss function 22747.943359375\n",
      "epoch 3782, loss function 22747.9453125\n",
      "epoch 3783, loss function 22747.9453125\n",
      "epoch 3784, loss function 22747.943359375\n",
      "epoch 3785, loss function 22747.94140625\n",
      "epoch 3786, loss function 22747.9453125\n",
      "epoch 3787, loss function 22747.943359375\n",
      "epoch 3788, loss function 22747.9453125\n",
      "epoch 3789, loss function 22747.943359375\n",
      "epoch 3790, loss function 22747.943359375\n",
      "epoch 3791, loss function 22747.9453125\n",
      "epoch 3792, loss function 22747.9453125\n",
      "epoch 3793, loss function 22747.943359375\n",
      "epoch 3794, loss function 22747.943359375\n",
      "epoch 3795, loss function 22747.94140625\n",
      "epoch 3796, loss function 22747.943359375\n",
      "epoch 3797, loss function 22747.9453125\n",
      "epoch 3798, loss function 22747.943359375\n",
      "epoch 3799, loss function 22747.943359375\n",
      "epoch 3800, loss function 22747.94140625\n",
      "epoch 3801, loss function 22747.9453125\n",
      "epoch 3802, loss function 22747.943359375\n",
      "epoch 3803, loss function 22747.9453125\n",
      "epoch 3804, loss function 22747.943359375\n",
      "epoch 3805, loss function 22747.9453125\n",
      "epoch 3806, loss function 22747.943359375\n",
      "epoch 3807, loss function 22747.943359375\n",
      "epoch 3808, loss function 22747.943359375\n",
      "epoch 3809, loss function 22747.9453125\n",
      "epoch 3810, loss function 22747.9453125\n",
      "epoch 3811, loss function 22747.943359375\n",
      "epoch 3812, loss function 22747.943359375\n",
      "epoch 3813, loss function 22747.943359375\n",
      "epoch 3814, loss function 22747.943359375\n",
      "epoch 3815, loss function 22747.94140625\n",
      "epoch 3816, loss function 22747.943359375\n",
      "epoch 3817, loss function 22747.943359375\n",
      "epoch 3818, loss function 22747.943359375\n",
      "epoch 3819, loss function 22747.943359375\n",
      "epoch 3820, loss function 22747.94140625\n",
      "epoch 3821, loss function 22747.943359375\n",
      "epoch 3822, loss function 22747.9453125\n",
      "epoch 3823, loss function 22747.943359375\n",
      "epoch 3824, loss function 22747.9453125\n",
      "epoch 3825, loss function 22747.943359375\n",
      "epoch 3826, loss function 22747.9453125\n",
      "epoch 3827, loss function 22747.943359375\n",
      "epoch 3828, loss function 22747.943359375\n",
      "epoch 3829, loss function 22747.943359375\n",
      "epoch 3830, loss function 22747.9453125\n",
      "epoch 3831, loss function 22747.943359375\n",
      "epoch 3832, loss function 22747.943359375\n",
      "epoch 3833, loss function 22747.943359375\n",
      "epoch 3834, loss function 22747.943359375\n",
      "epoch 3835, loss function 22747.9453125\n",
      "epoch 3836, loss function 22747.9453125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3837, loss function 22747.943359375\n",
      "epoch 3838, loss function 22747.943359375\n",
      "epoch 3839, loss function 22747.943359375\n",
      "epoch 3840, loss function 22747.94140625\n",
      "epoch 3841, loss function 22747.943359375\n",
      "epoch 3842, loss function 22747.943359375\n",
      "epoch 3843, loss function 22747.943359375\n",
      "epoch 3844, loss function 22747.9453125\n",
      "epoch 3845, loss function 22747.943359375\n",
      "epoch 3846, loss function 22747.943359375\n",
      "epoch 3847, loss function 22747.943359375\n",
      "epoch 3848, loss function 22747.943359375\n",
      "epoch 3849, loss function 22747.943359375\n",
      "epoch 3850, loss function 22747.9453125\n",
      "epoch 3851, loss function 22747.943359375\n",
      "epoch 3852, loss function 22747.943359375\n",
      "epoch 3853, loss function 22747.943359375\n",
      "epoch 3854, loss function 22747.94140625\n",
      "epoch 3855, loss function 22747.9453125\n",
      "epoch 3856, loss function 22747.943359375\n",
      "epoch 3857, loss function 22747.943359375\n",
      "epoch 3858, loss function 22747.943359375\n",
      "epoch 3859, loss function 22747.943359375\n",
      "epoch 3860, loss function 22747.94140625\n",
      "epoch 3861, loss function 22747.943359375\n",
      "epoch 3862, loss function 22747.9453125\n",
      "epoch 3863, loss function 22747.943359375\n",
      "epoch 3864, loss function 22747.94140625\n",
      "epoch 3865, loss function 22747.94140625\n",
      "epoch 3866, loss function 22747.94140625\n",
      "epoch 3867, loss function 22747.943359375\n",
      "epoch 3868, loss function 22747.943359375\n",
      "epoch 3869, loss function 22747.943359375\n",
      "epoch 3870, loss function 22747.94140625\n",
      "epoch 3871, loss function 22747.9453125\n",
      "epoch 3872, loss function 22747.9453125\n",
      "epoch 3873, loss function 22747.943359375\n",
      "epoch 3874, loss function 22747.943359375\n",
      "epoch 3875, loss function 22747.94140625\n",
      "epoch 3876, loss function 22747.94140625\n",
      "epoch 3877, loss function 22747.94140625\n",
      "epoch 3878, loss function 22747.943359375\n",
      "epoch 3879, loss function 22747.943359375\n",
      "epoch 3880, loss function 22747.943359375\n",
      "epoch 3881, loss function 22747.94140625\n",
      "epoch 3882, loss function 22747.94140625\n",
      "epoch 3883, loss function 22747.943359375\n",
      "epoch 3884, loss function 22747.943359375\n",
      "epoch 3885, loss function 22747.943359375\n",
      "epoch 3886, loss function 22747.94140625\n",
      "epoch 3887, loss function 22747.943359375\n",
      "epoch 3888, loss function 22747.94140625\n",
      "epoch 3889, loss function 22747.943359375\n",
      "epoch 3890, loss function 22747.94140625\n",
      "epoch 3891, loss function 22747.943359375\n",
      "epoch 3892, loss function 22747.943359375\n",
      "epoch 3893, loss function 22747.94140625\n",
      "epoch 3894, loss function 22747.9453125\n",
      "epoch 3895, loss function 22747.943359375\n",
      "epoch 3896, loss function 22747.943359375\n",
      "epoch 3897, loss function 22747.94140625\n",
      "epoch 3898, loss function 22747.94140625\n",
      "epoch 3899, loss function 22747.94140625\n",
      "epoch 3900, loss function 22747.9453125\n",
      "epoch 3901, loss function 22747.943359375\n",
      "epoch 3902, loss function 22747.94140625\n",
      "epoch 3903, loss function 22747.94140625\n",
      "epoch 3904, loss function 22747.94140625\n",
      "epoch 3905, loss function 22747.943359375\n",
      "epoch 3906, loss function 22747.9453125\n",
      "epoch 3907, loss function 22747.943359375\n",
      "epoch 3908, loss function 22747.94140625\n",
      "epoch 3909, loss function 22747.94140625\n",
      "epoch 3910, loss function 22747.9453125\n",
      "epoch 3911, loss function 22747.943359375\n",
      "epoch 3912, loss function 22747.9453125\n",
      "epoch 3913, loss function 22747.943359375\n",
      "epoch 3914, loss function 22747.943359375\n",
      "epoch 3915, loss function 22747.94140625\n",
      "epoch 3916, loss function 22747.94140625\n",
      "epoch 3917, loss function 22747.94140625\n",
      "epoch 3918, loss function 22747.94140625\n",
      "epoch 3919, loss function 22747.943359375\n",
      "epoch 3920, loss function 22747.94140625\n",
      "epoch 3921, loss function 22747.94140625\n",
      "epoch 3922, loss function 22747.943359375\n",
      "epoch 3923, loss function 22747.943359375\n",
      "epoch 3924, loss function 22747.943359375\n",
      "epoch 3925, loss function 22747.943359375\n",
      "epoch 3926, loss function 22747.943359375\n",
      "epoch 3927, loss function 22747.94140625\n",
      "epoch 3928, loss function 22747.9453125\n",
      "epoch 3929, loss function 22747.943359375\n",
      "epoch 3930, loss function 22747.94140625\n",
      "epoch 3931, loss function 22747.943359375\n",
      "epoch 3932, loss function 22747.943359375\n",
      "epoch 3933, loss function 22747.9453125\n",
      "epoch 3934, loss function 22747.94140625\n",
      "epoch 3935, loss function 22747.943359375\n",
      "epoch 3936, loss function 22747.943359375\n",
      "epoch 3937, loss function 22747.943359375\n",
      "epoch 3938, loss function 22747.94140625\n",
      "epoch 3939, loss function 22747.943359375\n",
      "epoch 3940, loss function 22747.94140625\n",
      "epoch 3941, loss function 22747.94140625\n",
      "epoch 3942, loss function 22747.94140625\n",
      "epoch 3943, loss function 22747.94140625\n",
      "epoch 3944, loss function 22747.94140625\n",
      "epoch 3945, loss function 22747.94140625\n",
      "epoch 3946, loss function 22747.9453125\n",
      "epoch 3947, loss function 22747.94140625\n",
      "epoch 3948, loss function 22747.943359375\n",
      "epoch 3949, loss function 22747.943359375\n",
      "epoch 3950, loss function 22747.943359375\n",
      "epoch 3951, loss function 22747.94140625\n",
      "epoch 3952, loss function 22747.94140625\n",
      "epoch 3953, loss function 22747.94140625\n",
      "epoch 3954, loss function 22747.943359375\n",
      "epoch 3955, loss function 22747.94140625\n",
      "epoch 3956, loss function 22747.94140625\n",
      "epoch 3957, loss function 22747.94140625\n",
      "epoch 3958, loss function 22747.94140625\n",
      "epoch 3959, loss function 22747.94140625\n",
      "epoch 3960, loss function 22747.943359375\n",
      "epoch 3961, loss function 22747.943359375\n",
      "epoch 3962, loss function 22747.94140625\n",
      "epoch 3963, loss function 22747.94140625\n",
      "epoch 3964, loss function 22747.94140625\n",
      "epoch 3965, loss function 22747.9453125\n",
      "epoch 3966, loss function 22747.94140625\n",
      "epoch 3967, loss function 22747.943359375\n",
      "epoch 3968, loss function 22747.943359375\n",
      "epoch 3969, loss function 22747.943359375\n",
      "epoch 3970, loss function 22747.94140625\n",
      "epoch 3971, loss function 22747.94140625\n",
      "epoch 3972, loss function 22747.943359375\n",
      "epoch 3973, loss function 22747.94140625\n",
      "epoch 3974, loss function 22747.943359375\n",
      "epoch 3975, loss function 22747.94140625\n",
      "epoch 3976, loss function 22747.943359375\n",
      "epoch 3977, loss function 22747.94140625\n",
      "epoch 3978, loss function 22747.943359375\n",
      "epoch 3979, loss function 22747.943359375\n",
      "epoch 3980, loss function 22747.94140625\n",
      "epoch 3981, loss function 22747.94140625\n",
      "epoch 3982, loss function 22747.94140625\n",
      "epoch 3983, loss function 22747.94140625\n",
      "epoch 3984, loss function 22747.94140625\n",
      "epoch 3985, loss function 22747.94140625\n",
      "epoch 3986, loss function 22747.943359375\n",
      "epoch 3987, loss function 22747.94140625\n",
      "epoch 3988, loss function 22747.943359375\n",
      "epoch 3989, loss function 22747.94140625\n",
      "epoch 3990, loss function 22747.94140625\n",
      "epoch 3991, loss function 22747.94140625\n",
      "epoch 3992, loss function 22747.94140625\n",
      "epoch 3993, loss function 22747.94140625\n",
      "epoch 3994, loss function 22747.94140625\n",
      "epoch 3995, loss function 22747.94140625\n",
      "epoch 3996, loss function 22747.94140625\n",
      "epoch 3997, loss function 22747.94140625\n",
      "epoch 3998, loss function 22747.94140625\n",
      "epoch 3999, loss function 22747.94140625\n",
      "epoch 4000, loss function 22747.943359375\n",
      "epoch 4001, loss function 22747.94140625\n",
      "epoch 4002, loss function 22747.94140625\n",
      "epoch 4003, loss function 22747.94140625\n",
      "epoch 4004, loss function 22747.94140625\n",
      "epoch 4005, loss function 22747.94140625\n",
      "epoch 4006, loss function 22747.94140625\n",
      "epoch 4007, loss function 22747.943359375\n",
      "epoch 4008, loss function 22747.94140625\n",
      "epoch 4009, loss function 22747.943359375\n",
      "epoch 4010, loss function 22747.943359375\n",
      "epoch 4011, loss function 22747.94140625\n",
      "epoch 4012, loss function 22747.94140625\n",
      "epoch 4013, loss function 22747.943359375\n",
      "epoch 4014, loss function 22747.94140625\n",
      "epoch 4015, loss function 22747.943359375\n",
      "epoch 4016, loss function 22747.94140625\n",
      "epoch 4017, loss function 22747.94140625\n",
      "epoch 4018, loss function 22747.943359375\n",
      "epoch 4019, loss function 22747.94140625\n",
      "epoch 4020, loss function 22747.94140625\n",
      "epoch 4021, loss function 22747.943359375\n",
      "epoch 4022, loss function 22747.943359375\n",
      "epoch 4023, loss function 22747.943359375\n",
      "epoch 4024, loss function 22747.94140625\n",
      "epoch 4025, loss function 22747.94140625\n",
      "epoch 4026, loss function 22747.94140625\n",
      "epoch 4027, loss function 22747.94140625\n",
      "epoch 4028, loss function 22747.94140625\n",
      "epoch 4029, loss function 22747.94140625\n",
      "epoch 4030, loss function 22747.939453125\n",
      "epoch 4031, loss function 22747.939453125\n",
      "epoch 4032, loss function 22747.94140625\n",
      "epoch 4033, loss function 22747.94140625\n",
      "epoch 4034, loss function 22747.943359375\n",
      "epoch 4035, loss function 22747.94140625\n",
      "epoch 4036, loss function 22747.94140625\n",
      "epoch 4037, loss function 22747.94140625\n",
      "epoch 4038, loss function 22747.94140625\n",
      "epoch 4039, loss function 22747.94140625\n",
      "epoch 4040, loss function 22747.94140625\n",
      "epoch 4041, loss function 22747.94140625\n",
      "epoch 4042, loss function 22747.943359375\n",
      "epoch 4043, loss function 22747.94140625\n",
      "epoch 4044, loss function 22747.94140625\n",
      "epoch 4045, loss function 22747.94140625\n",
      "epoch 4046, loss function 22747.94140625\n",
      "epoch 4047, loss function 22747.94140625\n",
      "epoch 4048, loss function 22747.94140625\n",
      "epoch 4049, loss function 22747.9453125\n",
      "epoch 4050, loss function 22747.94140625\n",
      "epoch 4051, loss function 22747.94140625\n",
      "epoch 4052, loss function 22747.943359375\n",
      "epoch 4053, loss function 22747.94140625\n",
      "epoch 4054, loss function 22747.939453125\n",
      "epoch 4055, loss function 22747.94140625\n",
      "epoch 4056, loss function 22747.943359375\n",
      "epoch 4057, loss function 22747.943359375\n",
      "epoch 4058, loss function 22747.94140625\n",
      "epoch 4059, loss function 22747.943359375\n",
      "epoch 4060, loss function 22747.94140625\n",
      "epoch 4061, loss function 22747.94140625\n",
      "epoch 4062, loss function 22747.939453125\n",
      "epoch 4063, loss function 22747.94140625\n",
      "epoch 4064, loss function 22747.943359375\n",
      "epoch 4065, loss function 22747.94140625\n",
      "epoch 4066, loss function 22747.94140625\n",
      "epoch 4067, loss function 22747.94140625\n",
      "epoch 4068, loss function 22747.94140625\n",
      "epoch 4069, loss function 22747.94140625\n",
      "epoch 4070, loss function 22747.94140625\n",
      "epoch 4071, loss function 22747.94140625\n",
      "epoch 4072, loss function 22747.94140625\n",
      "epoch 4073, loss function 22747.943359375\n",
      "epoch 4074, loss function 22747.94140625\n",
      "epoch 4075, loss function 22747.94140625\n",
      "epoch 4076, loss function 22747.939453125\n",
      "epoch 4077, loss function 22747.94140625\n",
      "epoch 4078, loss function 22747.94140625\n",
      "epoch 4079, loss function 22747.94140625\n",
      "epoch 4080, loss function 22747.94140625\n",
      "epoch 4081, loss function 22747.94140625\n",
      "epoch 4082, loss function 22747.94140625\n",
      "epoch 4083, loss function 22747.94140625\n",
      "epoch 4084, loss function 22747.94140625\n",
      "epoch 4085, loss function 22747.94140625\n",
      "epoch 4086, loss function 22747.94140625\n",
      "epoch 4087, loss function 22747.94140625\n",
      "epoch 4088, loss function 22747.943359375\n",
      "epoch 4089, loss function 22747.939453125\n",
      "epoch 4090, loss function 22747.94140625\n",
      "epoch 4091, loss function 22747.939453125\n",
      "epoch 4092, loss function 22747.94140625\n",
      "epoch 4093, loss function 22747.94140625\n",
      "epoch 4094, loss function 22747.94140625\n",
      "epoch 4095, loss function 22747.94140625\n",
      "epoch 4096, loss function 22747.94140625\n",
      "epoch 4097, loss function 22747.94140625\n",
      "epoch 4098, loss function 22747.94140625\n",
      "epoch 4099, loss function 22747.94140625\n",
      "epoch 4100, loss function 22747.94140625\n",
      "epoch 4101, loss function 22747.94140625\n",
      "epoch 4102, loss function 22747.943359375\n",
      "epoch 4103, loss function 22747.94140625\n",
      "epoch 4104, loss function 22747.94140625\n",
      "epoch 4105, loss function 22747.94140625\n",
      "epoch 4106, loss function 22747.94140625\n",
      "epoch 4107, loss function 22747.943359375\n",
      "epoch 4108, loss function 22747.939453125\n",
      "epoch 4109, loss function 22747.939453125\n",
      "epoch 4110, loss function 22747.9453125\n",
      "epoch 4111, loss function 22747.94140625\n",
      "epoch 4112, loss function 22747.943359375\n",
      "epoch 4113, loss function 22747.939453125\n",
      "epoch 4114, loss function 22747.94140625\n",
      "epoch 4115, loss function 22747.94140625\n",
      "epoch 4116, loss function 22747.94140625\n",
      "epoch 4117, loss function 22747.94140625\n",
      "epoch 4118, loss function 22747.94140625\n",
      "epoch 4119, loss function 22747.94140625\n",
      "epoch 4120, loss function 22747.94140625\n",
      "epoch 4121, loss function 22747.943359375\n",
      "epoch 4122, loss function 22747.94140625\n",
      "epoch 4123, loss function 22747.943359375\n",
      "epoch 4124, loss function 22747.939453125\n",
      "epoch 4125, loss function 22747.94140625\n",
      "epoch 4126, loss function 22747.94140625\n",
      "epoch 4127, loss function 22747.939453125\n",
      "epoch 4128, loss function 22747.94140625\n",
      "epoch 4129, loss function 22747.94140625\n",
      "epoch 4130, loss function 22747.943359375\n",
      "epoch 4131, loss function 22747.94140625\n",
      "epoch 4132, loss function 22747.94140625\n",
      "epoch 4133, loss function 22747.939453125\n",
      "epoch 4134, loss function 22747.94140625\n",
      "epoch 4135, loss function 22747.939453125\n",
      "epoch 4136, loss function 22747.94140625\n",
      "epoch 4137, loss function 22747.94140625\n",
      "epoch 4138, loss function 22747.94140625\n",
      "epoch 4139, loss function 22747.94140625\n",
      "epoch 4140, loss function 22747.94140625\n",
      "epoch 4141, loss function 22747.94140625\n",
      "epoch 4142, loss function 22747.94140625\n",
      "epoch 4143, loss function 22747.94140625\n",
      "epoch 4144, loss function 22747.939453125\n",
      "epoch 4145, loss function 22747.94140625\n",
      "epoch 4146, loss function 22747.94140625\n",
      "epoch 4147, loss function 22747.943359375\n",
      "epoch 4148, loss function 22747.943359375\n",
      "epoch 4149, loss function 22747.94140625\n",
      "epoch 4150, loss function 22747.94140625\n",
      "epoch 4151, loss function 22747.94140625\n",
      "epoch 4152, loss function 22747.94140625\n",
      "epoch 4153, loss function 22747.94140625\n",
      "epoch 4154, loss function 22747.94140625\n",
      "epoch 4155, loss function 22747.94140625\n",
      "epoch 4156, loss function 22747.94140625\n",
      "epoch 4157, loss function 22747.94140625\n",
      "epoch 4158, loss function 22747.94140625\n",
      "epoch 4159, loss function 22747.939453125\n",
      "epoch 4160, loss function 22747.94140625\n",
      "epoch 4161, loss function 22747.94140625\n",
      "epoch 4162, loss function 22747.94140625\n",
      "epoch 4163, loss function 22747.94140625\n",
      "epoch 4164, loss function 22747.94140625\n",
      "epoch 4165, loss function 22747.94140625\n",
      "epoch 4166, loss function 22747.94140625\n",
      "epoch 4167, loss function 22747.94140625\n",
      "epoch 4168, loss function 22747.94140625\n",
      "epoch 4169, loss function 22747.94140625\n",
      "epoch 4170, loss function 22747.94140625\n",
      "epoch 4171, loss function 22747.94140625\n",
      "epoch 4172, loss function 22747.94140625\n",
      "epoch 4173, loss function 22747.94140625\n",
      "epoch 4174, loss function 22747.94140625\n",
      "epoch 4175, loss function 22747.94140625\n",
      "epoch 4176, loss function 22747.94140625\n",
      "epoch 4177, loss function 22747.94140625\n",
      "epoch 4178, loss function 22747.939453125\n",
      "epoch 4179, loss function 22747.939453125\n",
      "epoch 4180, loss function 22747.939453125\n",
      "epoch 4181, loss function 22747.94140625\n",
      "epoch 4182, loss function 22747.94140625\n",
      "epoch 4183, loss function 22747.94140625\n",
      "epoch 4184, loss function 22747.94140625\n",
      "epoch 4185, loss function 22747.94140625\n",
      "epoch 4186, loss function 22747.94140625\n",
      "epoch 4187, loss function 22747.94140625\n",
      "epoch 4188, loss function 22747.94140625\n",
      "epoch 4189, loss function 22747.94140625\n",
      "epoch 4190, loss function 22747.94140625\n",
      "epoch 4191, loss function 22747.94140625\n",
      "epoch 4192, loss function 22747.9375\n",
      "epoch 4193, loss function 22747.94140625\n",
      "epoch 4194, loss function 22747.94140625\n",
      "epoch 4195, loss function 22747.94140625\n",
      "epoch 4196, loss function 22747.94140625\n",
      "epoch 4197, loss function 22747.94140625\n",
      "epoch 4198, loss function 22747.94140625\n",
      "epoch 4199, loss function 22747.939453125\n",
      "epoch 4200, loss function 22747.939453125\n",
      "epoch 4201, loss function 22747.94140625\n",
      "epoch 4202, loss function 22747.94140625\n",
      "epoch 4203, loss function 22747.94140625\n",
      "epoch 4204, loss function 22747.94140625\n",
      "epoch 4205, loss function 22747.94140625\n",
      "epoch 4206, loss function 22747.94140625\n",
      "epoch 4207, loss function 22747.94140625\n",
      "epoch 4208, loss function 22747.94140625\n",
      "epoch 4209, loss function 22747.94140625\n",
      "epoch 4210, loss function 22747.939453125\n",
      "epoch 4211, loss function 22747.939453125\n",
      "epoch 4212, loss function 22747.94140625\n",
      "epoch 4213, loss function 22747.94140625\n",
      "epoch 4214, loss function 22747.94140625\n",
      "epoch 4215, loss function 22747.94140625\n",
      "epoch 4216, loss function 22747.94140625\n",
      "epoch 4217, loss function 22747.94140625\n",
      "epoch 4218, loss function 22747.94140625\n",
      "epoch 4219, loss function 22747.939453125\n",
      "epoch 4220, loss function 22747.94140625\n",
      "epoch 4221, loss function 22747.94140625\n",
      "epoch 4222, loss function 22747.939453125\n",
      "epoch 4223, loss function 22747.94140625\n",
      "epoch 4224, loss function 22747.94140625\n",
      "epoch 4225, loss function 22747.94140625\n",
      "epoch 4226, loss function 22747.94140625\n",
      "epoch 4227, loss function 22747.94140625\n",
      "epoch 4228, loss function 22747.94140625\n",
      "epoch 4229, loss function 22747.94140625\n",
      "epoch 4230, loss function 22747.94140625\n",
      "epoch 4231, loss function 22747.94140625\n",
      "epoch 4232, loss function 22747.939453125\n",
      "epoch 4233, loss function 22747.94140625\n",
      "epoch 4234, loss function 22747.94140625\n",
      "epoch 4235, loss function 22747.94140625\n",
      "epoch 4236, loss function 22747.94140625\n",
      "epoch 4237, loss function 22747.943359375\n",
      "epoch 4238, loss function 22747.94140625\n",
      "epoch 4239, loss function 22747.94140625\n",
      "epoch 4240, loss function 22747.939453125\n",
      "epoch 4241, loss function 22747.939453125\n",
      "epoch 4242, loss function 22747.939453125\n",
      "epoch 4243, loss function 22747.94140625\n",
      "epoch 4244, loss function 22747.94140625\n",
      "epoch 4245, loss function 22747.94140625\n",
      "epoch 4246, loss function 22747.94140625\n",
      "epoch 4247, loss function 22747.94140625\n",
      "epoch 4248, loss function 22747.94140625\n",
      "epoch 4249, loss function 22747.94140625\n",
      "epoch 4250, loss function 22747.94140625\n",
      "epoch 4251, loss function 22747.94140625\n",
      "epoch 4252, loss function 22747.939453125\n",
      "epoch 4253, loss function 22747.94140625\n",
      "epoch 4254, loss function 22747.94140625\n",
      "epoch 4255, loss function 22747.94140625\n",
      "epoch 4256, loss function 22747.94140625\n",
      "epoch 4257, loss function 22747.94140625\n",
      "epoch 4258, loss function 22747.939453125\n",
      "epoch 4259, loss function 22747.939453125\n",
      "epoch 4260, loss function 22747.94140625\n",
      "epoch 4261, loss function 22747.939453125\n",
      "epoch 4262, loss function 22747.94140625\n",
      "epoch 4263, loss function 22747.94140625\n",
      "epoch 4264, loss function 22747.94140625\n",
      "epoch 4265, loss function 22747.94140625\n",
      "epoch 4266, loss function 22747.94140625\n",
      "epoch 4267, loss function 22747.94140625\n",
      "epoch 4268, loss function 22747.94140625\n",
      "epoch 4269, loss function 22747.939453125\n",
      "epoch 4270, loss function 22747.94140625\n",
      "epoch 4271, loss function 22747.939453125\n",
      "epoch 4272, loss function 22747.939453125\n",
      "epoch 4273, loss function 22747.94140625\n",
      "epoch 4274, loss function 22747.94140625\n",
      "epoch 4275, loss function 22747.94140625\n",
      "epoch 4276, loss function 22747.94140625\n",
      "epoch 4277, loss function 22747.943359375\n",
      "epoch 4278, loss function 22747.94140625\n",
      "epoch 4279, loss function 22747.94140625\n",
      "epoch 4280, loss function 22747.939453125\n",
      "epoch 4281, loss function 22747.939453125\n",
      "epoch 4282, loss function 22747.94140625\n",
      "epoch 4283, loss function 22747.94140625\n",
      "epoch 4284, loss function 22747.939453125\n",
      "epoch 4285, loss function 22747.939453125\n",
      "epoch 4286, loss function 22747.94140625\n",
      "epoch 4287, loss function 22747.94140625\n",
      "epoch 4288, loss function 22747.94140625\n",
      "epoch 4289, loss function 22747.94140625\n",
      "epoch 4290, loss function 22747.94140625\n",
      "epoch 4291, loss function 22747.94140625\n",
      "epoch 4292, loss function 22747.939453125\n",
      "epoch 4293, loss function 22747.94140625\n",
      "epoch 4294, loss function 22747.939453125\n",
      "epoch 4295, loss function 22747.94140625\n",
      "epoch 4296, loss function 22747.94140625\n",
      "epoch 4297, loss function 22747.939453125\n",
      "epoch 4298, loss function 22747.94140625\n",
      "epoch 4299, loss function 22747.943359375\n",
      "epoch 4300, loss function 22747.94140625\n",
      "epoch 4301, loss function 22747.943359375\n",
      "epoch 4302, loss function 22747.94140625\n",
      "epoch 4303, loss function 22747.94140625\n",
      "epoch 4304, loss function 22747.94140625\n",
      "epoch 4305, loss function 22747.94140625\n",
      "epoch 4306, loss function 22747.939453125\n",
      "epoch 4307, loss function 22747.939453125\n",
      "epoch 4308, loss function 22747.939453125\n",
      "epoch 4309, loss function 22747.939453125\n",
      "epoch 4310, loss function 22747.94140625\n",
      "epoch 4311, loss function 22747.94140625\n",
      "epoch 4312, loss function 22747.94140625\n",
      "epoch 4313, loss function 22747.94140625\n",
      "epoch 4314, loss function 22747.94140625\n",
      "epoch 4315, loss function 22747.94140625\n",
      "epoch 4316, loss function 22747.94140625\n",
      "epoch 4317, loss function 22747.94140625\n",
      "epoch 4318, loss function 22747.94140625\n",
      "epoch 4319, loss function 22747.94140625\n",
      "epoch 4320, loss function 22747.94140625\n",
      "epoch 4321, loss function 22747.939453125\n",
      "epoch 4322, loss function 22747.939453125\n",
      "epoch 4323, loss function 22747.939453125\n",
      "epoch 4324, loss function 22747.943359375\n",
      "epoch 4325, loss function 22747.94140625\n",
      "epoch 4326, loss function 22747.94140625\n",
      "epoch 4327, loss function 22747.943359375\n",
      "epoch 4328, loss function 22747.943359375\n",
      "epoch 4329, loss function 22747.939453125\n",
      "epoch 4330, loss function 22747.939453125\n",
      "epoch 4331, loss function 22747.94140625\n",
      "epoch 4332, loss function 22747.939453125\n",
      "epoch 4333, loss function 22747.94140625\n",
      "epoch 4334, loss function 22747.94140625\n",
      "epoch 4335, loss function 22747.94140625\n",
      "epoch 4336, loss function 22747.94140625\n",
      "epoch 4337, loss function 22747.94140625\n",
      "epoch 4338, loss function 22747.94140625\n",
      "epoch 4339, loss function 22747.94140625\n",
      "epoch 4340, loss function 22747.939453125\n",
      "epoch 4341, loss function 22747.94140625\n",
      "epoch 4342, loss function 22747.94140625\n",
      "epoch 4343, loss function 22747.939453125\n",
      "epoch 4344, loss function 22747.939453125\n",
      "epoch 4345, loss function 22747.939453125\n",
      "epoch 4346, loss function 22747.94140625\n",
      "epoch 4347, loss function 22747.939453125\n",
      "epoch 4348, loss function 22747.94140625\n",
      "epoch 4349, loss function 22747.94140625\n",
      "epoch 4350, loss function 22747.943359375\n",
      "epoch 4351, loss function 22747.94140625\n",
      "epoch 4352, loss function 22747.94140625\n",
      "epoch 4353, loss function 22747.94140625\n",
      "epoch 4354, loss function 22747.94140625\n",
      "epoch 4355, loss function 22747.94140625\n",
      "epoch 4356, loss function 22747.939453125\n",
      "epoch 4357, loss function 22747.94140625\n",
      "epoch 4358, loss function 22747.939453125\n",
      "epoch 4359, loss function 22747.94140625\n",
      "epoch 4360, loss function 22747.94140625\n",
      "epoch 4361, loss function 22747.94140625\n",
      "epoch 4362, loss function 22747.94140625\n",
      "epoch 4363, loss function 22747.939453125\n",
      "epoch 4364, loss function 22747.94140625\n",
      "epoch 4365, loss function 22747.94140625\n",
      "epoch 4366, loss function 22747.94140625\n",
      "epoch 4367, loss function 22747.939453125\n",
      "epoch 4368, loss function 22747.939453125\n",
      "epoch 4369, loss function 22747.94140625\n",
      "epoch 4370, loss function 22747.94140625\n",
      "epoch 4371, loss function 22747.94140625\n",
      "epoch 4372, loss function 22747.939453125\n",
      "epoch 4373, loss function 22747.94140625\n",
      "epoch 4374, loss function 22747.94140625\n",
      "epoch 4375, loss function 22747.94140625\n",
      "epoch 4376, loss function 22747.94140625\n",
      "epoch 4377, loss function 22747.94140625\n",
      "epoch 4378, loss function 22747.94140625\n",
      "epoch 4379, loss function 22747.94140625\n",
      "epoch 4380, loss function 22747.939453125\n",
      "epoch 4381, loss function 22747.94140625\n",
      "epoch 4382, loss function 22747.94140625\n",
      "epoch 4383, loss function 22747.94140625\n",
      "epoch 4384, loss function 22747.939453125\n",
      "epoch 4385, loss function 22747.939453125\n",
      "epoch 4386, loss function 22747.94140625\n",
      "epoch 4387, loss function 22747.94140625\n",
      "epoch 4388, loss function 22747.94140625\n",
      "epoch 4389, loss function 22747.94140625\n",
      "epoch 4390, loss function 22747.94140625\n",
      "epoch 4391, loss function 22747.94140625\n",
      "epoch 4392, loss function 22747.94140625\n",
      "epoch 4393, loss function 22747.94140625\n",
      "epoch 4394, loss function 22747.939453125\n",
      "epoch 4395, loss function 22747.94140625\n",
      "epoch 4396, loss function 22747.94140625\n",
      "epoch 4397, loss function 22747.939453125\n",
      "epoch 4398, loss function 22747.939453125\n",
      "epoch 4399, loss function 22747.939453125\n",
      "epoch 4400, loss function 22747.939453125\n",
      "epoch 4401, loss function 22747.94140625\n",
      "epoch 4402, loss function 22747.94140625\n",
      "epoch 4403, loss function 22747.94140625\n",
      "epoch 4404, loss function 22747.939453125\n",
      "epoch 4405, loss function 22747.94140625\n",
      "epoch 4406, loss function 22747.94140625\n",
      "epoch 4407, loss function 22747.939453125\n",
      "epoch 4408, loss function 22747.939453125\n",
      "epoch 4409, loss function 22747.94140625\n",
      "epoch 4410, loss function 22747.939453125\n",
      "epoch 4411, loss function 22747.939453125\n",
      "epoch 4412, loss function 22747.939453125\n",
      "epoch 4413, loss function 22747.939453125\n",
      "epoch 4414, loss function 22747.94140625\n",
      "epoch 4415, loss function 22747.94140625\n",
      "epoch 4416, loss function 22747.94140625\n",
      "epoch 4417, loss function 22747.94140625\n",
      "epoch 4418, loss function 22747.94140625\n",
      "epoch 4419, loss function 22747.94140625\n",
      "epoch 4420, loss function 22747.94140625\n",
      "epoch 4421, loss function 22747.94140625\n",
      "epoch 4422, loss function 22747.94140625\n",
      "epoch 4423, loss function 22747.94140625\n",
      "epoch 4424, loss function 22747.94140625\n",
      "epoch 4425, loss function 22747.94140625\n",
      "epoch 4426, loss function 22747.94140625\n",
      "epoch 4427, loss function 22747.939453125\n",
      "epoch 4428, loss function 22747.939453125\n",
      "epoch 4429, loss function 22747.939453125\n",
      "epoch 4430, loss function 22747.939453125\n",
      "epoch 4431, loss function 22747.939453125\n",
      "epoch 4432, loss function 22747.94140625\n",
      "epoch 4433, loss function 22747.94140625\n",
      "epoch 4434, loss function 22747.94140625\n",
      "epoch 4435, loss function 22747.939453125\n",
      "epoch 4436, loss function 22747.94140625\n",
      "epoch 4437, loss function 22747.94140625\n",
      "epoch 4438, loss function 22747.939453125\n",
      "epoch 4439, loss function 22747.939453125\n",
      "epoch 4440, loss function 22747.939453125\n",
      "epoch 4441, loss function 22747.939453125\n",
      "epoch 4442, loss function 22747.94140625\n",
      "epoch 4443, loss function 22747.94140625\n",
      "epoch 4444, loss function 22747.939453125\n",
      "epoch 4445, loss function 22747.939453125\n",
      "epoch 4446, loss function 22747.94140625\n",
      "epoch 4447, loss function 22747.94140625\n",
      "epoch 4448, loss function 22747.94140625\n",
      "epoch 4449, loss function 22747.94140625\n",
      "epoch 4450, loss function 22747.94140625\n",
      "epoch 4451, loss function 22747.94140625\n",
      "epoch 4452, loss function 22747.94140625\n",
      "epoch 4453, loss function 22747.94140625\n",
      "epoch 4454, loss function 22747.939453125\n",
      "epoch 4455, loss function 22747.94140625\n",
      "epoch 4456, loss function 22747.94140625\n",
      "epoch 4457, loss function 22747.94140625\n",
      "epoch 4458, loss function 22747.94140625\n",
      "epoch 4459, loss function 22747.939453125\n",
      "epoch 4460, loss function 22747.939453125\n",
      "epoch 4461, loss function 22747.94140625\n",
      "epoch 4462, loss function 22747.94140625\n",
      "epoch 4463, loss function 22747.9375\n",
      "epoch 4464, loss function 22747.939453125\n",
      "epoch 4465, loss function 22747.939453125\n",
      "epoch 4466, loss function 22747.94140625\n",
      "epoch 4467, loss function 22747.94140625\n",
      "epoch 4468, loss function 22747.94140625\n",
      "epoch 4469, loss function 22747.94140625\n",
      "epoch 4470, loss function 22747.939453125\n",
      "epoch 4471, loss function 22747.939453125\n",
      "epoch 4472, loss function 22747.94140625\n",
      "epoch 4473, loss function 22747.94140625\n",
      "epoch 4474, loss function 22747.94140625\n",
      "epoch 4475, loss function 22747.939453125\n",
      "epoch 4476, loss function 22747.94140625\n",
      "epoch 4477, loss function 22747.94140625\n",
      "epoch 4478, loss function 22747.94140625\n",
      "epoch 4479, loss function 22747.94140625\n",
      "epoch 4480, loss function 22747.94140625\n",
      "epoch 4481, loss function 22747.939453125\n",
      "epoch 4482, loss function 22747.94140625\n",
      "epoch 4483, loss function 22747.94140625\n",
      "epoch 4484, loss function 22747.94140625\n",
      "epoch 4485, loss function 22747.939453125\n",
      "epoch 4486, loss function 22747.94140625\n",
      "epoch 4487, loss function 22747.94140625\n",
      "epoch 4488, loss function 22747.94140625\n",
      "epoch 4489, loss function 22747.939453125\n",
      "epoch 4490, loss function 22747.939453125\n",
      "epoch 4491, loss function 22747.94140625\n",
      "epoch 4492, loss function 22747.939453125\n",
      "epoch 4493, loss function 22747.94140625\n",
      "epoch 4494, loss function 22747.94140625\n",
      "epoch 4495, loss function 22747.94140625\n",
      "epoch 4496, loss function 22747.94140625\n",
      "epoch 4497, loss function 22747.94140625\n",
      "epoch 4498, loss function 22747.94140625\n",
      "epoch 4499, loss function 22747.94140625\n",
      "epoch 4500, loss function 22747.94140625\n",
      "epoch 4501, loss function 22747.94140625\n",
      "epoch 4502, loss function 22747.939453125\n",
      "epoch 4503, loss function 22747.94140625\n",
      "epoch 4504, loss function 22747.94140625\n",
      "epoch 4505, loss function 22747.939453125\n",
      "epoch 4506, loss function 22747.939453125\n",
      "epoch 4507, loss function 22747.94140625\n",
      "epoch 4508, loss function 22747.94140625\n",
      "epoch 4509, loss function 22747.94140625\n",
      "epoch 4510, loss function 22747.94140625\n",
      "epoch 4511, loss function 22747.94140625\n",
      "epoch 4512, loss function 22747.94140625\n",
      "epoch 4513, loss function 22747.939453125\n",
      "epoch 4514, loss function 22747.939453125\n",
      "epoch 4515, loss function 22747.94140625\n",
      "epoch 4516, loss function 22747.94140625\n",
      "epoch 4517, loss function 22747.94140625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4518, loss function 22747.94140625\n",
      "epoch 4519, loss function 22747.9375\n",
      "epoch 4520, loss function 22747.94140625\n",
      "epoch 4521, loss function 22747.939453125\n",
      "epoch 4522, loss function 22747.939453125\n",
      "epoch 4523, loss function 22747.939453125\n",
      "epoch 4524, loss function 22747.939453125\n",
      "epoch 4525, loss function 22747.939453125\n",
      "epoch 4526, loss function 22747.94140625\n",
      "epoch 4527, loss function 22747.939453125\n",
      "epoch 4528, loss function 22747.939453125\n",
      "epoch 4529, loss function 22747.94140625\n",
      "epoch 4530, loss function 22747.943359375\n",
      "epoch 4531, loss function 22747.943359375\n",
      "epoch 4532, loss function 22747.943359375\n",
      "epoch 4533, loss function 22747.94140625\n",
      "epoch 4534, loss function 22747.939453125\n",
      "epoch 4535, loss function 22747.94140625\n",
      "epoch 4536, loss function 22747.94140625\n",
      "epoch 4537, loss function 22747.939453125\n",
      "epoch 4538, loss function 22747.94140625\n",
      "epoch 4539, loss function 22747.94140625\n",
      "epoch 4540, loss function 22747.939453125\n",
      "epoch 4541, loss function 22747.94140625\n",
      "epoch 4542, loss function 22747.939453125\n",
      "epoch 4543, loss function 22747.939453125\n",
      "epoch 4544, loss function 22747.939453125\n",
      "epoch 4545, loss function 22747.939453125\n",
      "epoch 4546, loss function 22747.939453125\n",
      "epoch 4547, loss function 22747.94140625\n",
      "epoch 4548, loss function 22747.94140625\n",
      "epoch 4549, loss function 22747.94140625\n",
      "epoch 4550, loss function 22747.94140625\n",
      "epoch 4551, loss function 22747.94140625\n",
      "epoch 4552, loss function 22747.94140625\n",
      "epoch 4553, loss function 22747.94140625\n",
      "epoch 4554, loss function 22747.94140625\n",
      "epoch 4555, loss function 22747.939453125\n",
      "epoch 4556, loss function 22747.94140625\n",
      "epoch 4557, loss function 22747.94140625\n",
      "epoch 4558, loss function 22747.939453125\n",
      "epoch 4559, loss function 22747.939453125\n",
      "epoch 4560, loss function 22747.94140625\n",
      "epoch 4561, loss function 22747.94140625\n",
      "epoch 4562, loss function 22747.939453125\n",
      "epoch 4563, loss function 22747.939453125\n",
      "epoch 4564, loss function 22747.939453125\n",
      "epoch 4565, loss function 22747.939453125\n",
      "epoch 4566, loss function 22747.939453125\n",
      "epoch 4567, loss function 22747.9375\n",
      "epoch 4568, loss function 22747.94140625\n",
      "epoch 4569, loss function 22747.94140625\n",
      "epoch 4570, loss function 22747.939453125\n",
      "epoch 4571, loss function 22747.939453125\n",
      "epoch 4572, loss function 22747.94140625\n",
      "epoch 4573, loss function 22747.939453125\n",
      "epoch 4574, loss function 22747.939453125\n",
      "epoch 4575, loss function 22747.94140625\n",
      "epoch 4576, loss function 22747.939453125\n",
      "epoch 4577, loss function 22747.94140625\n",
      "epoch 4578, loss function 22747.939453125\n",
      "epoch 4579, loss function 22747.94140625\n",
      "epoch 4580, loss function 22747.94140625\n",
      "epoch 4581, loss function 22747.939453125\n",
      "epoch 4582, loss function 22747.939453125\n",
      "epoch 4583, loss function 22747.939453125\n",
      "epoch 4584, loss function 22747.939453125\n",
      "epoch 4585, loss function 22747.939453125\n",
      "epoch 4586, loss function 22747.939453125\n",
      "epoch 4587, loss function 22747.94140625\n",
      "epoch 4588, loss function 22747.94140625\n",
      "epoch 4589, loss function 22747.94140625\n",
      "epoch 4590, loss function 22747.94140625\n",
      "epoch 4591, loss function 22747.94140625\n",
      "epoch 4592, loss function 22747.9375\n",
      "epoch 4593, loss function 22747.939453125\n",
      "epoch 4594, loss function 22747.94140625\n",
      "epoch 4595, loss function 22747.94140625\n",
      "epoch 4596, loss function 22747.939453125\n",
      "epoch 4597, loss function 22747.94140625\n",
      "epoch 4598, loss function 22747.939453125\n",
      "epoch 4599, loss function 22747.94140625\n",
      "epoch 4600, loss function 22747.939453125\n",
      "epoch 4601, loss function 22747.94140625\n",
      "epoch 4602, loss function 22747.939453125\n",
      "epoch 4603, loss function 22747.939453125\n",
      "epoch 4604, loss function 22747.94140625\n",
      "epoch 4605, loss function 22747.94140625\n",
      "epoch 4606, loss function 22747.94140625\n",
      "epoch 4607, loss function 22747.94140625\n",
      "epoch 4608, loss function 22747.94140625\n",
      "epoch 4609, loss function 22747.94140625\n",
      "epoch 4610, loss function 22747.94140625\n",
      "epoch 4611, loss function 22747.94140625\n",
      "epoch 4612, loss function 22747.94140625\n",
      "epoch 4613, loss function 22747.94140625\n",
      "epoch 4614, loss function 22747.94140625\n",
      "epoch 4615, loss function 22747.94140625\n",
      "epoch 4616, loss function 22747.94140625\n",
      "epoch 4617, loss function 22747.939453125\n",
      "epoch 4618, loss function 22747.94140625\n",
      "epoch 4619, loss function 22747.939453125\n",
      "epoch 4620, loss function 22747.939453125\n",
      "epoch 4621, loss function 22747.939453125\n",
      "epoch 4622, loss function 22747.939453125\n",
      "epoch 4623, loss function 22747.939453125\n",
      "epoch 4624, loss function 22747.939453125\n",
      "epoch 4625, loss function 22747.939453125\n",
      "epoch 4626, loss function 22747.939453125\n",
      "epoch 4627, loss function 22747.939453125\n",
      "epoch 4628, loss function 22747.939453125\n",
      "epoch 4629, loss function 22747.94140625\n",
      "epoch 4630, loss function 22747.94140625\n",
      "epoch 4631, loss function 22747.94140625\n",
      "epoch 4632, loss function 22747.94140625\n",
      "epoch 4633, loss function 22747.94140625\n",
      "epoch 4634, loss function 22747.939453125\n",
      "epoch 4635, loss function 22747.94140625\n",
      "epoch 4636, loss function 22747.94140625\n",
      "epoch 4637, loss function 22747.94140625\n",
      "epoch 4638, loss function 22747.94140625\n",
      "epoch 4639, loss function 22747.94140625\n",
      "epoch 4640, loss function 22747.94140625\n",
      "epoch 4641, loss function 22747.939453125\n",
      "epoch 4642, loss function 22747.939453125\n",
      "epoch 4643, loss function 22747.939453125\n",
      "epoch 4644, loss function 22747.939453125\n",
      "epoch 4645, loss function 22747.94140625\n",
      "epoch 4646, loss function 22747.94140625\n",
      "epoch 4647, loss function 22747.94140625\n",
      "epoch 4648, loss function 22747.94140625\n",
      "epoch 4649, loss function 22747.94140625\n",
      "epoch 4650, loss function 22747.94140625\n",
      "epoch 4651, loss function 22747.94140625\n",
      "epoch 4652, loss function 22747.94140625\n",
      "epoch 4653, loss function 22747.939453125\n",
      "epoch 4654, loss function 22747.94140625\n",
      "epoch 4655, loss function 22747.939453125\n",
      "epoch 4656, loss function 22747.94140625\n",
      "epoch 4657, loss function 22747.939453125\n",
      "epoch 4658, loss function 22747.939453125\n",
      "epoch 4659, loss function 22747.939453125\n",
      "epoch 4660, loss function 22747.939453125\n",
      "epoch 4661, loss function 22747.94140625\n",
      "epoch 4662, loss function 22747.939453125\n",
      "epoch 4663, loss function 22747.939453125\n",
      "epoch 4664, loss function 22747.939453125\n",
      "epoch 4665, loss function 22747.939453125\n",
      "epoch 4666, loss function 22747.939453125\n",
      "epoch 4667, loss function 22747.939453125\n",
      "epoch 4668, loss function 22747.94140625\n",
      "epoch 4669, loss function 22747.94140625\n",
      "epoch 4670, loss function 22747.94140625\n",
      "epoch 4671, loss function 22747.94140625\n",
      "epoch 4672, loss function 22747.94140625\n",
      "epoch 4673, loss function 22747.94140625\n",
      "epoch 4674, loss function 22747.94140625\n",
      "epoch 4675, loss function 22747.94140625\n",
      "epoch 4676, loss function 22747.94140625\n",
      "epoch 4677, loss function 22747.939453125\n",
      "epoch 4678, loss function 22747.939453125\n",
      "epoch 4679, loss function 22747.94140625\n",
      "epoch 4680, loss function 22747.94140625\n",
      "epoch 4681, loss function 22747.9375\n",
      "epoch 4682, loss function 22747.939453125\n",
      "epoch 4683, loss function 22747.94140625\n",
      "epoch 4684, loss function 22747.939453125\n",
      "epoch 4685, loss function 22747.939453125\n",
      "epoch 4686, loss function 22747.939453125\n",
      "epoch 4687, loss function 22747.939453125\n",
      "epoch 4688, loss function 22747.9375\n",
      "epoch 4689, loss function 22747.94140625\n",
      "epoch 4690, loss function 22747.94140625\n",
      "epoch 4691, loss function 22747.9375\n",
      "epoch 4692, loss function 22747.9375\n",
      "epoch 4693, loss function 22747.94140625\n",
      "epoch 4694, loss function 22747.94140625\n",
      "epoch 4695, loss function 22747.94140625\n",
      "epoch 4696, loss function 22747.94140625\n",
      "epoch 4697, loss function 22747.94140625\n",
      "epoch 4698, loss function 22747.94140625\n",
      "epoch 4699, loss function 22747.94140625\n",
      "epoch 4700, loss function 22747.94140625\n",
      "epoch 4701, loss function 22747.94140625\n",
      "epoch 4702, loss function 22747.939453125\n",
      "epoch 4703, loss function 22747.939453125\n",
      "epoch 4704, loss function 22747.94140625\n",
      "epoch 4705, loss function 22747.94140625\n",
      "epoch 4706, loss function 22747.94140625\n",
      "epoch 4707, loss function 22747.94140625\n",
      "epoch 4708, loss function 22747.939453125\n",
      "epoch 4709, loss function 22747.94140625\n",
      "epoch 4710, loss function 22747.939453125\n",
      "epoch 4711, loss function 22747.939453125\n",
      "epoch 4712, loss function 22747.939453125\n",
      "epoch 4713, loss function 22747.939453125\n",
      "epoch 4714, loss function 22747.939453125\n",
      "epoch 4715, loss function 22747.939453125\n",
      "epoch 4716, loss function 22747.939453125\n",
      "epoch 4717, loss function 22747.94140625\n",
      "epoch 4718, loss function 22747.94140625\n",
      "epoch 4719, loss function 22747.939453125\n",
      "epoch 4720, loss function 22747.94140625\n",
      "epoch 4721, loss function 22747.94140625\n",
      "epoch 4722, loss function 22747.94140625\n",
      "epoch 4723, loss function 22747.94140625\n",
      "epoch 4724, loss function 22747.94140625\n",
      "epoch 4725, loss function 22747.94140625\n",
      "epoch 4726, loss function 22747.94140625\n",
      "epoch 4727, loss function 22747.94140625\n",
      "epoch 4728, loss function 22747.94140625\n",
      "epoch 4729, loss function 22747.939453125\n",
      "epoch 4730, loss function 22747.94140625\n",
      "epoch 4731, loss function 22747.94140625\n",
      "epoch 4732, loss function 22747.94140625\n",
      "epoch 4733, loss function 22747.939453125\n",
      "epoch 4734, loss function 22747.939453125\n",
      "epoch 4735, loss function 22747.94140625\n",
      "epoch 4736, loss function 22747.94140625\n",
      "epoch 4737, loss function 22747.94140625\n",
      "epoch 4738, loss function 22747.939453125\n",
      "epoch 4739, loss function 22747.939453125\n",
      "epoch 4740, loss function 22747.939453125\n",
      "epoch 4741, loss function 22747.939453125\n",
      "epoch 4742, loss function 22747.939453125\n",
      "epoch 4743, loss function 22747.939453125\n",
      "epoch 4744, loss function 22747.939453125\n",
      "epoch 4745, loss function 22747.939453125\n",
      "epoch 4746, loss function 22747.939453125\n",
      "epoch 4747, loss function 22747.94140625\n",
      "epoch 4748, loss function 22747.939453125\n",
      "epoch 4749, loss function 22747.94140625\n",
      "epoch 4750, loss function 22747.94140625\n",
      "epoch 4751, loss function 22747.9375\n",
      "epoch 4752, loss function 22747.943359375\n",
      "epoch 4753, loss function 22747.94140625\n",
      "epoch 4754, loss function 22747.94140625\n",
      "epoch 4755, loss function 22747.94140625\n",
      "epoch 4756, loss function 22747.94140625\n",
      "epoch 4757, loss function 22747.94140625\n",
      "epoch 4758, loss function 22747.94140625\n",
      "epoch 4759, loss function 22747.939453125\n",
      "epoch 4760, loss function 22747.939453125\n",
      "epoch 4761, loss function 22747.94140625\n",
      "epoch 4762, loss function 22747.94140625\n",
      "epoch 4763, loss function 22747.94140625\n",
      "epoch 4764, loss function 22747.939453125\n",
      "epoch 4765, loss function 22747.939453125\n",
      "epoch 4766, loss function 22747.939453125\n",
      "epoch 4767, loss function 22747.939453125\n",
      "epoch 4768, loss function 22747.939453125\n",
      "epoch 4769, loss function 22747.939453125\n",
      "epoch 4770, loss function 22747.94140625\n",
      "epoch 4771, loss function 22747.939453125\n",
      "epoch 4772, loss function 22747.939453125\n",
      "epoch 4773, loss function 22747.939453125\n",
      "epoch 4774, loss function 22747.939453125\n",
      "epoch 4775, loss function 22747.939453125\n",
      "epoch 4776, loss function 22747.939453125\n",
      "epoch 4777, loss function 22747.939453125\n",
      "epoch 4778, loss function 22747.94140625\n",
      "epoch 4779, loss function 22747.9375\n",
      "epoch 4780, loss function 22747.94140625\n",
      "epoch 4781, loss function 22747.94140625\n",
      "epoch 4782, loss function 22747.94140625\n",
      "epoch 4783, loss function 22747.94140625\n",
      "epoch 4784, loss function 22747.94140625\n",
      "epoch 4785, loss function 22747.939453125\n",
      "epoch 4786, loss function 22747.939453125\n",
      "epoch 4787, loss function 22747.939453125\n",
      "epoch 4788, loss function 22747.94140625\n",
      "epoch 4789, loss function 22747.94140625\n",
      "epoch 4790, loss function 22747.94140625\n",
      "epoch 4791, loss function 22747.94140625\n",
      "epoch 4792, loss function 22747.939453125\n",
      "epoch 4793, loss function 22747.94140625\n",
      "epoch 4794, loss function 22747.94140625\n",
      "epoch 4795, loss function 22747.939453125\n",
      "epoch 4796, loss function 22747.939453125\n",
      "epoch 4797, loss function 22747.939453125\n",
      "epoch 4798, loss function 22747.939453125\n",
      "epoch 4799, loss function 22747.94140625\n",
      "epoch 4800, loss function 22747.94140625\n",
      "epoch 4801, loss function 22747.94140625\n",
      "epoch 4802, loss function 22747.939453125\n",
      "epoch 4803, loss function 22747.939453125\n",
      "epoch 4804, loss function 22747.9375\n",
      "epoch 4805, loss function 22747.94140625\n",
      "epoch 4806, loss function 22747.94140625\n",
      "epoch 4807, loss function 22747.94140625\n",
      "epoch 4808, loss function 22747.94140625\n",
      "epoch 4809, loss function 22747.94140625\n",
      "epoch 4810, loss function 22747.94140625\n",
      "epoch 4811, loss function 22747.94140625\n",
      "epoch 4812, loss function 22747.94140625\n",
      "epoch 4813, loss function 22747.94140625\n",
      "epoch 4814, loss function 22747.94140625\n",
      "epoch 4815, loss function 22747.94140625\n",
      "epoch 4816, loss function 22747.94140625\n",
      "epoch 4817, loss function 22747.94140625\n",
      "epoch 4818, loss function 22747.939453125\n",
      "epoch 4819, loss function 22747.939453125\n",
      "epoch 4820, loss function 22747.939453125\n",
      "epoch 4821, loss function 22747.939453125\n",
      "epoch 4822, loss function 22747.939453125\n",
      "epoch 4823, loss function 22747.939453125\n",
      "epoch 4824, loss function 22747.939453125\n",
      "epoch 4825, loss function 22747.939453125\n",
      "epoch 4826, loss function 22747.94140625\n",
      "epoch 4827, loss function 22747.94140625\n",
      "epoch 4828, loss function 22747.94140625\n",
      "epoch 4829, loss function 22747.939453125\n",
      "epoch 4830, loss function 22747.939453125\n",
      "epoch 4831, loss function 22747.939453125\n",
      "epoch 4832, loss function 22747.939453125\n",
      "epoch 4833, loss function 22747.939453125\n",
      "epoch 4834, loss function 22747.939453125\n",
      "epoch 4835, loss function 22747.94140625\n",
      "epoch 4836, loss function 22747.9375\n",
      "epoch 4837, loss function 22747.94140625\n",
      "epoch 4838, loss function 22747.94140625\n",
      "epoch 4839, loss function 22747.94140625\n",
      "epoch 4840, loss function 22747.94140625\n",
      "epoch 4841, loss function 22747.939453125\n",
      "epoch 4842, loss function 22747.939453125\n",
      "epoch 4843, loss function 22747.94140625\n",
      "epoch 4844, loss function 22747.94140625\n",
      "epoch 4845, loss function 22747.94140625\n",
      "epoch 4846, loss function 22747.94140625\n",
      "epoch 4847, loss function 22747.94140625\n",
      "epoch 4848, loss function 22747.94140625\n",
      "epoch 4849, loss function 22747.939453125\n",
      "epoch 4850, loss function 22747.939453125\n",
      "epoch 4851, loss function 22747.94140625\n",
      "epoch 4852, loss function 22747.94140625\n",
      "epoch 4853, loss function 22747.939453125\n",
      "epoch 4854, loss function 22747.94140625\n",
      "epoch 4855, loss function 22747.94140625\n",
      "epoch 4856, loss function 22747.939453125\n",
      "epoch 4857, loss function 22747.939453125\n",
      "epoch 4858, loss function 22747.94140625\n",
      "epoch 4859, loss function 22747.94140625\n",
      "epoch 4860, loss function 22747.939453125\n",
      "epoch 4861, loss function 22747.939453125\n",
      "epoch 4862, loss function 22747.939453125\n",
      "epoch 4863, loss function 22747.939453125\n",
      "epoch 4864, loss function 22747.939453125\n",
      "epoch 4865, loss function 22747.939453125\n",
      "epoch 4866, loss function 22747.94140625\n",
      "epoch 4867, loss function 22747.94140625\n",
      "epoch 4868, loss function 22747.94140625\n",
      "epoch 4869, loss function 22747.94140625\n",
      "epoch 4870, loss function 22747.939453125\n",
      "epoch 4871, loss function 22747.94140625\n",
      "epoch 4872, loss function 22747.94140625\n",
      "epoch 4873, loss function 22747.94140625\n",
      "epoch 4874, loss function 22747.94140625\n",
      "epoch 4875, loss function 22747.94140625\n",
      "epoch 4876, loss function 22747.939453125\n",
      "epoch 4877, loss function 22747.939453125\n",
      "epoch 4878, loss function 22747.939453125\n",
      "epoch 4879, loss function 22747.939453125\n",
      "epoch 4880, loss function 22747.939453125\n",
      "epoch 4881, loss function 22747.939453125\n",
      "epoch 4882, loss function 22747.939453125\n",
      "epoch 4883, loss function 22747.939453125\n",
      "epoch 4884, loss function 22747.939453125\n",
      "epoch 4885, loss function 22747.94140625\n",
      "epoch 4886, loss function 22747.939453125\n",
      "epoch 4887, loss function 22747.939453125\n",
      "epoch 4888, loss function 22747.939453125\n",
      "epoch 4889, loss function 22747.939453125\n",
      "epoch 4890, loss function 22747.939453125\n",
      "epoch 4891, loss function 22747.939453125\n",
      "epoch 4892, loss function 22747.939453125\n",
      "epoch 4893, loss function 22747.939453125\n",
      "epoch 4894, loss function 22747.94140625\n",
      "epoch 4895, loss function 22747.939453125\n",
      "epoch 4896, loss function 22747.94140625\n",
      "epoch 4897, loss function 22747.94140625\n",
      "epoch 4898, loss function 22747.94140625\n",
      "epoch 4899, loss function 22747.94140625\n",
      "epoch 4900, loss function 22747.94140625\n",
      "epoch 4901, loss function 22747.939453125\n",
      "epoch 4902, loss function 22747.94140625\n",
      "epoch 4903, loss function 22747.94140625\n",
      "epoch 4904, loss function 22747.94140625\n",
      "epoch 4905, loss function 22747.94140625\n",
      "epoch 4906, loss function 22747.94140625\n",
      "epoch 4907, loss function 22747.94140625\n",
      "epoch 4908, loss function 22747.94140625\n",
      "epoch 4909, loss function 22747.94140625\n",
      "epoch 4910, loss function 22747.94140625\n",
      "epoch 4911, loss function 22747.94140625\n",
      "epoch 4912, loss function 22747.94140625\n",
      "epoch 4913, loss function 22747.94140625\n",
      "epoch 4914, loss function 22747.939453125\n",
      "epoch 4915, loss function 22747.939453125\n",
      "epoch 4916, loss function 22747.939453125\n",
      "epoch 4917, loss function 22747.939453125\n",
      "epoch 4918, loss function 22747.939453125\n",
      "epoch 4919, loss function 22747.939453125\n",
      "epoch 4920, loss function 22747.939453125\n",
      "epoch 4921, loss function 22747.939453125\n",
      "epoch 4922, loss function 22747.939453125\n",
      "epoch 4923, loss function 22747.939453125\n",
      "epoch 4924, loss function 22747.939453125\n",
      "epoch 4925, loss function 22747.939453125\n",
      "epoch 4926, loss function 22747.94140625\n",
      "epoch 4927, loss function 22747.94140625\n",
      "epoch 4928, loss function 22747.94140625\n",
      "epoch 4929, loss function 22747.9375\n",
      "epoch 4930, loss function 22747.94140625\n",
      "epoch 4931, loss function 22747.94140625\n",
      "epoch 4932, loss function 22747.94140625\n",
      "epoch 4933, loss function 22747.9375\n",
      "epoch 4934, loss function 22747.939453125\n",
      "epoch 4935, loss function 22747.94140625\n",
      "epoch 4936, loss function 22747.94140625\n",
      "epoch 4937, loss function 22747.94140625\n",
      "epoch 4938, loss function 22747.939453125\n",
      "epoch 4939, loss function 22747.939453125\n",
      "epoch 4940, loss function 22747.939453125\n",
      "epoch 4941, loss function 22747.94140625\n",
      "epoch 4942, loss function 22747.94140625\n",
      "epoch 4943, loss function 22747.94140625\n",
      "epoch 4944, loss function 22747.94140625\n",
      "epoch 4945, loss function 22747.94140625\n",
      "epoch 4946, loss function 22747.939453125\n",
      "epoch 4947, loss function 22747.939453125\n",
      "epoch 4948, loss function 22747.939453125\n",
      "epoch 4949, loss function 22747.9375\n",
      "epoch 4950, loss function 22747.94140625\n",
      "epoch 4951, loss function 22747.939453125\n",
      "epoch 4952, loss function 22747.939453125\n",
      "epoch 4953, loss function 22747.939453125\n",
      "epoch 4954, loss function 22747.939453125\n",
      "epoch 4955, loss function 22747.939453125\n",
      "epoch 4956, loss function 22747.939453125\n",
      "epoch 4957, loss function 22747.939453125\n",
      "epoch 4958, loss function 22747.939453125\n",
      "epoch 4959, loss function 22747.94140625\n",
      "epoch 4960, loss function 22747.94140625\n",
      "epoch 4961, loss function 22747.94140625\n",
      "epoch 4962, loss function 22747.94140625\n",
      "epoch 4963, loss function 22747.943359375\n",
      "epoch 4964, loss function 22747.94140625\n",
      "epoch 4965, loss function 22747.94140625\n",
      "epoch 4966, loss function 22747.94140625\n",
      "epoch 4967, loss function 22747.94140625\n",
      "epoch 4968, loss function 22747.94140625\n",
      "epoch 4969, loss function 22747.94140625\n",
      "epoch 4970, loss function 22747.94140625\n",
      "epoch 4971, loss function 22747.94140625\n",
      "epoch 4972, loss function 22747.94140625\n",
      "epoch 4973, loss function 22747.94140625\n",
      "epoch 4974, loss function 22747.94140625\n",
      "epoch 4975, loss function 22747.94140625\n",
      "epoch 4976, loss function 22747.94140625\n",
      "epoch 4977, loss function 22747.94140625\n",
      "epoch 4978, loss function 22747.94140625\n",
      "epoch 4979, loss function 22747.94140625\n",
      "epoch 4980, loss function 22747.94140625\n",
      "epoch 4981, loss function 22747.94140625\n",
      "epoch 4982, loss function 22747.94140625\n",
      "epoch 4983, loss function 22747.94140625\n",
      "epoch 4984, loss function 22747.94140625\n",
      "epoch 4985, loss function 22747.939453125\n",
      "epoch 4986, loss function 22747.939453125\n",
      "epoch 4987, loss function 22747.939453125\n",
      "epoch 4988, loss function 22747.939453125\n",
      "epoch 4989, loss function 22747.94140625\n",
      "epoch 4990, loss function 22747.939453125\n",
      "epoch 4991, loss function 22747.939453125\n",
      "epoch 4992, loss function 22747.939453125\n",
      "epoch 4993, loss function 22747.94140625\n",
      "epoch 4994, loss function 22747.939453125\n",
      "epoch 4995, loss function 22747.939453125\n",
      "epoch 4996, loss function 22747.939453125\n",
      "epoch 4997, loss function 22747.939453125\n",
      "epoch 4998, loss function 22747.939453125\n",
      "epoch 4999, loss function 22747.939453125\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5000): \n",
    "    yhat = linear_model(X_Train)\n",
    "    loss = criterion(yhat, Y_Train) \n",
    "    Optimizer.zero_grad() \n",
    "    loss.backward() \n",
    "    Optimizer.step() \n",
    "    print('epoch {}, loss function {}'.format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "4bc890ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0267]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_variable = torch.randn(1, 3, requires_grad=True)\n",
    "\n",
    "predict_y = linear_model()\n",
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "2ddeef70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6843]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Test  = torch.normal(0, 1, (1, 3))\n",
    "y1 = torch.matmul(X_Test, torch.tensor([1.0, 2, 4])) + 3 + torch.normal(0, 1.0,torch.Size([1]))\n",
    "Y_Test = y1.reshape((-1, 1))\n",
    "yhat = linear_model(X_Test)\n",
    "criterion(yhat, Y_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "dcef0761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5381]])"
      ]
     },
     "execution_count": 631,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5f290f",
   "metadata": {},
   "source": [
    "# Now I want to go deeper into this topic\n",
    "* https://www.docker.com/blog/how-to-train-and-deploy-a-linear-regression-model-using-pytorch-part-1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e71517b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "22313955",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 1000\n",
    "true_m = torch.tensor([2, -3.4, 8])\n",
    "true_c = 4.2\n",
    "X = torch.normal(0, 1, (num_examples, len(true_m)))\n",
    "y = torch.matmul(X, true_m) + true_c\n",
    "y += torch.normal(0, 0.01, y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "2e9ad5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.5992e+01,  1.0520e+01,  1.6187e+01,  3.1880e-01, -3.0951e-01,\n",
       "         5.9327e+00,  1.3813e+01, -4.3555e-01,  7.9810e+00,  9.8630e+00,\n",
       "        -4.1379e+00,  9.9030e+00, -1.0143e+00, -2.8659e+00, -5.8441e+00,\n",
       "         7.4970e+00,  1.0933e+00,  1.8477e+00, -7.8330e+00,  1.7300e+01,\n",
       "         9.8987e+00,  7.7476e+00, -5.5060e+00,  1.7474e+00,  9.5069e+00,\n",
       "        -1.1930e+00, -2.7354e+00, -7.6727e-01,  9.1535e+00,  1.1988e+01,\n",
       "         2.7396e+00,  1.6699e+00,  7.9077e-01, -1.2517e+01,  1.7307e+01,\n",
       "         2.1991e+01,  6.5792e+00, -2.5275e+00,  7.2011e+00, -3.5696e+00,\n",
       "         1.0896e+01,  6.7077e+00, -1.6973e+01,  6.7691e+00,  1.4527e+01,\n",
       "         1.4496e+01,  4.3423e+00, -5.6553e+00,  1.4569e+01,  2.7133e+00,\n",
       "        -1.1959e+01,  2.6006e+00,  9.2810e+00, -9.9610e+00,  7.2776e+00,\n",
       "         2.2769e+00, -6.0013e-01,  2.6475e+00, -7.9681e+00,  6.8091e+00,\n",
       "         4.2370e+00,  9.6687e+00,  7.9880e+00,  1.2205e+01,  1.8572e+01,\n",
       "         3.4821e-01,  5.5847e+00,  1.5187e+01, -1.5010e+01,  2.8282e+01,\n",
       "         1.0402e+01, -3.5058e+00, -6.7540e+00,  3.8747e+00,  6.9673e+00,\n",
       "        -2.3071e+00, -1.3838e+00, -7.4831e+00,  2.2353e+01,  1.9753e+00,\n",
       "        -9.6813e-01,  7.3189e+00,  7.0855e+00, -1.6412e-01,  1.0708e+01,\n",
       "         1.4224e+01,  2.1406e+00, -6.4785e+00,  3.9513e+00, -3.8755e+00,\n",
       "         3.9327e+00,  1.7265e+01,  1.7909e+01,  2.5472e+00,  8.2240e-01,\n",
       "         3.6053e+00,  5.2612e+00, -3.0792e-01, -6.7840e+00,  4.1621e+00,\n",
       "         1.1572e+01, -1.1009e+00, -3.5759e+00,  1.2643e+01,  8.7059e+00,\n",
       "         6.7760e+00,  1.1357e+01, -1.2597e+01, -3.6029e+00, -5.4759e+00,\n",
       "         1.1931e+01,  3.1300e+00,  1.7476e+01, -1.7984e+01,  9.6292e+00,\n",
       "        -6.8533e+00,  2.9563e+00,  1.2772e+01, -1.2842e+01,  2.3524e+00,\n",
       "         7.6107e+00,  9.8800e+00,  1.3822e+01,  1.8430e+01,  4.1049e+00,\n",
       "         6.0980e+00, -8.1540e+00,  5.8308e+00, -7.3575e+00, -1.4568e+01,\n",
       "         1.0804e+01,  5.2543e+00, -4.8453e+00,  6.8319e+00,  3.2821e+00,\n",
       "         2.2017e+01,  5.1454e+00, -3.4420e+00,  1.3452e+00,  1.8176e+00,\n",
       "         8.2351e+00,  7.8859e-01,  5.8989e+00, -3.1409e+00,  2.3682e+00,\n",
       "        -9.9355e+00, -2.8193e+00,  2.1523e+01,  2.2227e+01,  9.9070e-01,\n",
       "        -1.2904e+01,  1.0439e+01,  2.4663e+00,  2.2213e+01,  1.0531e+01,\n",
       "         2.2359e+00, -3.3990e-01,  8.6906e+00,  1.4599e+01,  4.1351e+00,\n",
       "         1.8434e+01, -1.3372e+01,  1.2475e+01,  1.6603e+01,  1.9050e+01,\n",
       "         6.0202e+00,  1.8724e+01,  2.9366e+00,  4.2677e+00,  2.3070e+00,\n",
       "        -3.6485e+00,  1.1722e+01,  6.1357e+00,  1.1908e+01,  2.0268e+01,\n",
       "        -9.1353e+00,  1.3442e+01,  3.9628e+00,  8.6398e-01,  7.9614e+00,\n",
       "        -8.0381e+00,  3.8141e+00,  6.8432e+00,  2.8306e+00, -3.6347e-01,\n",
       "        -2.7163e+00,  4.7276e+00, -2.8169e+00,  2.0642e+01, -1.2756e+00,\n",
       "        -1.3594e+00,  3.7782e+00, -5.4717e+00,  7.3367e+00, -1.5763e+01,\n",
       "        -7.2648e+00,  8.9009e+00,  1.4418e+01,  2.5633e+00, -5.0655e+00,\n",
       "         3.1113e+00, -5.1234e-01, -2.7812e-01,  4.6908e+00, -6.6974e+00,\n",
       "         9.2947e+00, -6.9855e+00,  1.3393e+01,  5.5636e+00, -1.3090e+01,\n",
       "        -1.3105e+01, -2.3743e+01, -4.6048e+00, -6.2351e+00,  1.6458e+01,\n",
       "         1.4312e+00,  1.5084e+01,  1.9372e+01,  2.4456e+00,  1.1132e+01,\n",
       "         3.1904e+01, -1.9326e+00,  8.2112e+00,  2.5707e+00,  1.7789e-02,\n",
       "        -9.8691e+00, -7.5122e+00,  6.7447e+00, -6.0244e+00,  1.7359e+01,\n",
       "         3.3385e-01,  6.7212e+00, -1.6849e+00,  1.5153e+00,  1.6446e+01,\n",
       "         1.3685e+01, -4.5887e-02, -2.4845e+00,  2.1678e+01,  1.6803e+01,\n",
       "         1.9174e+00, -3.5752e+00,  6.4917e+00,  1.6110e+01, -3.9256e+00,\n",
       "        -2.6817e+00,  1.0754e+01, -1.5655e+00,  4.0622e+00,  1.3010e+01,\n",
       "        -2.3365e+00,  5.4094e+00, -8.2419e+00, -1.1790e+00,  6.2360e+00,\n",
       "         2.1044e+01, -1.2322e+01, -3.3937e+00,  5.8006e+00,  8.2829e+00,\n",
       "        -8.6060e+00,  7.1399e+00, -6.3707e+00, -2.4653e+00,  1.8431e+00,\n",
       "        -6.9516e+00,  2.1398e+00,  3.0807e+00,  4.6405e+00,  1.7278e+01,\n",
       "         5.7405e+00,  1.9311e+01, -7.6542e+00,  1.5150e+01, -8.7522e+00,\n",
       "         4.8846e+00, -1.1588e+01, -1.5796e+01, -6.2121e+00,  5.7546e+00,\n",
       "         4.8647e+00, -4.2252e+00,  1.2382e+01,  8.7304e+00, -5.7272e+00,\n",
       "         1.3119e+01,  1.0216e+01,  2.8061e+00,  3.3668e+00,  8.5426e+00,\n",
       "         7.8350e+00, -5.9939e+00,  2.6160e-01,  3.5128e+00, -7.6337e+00,\n",
       "         2.7661e+00,  9.6139e+00,  7.9274e+00,  4.4167e+00,  1.1167e+00,\n",
       "        -1.1127e+00,  1.2854e+01, -3.3816e+00, -1.2178e+01, -5.9192e+00,\n",
       "         2.1507e+00,  8.3203e+00, -5.1383e+00, -5.9940e+00,  1.2286e+01,\n",
       "        -7.9297e+00,  3.0268e+00,  4.6203e+00,  7.9187e+00,  5.0090e+00,\n",
       "        -8.1653e-01,  1.4166e+01,  1.9592e+01,  3.2562e+00,  1.3356e+01,\n",
       "         1.2035e+01,  1.5677e+01,  8.5726e+00,  7.6243e+00,  1.0129e+01,\n",
       "         7.3508e+00, -9.5080e+00, -8.2662e+00,  4.6174e+00, -4.5542e+00,\n",
       "         1.1363e+01, -6.6191e+00,  1.4533e-02,  2.5647e+00, -2.8813e+00,\n",
       "         1.3270e+01,  5.3183e-01, -1.2779e+00, -1.2964e+00, -1.0770e-01,\n",
       "         1.8727e+01,  4.7153e+00,  6.4672e+00,  7.4407e+00,  7.7292e+00,\n",
       "         1.5673e+01, -3.9365e+00, -6.8168e+00, -7.7968e+00,  2.3700e+00,\n",
       "         2.3706e+01,  1.8350e+01,  5.9857e+00, -1.0805e+01,  1.8249e+00,\n",
       "         6.0639e+00,  1.7914e+01, -8.2689e-01, -1.3884e+00,  7.6182e+00,\n",
       "         7.9389e+00,  1.0276e+01, -1.0272e+00,  1.2835e+00, -1.2121e+01,\n",
       "        -1.1289e+01,  1.6578e+01,  9.9521e+00,  1.3900e+01, -5.4462e+00,\n",
       "         7.1072e+00, -4.5436e+00, -1.8632e+01,  1.2657e+01, -4.7188e+00,\n",
       "         1.3013e+01, -4.4684e+00, -1.0046e+01,  1.6130e+00,  1.1245e+01,\n",
       "         9.1352e+00, -6.9535e+00, -3.9289e+00,  1.0264e+01,  1.2087e+01,\n",
       "         9.1528e+00,  2.1594e+01, -7.8064e+00, -1.9454e+00, -7.4161e+00,\n",
       "         2.4856e+00, -3.6942e+00, -4.2260e+00, -3.9647e-01,  5.4784e-01,\n",
       "        -7.2603e-02, -4.7273e+00,  2.5079e+01,  1.1045e+01, -1.3995e+00,\n",
       "         5.2554e-01,  1.0827e+01, -1.0959e+01,  2.5070e+00,  7.3364e+00,\n",
       "         1.6360e+01, -5.3666e+00, -9.7506e+00,  2.3229e+01,  1.5659e+01,\n",
       "         1.2394e+01,  3.3211e+00,  1.7271e+01,  3.8677e+00,  2.4076e+00,\n",
       "         8.9028e+00, -8.1255e+00,  1.9281e+01, -9.9840e+00, -1.0407e+01,\n",
       "         6.6742e+00, -1.4667e+00, -7.1232e+00, -4.8774e+00, -5.7523e+00,\n",
       "        -1.4514e+01,  1.2090e+01, -8.1272e+00, -7.1763e+00, -7.6672e-01,\n",
       "         1.0996e+01,  4.3930e+00, -3.5305e+00,  2.1376e+01, -2.4705e+00,\n",
       "        -4.5434e+00,  7.9395e+00,  1.2014e+01,  1.1672e+00,  3.4701e+00,\n",
       "         2.0694e+01,  6.4897e+00,  8.8901e+00, -1.5025e+00,  1.0177e+01,\n",
       "        -3.7768e+00,  6.6274e+00,  1.1614e+01,  1.4785e-01,  1.0758e+01,\n",
       "        -7.8550e+00, -4.7541e+00,  8.9744e+00,  1.6369e+01,  5.3968e-01,\n",
       "        -2.0186e+01,  2.6185e-01,  1.1957e+01,  1.4659e+00,  6.7324e+00,\n",
       "         1.3326e+00,  9.4719e+00,  5.6339e+00, -2.8488e+00,  9.7334e+00,\n",
       "         3.3534e+00, -1.2733e+00, -2.9777e+00,  2.3459e+01,  1.3237e+01,\n",
       "        -3.2312e+00,  1.2642e+01, -1.5018e+01,  8.1881e+00,  1.1996e+01,\n",
       "         4.3523e+00,  1.4621e+01,  4.2763e-01,  2.6851e+00, -4.2621e+00,\n",
       "         1.0142e+00,  2.0273e+01,  4.4120e+00, -5.0907e-02,  1.6001e+01,\n",
       "         2.7395e+00,  1.5673e+01,  1.2954e+01, -1.4172e+01, -8.1601e+00,\n",
       "         1.0882e+01,  3.8493e+00,  1.1644e+01, -1.9684e+01, -6.7149e+00,\n",
       "        -1.3575e+00, -9.3857e+00,  2.2443e+01,  5.4094e+00,  1.7912e+01,\n",
       "        -2.5346e-01,  3.2429e+00,  6.9100e+00,  3.9488e+00, -5.2058e+00,\n",
       "         1.2656e+01, -3.6970e+00, -5.2622e+00,  9.3036e-01,  1.1061e+01,\n",
       "         1.3362e+01,  9.8525e+00,  1.3598e+01,  7.3098e-01, -9.3137e+00,\n",
       "         1.2016e+01,  2.0902e+01, -2.5209e+00,  8.6290e+00, -6.0640e+00,\n",
       "        -4.9964e+00,  2.3196e+01, -2.9123e+00,  3.2730e+00,  1.4358e+01,\n",
       "         9.8226e+00,  1.9992e+00,  3.4598e+01,  6.2844e-01, -4.2793e+00,\n",
       "        -1.0547e+01,  1.0493e+01, -1.2992e+01,  1.4468e+00,  7.5207e-01,\n",
       "         2.7539e+00, -7.7611e-01, -1.2764e+00,  2.2626e+01,  5.6030e+00,\n",
       "        -7.0018e+00, -5.2588e+00, -1.2937e+00,  7.1057e+00, -1.9013e+01,\n",
       "         9.0072e+00,  1.6532e+00, -1.9414e+01, -1.0303e+01,  1.3633e+01,\n",
       "         1.9015e+00,  3.3027e+00,  1.4602e+01,  4.6173e-02,  1.3715e+00,\n",
       "         7.3839e+00,  5.7270e+00,  1.0756e+01, -2.8658e+00, -6.3454e+00,\n",
       "         3.7007e+00,  4.2566e+00,  2.4889e+00, -1.9475e+00,  7.9468e+00,\n",
       "         8.2207e+00, -4.5918e+00, -6.3430e+00,  1.6693e+01, -6.6801e+00,\n",
       "         2.1210e+01,  1.3223e+01, -1.0080e+01,  6.2050e+00, -1.3271e+01,\n",
       "         1.2231e+01,  1.9470e+01,  2.0339e+01, -4.3693e+00,  6.1724e+00,\n",
       "         5.0942e+00,  1.4988e+00,  8.6469e+00, -5.2662e-01,  2.9463e+00,\n",
       "         2.5223e+00,  4.2858e-01,  8.1953e-01,  1.5330e+01, -5.4762e+00,\n",
       "        -1.2244e+00, -9.2716e+00,  1.4383e+01,  7.3110e-01,  5.8061e+00,\n",
       "        -1.0162e+01,  9.9102e+00,  2.3005e+00,  1.3246e+00,  2.2694e+01,\n",
       "         8.8863e+00,  1.3645e+01,  5.8687e-01, -1.2452e+00, -1.2956e+00,\n",
       "         9.6418e+00,  1.0048e+01,  1.7007e+01,  1.3861e+01, -1.3039e+01,\n",
       "         1.7577e+01,  4.2718e+00,  2.6737e+00, -2.0070e+00,  8.1298e+00,\n",
       "         9.3532e+00,  1.9337e+01,  4.8559e+00,  1.4055e+01,  1.0227e+01,\n",
       "         1.5076e+01,  2.6307e-01, -3.8183e+00,  3.8194e+00,  5.8632e+00,\n",
       "        -2.0879e+00,  8.7732e+00, -2.4144e-01,  8.1840e-01,  1.6637e+01,\n",
       "         2.1450e+01,  4.9594e+00,  1.8736e+01,  5.7762e+00, -1.1959e+01,\n",
       "        -1.8175e-01, -2.8406e+00,  1.3169e+01,  2.5632e+00,  6.2915e+00,\n",
       "         8.1874e+00,  4.6612e+00,  1.0842e+01,  3.6929e+00, -1.3995e+01,\n",
       "         8.3106e+00, -4.1285e+00,  1.1589e+01, -7.3777e+00,  2.3000e+01,\n",
       "         3.9335e+00, -2.4415e+00,  8.6033e+00,  1.0967e+01,  1.2009e+01,\n",
       "         1.0064e+01,  8.2494e+00,  1.3050e+01,  3.4657e+00,  8.0726e+00,\n",
       "         6.3285e+00, -2.1016e+01,  4.4663e+00,  3.9936e+00,  9.0333e+00,\n",
       "         1.9065e+01,  3.7926e+00,  1.2360e+01, -5.0245e+00,  1.1634e+01,\n",
       "         1.2417e+01, -3.9455e-01,  1.4751e+01, -5.9149e+00,  6.0239e+00,\n",
       "         1.0171e+00,  1.3739e+01,  3.3372e+00,  2.7443e+00,  3.3608e+00,\n",
       "         1.4686e+01,  4.6719e+00,  2.7805e+00,  5.9741e+00,  3.1194e+00,\n",
       "         1.3694e+01,  1.1320e+01, -1.8999e-01, -8.5929e+00,  2.3149e+01,\n",
       "         5.6751e+00,  1.0234e-01,  4.6293e-01,  8.3004e+00,  1.0980e+01,\n",
       "        -2.7372e+00,  1.5525e+01,  9.2299e+00,  6.5561e+00, -8.4148e-01,\n",
       "         2.0386e+00, -7.1072e+00, -1.8495e+00,  5.5766e+00, -4.3735e+00,\n",
       "        -1.8604e+01,  8.8345e+00,  9.5867e+00, -9.2901e+00,  7.4710e+00,\n",
       "         5.9083e+00,  1.3723e+00, -7.0134e+00,  1.5009e+01, -8.7778e+00,\n",
       "         2.5686e+00,  3.0497e+00,  7.0673e+00, -1.1930e+01, -4.1693e+00,\n",
       "        -9.7695e-01,  5.6966e+00, -4.6413e+00,  4.0355e+00,  6.1084e+00,\n",
       "         2.5787e-01,  1.6322e+00,  7.9962e+00, -5.8332e+00,  2.9731e+01,\n",
       "         5.7504e+00, -6.2083e+00,  2.3555e+01,  5.2062e+00, -2.4962e+00,\n",
       "        -2.2991e-01, -1.2548e+00,  2.2058e+01,  5.6954e+00,  1.5127e+01,\n",
       "        -1.0786e+00,  1.4842e+01,  3.3425e+00,  2.9391e+00, -7.9280e-01,\n",
       "        -5.8857e+00,  5.6585e+00,  1.8678e+01,  5.7983e+00,  6.9978e+00,\n",
       "        -4.0584e+00, -4.8589e+00,  1.1520e+01,  7.1080e+00, -5.9225e+00,\n",
       "        -1.4133e+01,  2.1328e+01,  1.1953e+01, -2.6450e+00,  1.8447e+01,\n",
       "         1.7573e+01,  3.1125e+00,  6.8041e+00,  1.0322e+01,  1.0578e+01,\n",
       "         5.1834e+00,  5.6886e+00,  9.7483e+00,  5.3421e+00, -5.7937e+00,\n",
       "         7.9412e+00,  9.1768e+00,  8.0607e+00, -2.7024e+00, -4.7162e+00,\n",
       "         1.2667e+00, -9.1225e-01,  2.1248e-03,  2.9123e+00,  9.5907e+00,\n",
       "         1.8958e+00,  7.3428e+00,  1.0228e+01,  5.3266e+00,  7.3307e+00,\n",
       "         1.7528e+01, -6.8669e-03, -1.8642e+01,  4.3624e+00,  4.1399e-01,\n",
       "        -6.6694e+00, -3.1465e+00,  1.4321e+01,  3.1908e+00, -1.7437e+00,\n",
       "        -7.1305e+00,  1.1566e+01,  2.8990e+00, -6.1228e+00, -2.0773e+00,\n",
       "         1.1369e+01,  1.1372e+01,  7.3158e+00,  7.2312e+00,  1.2194e+01,\n",
       "         6.8033e+00,  3.2990e+00,  1.7118e+01, -5.1703e+00,  1.7789e+01,\n",
       "         4.9187e+00,  4.1659e+00,  1.2142e+01, -9.0031e+00,  4.7218e+00,\n",
       "        -1.0257e+01,  3.9083e+00, -2.4608e-01,  7.2900e+00, -1.1843e+00,\n",
       "         1.1430e+01,  1.6659e+00,  3.9482e+00,  8.9647e-01,  7.0888e+00,\n",
       "        -1.2895e+00, -1.4557e+00,  1.4238e+00,  1.5628e+01,  9.0142e+00,\n",
       "         6.0381e-01,  7.7980e+00,  1.0588e+01,  5.6265e+00, -2.2509e+00,\n",
       "         1.1869e+01,  8.4159e-01, -1.8295e+00, -3.7623e+00,  5.9279e+00,\n",
       "        -1.4881e+01,  1.6430e+01, -1.2460e+00,  5.2057e+00,  1.1677e+01,\n",
       "         4.0825e+00,  8.8192e+00,  3.2896e+00,  9.8064e+00,  1.4085e+01,\n",
       "         9.6843e+00,  1.6231e+01,  4.2082e+00,  1.1844e+01,  1.1553e+01,\n",
       "         6.4024e+00,  1.4109e+01, -5.6718e+00,  3.2609e+00,  9.3171e+00,\n",
       "         9.8099e+00, -6.1290e+00,  1.3008e+01, -4.0834e+00,  3.2125e+00,\n",
       "         3.5980e+00,  2.3896e+01, -4.2004e+00,  6.5373e+00,  5.4994e+00,\n",
       "        -4.3510e+00,  1.2986e+00, -4.6921e+00, -5.3699e+00,  2.2812e+00,\n",
       "        -8.2363e+00, -4.9033e+00,  1.3671e+01,  9.7120e+00,  3.7051e+00,\n",
       "         5.4619e+00, -1.1130e+00, -1.1737e+01,  3.0815e-01,  1.6886e+01,\n",
       "         9.0635e+00,  4.3231e+00,  2.0599e+00, -1.2039e+01, -2.7689e+00,\n",
       "         1.8410e+01,  7.4817e+00, -1.7764e+01,  1.9516e+01,  1.0281e+01,\n",
       "        -8.7264e-01,  5.0907e+00,  1.1876e+01, -2.3906e+00, -1.9313e+00,\n",
       "         1.4379e+00,  1.0859e+01, -9.9066e+00,  1.8098e+00,  2.1987e+01,\n",
       "         2.2150e+01, -3.5827e+00, -2.9805e+00, -2.8840e+00,  7.7248e-05,\n",
       "        -2.2995e+01, -6.3231e+00,  1.6887e+01,  9.7318e+00,  3.0228e-01,\n",
       "         2.5666e+00, -9.0575e+00,  5.9352e-01,  1.1187e+01,  5.6152e+00,\n",
       "         4.7389e-01,  1.3879e+01,  1.7284e+00,  8.2942e-01, -7.3225e+00,\n",
       "         2.9350e+00,  4.7754e+00,  7.7851e-01, -2.2753e+00,  1.0715e+01,\n",
       "         7.6006e+00,  4.7917e+00,  1.4307e+01,  6.1563e+00,  6.8157e+00,\n",
       "        -5.5919e+00, -5.3209e+00,  5.1971e+00, -1.5570e-01,  9.3120e+00,\n",
       "        -8.9720e+00,  7.0830e+00, -1.5202e+00, -1.3925e+00,  2.0611e+01,\n",
       "         6.9438e+00, -1.5738e+00, -2.7774e+00,  1.4480e+01,  1.0138e+01,\n",
       "         1.1406e+01,  8.6084e+00,  1.0398e+01,  5.8840e+00,  1.8354e+01,\n",
       "         7.6440e+00,  1.3977e+01, -1.2281e+01,  1.6963e+01, -1.1788e+00,\n",
       "         1.0689e+01,  5.2257e-03,  3.4940e+00, -5.2181e-01,  1.5029e+01,\n",
       "        -6.5594e+00,  2.3259e+01,  5.4361e-01, -4.6186e+00, -1.7060e+01,\n",
       "        -5.5709e+00,  9.5214e+00, -7.9763e+00,  4.2252e+00,  1.5092e+00,\n",
       "         7.0865e+00,  9.0257e+00,  7.0669e+00,  2.4924e+00,  1.2331e+00,\n",
       "         3.7890e+00,  1.7030e+01,  2.2109e+01,  7.1882e+00, -5.2052e+00,\n",
       "         5.0795e+00,  7.2834e+00,  1.2444e+01,  1.4443e+01,  1.8640e+00,\n",
       "         1.5246e+01, -1.0635e+00,  1.4088e+00,  2.8884e+01, -6.2733e-01,\n",
       "        -1.9599e+00,  6.5011e+00,  1.3949e+00,  2.6366e+00, -5.8401e+00])"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "id": "9e90c744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "be25b22e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5992e+01],\n",
       "        [ 1.0520e+01],\n",
       "        [ 1.6187e+01],\n",
       "        [ 3.1880e-01],\n",
       "        [-3.0951e-01],\n",
       "        [ 5.9327e+00],\n",
       "        [ 1.3813e+01],\n",
       "        [-4.3555e-01],\n",
       "        [ 7.9810e+00],\n",
       "        [ 9.8630e+00],\n",
       "        [-4.1379e+00],\n",
       "        [ 9.9030e+00],\n",
       "        [-1.0143e+00],\n",
       "        [-2.8659e+00],\n",
       "        [-5.8441e+00],\n",
       "        [ 7.4970e+00],\n",
       "        [ 1.0933e+00],\n",
       "        [ 1.8477e+00],\n",
       "        [-7.8330e+00],\n",
       "        [ 1.7300e+01],\n",
       "        [ 9.8987e+00],\n",
       "        [ 7.7476e+00],\n",
       "        [-5.5060e+00],\n",
       "        [ 1.7474e+00],\n",
       "        [ 9.5069e+00],\n",
       "        [-1.1930e+00],\n",
       "        [-2.7354e+00],\n",
       "        [-7.6727e-01],\n",
       "        [ 9.1535e+00],\n",
       "        [ 1.1988e+01],\n",
       "        [ 2.7396e+00],\n",
       "        [ 1.6699e+00],\n",
       "        [ 7.9077e-01],\n",
       "        [-1.2517e+01],\n",
       "        [ 1.7307e+01],\n",
       "        [ 2.1991e+01],\n",
       "        [ 6.5792e+00],\n",
       "        [-2.5275e+00],\n",
       "        [ 7.2011e+00],\n",
       "        [-3.5696e+00],\n",
       "        [ 1.0896e+01],\n",
       "        [ 6.7077e+00],\n",
       "        [-1.6973e+01],\n",
       "        [ 6.7691e+00],\n",
       "        [ 1.4527e+01],\n",
       "        [ 1.4496e+01],\n",
       "        [ 4.3423e+00],\n",
       "        [-5.6553e+00],\n",
       "        [ 1.4569e+01],\n",
       "        [ 2.7133e+00],\n",
       "        [-1.1959e+01],\n",
       "        [ 2.6006e+00],\n",
       "        [ 9.2810e+00],\n",
       "        [-9.9610e+00],\n",
       "        [ 7.2776e+00],\n",
       "        [ 2.2769e+00],\n",
       "        [-6.0013e-01],\n",
       "        [ 2.6475e+00],\n",
       "        [-7.9681e+00],\n",
       "        [ 6.8091e+00],\n",
       "        [ 4.2370e+00],\n",
       "        [ 9.6687e+00],\n",
       "        [ 7.9880e+00],\n",
       "        [ 1.2205e+01],\n",
       "        [ 1.8572e+01],\n",
       "        [ 3.4821e-01],\n",
       "        [ 5.5847e+00],\n",
       "        [ 1.5187e+01],\n",
       "        [-1.5010e+01],\n",
       "        [ 2.8282e+01],\n",
       "        [ 1.0402e+01],\n",
       "        [-3.5058e+00],\n",
       "        [-6.7540e+00],\n",
       "        [ 3.8747e+00],\n",
       "        [ 6.9673e+00],\n",
       "        [-2.3071e+00],\n",
       "        [-1.3838e+00],\n",
       "        [-7.4831e+00],\n",
       "        [ 2.2353e+01],\n",
       "        [ 1.9753e+00],\n",
       "        [-9.6813e-01],\n",
       "        [ 7.3189e+00],\n",
       "        [ 7.0855e+00],\n",
       "        [-1.6412e-01],\n",
       "        [ 1.0708e+01],\n",
       "        [ 1.4224e+01],\n",
       "        [ 2.1406e+00],\n",
       "        [-6.4785e+00],\n",
       "        [ 3.9513e+00],\n",
       "        [-3.8755e+00],\n",
       "        [ 3.9327e+00],\n",
       "        [ 1.7265e+01],\n",
       "        [ 1.7909e+01],\n",
       "        [ 2.5472e+00],\n",
       "        [ 8.2240e-01],\n",
       "        [ 3.6053e+00],\n",
       "        [ 5.2612e+00],\n",
       "        [-3.0792e-01],\n",
       "        [-6.7840e+00],\n",
       "        [ 4.1621e+00],\n",
       "        [ 1.1572e+01],\n",
       "        [-1.1009e+00],\n",
       "        [-3.5759e+00],\n",
       "        [ 1.2643e+01],\n",
       "        [ 8.7059e+00],\n",
       "        [ 6.7760e+00],\n",
       "        [ 1.1357e+01],\n",
       "        [-1.2597e+01],\n",
       "        [-3.6029e+00],\n",
       "        [-5.4759e+00],\n",
       "        [ 1.1931e+01],\n",
       "        [ 3.1300e+00],\n",
       "        [ 1.7476e+01],\n",
       "        [-1.7984e+01],\n",
       "        [ 9.6292e+00],\n",
       "        [-6.8533e+00],\n",
       "        [ 2.9563e+00],\n",
       "        [ 1.2772e+01],\n",
       "        [-1.2842e+01],\n",
       "        [ 2.3524e+00],\n",
       "        [ 7.6107e+00],\n",
       "        [ 9.8800e+00],\n",
       "        [ 1.3822e+01],\n",
       "        [ 1.8430e+01],\n",
       "        [ 4.1049e+00],\n",
       "        [ 6.0980e+00],\n",
       "        [-8.1540e+00],\n",
       "        [ 5.8308e+00],\n",
       "        [-7.3575e+00],\n",
       "        [-1.4568e+01],\n",
       "        [ 1.0804e+01],\n",
       "        [ 5.2543e+00],\n",
       "        [-4.8453e+00],\n",
       "        [ 6.8319e+00],\n",
       "        [ 3.2821e+00],\n",
       "        [ 2.2017e+01],\n",
       "        [ 5.1454e+00],\n",
       "        [-3.4420e+00],\n",
       "        [ 1.3452e+00],\n",
       "        [ 1.8176e+00],\n",
       "        [ 8.2351e+00],\n",
       "        [ 7.8859e-01],\n",
       "        [ 5.8989e+00],\n",
       "        [-3.1409e+00],\n",
       "        [ 2.3682e+00],\n",
       "        [-9.9355e+00],\n",
       "        [-2.8193e+00],\n",
       "        [ 2.1523e+01],\n",
       "        [ 2.2227e+01],\n",
       "        [ 9.9070e-01],\n",
       "        [-1.2904e+01],\n",
       "        [ 1.0439e+01],\n",
       "        [ 2.4663e+00],\n",
       "        [ 2.2213e+01],\n",
       "        [ 1.0531e+01],\n",
       "        [ 2.2359e+00],\n",
       "        [-3.3990e-01],\n",
       "        [ 8.6906e+00],\n",
       "        [ 1.4599e+01],\n",
       "        [ 4.1351e+00],\n",
       "        [ 1.8434e+01],\n",
       "        [-1.3372e+01],\n",
       "        [ 1.2475e+01],\n",
       "        [ 1.6603e+01],\n",
       "        [ 1.9050e+01],\n",
       "        [ 6.0202e+00],\n",
       "        [ 1.8724e+01],\n",
       "        [ 2.9366e+00],\n",
       "        [ 4.2677e+00],\n",
       "        [ 2.3070e+00],\n",
       "        [-3.6485e+00],\n",
       "        [ 1.1722e+01],\n",
       "        [ 6.1357e+00],\n",
       "        [ 1.1908e+01],\n",
       "        [ 2.0268e+01],\n",
       "        [-9.1353e+00],\n",
       "        [ 1.3442e+01],\n",
       "        [ 3.9628e+00],\n",
       "        [ 8.6398e-01],\n",
       "        [ 7.9614e+00],\n",
       "        [-8.0381e+00],\n",
       "        [ 3.8141e+00],\n",
       "        [ 6.8432e+00],\n",
       "        [ 2.8306e+00],\n",
       "        [-3.6347e-01],\n",
       "        [-2.7163e+00],\n",
       "        [ 4.7276e+00],\n",
       "        [-2.8169e+00],\n",
       "        [ 2.0642e+01],\n",
       "        [-1.2756e+00],\n",
       "        [-1.3594e+00],\n",
       "        [ 3.7782e+00],\n",
       "        [-5.4717e+00],\n",
       "        [ 7.3367e+00],\n",
       "        [-1.5763e+01],\n",
       "        [-7.2648e+00],\n",
       "        [ 8.9009e+00],\n",
       "        [ 1.4418e+01],\n",
       "        [ 2.5633e+00],\n",
       "        [-5.0655e+00],\n",
       "        [ 3.1113e+00],\n",
       "        [-5.1234e-01],\n",
       "        [-2.7812e-01],\n",
       "        [ 4.6908e+00],\n",
       "        [-6.6974e+00],\n",
       "        [ 9.2947e+00],\n",
       "        [-6.9855e+00],\n",
       "        [ 1.3393e+01],\n",
       "        [ 5.5636e+00],\n",
       "        [-1.3090e+01],\n",
       "        [-1.3105e+01],\n",
       "        [-2.3743e+01],\n",
       "        [-4.6048e+00],\n",
       "        [-6.2351e+00],\n",
       "        [ 1.6458e+01],\n",
       "        [ 1.4312e+00],\n",
       "        [ 1.5084e+01],\n",
       "        [ 1.9372e+01],\n",
       "        [ 2.4456e+00],\n",
       "        [ 1.1132e+01],\n",
       "        [ 3.1904e+01],\n",
       "        [-1.9326e+00],\n",
       "        [ 8.2112e+00],\n",
       "        [ 2.5707e+00],\n",
       "        [ 1.7789e-02],\n",
       "        [-9.8691e+00],\n",
       "        [-7.5122e+00],\n",
       "        [ 6.7447e+00],\n",
       "        [-6.0244e+00],\n",
       "        [ 1.7359e+01],\n",
       "        [ 3.3385e-01],\n",
       "        [ 6.7212e+00],\n",
       "        [-1.6849e+00],\n",
       "        [ 1.5153e+00],\n",
       "        [ 1.6446e+01],\n",
       "        [ 1.3685e+01],\n",
       "        [-4.5887e-02],\n",
       "        [-2.4845e+00],\n",
       "        [ 2.1678e+01],\n",
       "        [ 1.6803e+01],\n",
       "        [ 1.9174e+00],\n",
       "        [-3.5752e+00],\n",
       "        [ 6.4917e+00],\n",
       "        [ 1.6110e+01],\n",
       "        [-3.9256e+00],\n",
       "        [-2.6817e+00],\n",
       "        [ 1.0754e+01],\n",
       "        [-1.5655e+00],\n",
       "        [ 4.0622e+00],\n",
       "        [ 1.3010e+01],\n",
       "        [-2.3365e+00],\n",
       "        [ 5.4094e+00],\n",
       "        [-8.2419e+00],\n",
       "        [-1.1790e+00],\n",
       "        [ 6.2360e+00],\n",
       "        [ 2.1044e+01],\n",
       "        [-1.2322e+01],\n",
       "        [-3.3937e+00],\n",
       "        [ 5.8006e+00],\n",
       "        [ 8.2829e+00],\n",
       "        [-8.6060e+00],\n",
       "        [ 7.1399e+00],\n",
       "        [-6.3707e+00],\n",
       "        [-2.4653e+00],\n",
       "        [ 1.8431e+00],\n",
       "        [-6.9516e+00],\n",
       "        [ 2.1398e+00],\n",
       "        [ 3.0807e+00],\n",
       "        [ 4.6405e+00],\n",
       "        [ 1.7278e+01],\n",
       "        [ 5.7405e+00],\n",
       "        [ 1.9311e+01],\n",
       "        [-7.6542e+00],\n",
       "        [ 1.5150e+01],\n",
       "        [-8.7522e+00],\n",
       "        [ 4.8846e+00],\n",
       "        [-1.1588e+01],\n",
       "        [-1.5796e+01],\n",
       "        [-6.2121e+00],\n",
       "        [ 5.7546e+00],\n",
       "        [ 4.8647e+00],\n",
       "        [-4.2252e+00],\n",
       "        [ 1.2382e+01],\n",
       "        [ 8.7304e+00],\n",
       "        [-5.7272e+00],\n",
       "        [ 1.3119e+01],\n",
       "        [ 1.0216e+01],\n",
       "        [ 2.8061e+00],\n",
       "        [ 3.3668e+00],\n",
       "        [ 8.5426e+00],\n",
       "        [ 7.8350e+00],\n",
       "        [-5.9939e+00],\n",
       "        [ 2.6160e-01],\n",
       "        [ 3.5128e+00],\n",
       "        [-7.6337e+00],\n",
       "        [ 2.7661e+00],\n",
       "        [ 9.6139e+00],\n",
       "        [ 7.9274e+00],\n",
       "        [ 4.4167e+00],\n",
       "        [ 1.1167e+00],\n",
       "        [-1.1127e+00],\n",
       "        [ 1.2854e+01],\n",
       "        [-3.3816e+00],\n",
       "        [-1.2178e+01],\n",
       "        [-5.9192e+00],\n",
       "        [ 2.1507e+00],\n",
       "        [ 8.3203e+00],\n",
       "        [-5.1383e+00],\n",
       "        [-5.9940e+00],\n",
       "        [ 1.2286e+01],\n",
       "        [-7.9297e+00],\n",
       "        [ 3.0268e+00],\n",
       "        [ 4.6203e+00],\n",
       "        [ 7.9187e+00],\n",
       "        [ 5.0090e+00],\n",
       "        [-8.1653e-01],\n",
       "        [ 1.4166e+01],\n",
       "        [ 1.9592e+01],\n",
       "        [ 3.2562e+00],\n",
       "        [ 1.3356e+01],\n",
       "        [ 1.2035e+01],\n",
       "        [ 1.5677e+01],\n",
       "        [ 8.5726e+00],\n",
       "        [ 7.6243e+00],\n",
       "        [ 1.0129e+01],\n",
       "        [ 7.3508e+00],\n",
       "        [-9.5080e+00],\n",
       "        [-8.2662e+00],\n",
       "        [ 4.6174e+00],\n",
       "        [-4.5542e+00],\n",
       "        [ 1.1363e+01],\n",
       "        [-6.6191e+00],\n",
       "        [ 1.4533e-02],\n",
       "        [ 2.5647e+00],\n",
       "        [-2.8813e+00],\n",
       "        [ 1.3270e+01],\n",
       "        [ 5.3183e-01],\n",
       "        [-1.2779e+00],\n",
       "        [-1.2964e+00],\n",
       "        [-1.0770e-01],\n",
       "        [ 1.8727e+01],\n",
       "        [ 4.7153e+00],\n",
       "        [ 6.4672e+00],\n",
       "        [ 7.4407e+00],\n",
       "        [ 7.7292e+00],\n",
       "        [ 1.5673e+01],\n",
       "        [-3.9365e+00],\n",
       "        [-6.8168e+00],\n",
       "        [-7.7968e+00],\n",
       "        [ 2.3700e+00],\n",
       "        [ 2.3706e+01],\n",
       "        [ 1.8350e+01],\n",
       "        [ 5.9857e+00],\n",
       "        [-1.0805e+01],\n",
       "        [ 1.8249e+00],\n",
       "        [ 6.0639e+00],\n",
       "        [ 1.7914e+01],\n",
       "        [-8.2689e-01],\n",
       "        [-1.3884e+00],\n",
       "        [ 7.6182e+00],\n",
       "        [ 7.9389e+00],\n",
       "        [ 1.0276e+01],\n",
       "        [-1.0272e+00],\n",
       "        [ 1.2835e+00],\n",
       "        [-1.2121e+01],\n",
       "        [-1.1289e+01],\n",
       "        [ 1.6578e+01],\n",
       "        [ 9.9521e+00],\n",
       "        [ 1.3900e+01],\n",
       "        [-5.4462e+00],\n",
       "        [ 7.1072e+00],\n",
       "        [-4.5436e+00],\n",
       "        [-1.8632e+01],\n",
       "        [ 1.2657e+01],\n",
       "        [-4.7188e+00],\n",
       "        [ 1.3013e+01],\n",
       "        [-4.4684e+00],\n",
       "        [-1.0046e+01],\n",
       "        [ 1.6130e+00],\n",
       "        [ 1.1245e+01],\n",
       "        [ 9.1352e+00],\n",
       "        [-6.9535e+00],\n",
       "        [-3.9289e+00],\n",
       "        [ 1.0264e+01],\n",
       "        [ 1.2087e+01],\n",
       "        [ 9.1528e+00],\n",
       "        [ 2.1594e+01],\n",
       "        [-7.8064e+00],\n",
       "        [-1.9454e+00],\n",
       "        [-7.4161e+00],\n",
       "        [ 2.4856e+00],\n",
       "        [-3.6942e+00],\n",
       "        [-4.2260e+00],\n",
       "        [-3.9647e-01],\n",
       "        [ 5.4784e-01],\n",
       "        [-7.2603e-02],\n",
       "        [-4.7273e+00],\n",
       "        [ 2.5079e+01],\n",
       "        [ 1.1045e+01],\n",
       "        [-1.3995e+00],\n",
       "        [ 5.2554e-01],\n",
       "        [ 1.0827e+01],\n",
       "        [-1.0959e+01],\n",
       "        [ 2.5070e+00],\n",
       "        [ 7.3364e+00],\n",
       "        [ 1.6360e+01],\n",
       "        [-5.3666e+00],\n",
       "        [-9.7506e+00],\n",
       "        [ 2.3229e+01],\n",
       "        [ 1.5659e+01],\n",
       "        [ 1.2394e+01],\n",
       "        [ 3.3211e+00],\n",
       "        [ 1.7271e+01],\n",
       "        [ 3.8677e+00],\n",
       "        [ 2.4076e+00],\n",
       "        [ 8.9028e+00],\n",
       "        [-8.1255e+00],\n",
       "        [ 1.9281e+01],\n",
       "        [-9.9840e+00],\n",
       "        [-1.0407e+01],\n",
       "        [ 6.6742e+00],\n",
       "        [-1.4667e+00],\n",
       "        [-7.1232e+00],\n",
       "        [-4.8774e+00],\n",
       "        [-5.7523e+00],\n",
       "        [-1.4514e+01],\n",
       "        [ 1.2090e+01],\n",
       "        [-8.1272e+00],\n",
       "        [-7.1763e+00],\n",
       "        [-7.6672e-01],\n",
       "        [ 1.0996e+01],\n",
       "        [ 4.3930e+00],\n",
       "        [-3.5305e+00],\n",
       "        [ 2.1376e+01],\n",
       "        [-2.4705e+00],\n",
       "        [-4.5434e+00],\n",
       "        [ 7.9395e+00],\n",
       "        [ 1.2014e+01],\n",
       "        [ 1.1672e+00],\n",
       "        [ 3.4701e+00],\n",
       "        [ 2.0694e+01],\n",
       "        [ 6.4897e+00],\n",
       "        [ 8.8901e+00],\n",
       "        [-1.5025e+00],\n",
       "        [ 1.0177e+01],\n",
       "        [-3.7768e+00],\n",
       "        [ 6.6274e+00],\n",
       "        [ 1.1614e+01],\n",
       "        [ 1.4785e-01],\n",
       "        [ 1.0758e+01],\n",
       "        [-7.8550e+00],\n",
       "        [-4.7541e+00],\n",
       "        [ 8.9744e+00],\n",
       "        [ 1.6369e+01],\n",
       "        [ 5.3968e-01],\n",
       "        [-2.0186e+01],\n",
       "        [ 2.6185e-01],\n",
       "        [ 1.1957e+01],\n",
       "        [ 1.4659e+00],\n",
       "        [ 6.7324e+00],\n",
       "        [ 1.3326e+00],\n",
       "        [ 9.4719e+00],\n",
       "        [ 5.6339e+00],\n",
       "        [-2.8488e+00],\n",
       "        [ 9.7334e+00],\n",
       "        [ 3.3534e+00],\n",
       "        [-1.2733e+00],\n",
       "        [-2.9777e+00],\n",
       "        [ 2.3459e+01],\n",
       "        [ 1.3237e+01],\n",
       "        [-3.2312e+00],\n",
       "        [ 1.2642e+01],\n",
       "        [-1.5018e+01],\n",
       "        [ 8.1881e+00],\n",
       "        [ 1.1996e+01],\n",
       "        [ 4.3523e+00],\n",
       "        [ 1.4621e+01],\n",
       "        [ 4.2763e-01],\n",
       "        [ 2.6851e+00],\n",
       "        [-4.2621e+00],\n",
       "        [ 1.0142e+00],\n",
       "        [ 2.0273e+01],\n",
       "        [ 4.4120e+00],\n",
       "        [-5.0907e-02],\n",
       "        [ 1.6001e+01],\n",
       "        [ 2.7395e+00],\n",
       "        [ 1.5673e+01],\n",
       "        [ 1.2954e+01],\n",
       "        [-1.4172e+01],\n",
       "        [-8.1601e+00],\n",
       "        [ 1.0882e+01],\n",
       "        [ 3.8493e+00],\n",
       "        [ 1.1644e+01],\n",
       "        [-1.9684e+01],\n",
       "        [-6.7149e+00],\n",
       "        [-1.3575e+00],\n",
       "        [-9.3857e+00],\n",
       "        [ 2.2443e+01],\n",
       "        [ 5.4094e+00],\n",
       "        [ 1.7912e+01],\n",
       "        [-2.5346e-01],\n",
       "        [ 3.2429e+00],\n",
       "        [ 6.9100e+00],\n",
       "        [ 3.9488e+00],\n",
       "        [-5.2058e+00],\n",
       "        [ 1.2656e+01],\n",
       "        [-3.6970e+00],\n",
       "        [-5.2622e+00],\n",
       "        [ 9.3036e-01],\n",
       "        [ 1.1061e+01],\n",
       "        [ 1.3362e+01],\n",
       "        [ 9.8525e+00],\n",
       "        [ 1.3598e+01],\n",
       "        [ 7.3098e-01],\n",
       "        [-9.3137e+00],\n",
       "        [ 1.2016e+01],\n",
       "        [ 2.0902e+01],\n",
       "        [-2.5209e+00],\n",
       "        [ 8.6290e+00],\n",
       "        [-6.0640e+00],\n",
       "        [-4.9964e+00],\n",
       "        [ 2.3196e+01],\n",
       "        [-2.9123e+00],\n",
       "        [ 3.2730e+00],\n",
       "        [ 1.4358e+01],\n",
       "        [ 9.8226e+00],\n",
       "        [ 1.9992e+00],\n",
       "        [ 3.4598e+01],\n",
       "        [ 6.2844e-01],\n",
       "        [-4.2793e+00],\n",
       "        [-1.0547e+01],\n",
       "        [ 1.0493e+01],\n",
       "        [-1.2992e+01],\n",
       "        [ 1.4468e+00],\n",
       "        [ 7.5207e-01],\n",
       "        [ 2.7539e+00],\n",
       "        [-7.7611e-01],\n",
       "        [-1.2764e+00],\n",
       "        [ 2.2626e+01],\n",
       "        [ 5.6030e+00],\n",
       "        [-7.0018e+00],\n",
       "        [-5.2588e+00],\n",
       "        [-1.2937e+00],\n",
       "        [ 7.1057e+00],\n",
       "        [-1.9013e+01],\n",
       "        [ 9.0072e+00],\n",
       "        [ 1.6532e+00],\n",
       "        [-1.9414e+01],\n",
       "        [-1.0303e+01],\n",
       "        [ 1.3633e+01],\n",
       "        [ 1.9015e+00],\n",
       "        [ 3.3027e+00],\n",
       "        [ 1.4602e+01],\n",
       "        [ 4.6173e-02],\n",
       "        [ 1.3715e+00],\n",
       "        [ 7.3839e+00],\n",
       "        [ 5.7270e+00],\n",
       "        [ 1.0756e+01],\n",
       "        [-2.8658e+00],\n",
       "        [-6.3454e+00],\n",
       "        [ 3.7007e+00],\n",
       "        [ 4.2566e+00],\n",
       "        [ 2.4889e+00],\n",
       "        [-1.9475e+00],\n",
       "        [ 7.9468e+00],\n",
       "        [ 8.2207e+00],\n",
       "        [-4.5918e+00],\n",
       "        [-6.3430e+00],\n",
       "        [ 1.6693e+01],\n",
       "        [-6.6801e+00],\n",
       "        [ 2.1210e+01],\n",
       "        [ 1.3223e+01],\n",
       "        [-1.0080e+01],\n",
       "        [ 6.2050e+00],\n",
       "        [-1.3271e+01],\n",
       "        [ 1.2231e+01],\n",
       "        [ 1.9470e+01],\n",
       "        [ 2.0339e+01],\n",
       "        [-4.3693e+00],\n",
       "        [ 6.1724e+00],\n",
       "        [ 5.0942e+00],\n",
       "        [ 1.4988e+00],\n",
       "        [ 8.6469e+00],\n",
       "        [-5.2662e-01],\n",
       "        [ 2.9463e+00],\n",
       "        [ 2.5223e+00],\n",
       "        [ 4.2858e-01],\n",
       "        [ 8.1953e-01],\n",
       "        [ 1.5330e+01],\n",
       "        [-5.4762e+00],\n",
       "        [-1.2244e+00],\n",
       "        [-9.2716e+00],\n",
       "        [ 1.4383e+01],\n",
       "        [ 7.3110e-01],\n",
       "        [ 5.8061e+00],\n",
       "        [-1.0162e+01],\n",
       "        [ 9.9102e+00],\n",
       "        [ 2.3005e+00],\n",
       "        [ 1.3246e+00],\n",
       "        [ 2.2694e+01],\n",
       "        [ 8.8863e+00],\n",
       "        [ 1.3645e+01],\n",
       "        [ 5.8687e-01],\n",
       "        [-1.2452e+00],\n",
       "        [-1.2956e+00],\n",
       "        [ 9.6418e+00],\n",
       "        [ 1.0048e+01],\n",
       "        [ 1.7007e+01],\n",
       "        [ 1.3861e+01],\n",
       "        [-1.3039e+01],\n",
       "        [ 1.7577e+01],\n",
       "        [ 4.2718e+00],\n",
       "        [ 2.6737e+00],\n",
       "        [-2.0070e+00],\n",
       "        [ 8.1298e+00],\n",
       "        [ 9.3532e+00],\n",
       "        [ 1.9337e+01],\n",
       "        [ 4.8559e+00],\n",
       "        [ 1.4055e+01],\n",
       "        [ 1.0227e+01],\n",
       "        [ 1.5076e+01],\n",
       "        [ 2.6307e-01],\n",
       "        [-3.8183e+00],\n",
       "        [ 3.8194e+00],\n",
       "        [ 5.8632e+00],\n",
       "        [-2.0879e+00],\n",
       "        [ 8.7732e+00],\n",
       "        [-2.4144e-01],\n",
       "        [ 8.1840e-01],\n",
       "        [ 1.6637e+01],\n",
       "        [ 2.1450e+01],\n",
       "        [ 4.9594e+00],\n",
       "        [ 1.8736e+01],\n",
       "        [ 5.7762e+00],\n",
       "        [-1.1959e+01],\n",
       "        [-1.8175e-01],\n",
       "        [-2.8406e+00],\n",
       "        [ 1.3169e+01],\n",
       "        [ 2.5632e+00],\n",
       "        [ 6.2915e+00],\n",
       "        [ 8.1874e+00],\n",
       "        [ 4.6612e+00],\n",
       "        [ 1.0842e+01],\n",
       "        [ 3.6929e+00],\n",
       "        [-1.3995e+01],\n",
       "        [ 8.3106e+00],\n",
       "        [-4.1285e+00],\n",
       "        [ 1.1589e+01],\n",
       "        [-7.3777e+00],\n",
       "        [ 2.3000e+01],\n",
       "        [ 3.9335e+00],\n",
       "        [-2.4415e+00],\n",
       "        [ 8.6033e+00],\n",
       "        [ 1.0967e+01],\n",
       "        [ 1.2009e+01],\n",
       "        [ 1.0064e+01],\n",
       "        [ 8.2494e+00],\n",
       "        [ 1.3050e+01],\n",
       "        [ 3.4657e+00],\n",
       "        [ 8.0726e+00],\n",
       "        [ 6.3285e+00],\n",
       "        [-2.1016e+01],\n",
       "        [ 4.4663e+00],\n",
       "        [ 3.9936e+00],\n",
       "        [ 9.0333e+00],\n",
       "        [ 1.9065e+01],\n",
       "        [ 3.7926e+00],\n",
       "        [ 1.2360e+01],\n",
       "        [-5.0245e+00],\n",
       "        [ 1.1634e+01],\n",
       "        [ 1.2417e+01],\n",
       "        [-3.9455e-01],\n",
       "        [ 1.4751e+01],\n",
       "        [-5.9149e+00],\n",
       "        [ 6.0239e+00],\n",
       "        [ 1.0171e+00],\n",
       "        [ 1.3739e+01],\n",
       "        [ 3.3372e+00],\n",
       "        [ 2.7443e+00],\n",
       "        [ 3.3608e+00],\n",
       "        [ 1.4686e+01],\n",
       "        [ 4.6719e+00],\n",
       "        [ 2.7805e+00],\n",
       "        [ 5.9741e+00],\n",
       "        [ 3.1194e+00],\n",
       "        [ 1.3694e+01],\n",
       "        [ 1.1320e+01],\n",
       "        [-1.8999e-01],\n",
       "        [-8.5929e+00],\n",
       "        [ 2.3149e+01],\n",
       "        [ 5.6751e+00],\n",
       "        [ 1.0234e-01],\n",
       "        [ 4.6293e-01],\n",
       "        [ 8.3004e+00],\n",
       "        [ 1.0980e+01],\n",
       "        [-2.7372e+00],\n",
       "        [ 1.5525e+01],\n",
       "        [ 9.2299e+00],\n",
       "        [ 6.5561e+00],\n",
       "        [-8.4148e-01],\n",
       "        [ 2.0386e+00],\n",
       "        [-7.1072e+00],\n",
       "        [-1.8495e+00],\n",
       "        [ 5.5766e+00],\n",
       "        [-4.3735e+00],\n",
       "        [-1.8604e+01],\n",
       "        [ 8.8345e+00],\n",
       "        [ 9.5867e+00],\n",
       "        [-9.2901e+00],\n",
       "        [ 7.4710e+00],\n",
       "        [ 5.9083e+00],\n",
       "        [ 1.3723e+00],\n",
       "        [-7.0134e+00],\n",
       "        [ 1.5009e+01],\n",
       "        [-8.7778e+00],\n",
       "        [ 2.5686e+00],\n",
       "        [ 3.0497e+00],\n",
       "        [ 7.0673e+00],\n",
       "        [-1.1930e+01],\n",
       "        [-4.1693e+00],\n",
       "        [-9.7695e-01],\n",
       "        [ 5.6966e+00],\n",
       "        [-4.6413e+00],\n",
       "        [ 4.0355e+00],\n",
       "        [ 6.1084e+00],\n",
       "        [ 2.5787e-01],\n",
       "        [ 1.6322e+00],\n",
       "        [ 7.9962e+00],\n",
       "        [-5.8332e+00],\n",
       "        [ 2.9731e+01],\n",
       "        [ 5.7504e+00],\n",
       "        [-6.2083e+00],\n",
       "        [ 2.3555e+01],\n",
       "        [ 5.2062e+00],\n",
       "        [-2.4962e+00],\n",
       "        [-2.2991e-01],\n",
       "        [-1.2548e+00],\n",
       "        [ 2.2058e+01],\n",
       "        [ 5.6954e+00],\n",
       "        [ 1.5127e+01],\n",
       "        [-1.0786e+00],\n",
       "        [ 1.4842e+01],\n",
       "        [ 3.3425e+00],\n",
       "        [ 2.9391e+00],\n",
       "        [-7.9280e-01],\n",
       "        [-5.8857e+00],\n",
       "        [ 5.6585e+00],\n",
       "        [ 1.8678e+01],\n",
       "        [ 5.7983e+00],\n",
       "        [ 6.9978e+00],\n",
       "        [-4.0584e+00],\n",
       "        [-4.8589e+00],\n",
       "        [ 1.1520e+01],\n",
       "        [ 7.1080e+00],\n",
       "        [-5.9225e+00],\n",
       "        [-1.4133e+01],\n",
       "        [ 2.1328e+01],\n",
       "        [ 1.1953e+01],\n",
       "        [-2.6450e+00],\n",
       "        [ 1.8447e+01],\n",
       "        [ 1.7573e+01],\n",
       "        [ 3.1125e+00],\n",
       "        [ 6.8041e+00],\n",
       "        [ 1.0322e+01],\n",
       "        [ 1.0578e+01],\n",
       "        [ 5.1834e+00],\n",
       "        [ 5.6886e+00],\n",
       "        [ 9.7483e+00],\n",
       "        [ 5.3421e+00],\n",
       "        [-5.7937e+00],\n",
       "        [ 7.9412e+00],\n",
       "        [ 9.1768e+00],\n",
       "        [ 8.0607e+00],\n",
       "        [-2.7024e+00],\n",
       "        [-4.7162e+00],\n",
       "        [ 1.2667e+00],\n",
       "        [-9.1225e-01],\n",
       "        [ 2.1248e-03],\n",
       "        [ 2.9123e+00],\n",
       "        [ 9.5907e+00],\n",
       "        [ 1.8958e+00],\n",
       "        [ 7.3428e+00],\n",
       "        [ 1.0228e+01],\n",
       "        [ 5.3266e+00],\n",
       "        [ 7.3307e+00],\n",
       "        [ 1.7528e+01],\n",
       "        [-6.8669e-03],\n",
       "        [-1.8642e+01],\n",
       "        [ 4.3624e+00],\n",
       "        [ 4.1399e-01],\n",
       "        [-6.6694e+00],\n",
       "        [-3.1465e+00],\n",
       "        [ 1.4321e+01],\n",
       "        [ 3.1908e+00],\n",
       "        [-1.7437e+00],\n",
       "        [-7.1305e+00],\n",
       "        [ 1.1566e+01],\n",
       "        [ 2.8990e+00],\n",
       "        [-6.1228e+00],\n",
       "        [-2.0773e+00],\n",
       "        [ 1.1369e+01],\n",
       "        [ 1.1372e+01],\n",
       "        [ 7.3158e+00],\n",
       "        [ 7.2312e+00],\n",
       "        [ 1.2194e+01],\n",
       "        [ 6.8033e+00],\n",
       "        [ 3.2990e+00],\n",
       "        [ 1.7118e+01],\n",
       "        [-5.1703e+00],\n",
       "        [ 1.7789e+01],\n",
       "        [ 4.9187e+00],\n",
       "        [ 4.1659e+00],\n",
       "        [ 1.2142e+01],\n",
       "        [-9.0031e+00],\n",
       "        [ 4.7218e+00],\n",
       "        [-1.0257e+01],\n",
       "        [ 3.9083e+00],\n",
       "        [-2.4608e-01],\n",
       "        [ 7.2900e+00],\n",
       "        [-1.1843e+00],\n",
       "        [ 1.1430e+01],\n",
       "        [ 1.6659e+00],\n",
       "        [ 3.9482e+00],\n",
       "        [ 8.9647e-01],\n",
       "        [ 7.0888e+00],\n",
       "        [-1.2895e+00],\n",
       "        [-1.4557e+00],\n",
       "        [ 1.4238e+00],\n",
       "        [ 1.5628e+01],\n",
       "        [ 9.0142e+00],\n",
       "        [ 6.0381e-01],\n",
       "        [ 7.7980e+00],\n",
       "        [ 1.0588e+01],\n",
       "        [ 5.6265e+00],\n",
       "        [-2.2509e+00],\n",
       "        [ 1.1869e+01],\n",
       "        [ 8.4159e-01],\n",
       "        [-1.8295e+00],\n",
       "        [-3.7623e+00],\n",
       "        [ 5.9279e+00],\n",
       "        [-1.4881e+01],\n",
       "        [ 1.6430e+01],\n",
       "        [-1.2460e+00],\n",
       "        [ 5.2057e+00],\n",
       "        [ 1.1677e+01],\n",
       "        [ 4.0825e+00],\n",
       "        [ 8.8192e+00],\n",
       "        [ 3.2896e+00],\n",
       "        [ 9.8064e+00],\n",
       "        [ 1.4085e+01],\n",
       "        [ 9.6843e+00],\n",
       "        [ 1.6231e+01],\n",
       "        [ 4.2082e+00],\n",
       "        [ 1.1844e+01],\n",
       "        [ 1.1553e+01],\n",
       "        [ 6.4024e+00],\n",
       "        [ 1.4109e+01],\n",
       "        [-5.6718e+00],\n",
       "        [ 3.2609e+00],\n",
       "        [ 9.3171e+00],\n",
       "        [ 9.8099e+00],\n",
       "        [-6.1290e+00],\n",
       "        [ 1.3008e+01],\n",
       "        [-4.0834e+00],\n",
       "        [ 3.2125e+00],\n",
       "        [ 3.5980e+00],\n",
       "        [ 2.3896e+01],\n",
       "        [-4.2004e+00],\n",
       "        [ 6.5373e+00],\n",
       "        [ 5.4994e+00],\n",
       "        [-4.3510e+00],\n",
       "        [ 1.2986e+00],\n",
       "        [-4.6921e+00],\n",
       "        [-5.3699e+00],\n",
       "        [ 2.2812e+00],\n",
       "        [-8.2363e+00],\n",
       "        [-4.9033e+00],\n",
       "        [ 1.3671e+01],\n",
       "        [ 9.7120e+00],\n",
       "        [ 3.7051e+00],\n",
       "        [ 5.4619e+00],\n",
       "        [-1.1130e+00],\n",
       "        [-1.1737e+01],\n",
       "        [ 3.0815e-01],\n",
       "        [ 1.6886e+01],\n",
       "        [ 9.0635e+00],\n",
       "        [ 4.3231e+00],\n",
       "        [ 2.0599e+00],\n",
       "        [-1.2039e+01],\n",
       "        [-2.7689e+00],\n",
       "        [ 1.8410e+01],\n",
       "        [ 7.4817e+00],\n",
       "        [-1.7764e+01],\n",
       "        [ 1.9516e+01],\n",
       "        [ 1.0281e+01],\n",
       "        [-8.7264e-01],\n",
       "        [ 5.0907e+00],\n",
       "        [ 1.1876e+01],\n",
       "        [-2.3906e+00],\n",
       "        [-1.9313e+00],\n",
       "        [ 1.4379e+00],\n",
       "        [ 1.0859e+01],\n",
       "        [-9.9066e+00],\n",
       "        [ 1.8098e+00],\n",
       "        [ 2.1987e+01],\n",
       "        [ 2.2150e+01],\n",
       "        [-3.5827e+00],\n",
       "        [-2.9805e+00],\n",
       "        [-2.8840e+00],\n",
       "        [ 7.7248e-05],\n",
       "        [-2.2995e+01],\n",
       "        [-6.3231e+00],\n",
       "        [ 1.6887e+01],\n",
       "        [ 9.7318e+00],\n",
       "        [ 3.0228e-01],\n",
       "        [ 2.5666e+00],\n",
       "        [-9.0575e+00],\n",
       "        [ 5.9352e-01],\n",
       "        [ 1.1187e+01],\n",
       "        [ 5.6152e+00],\n",
       "        [ 4.7389e-01],\n",
       "        [ 1.3879e+01],\n",
       "        [ 1.7284e+00],\n",
       "        [ 8.2942e-01],\n",
       "        [-7.3225e+00],\n",
       "        [ 2.9350e+00],\n",
       "        [ 4.7754e+00],\n",
       "        [ 7.7851e-01],\n",
       "        [-2.2753e+00],\n",
       "        [ 1.0715e+01],\n",
       "        [ 7.6006e+00],\n",
       "        [ 4.7917e+00],\n",
       "        [ 1.4307e+01],\n",
       "        [ 6.1563e+00],\n",
       "        [ 6.8157e+00],\n",
       "        [-5.5919e+00],\n",
       "        [-5.3209e+00],\n",
       "        [ 5.1971e+00],\n",
       "        [-1.5570e-01],\n",
       "        [ 9.3120e+00],\n",
       "        [-8.9720e+00],\n",
       "        [ 7.0830e+00],\n",
       "        [-1.5202e+00],\n",
       "        [-1.3925e+00],\n",
       "        [ 2.0611e+01],\n",
       "        [ 6.9438e+00],\n",
       "        [-1.5738e+00],\n",
       "        [-2.7774e+00],\n",
       "        [ 1.4480e+01],\n",
       "        [ 1.0138e+01],\n",
       "        [ 1.1406e+01],\n",
       "        [ 8.6084e+00],\n",
       "        [ 1.0398e+01],\n",
       "        [ 5.8840e+00],\n",
       "        [ 1.8354e+01],\n",
       "        [ 7.6440e+00],\n",
       "        [ 1.3977e+01],\n",
       "        [-1.2281e+01],\n",
       "        [ 1.6963e+01],\n",
       "        [-1.1788e+00],\n",
       "        [ 1.0689e+01],\n",
       "        [ 5.2257e-03],\n",
       "        [ 3.4940e+00],\n",
       "        [-5.2181e-01],\n",
       "        [ 1.5029e+01],\n",
       "        [-6.5594e+00],\n",
       "        [ 2.3259e+01],\n",
       "        [ 5.4361e-01],\n",
       "        [-4.6186e+00],\n",
       "        [-1.7060e+01],\n",
       "        [-5.5709e+00],\n",
       "        [ 9.5214e+00],\n",
       "        [-7.9763e+00],\n",
       "        [ 4.2252e+00],\n",
       "        [ 1.5092e+00],\n",
       "        [ 7.0865e+00],\n",
       "        [ 9.0257e+00],\n",
       "        [ 7.0669e+00],\n",
       "        [ 2.4924e+00],\n",
       "        [ 1.2331e+00],\n",
       "        [ 3.7890e+00],\n",
       "        [ 1.7030e+01],\n",
       "        [ 2.2109e+01],\n",
       "        [ 7.1882e+00],\n",
       "        [-5.2052e+00],\n",
       "        [ 5.0795e+00],\n",
       "        [ 7.2834e+00],\n",
       "        [ 1.2444e+01],\n",
       "        [ 1.4443e+01],\n",
       "        [ 1.8640e+00],\n",
       "        [ 1.5246e+01],\n",
       "        [-1.0635e+00],\n",
       "        [ 1.4088e+00],\n",
       "        [ 2.8884e+01],\n",
       "        [-6.2733e-01],\n",
       "        [-1.9599e+00],\n",
       "        [ 6.5011e+00],\n",
       "        [ 1.3949e+00],\n",
       "        [ 2.6366e+00],\n",
       "        [-5.8401e+00]])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = y.reshape((-1, 1))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d4fa52b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "cd2f8cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_arrays = (X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d26f5ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.TensorDataset at 0x7f8949d7f7f0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = data.TensorDataset(*data_arrays)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1bd3b8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f8949d7ef80>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_iter = data.DataLoader(dataset, batch_size, shuffle=True)\n",
    "data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3482cd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4741,  0.0645, -0.2747],\n",
      "        [ 1.1765,  0.0767,  0.7029],\n",
      "        [-0.1647,  0.7800, -0.7397],\n",
      "        [ 0.9177, -0.3356, -1.5822],\n",
      "        [ 0.7624,  0.7372, -0.3704],\n",
      "        [-0.4355,  0.0917, -1.1242],\n",
      "        [ 1.8802, -0.6526,  0.3868],\n",
      "        [ 1.1768, -1.3929,  0.1586],\n",
      "        [-0.0452, -0.5718,  0.1165],\n",
      "        [ 0.6459,  0.6444, -0.4780]]) tensor([[ 0.8407],\n",
      "        [11.9224],\n",
      "        [-4.6837],\n",
      "        [-5.4909],\n",
      "        [ 0.2721],\n",
      "        [-5.9651],\n",
      "        [13.2642],\n",
      "        [12.5562],\n",
      "        [ 6.9896],\n",
      "        [-0.5261]])\n",
      "tensor([[ 1.0635,  0.4535, -2.1084],\n",
      "        [-0.8982,  1.2297, -0.2024],\n",
      "        [ 0.2801,  0.2418, -0.3988],\n",
      "        [-0.0743,  1.0724, -0.6607],\n",
      "        [ 2.5289,  2.5730, -1.9285],\n",
      "        [-1.3788, -0.1598,  0.0705],\n",
      "        [ 1.2497,  1.1856, -0.5210],\n",
      "        [-1.3608,  2.4439,  0.4963],\n",
      "        [ 0.0881, -0.4497,  0.9120],\n",
      "        [ 1.2733, -1.2467, -0.3691]]) tensor([[-12.0729],\n",
      "        [ -3.3824],\n",
      "        [  0.7515],\n",
      "        [ -4.8782],\n",
      "        [-14.9111],\n",
      "        [  2.5498],\n",
      "        [ -1.5003],\n",
      "        [ -2.8696],\n",
      "        [ 13.2100],\n",
      "        [  8.0338]])\n",
      "tensor([[ 0.4041,  0.0491, -0.0550],\n",
      "        [ 0.4883, -0.3607, -0.4352],\n",
      "        [-0.8821,  0.7723,  0.6139],\n",
      "        [-2.0936, -0.1589,  1.1179],\n",
      "        [ 1.9686,  0.2384,  0.4716],\n",
      "        [-1.5104, -0.4103, -0.6435],\n",
      "        [ 0.6755,  0.1372,  0.5905],\n",
      "        [ 0.1445,  0.2693,  0.1110],\n",
      "        [ 0.0614, -1.9995,  0.8815],\n",
      "        [-0.4741,  0.7381,  0.6824]]) tensor([[ 4.3992],\n",
      "        [ 2.9237],\n",
      "        [ 4.7244],\n",
      "        [ 9.4918],\n",
      "        [11.0844],\n",
      "        [-2.5771],\n",
      "        [ 9.8014],\n",
      "        [ 4.4602],\n",
      "        [18.1727],\n",
      "        [ 6.1987]])\n",
      "tensor([[ 1.5031,  0.5808, -0.2110],\n",
      "        [ 0.1146, -0.9996, -1.1717],\n",
      "        [ 0.9244, -1.6803,  0.8692],\n",
      "        [ 0.3932, -0.6580, -1.3530],\n",
      "        [-0.5807,  0.7998, -1.4105],\n",
      "        [-0.8193,  0.2486, -1.3396],\n",
      "        [-0.7052,  0.7371,  0.4243],\n",
      "        [-0.0244,  0.3646, -0.0385],\n",
      "        [-0.2672,  0.4276, -1.2282],\n",
      "        [-1.1384, -1.5192, -0.7185]]) tensor([[  3.5527],\n",
      "        [ -1.5405],\n",
      "        [ 18.7210],\n",
      "        [ -3.6017],\n",
      "        [-10.9778],\n",
      "        [ -8.9979],\n",
      "        [  3.6854],\n",
      "        [  2.6064],\n",
      "        [ -7.6018],\n",
      "        [  1.3492]])\n",
      "tensor([[-0.1745,  0.0758, -0.3880],\n",
      "        [ 0.8799, -1.5440,  0.7604],\n",
      "        [-0.6381,  1.2729, -0.2008],\n",
      "        [ 0.2701, -0.8094, -0.1077],\n",
      "        [ 0.1669, -2.1641,  0.8737],\n",
      "        [ 0.1323, -0.9691,  0.2085],\n",
      "        [ 0.1694, -0.2636,  0.0377],\n",
      "        [-1.1261, -1.2635,  0.0054],\n",
      "        [-0.4862,  0.5647, -0.7726],\n",
      "        [-1.6460,  0.9825, -0.4898]]) tensor([[ 0.4799],\n",
      "        [17.2961],\n",
      "        [-3.0204],\n",
      "        [ 6.6368],\n",
      "        [18.8715],\n",
      "        [ 9.4265],\n",
      "        [ 5.7424],\n",
      "        [ 6.2871],\n",
      "        [-4.8967],\n",
      "        [-6.3578]])\n",
      "tensor([[-0.3311,  1.4601,  2.0913],\n",
      "        [ 1.4532, -1.1955,  1.3946],\n",
      "        [ 1.4055, -0.1576,  1.6127],\n",
      "        [-0.7826, -0.8797,  1.2848],\n",
      "        [ 2.3854,  0.2206,  0.3268],\n",
      "        [ 0.0423,  0.2157,  0.0097],\n",
      "        [ 0.0472,  0.3625, -0.7417],\n",
      "        [ 1.3760,  0.0865, -0.6063],\n",
      "        [-0.5417,  0.3632,  1.7842],\n",
      "        [ 1.1246,  0.2206,  0.3202]]) tensor([[15.3025],\n",
      "        [22.3361],\n",
      "        [20.4559],\n",
      "        [15.8851],\n",
      "        [10.8399],\n",
      "        [ 3.6172],\n",
      "        [-2.8761],\n",
      "        [ 1.8053],\n",
      "        [16.1514],\n",
      "        [ 8.2547]])\n",
      "tensor([[ 0.0168,  0.2083,  1.9224],\n",
      "        [ 0.4389, -1.0756,  0.5109],\n",
      "        [-0.6889,  1.3279, -1.1096],\n",
      "        [-0.7307, -1.0804,  1.4829],\n",
      "        [-1.7672, -0.5906, -0.1936],\n",
      "        [ 0.3857, -1.4798,  1.3846],\n",
      "        [ 0.1040, -0.9204,  0.1222],\n",
      "        [ 0.0732, -0.5299, -0.4627],\n",
      "        [-2.2363,  0.0754, -1.2249],\n",
      "        [ 0.9042,  1.4456, -1.0692]]) tensor([[ 18.8951],\n",
      "        [ 12.8244],\n",
      "        [-10.5731],\n",
      "        [ 18.2772],\n",
      "        [  1.1272],\n",
      "        [ 21.0747],\n",
      "        [  8.5060],\n",
      "        [  2.4436],\n",
      "        [-10.3533],\n",
      "        [ -7.4651]])\n",
      "tensor([[ 0.9584,  0.3898, -0.2219],\n",
      "        [ 0.3578, -0.0820,  0.5644],\n",
      "        [-1.3841,  1.1296,  0.8260],\n",
      "        [-1.8243, -0.3132,  0.1420],\n",
      "        [ 0.2290,  0.6890, -0.4778],\n",
      "        [ 0.6697,  0.8256,  0.4716],\n",
      "        [-0.0874,  1.2363,  0.7240],\n",
      "        [-0.3858,  1.4511, -0.3617],\n",
      "        [-0.2431,  1.5711, -1.6574],\n",
      "        [ 0.7819, -0.5023, -3.5054]]) tensor([[  3.0145],\n",
      "        [  9.7221],\n",
      "        [  4.2076],\n",
      "        [  2.7161],\n",
      "        [ -1.5084],\n",
      "        [  6.5037],\n",
      "        [  5.6091],\n",
      "        [ -4.3981],\n",
      "        [-14.8816],\n",
      "        [-20.5613]])\n",
      "tensor([[ 0.3311,  0.1183, -0.6477],\n",
      "        [-1.4320, -1.4606, -0.2012],\n",
      "        [-0.7159,  0.0836, -0.6192],\n",
      "        [ 0.3889,  0.3143,  0.2797],\n",
      "        [ 1.1245, -1.2821, -0.4528],\n",
      "        [-1.5564, -0.3158, -1.4377],\n",
      "        [-0.4597,  0.0689,  2.0930],\n",
      "        [ 0.0102, -0.1998,  0.8459],\n",
      "        [-1.2822,  0.9821, -1.0718],\n",
      "        [ 2.0344, -0.9753, -0.4011]]) tensor([[ -0.7222],\n",
      "        [  4.6808],\n",
      "        [ -2.4597],\n",
      "        [  6.1438],\n",
      "        [  7.1968],\n",
      "        [ -9.3439],\n",
      "        [ 19.7876],\n",
      "        [ 11.6679],\n",
      "        [-10.2745],\n",
      "        [  8.3694]])\n",
      "tensor([[-0.1850, -0.5509, -0.2536],\n",
      "        [ 0.8317,  0.7316,  2.0511],\n",
      "        [ 0.8169, -1.5967, -0.8513],\n",
      "        [-0.4856, -0.9008, -0.1214],\n",
      "        [ 0.7487,  0.6938, -0.5076],\n",
      "        [ 0.9752, -0.7320,  0.0872],\n",
      "        [ 0.5173,  0.2513,  1.3890],\n",
      "        [-0.3664, -0.3942,  0.1424],\n",
      "        [-0.4938,  1.6206,  0.6557],\n",
      "        [ 0.9566, -0.7557, -0.3937]]) tensor([[ 3.6837],\n",
      "        [19.7708],\n",
      "        [ 4.4553],\n",
      "        [ 5.3139],\n",
      "        [-0.7306],\n",
      "        [ 9.3331],\n",
      "        [15.4828],\n",
      "        [ 5.9458],\n",
      "        [ 2.9683],\n",
      "        [ 5.5271]])\n",
      "tensor([[-0.6368, -0.4433, -0.1476],\n",
      "        [-0.3976, -0.7645, -1.5008],\n",
      "        [ 1.9277,  0.0634,  2.1618],\n",
      "        [-0.2644,  1.0337, -0.8442],\n",
      "        [-0.7935, -0.1621, -0.4689],\n",
      "        [-1.1837, -2.0563, -1.0794],\n",
      "        [ 1.8153, -0.3839, -0.6036],\n",
      "        [ 0.9253, -2.2247, -1.2177],\n",
      "        [-1.0339,  0.2436, -0.3611],\n",
      "        [-0.7130, -0.1228, -0.1866]]) tensor([[ 3.2477],\n",
      "        [-5.9998],\n",
      "        [25.1375],\n",
      "        [-6.5965],\n",
      "        [-0.5775],\n",
      "        [ 0.1989],\n",
      "        [ 4.3095],\n",
      "        [ 3.8670],\n",
      "        [-1.5787],\n",
      "        [ 1.7147]])\n",
      "tensor([[-0.3177, -0.9514, -3.1578],\n",
      "        [-0.5169,  2.7027, -0.0707],\n",
      "        [-0.2365, -0.8615,  1.5598],\n",
      "        [-0.5891, -1.1776,  1.3168],\n",
      "        [-1.5139,  0.0939,  0.5022],\n",
      "        [ 0.5547,  0.7236,  1.7680],\n",
      "        [ 0.6341,  0.0687,  1.3599],\n",
      "        [-1.8790, -0.1228, -1.0877],\n",
      "        [-0.5141, -1.2536, -0.3905],\n",
      "        [-1.5642, -0.5467,  0.2053]]) tensor([[-18.4421],\n",
      "        [ -6.6034],\n",
      "        [ 19.1411],\n",
      "        [ 17.5668],\n",
      "        [  4.8649],\n",
      "        [ 17.0038],\n",
      "        [ 16.1134],\n",
      "        [ -7.8527],\n",
      "        [  4.3133],\n",
      "        [  4.5589]])\n",
      "tensor([[-0.9344, -0.3518,  2.1907],\n",
      "        [ 0.8248, -0.0826,  1.5034],\n",
      "        [-1.4325,  0.6003,  1.5040],\n",
      "        [ 0.3141, -1.7126,  1.3030],\n",
      "        [-0.9460,  0.3483, -0.2151],\n",
      "        [-1.3164, -0.0954, -1.2924],\n",
      "        [-0.8678,  0.7954,  0.3624],\n",
      "        [ 1.2861, -0.1302, -0.8388],\n",
      "        [ 0.5546,  1.8674, -0.6394],\n",
      "        [-1.0695,  2.3615, -0.2984]]) tensor([[21.0561],\n",
      "        [18.1684],\n",
      "        [11.3203],\n",
      "        [21.0907],\n",
      "        [-0.6055],\n",
      "        [-8.4516],\n",
      "        [ 2.6672],\n",
      "        [ 0.4792],\n",
      "        [-6.1444],\n",
      "        [-8.3722]])\n",
      "tensor([[ 0.4222, -0.3037,  1.1029],\n",
      "        [ 0.4914, -1.4725, -1.4017],\n",
      "        [ 0.4173,  0.5664,  0.6168],\n",
      "        [ 0.1673,  1.6207, -0.0658],\n",
      "        [ 1.4558, -0.9361,  0.0882],\n",
      "        [ 0.4263, -0.9680,  0.4443],\n",
      "        [-0.0896,  0.3697, -0.3382],\n",
      "        [-0.3003,  0.3852, -0.5902],\n",
      "        [-0.7472,  0.7432, -0.9878],\n",
      "        [-0.4796,  0.6680, -0.2852]]) tensor([[14.9078],\n",
      "        [-1.0056],\n",
      "        [ 8.0619],\n",
      "        [-1.5000],\n",
      "        [10.9784],\n",
      "        [11.9012],\n",
      "        [ 0.0429],\n",
      "        [-2.4372],\n",
      "        [-7.7170],\n",
      "        [-1.3057]])\n",
      "tensor([[-1.0279e+00,  7.5267e-01,  3.2746e-01],\n",
      "        [ 2.8155e-01, -8.5928e-02, -1.1825e-01],\n",
      "        [ 1.0805e+00,  6.6820e-01,  1.0015e+00],\n",
      "        [ 6.2148e-01, -2.8109e-01, -9.9460e-01],\n",
      "        [ 8.4375e-01,  9.0999e-01, -3.3566e-01],\n",
      "        [-7.7081e-01,  6.2308e-01,  6.1875e-02],\n",
      "        [-3.0551e-01,  4.2469e-02,  2.3390e-01],\n",
      "        [-4.4434e-01, -4.8935e-01,  5.2932e-01],\n",
      "        [-2.4868e+00, -7.5233e-01, -8.3988e-01],\n",
      "        [-1.2390e+00,  8.5203e-04,  1.7862e+00]]) tensor([[ 2.2004],\n",
      "        [ 4.1232],\n",
      "        [12.1137],\n",
      "        [-1.5755],\n",
      "        [ 0.1042],\n",
      "        [ 1.0475],\n",
      "        [ 5.3081],\n",
      "        [ 9.2119],\n",
      "        [-4.9342],\n",
      "        [16.0011]])\n",
      "tensor([[-1.2707e+00,  1.4681e-01, -1.0533e-01],\n",
      "        [ 5.9245e-01,  3.8710e-01, -3.4353e-01],\n",
      "        [ 6.1579e-01,  1.4668e+00, -1.2478e+00],\n",
      "        [-9.4807e-01,  7.4086e-01, -2.1961e-01],\n",
      "        [ 3.2072e-01, -2.6920e-01,  2.6364e-01],\n",
      "        [ 5.7419e-01, -3.6292e-01, -1.1369e-01],\n",
      "        [-1.5653e+00, -4.6619e-01,  9.4160e-01],\n",
      "        [-1.0773e+00, -3.0326e-01,  7.0133e-01],\n",
      "        [ 9.3377e-01, -1.3813e+00,  2.3084e-04],\n",
      "        [-7.9813e-01,  1.1368e+00, -9.9027e-01]]) tensor([[ 0.3030],\n",
      "        [ 1.3243],\n",
      "        [-9.5449],\n",
      "        [-1.9831],\n",
      "        [ 7.8850],\n",
      "        [ 5.6724],\n",
      "        [10.1771],\n",
      "        [ 8.6933],\n",
      "        [10.7667],\n",
      "        [-9.1903]])\n",
      "tensor([[-1.7043, -1.1492, -1.8234],\n",
      "        [ 1.1459,  0.8706, -0.7110],\n",
      "        [ 0.6292,  1.0678,  0.7865],\n",
      "        [ 0.4735,  0.7685, -0.2403],\n",
      "        [ 1.5848, -1.8165,  0.9159],\n",
      "        [-0.4129, -0.4257, -0.1015],\n",
      "        [ 0.5457, -0.7605, -0.6500],\n",
      "        [ 0.1506,  0.5158,  0.2962],\n",
      "        [ 1.4940,  1.4104,  0.2064],\n",
      "        [ 0.4609, -0.4964, -1.5431]]) tensor([[-9.8997],\n",
      "        [-2.1544],\n",
      "        [ 8.1214],\n",
      "        [ 0.5936],\n",
      "        [20.8727],\n",
      "        [ 4.0181],\n",
      "        [ 2.6823],\n",
      "        [ 5.0941],\n",
      "        [ 4.0452],\n",
      "        [-5.5348]])\n",
      "tensor([[ 0.4440,  0.1946,  0.0513],\n",
      "        [-0.1821, -1.2626,  0.0322],\n",
      "        [ 1.1460, -0.3986, -1.0911],\n",
      "        [-0.7493, -0.9795, -0.9044],\n",
      "        [-0.0140,  1.0785,  0.5319],\n",
      "        [ 0.6085,  0.7595, -1.1528],\n",
      "        [ 0.5288, -0.5039,  0.6042],\n",
      "        [ 0.3017,  0.0841,  0.3353],\n",
      "        [-0.0099,  0.7017,  1.0472],\n",
      "        [ 1.6686, -1.3914,  0.3792]]) tensor([[ 4.8399],\n",
      "        [ 8.3771],\n",
      "        [-0.8837],\n",
      "        [-1.2107],\n",
      "        [ 4.7647],\n",
      "        [-6.4006],\n",
      "        [11.8095],\n",
      "        [ 7.2122],\n",
      "        [10.1923],\n",
      "        [15.3140]])\n",
      "tensor([[ 9.5145e-01, -2.0586e+00, -1.7822e+00],\n",
      "        [-6.3575e-01, -6.1017e-01,  1.2864e+00],\n",
      "        [-5.3141e-01,  8.7481e-02,  7.4041e-01],\n",
      "        [-2.9504e-01, -6.6592e-01,  5.5584e-01],\n",
      "        [-8.2387e-01,  1.2548e+00, -9.3452e-01],\n",
      "        [ 1.2518e+00,  1.0203e+00, -1.8897e+00],\n",
      "        [-2.9817e-02,  6.7659e-01, -1.7726e-01],\n",
      "        [-1.7688e-01,  4.4640e-01,  3.5070e-01],\n",
      "        [-1.7957e-03,  1.1493e+00, -8.3204e-01],\n",
      "        [-3.0788e-01,  3.0392e-01, -3.8311e-01]]) tensor([[ -1.1499],\n",
      "        [ 15.2936],\n",
      "        [  8.7572],\n",
      "        [ 10.3244],\n",
      "        [ -9.1752],\n",
      "        [-11.8725],\n",
      "        [  0.4136],\n",
      "        [  5.1208],\n",
      "        [ -6.3669],\n",
      "        [ -0.5153]])\n",
      "tensor([[ 0.5078,  1.5300, -1.2263],\n",
      "        [ 1.3927,  0.8307, -1.8142],\n",
      "        [ 0.8570, -0.6438, -0.2425],\n",
      "        [ 1.5877,  0.4611,  0.3999],\n",
      "        [-0.6490, -1.8536, -1.4432],\n",
      "        [ 0.6859,  0.8519, -0.5962],\n",
      "        [ 0.7095, -1.4409,  0.2374],\n",
      "        [-0.2444, -1.1220,  0.5056],\n",
      "        [ 0.1659, -1.1669, -2.3247],\n",
      "        [-0.9729, -1.6951,  1.6827]]) tensor([[ -9.7960],\n",
      "        [-10.3542],\n",
      "        [  6.1595],\n",
      "        [  9.0006],\n",
      "        [ -2.3354],\n",
      "        [ -2.1062],\n",
      "        [ 12.4211],\n",
      "        [ 11.5647],\n",
      "        [-10.0931],\n",
      "        [ 21.4672]])\n",
      "tensor([[ 0.8707, -1.0289,  1.2001],\n",
      "        [ 0.1609, -0.0112, -0.8018],\n",
      "        [-0.1170, -0.6442, -0.1941],\n",
      "        [-0.1531,  1.5628, -0.5669],\n",
      "        [-0.7946,  0.7646, -1.0849],\n",
      "        [ 1.3266,  0.1931,  0.9818],\n",
      "        [ 0.8168, -1.9562, -0.6898],\n",
      "        [ 0.7160,  0.3978, -0.1640],\n",
      "        [-1.0972, -1.1612, -1.1656],\n",
      "        [ 2.3101, -0.7348, -0.8405]]) tensor([[19.0597],\n",
      "        [-1.8666],\n",
      "        [ 4.6038],\n",
      "        [-5.9429],\n",
      "        [-8.6668],\n",
      "        [14.0541],\n",
      "        [ 6.9701],\n",
      "        [ 2.9728],\n",
      "        [-3.3859],\n",
      "        [ 4.5799]])\n",
      "tensor([[-0.7448,  0.2038,  1.9694],\n",
      "        [ 1.7649,  1.3589,  0.3371],\n",
      "        [ 0.7178,  0.6469,  0.4517],\n",
      "        [-0.0226, -1.1530,  1.6667],\n",
      "        [ 1.1354,  1.5405,  1.2896],\n",
      "        [ 0.4713, -0.4250,  1.4711],\n",
      "        [ 1.5904,  0.7891,  0.7947],\n",
      "        [ 1.4727, -1.7199, -0.4064],\n",
      "        [ 0.2359, -0.4277, -0.8002],\n",
      "        [ 1.2002, -0.0237, -0.5686]]) tensor([[17.7860],\n",
      "        [ 5.8033],\n",
      "        [ 7.0463],\n",
      "        [21.4106],\n",
      "        [11.5572],\n",
      "        [18.3608],\n",
      "        [11.0782],\n",
      "        [ 9.7325],\n",
      "        [-0.2845],\n",
      "        [ 2.1332]])\n",
      "tensor([[-0.5192,  0.4501,  0.1154],\n",
      "        [ 2.1706, -0.1347, -0.1882],\n",
      "        [-1.5768, -0.2139, -0.6241],\n",
      "        [-1.2775,  0.5416, -1.6555],\n",
      "        [ 0.4902, -0.1571,  1.3450],\n",
      "        [ 0.5760, -0.4226,  0.2293],\n",
      "        [ 0.1907, -0.0879,  0.3172],\n",
      "        [-0.5227, -1.2501, -0.2646],\n",
      "        [-0.0778, -3.0816,  1.3442],\n",
      "        [ 0.6771, -0.8018,  0.3598]]) tensor([[  2.5586],\n",
      "        [  7.4968],\n",
      "        [ -3.2293],\n",
      "        [-13.4459],\n",
      "        [ 16.5093],\n",
      "        [  8.6220],\n",
      "        [  7.4114],\n",
      "        [  5.2880],\n",
      "        [ 25.2710],\n",
      "        [ 11.1678]])\n",
      "tensor([[-0.7549, -1.3611, -2.3603],\n",
      "        [ 1.1992, -2.6745, -0.0462],\n",
      "        [-0.7089, -0.2613, -0.1099],\n",
      "        [-1.5054,  0.4983,  0.3026],\n",
      "        [ 1.5157,  0.9985,  0.0410],\n",
      "        [ 1.1560,  1.2189, -1.8276],\n",
      "        [-0.5908, -0.7372,  1.9853],\n",
      "        [ 1.5913, -0.4965, -0.2463],\n",
      "        [ 0.5723, -0.9807,  0.3960],\n",
      "        [-0.5347,  0.4405, -0.4946]]) tensor([[-11.5590],\n",
      "        [ 15.3107],\n",
      "        [  2.8055],\n",
      "        [  1.9171],\n",
      "        [  4.1596],\n",
      "        [-12.2802],\n",
      "        [ 21.4059],\n",
      "        [  7.1046],\n",
      "        [ 11.8594],\n",
      "        [ -2.3333]])\n",
      "tensor([[ 2.3235, -1.8612,  0.1031],\n",
      "        [-1.7134,  0.5841, -1.3893],\n",
      "        [-0.4518,  0.6559,  1.7585],\n",
      "        [-1.2007,  1.7714, -2.3237],\n",
      "        [-0.5811,  0.8026,  0.1971],\n",
      "        [-0.1753,  2.6765, -0.9989],\n",
      "        [-0.6683,  0.4649, -0.2145],\n",
      "        [ 0.9613, -0.4850, -2.0285],\n",
      "        [ 0.7613,  2.3369, -0.1459],\n",
      "        [-0.8752, -0.4033, -2.0064]]) tensor([[ 16.0129],\n",
      "        [-12.3204],\n",
      "        [ 15.1322],\n",
      "        [-22.8149],\n",
      "        [  1.8963],\n",
      "        [-13.2366],\n",
      "        [ -0.4293],\n",
      "        [ -8.4395],\n",
      "        [ -3.3799],\n",
      "        [-12.2147]])\n",
      "tensor([[ 0.2492,  0.1134, -0.9290],\n",
      "        [ 0.1833, -0.4444, -0.5910],\n",
      "        [-0.7470,  0.1184,  0.1912],\n",
      "        [-0.8463, -2.7005,  1.0593],\n",
      "        [-0.4982, -2.5614, -1.3492],\n",
      "        [ 1.2534, -1.0493,  0.3597],\n",
      "        [-0.0478,  0.4581,  1.8958],\n",
      "        [-1.3299,  0.6880, -0.1426],\n",
      "        [ 0.0456,  1.2367,  1.8669],\n",
      "        [-0.5940,  0.6423, -0.4559]]) tensor([[-3.1204],\n",
      "        [ 1.3441],\n",
      "        [ 3.8291],\n",
      "        [20.1783],\n",
      "        [ 1.1126],\n",
      "        [13.1735],\n",
      "        [17.7070],\n",
      "        [-1.9406],\n",
      "        [15.0143],\n",
      "        [-2.8084]])\n",
      "tensor([[ 0.6976, -0.4842, -1.6660],\n",
      "        [-2.2493, -0.1093, -0.9912],\n",
      "        [ 0.7546, -0.8336, -0.6958],\n",
      "        [-0.1753,  1.4471, -0.0229],\n",
      "        [ 0.7130,  0.4518,  0.4889],\n",
      "        [-0.3869,  0.6986, -0.2143],\n",
      "        [-1.0243,  0.9412, -0.4945],\n",
      "        [ 1.2709,  0.6559, -0.1075],\n",
      "        [-0.5948, -0.3285, -1.0974],\n",
      "        [ 0.2686,  1.0536, -0.9170]]) tensor([[-6.0857],\n",
      "        [-7.8440],\n",
      "        [ 2.9855],\n",
      "        [-1.2593],\n",
      "        [ 8.0138],\n",
      "        [-0.6627],\n",
      "        [-5.0026],\n",
      "        [ 3.6535],\n",
      "        [-4.6462],\n",
      "        [-6.1911]])\n",
      "tensor([[-0.7925,  1.3374,  1.9542],\n",
      "        [ 0.2206,  0.2752, -0.1340],\n",
      "        [-0.9323,  0.0251, -0.6248],\n",
      "        [-0.7662, -0.8430, -2.9145],\n",
      "        [ 0.5024, -0.1574, -0.9036],\n",
      "        [-0.0475, -0.1525, -0.0168],\n",
      "        [ 2.4878,  0.5717,  0.8701],\n",
      "        [-1.3174,  2.0375,  0.4763],\n",
      "        [-1.1099, -0.1579,  1.3397],\n",
      "        [ 0.0507, -0.6251,  0.9605]]) tensor([[ 13.7079],\n",
      "        [  2.6398],\n",
      "        [ -2.7604],\n",
      "        [-17.7683],\n",
      "        [ -1.4767],\n",
      "        [  4.5020],\n",
      "        [ 14.2156],\n",
      "        [ -1.5502],\n",
      "        [ 13.2289],\n",
      "        [ 14.1217]])\n",
      "tensor([[-0.7202,  0.4177,  1.0422],\n",
      "        [-1.8818, -1.2584, -0.7192],\n",
      "        [ 1.1487,  0.9226, -0.4794],\n",
      "        [ 0.9149,  0.7753, -0.2914],\n",
      "        [ 1.0325,  1.2714,  0.8727],\n",
      "        [ 0.1146,  0.3504, -0.6076],\n",
      "        [-0.8842, -1.2303, -0.2375],\n",
      "        [ 2.1499, -1.7357, -1.0138],\n",
      "        [ 0.4598, -0.8868,  0.0734],\n",
      "        [ 0.5848, -0.2917,  1.6120]]) tensor([[ 9.6785],\n",
      "        [-1.0499],\n",
      "        [-0.4854],\n",
      "        [ 1.0567],\n",
      "        [ 8.9381],\n",
      "        [-1.6415],\n",
      "        [ 4.7112],\n",
      "        [ 6.2837],\n",
      "        [ 8.7108],\n",
      "        [19.2511]])\n",
      "tensor([[ 2.2783,  0.5955,  0.2390],\n",
      "        [ 1.1899,  0.7076,  0.4060],\n",
      "        [-0.1127,  0.2307,  0.7532],\n",
      "        [ 1.0378,  0.8373, -0.5548],\n",
      "        [ 0.8488,  1.5538,  1.0215],\n",
      "        [-0.6395,  0.9236,  1.3834],\n",
      "        [-0.7747, -1.4492,  0.0211],\n",
      "        [ 0.0257,  0.2618,  0.7339],\n",
      "        [-0.7276, -0.4878, -0.4706],\n",
      "        [-1.2298,  2.0943, -0.3492]]) tensor([[ 8.6431],\n",
      "        [ 7.4099],\n",
      "        [ 9.2215],\n",
      "        [-0.9997],\n",
      "        [ 8.7944],\n",
      "        [10.8594],\n",
      "        [ 7.7497],\n",
      "        [ 9.2237],\n",
      "        [ 0.6324],\n",
      "        [-8.1867]])\n",
      "tensor([[ 0.9245, -1.0439, -1.0164],\n",
      "        [ 0.4320, -0.0490, -0.6457],\n",
      "        [ 1.4357, -0.5626,  1.9733],\n",
      "        [-1.0972,  0.6823,  1.1774],\n",
      "        [-2.3837, -0.2362, -0.3858],\n",
      "        [ 0.4364,  0.7611, -0.3668],\n",
      "        [ 1.2257, -0.5878, -1.4502],\n",
      "        [ 1.3717,  0.5936,  0.1335],\n",
      "        [ 0.6670,  0.1114,  2.4118],\n",
      "        [-1.5764,  0.0095,  0.0582]]) tensor([[ 1.4505],\n",
      "        [ 0.0553],\n",
      "        [24.7720],\n",
      "        [ 9.1228],\n",
      "        [-2.8501],\n",
      "        [-0.4633],\n",
      "        [-2.9516],\n",
      "        [ 5.9949],\n",
      "        [24.4538],\n",
      "        [ 1.4707]])\n",
      "tensor([[ 0.1134,  0.1160, -0.6303],\n",
      "        [-0.1498,  0.7149, -0.1724],\n",
      "        [ 1.5229,  0.2645,  1.7155],\n",
      "        [-0.2214,  2.7953, -0.7872],\n",
      "        [ 1.0915, -0.2361,  0.3922],\n",
      "        [ 0.1426,  0.2805,  0.6576],\n",
      "        [-2.8811, -0.9143, -0.5819],\n",
      "        [-0.4870,  0.5904,  0.8621],\n",
      "        [ 0.8914, -1.1278,  0.0339],\n",
      "        [-1.2590, -0.9420, -0.3804]]) tensor([[ -1.0229],\n",
      "        [  0.0967],\n",
      "        [ 20.0677],\n",
      "        [-12.0320],\n",
      "        [ 10.3119],\n",
      "        [  8.7865],\n",
      "        [ -3.1081],\n",
      "        [  8.1245],\n",
      "        [ 10.0954],\n",
      "        [  1.8552]])\n",
      "tensor([[ 0.4569,  0.0476,  0.3222],\n",
      "        [-0.1189,  1.2708,  1.0957],\n",
      "        [-0.1859, -1.5840,  0.3033],\n",
      "        [ 1.7717,  0.7244,  0.3865],\n",
      "        [ 0.3789, -0.4894, -2.3594],\n",
      "        [-1.8788,  0.5861, -0.9575],\n",
      "        [-1.2069, -0.6114, -0.0899],\n",
      "        [-0.6626,  0.3396, -0.8069],\n",
      "        [-0.1308,  2.2479, -0.2293],\n",
      "        [ 1.2761,  0.3431, -0.2670]]) tensor([[  7.5221],\n",
      "        [  8.3986],\n",
      "        [ 11.6458],\n",
      "        [  8.4007],\n",
      "        [-12.2554],\n",
      "        [ -9.2348],\n",
      "        [  3.1516],\n",
      "        [ -4.7380],\n",
      "        [ -5.5292],\n",
      "        [  3.4531]])\n",
      "tensor([[ 1.5144,  1.9855, -2.7830],\n",
      "        [-0.5324, -0.5650, -0.4389],\n",
      "        [-0.3257,  0.6086,  0.0400],\n",
      "        [ 0.1059, -0.1381,  0.3112],\n",
      "        [ 0.1023,  1.4309,  0.5409],\n",
      "        [ 1.1517, -0.7384, -1.3156],\n",
      "        [ 0.7948, -0.5148, -0.6238],\n",
      "        [-0.9653,  2.2755,  0.7736],\n",
      "        [ 0.7567, -1.1930, -0.7554],\n",
      "        [-0.2917, -0.9465, -1.1496]]) tensor([[-21.7873],\n",
      "        [  1.5336],\n",
      "        [  1.8010],\n",
      "        [  7.3839],\n",
      "        [  3.8710],\n",
      "        [ -1.5139],\n",
      "        [  2.5494],\n",
      "        [  0.7159],\n",
      "        [  3.7164],\n",
      "        [ -2.3554]])\n",
      "tensor([[ 2.4873, -0.6766,  0.4400],\n",
      "        [ 0.3763, -0.6747,  0.0044],\n",
      "        [-0.3104,  0.6234,  2.0279],\n",
      "        [ 0.5203,  1.8798,  0.9779],\n",
      "        [ 1.1360, -0.6318, -1.3140],\n",
      "        [-0.0515, -0.2373,  0.0551],\n",
      "        [ 0.0406,  1.1463, -1.1662],\n",
      "        [-1.8243, -0.7761,  1.4030],\n",
      "        [ 0.3040, -0.2683, -1.2491],\n",
      "        [ 1.0368, -0.2864,  0.9377]]) tensor([[15.0023],\n",
      "        [ 7.2758],\n",
      "        [17.6998],\n",
      "        [ 6.6955],\n",
      "        [-1.8892],\n",
      "        [ 5.3568],\n",
      "        [-8.9542],\n",
      "        [14.4097],\n",
      "        [-4.2807],\n",
      "        [14.7538]])\n",
      "tensor([[ 1.4004,  0.2116,  0.8732],\n",
      "        [-0.4787, -1.0420, -0.0711],\n",
      "        [-2.0499,  1.0068, -0.3589],\n",
      "        [-0.6104, -0.5908, -0.3040],\n",
      "        [-1.1130,  0.8364, -0.5410],\n",
      "        [-0.3188, -1.3436,  2.2420],\n",
      "        [-2.0351, -0.2755, -0.1509],\n",
      "        [-0.3224,  1.5565, -2.0602],\n",
      "        [-1.9028, -0.8713,  0.4981],\n",
      "        [-0.3417,  0.6954,  1.9297]]) tensor([[ 13.2620],\n",
      "        [  6.2251],\n",
      "        [ -6.1937],\n",
      "        [  2.5445],\n",
      "        [ -5.1908],\n",
      "        [ 26.0652],\n",
      "        [ -0.1539],\n",
      "        [-18.2261],\n",
      "        [  7.3311],\n",
      "        [ 16.6063]])\n",
      "tensor([[ 0.1037,  1.8890, -0.7844],\n",
      "        [-1.4482, -1.9719,  0.5757],\n",
      "        [-0.4691, -0.3070, -0.3987],\n",
      "        [-0.3756, -1.9729, -1.1931],\n",
      "        [-1.5592, -0.2812, -0.4813],\n",
      "        [-0.3190, -0.4193,  0.2027],\n",
      "        [-1.4404,  0.8576, -0.0483],\n",
      "        [ 0.3531, -0.5342, -1.5559],\n",
      "        [-1.2813, -2.3251, -0.6319],\n",
      "        [ 0.2425,  0.0893,  0.6434]]) tensor([[-8.2876],\n",
      "        [12.6027],\n",
      "        [ 1.1099],\n",
      "        [ 0.6263],\n",
      "        [-1.8240],\n",
      "        [ 6.6195],\n",
      "        [-1.9848],\n",
      "        [-5.7069],\n",
      "        [ 4.4805],\n",
      "        [ 9.5299]])\n",
      "tensor([[ 0.8591, -0.4890, -0.8425],\n",
      "        [-1.5972, -0.3843, -1.1937],\n",
      "        [ 0.5646,  1.0474, -1.2570],\n",
      "        [ 0.7818,  1.6315, -0.5317],\n",
      "        [-0.0040, -0.6796,  1.9217],\n",
      "        [ 1.9815,  0.0976, -1.1103],\n",
      "        [-0.0274, -3.5697,  0.3177],\n",
      "        [-0.8633,  1.5304, -1.4527],\n",
      "        [ 1.1048,  1.3211,  0.8469],\n",
      "        [-0.8532, -0.5630, -0.2759]]) tensor([[  0.8413],\n",
      "        [ -7.2291],\n",
      "        [ -8.2985],\n",
      "        [ -4.0404],\n",
      "        [ 21.8897],\n",
      "        [ -1.0541],\n",
      "        [ 18.8173],\n",
      "        [-14.3437],\n",
      "        [  8.7073],\n",
      "        [  2.2092]])\n",
      "tensor([[-0.7095,  0.7649, -1.0261],\n",
      "        [-0.1977,  0.3058,  0.4852],\n",
      "        [ 0.6258,  0.1238,  1.1628],\n",
      "        [-0.9119,  1.6745, -0.8981],\n",
      "        [ 0.6657,  1.9955, -0.2951],\n",
      "        [-0.4780,  0.2831, -0.9373],\n",
      "        [ 0.2880,  0.2231, -0.2280],\n",
      "        [-0.4029, -1.1619,  0.0979],\n",
      "        [ 1.3607,  0.0543,  0.2311],\n",
      "        [-1.1804,  0.5148, -0.5313]]) tensor([[ -8.0419],\n",
      "        [  6.6466],\n",
      "        [ 14.3410],\n",
      "        [-10.4984],\n",
      "        [ -3.6183],\n",
      "        [ -5.2191],\n",
      "        [  2.1722],\n",
      "        [  8.1229],\n",
      "        [  8.5879],\n",
      "        [ -4.1730]])\n",
      "tensor([[ 0.3261, -0.6522, -0.0138],\n",
      "        [-0.2612,  0.5108,  0.3438],\n",
      "        [-0.3894,  0.7555, -1.3607],\n",
      "        [-0.0467, -0.6306,  0.4417],\n",
      "        [-0.4574, -1.6230, -0.2014],\n",
      "        [-1.3232, -1.5043,  0.7818],\n",
      "        [-0.4924,  1.1271,  0.0554],\n",
      "        [-0.4324,  0.4049, -0.3483],\n",
      "        [-1.7873, -0.6478,  0.2476],\n",
      "        [ 0.1061,  0.3695,  0.5584]]) tensor([[  6.9670],\n",
      "        [  4.7028],\n",
      "        [-10.0374],\n",
      "        [  9.7779],\n",
      "        [  7.1899],\n",
      "        [ 12.9208],\n",
      "        [ -0.1749],\n",
      "        [ -0.8226],\n",
      "        [  4.8035],\n",
      "        [  7.6005]])\n",
      "tensor([[ 0.1408, -0.2226, -0.3808],\n",
      "        [ 0.0179,  1.3296,  0.8342],\n",
      "        [ 0.7588,  0.3561, -0.8854],\n",
      "        [ 1.2010, -0.1103,  1.7728],\n",
      "        [-0.3499, -0.2871, -0.1644],\n",
      "        [-0.1635, -1.8247,  1.3815],\n",
      "        [ 0.2094, -1.0167, -0.5020],\n",
      "        [ 0.7039,  0.0239, -0.1714],\n",
      "        [ 1.2907, -1.1689, -0.8875],\n",
      "        [-0.4276, -0.1071,  0.2084]]) tensor([[ 2.1982],\n",
      "        [ 6.3912],\n",
      "        [-2.5678],\n",
      "        [21.1538],\n",
      "        [ 3.1732],\n",
      "        [21.1225],\n",
      "        [ 4.0462],\n",
      "        [ 4.1583],\n",
      "        [ 3.6579],\n",
      "        [ 5.3845]])\n",
      "tensor([[-1.4997, -1.6879, -0.1364],\n",
      "        [ 0.9043,  1.1295,  0.9548],\n",
      "        [ 0.6372,  0.7760, -0.7526],\n",
      "        [-0.0799,  2.0039,  0.0849],\n",
      "        [ 0.4254,  1.6994,  1.3674],\n",
      "        [-1.2001, -0.0991, -0.9171],\n",
      "        [ 1.0063,  0.8309,  1.2911],\n",
      "        [ 1.3656,  0.7070,  1.3021],\n",
      "        [-0.7225, -2.0189,  0.3976],\n",
      "        [-1.5766,  1.6516, -0.2495]]) tensor([[ 5.8373],\n",
      "        [ 9.7962],\n",
      "        [-3.2039],\n",
      "        [-2.1037],\n",
      "        [10.2253],\n",
      "        [-5.2022],\n",
      "        [13.7123],\n",
      "        [14.9600],\n",
      "        [12.7832],\n",
      "        [-6.5712]])\n",
      "tensor([[ 1.3227, -0.1885,  0.8696],\n",
      "        [-0.7565,  1.0787, -0.1598],\n",
      "        [ 1.4504,  1.9150,  1.4399],\n",
      "        [-2.1790,  0.0461,  1.0412],\n",
      "        [-0.6853,  1.4323,  1.4790],\n",
      "        [ 0.6994, -1.9481,  1.0578],\n",
      "        [-1.2822, -0.2956, -1.0795],\n",
      "        [ 0.2290,  0.1773,  0.8589],\n",
      "        [-0.3849,  0.4597, -0.0931],\n",
      "        [-0.3495, -0.5284,  0.3403]]) tensor([[14.4371],\n",
      "        [-2.2267],\n",
      "        [12.1038],\n",
      "        [ 8.0087],\n",
      "        [ 9.7781],\n",
      "        [20.6698],\n",
      "        [-5.9973],\n",
      "        [10.9265],\n",
      "        [ 1.1186],\n",
      "        [ 8.0298]])\n",
      "tensor([[ 1.1583,  1.6001, -0.0907],\n",
      "        [-0.0467, -0.2170, -0.4629],\n",
      "        [ 0.6358, -0.6582,  0.4366],\n",
      "        [ 2.5771,  0.5774, -1.2718],\n",
      "        [-1.5101,  0.2555,  1.1252],\n",
      "        [ 0.9372,  0.5091,  0.8952],\n",
      "        [-0.2905, -1.1464, -0.7902],\n",
      "        [-0.5372, -0.5529,  1.3165],\n",
      "        [-1.1394,  0.6529, -1.3020],\n",
      "        [ 0.8387, -0.4873,  0.1103]]) tensor([[  0.3444],\n",
      "        [  1.1391],\n",
      "        [ 11.1823],\n",
      "        [ -2.7845],\n",
      "        [  9.3125],\n",
      "        [ 11.5129],\n",
      "        [  1.2054],\n",
      "        [ 15.5417],\n",
      "        [-10.7124],\n",
      "        [  8.4162]])\n",
      "tensor([[ 0.8149,  0.1829, -0.5063],\n",
      "        [-1.1118,  0.1718, -0.9893],\n",
      "        [-0.0776,  0.2332,  1.5461],\n",
      "        [ 1.1014,  0.1101,  2.1176],\n",
      "        [-0.8160,  0.1430, -0.4229],\n",
      "        [-0.7553, -1.2595, -0.5308],\n",
      "        [-0.1493, -0.2081,  0.6363],\n",
      "        [-1.6543, -0.5342, -1.5251],\n",
      "        [-0.5575,  0.0963,  0.3178],\n",
      "        [ 0.6242,  0.3475, -0.9078]]) tensor([[ 1.1742],\n",
      "        [-6.5180],\n",
      "        [15.6285],\n",
      "        [22.9632],\n",
      "        [-1.3255],\n",
      "        [ 2.7159],\n",
      "        [ 9.7071],\n",
      "        [-9.5076],\n",
      "        [ 5.2901],\n",
      "        [-2.9813]])\n",
      "tensor([[ 0.3150, -0.2067, -0.7175],\n",
      "        [ 0.1306, -0.7822,  0.4494],\n",
      "        [-0.2884,  0.2536,  0.0452],\n",
      "        [-1.6799, -0.3145, -0.4572],\n",
      "        [ 3.4603, -0.3154, -0.7179],\n",
      "        [ 1.4362,  0.5012,  0.3581],\n",
      "        [ 1.5152, -0.1755,  0.3891],\n",
      "        [-0.2919, -2.1206,  0.3026],\n",
      "        [-0.3946, -0.8969, -1.0124],\n",
      "        [ 1.1187, -0.3508, -1.4212]]) tensor([[-0.1973],\n",
      "        [10.7204],\n",
      "        [ 3.1174],\n",
      "        [-1.7497],\n",
      "        [ 6.4465],\n",
      "        [ 8.2306],\n",
      "        [10.9427],\n",
      "        [13.2525],\n",
      "        [-1.6470],\n",
      "        [-3.7364]])\n",
      "tensor([[-0.8443,  0.8626,  0.3437],\n",
      "        [ 0.1300, -1.2364, -0.5960],\n",
      "        [ 0.0573, -0.5365, -0.4285],\n",
      "        [ 2.3443,  0.2049,  1.3177],\n",
      "        [-0.5902, -0.0390,  0.9303],\n",
      "        [-0.4235, -0.9168, -1.9199],\n",
      "        [ 0.3214, -0.3984, -1.6137],\n",
      "        [-0.3300, -0.6045,  1.8792],\n",
      "        [ 0.8484,  0.9149, -0.4109],\n",
      "        [ 0.5894, -0.1995, -0.2825]]) tensor([[ 2.3171],\n",
      "        [ 3.8995],\n",
      "        [ 2.6960],\n",
      "        [18.7500],\n",
      "        [10.5937],\n",
      "        [-8.8928],\n",
      "        [-6.7236],\n",
      "        [20.6255],\n",
      "        [-0.4993],\n",
      "        [ 3.8016]])\n",
      "tensor([[ 1.4137, -0.4351,  0.7382],\n",
      "        [ 2.3529,  1.0090,  0.9990],\n",
      "        [-0.4760, -0.5819,  0.8639],\n",
      "        [-0.9459,  0.1736,  0.4805],\n",
      "        [ 1.9201, -0.3665,  0.8441],\n",
      "        [-1.9459,  0.3715, -0.1065],\n",
      "        [-0.8056,  0.3676,  0.5995],\n",
      "        [-1.3129,  1.2429, -0.1835],\n",
      "        [-0.9816,  0.0368,  1.4228],\n",
      "        [ 0.6955, -0.6587, -0.0781]]) tensor([[14.4080],\n",
      "        [13.4722],\n",
      "        [12.1254],\n",
      "        [ 5.5678],\n",
      "        [16.0536],\n",
      "        [-1.8046],\n",
      "        [ 6.1251],\n",
      "        [-4.1111],\n",
      "        [13.4864],\n",
      "        [ 7.2173]])\n",
      "tensor([[-1.2419,  0.6259, -1.4631],\n",
      "        [-1.6016,  1.5707,  0.2559],\n",
      "        [-0.9295,  0.6391,  1.1627],\n",
      "        [ 0.7024, -0.6645, -0.7330],\n",
      "        [-0.4501,  0.7709, -0.4376],\n",
      "        [ 1.2010,  0.0177,  0.6333],\n",
      "        [ 0.0662, -0.1737, -0.0319],\n",
      "        [-1.3442,  0.1329,  0.0405],\n",
      "        [ 1.0844, -0.8576, -1.2600],\n",
      "        [-0.5234, -1.0868, -1.5606]]) tensor([[-12.0976],\n",
      "        [ -2.3052],\n",
      "        [  9.4692],\n",
      "        [  1.9974],\n",
      "        [ -2.8144],\n",
      "        [ 11.5904],\n",
      "        [  4.6739],\n",
      "        [  1.3857],\n",
      "        [ -0.7851],\n",
      "        [ -5.6352]])\n",
      "tensor([[-0.9074,  1.2549,  0.1135],\n",
      "        [ 1.2772,  0.7415,  0.9955],\n",
      "        [ 0.2283,  0.7457,  0.0420],\n",
      "        [ 1.7789,  0.0291,  1.1006],\n",
      "        [-1.0118, -0.8792, -1.3560],\n",
      "        [-0.5820,  0.9975,  1.2328],\n",
      "        [-1.5172,  0.1701,  0.0036],\n",
      "        [ 0.7054, -0.4602,  0.2756],\n",
      "        [-0.5454, -1.4548, -0.5346],\n",
      "        [-0.0533, -0.2931,  0.3614]]) tensor([[-0.9637],\n",
      "        [12.1877],\n",
      "        [ 2.4566],\n",
      "        [16.4653],\n",
      "        [-5.6819],\n",
      "        [ 9.4883],\n",
      "        [ 0.6192],\n",
      "        [ 9.3693],\n",
      "        [ 3.7850],\n",
      "        [ 7.9735]])\n",
      "tensor([[ 0.8383,  1.0171, -1.1319],\n",
      "        [-1.9791,  0.6184, -0.2749],\n",
      "        [ 0.1151, -1.3343, -2.9533],\n",
      "        [ 2.2424, -0.5456, -1.0312],\n",
      "        [-0.3892, -0.3468,  0.0139],\n",
      "        [ 0.3416,  1.1043, -0.9278],\n",
      "        [-0.7010,  0.8702, -0.0296],\n",
      "        [ 0.4260,  0.0865, -0.3298],\n",
      "        [ 0.5125, -0.2720, -0.2897],\n",
      "        [-0.3681,  0.0626,  0.1218]]) tensor([[ -6.6312],\n",
      "        [ -4.0490],\n",
      "        [-14.6615],\n",
      "        [  2.2759],\n",
      "        [  4.7152],\n",
      "        [ -6.2974],\n",
      "        [ -0.3946],\n",
      "        [  2.1109],\n",
      "        [  3.8309],\n",
      "        [  4.2394]])\n",
      "tensor([[-0.5784,  1.1818,  0.7680],\n",
      "        [ 0.3960,  0.3351,  1.0993],\n",
      "        [ 1.4412, -0.4229,  1.7416],\n",
      "        [-1.0655, -0.9124, -0.3662],\n",
      "        [-0.3166,  0.2333,  0.7499],\n",
      "        [ 0.3525, -1.9074, -0.8103],\n",
      "        [ 0.4183, -0.0595,  0.0799],\n",
      "        [ 1.2304, -0.5642, -0.2701],\n",
      "        [-1.4346,  0.6679, -0.9024],\n",
      "        [-0.1175, -0.7945, -2.0230]]) tensor([[ 5.1584],\n",
      "        [12.6396],\n",
      "        [22.4647],\n",
      "        [ 2.2205],\n",
      "        [ 8.7803],\n",
      "        [ 4.9045],\n",
      "        [ 5.8738],\n",
      "        [ 6.4018],\n",
      "        [-8.1590],\n",
      "        [-9.5226]])\n",
      "tensor([[ 1.2975, -0.5573, -0.0056],\n",
      "        [-0.7588,  0.4300,  0.7311],\n",
      "        [ 2.5874,  1.1584,  0.0945],\n",
      "        [-0.5825, -0.8841, -0.0761],\n",
      "        [-0.3831,  0.1448, -0.8926],\n",
      "        [-0.1084,  0.0195,  0.2850],\n",
      "        [ 0.6513, -0.1371, -1.5437],\n",
      "        [ 0.3048, -0.1064, -0.1282],\n",
      "        [ 0.6568, -0.1023,  0.2260],\n",
      "        [-0.3165,  1.5197, -1.1153]]) tensor([[  8.6622],\n",
      "        [  7.0535],\n",
      "        [  6.1915],\n",
      "        [  5.4126],\n",
      "        [ -4.1727],\n",
      "        [  6.1968],\n",
      "        [ -6.4002],\n",
      "        [  4.1432],\n",
      "        [  7.6654],\n",
      "        [-10.5054]])\n",
      "tensor([[-0.0750, -0.7030, -0.5787],\n",
      "        [ 0.1930, -0.3596,  0.6916],\n",
      "        [-0.5202, -0.1929,  1.3784],\n",
      "        [ 0.4346,  2.3427, -1.9545],\n",
      "        [ 0.4696, -0.2179,  1.7316],\n",
      "        [-0.5135, -0.3750,  2.2284],\n",
      "        [ 2.4411,  0.4634,  1.1110],\n",
      "        [-1.2844, -0.7360,  0.4927],\n",
      "        [ 0.3964, -1.1251,  0.8666],\n",
      "        [-0.0512,  0.4433, -0.5032]]) tensor([[  1.7949],\n",
      "        [ 11.3488],\n",
      "        [ 14.8411],\n",
      "        [-18.5283],\n",
      "        [ 19.7562],\n",
      "        [ 22.2738],\n",
      "        [ 16.3986],\n",
      "        [  8.0897],\n",
      "        [ 15.7348],\n",
      "        [ -1.4188]])\n",
      "tensor([[-0.5754, -0.9881, -1.6287],\n",
      "        [ 0.1290,  0.4757,  0.4568],\n",
      "        [-0.5461,  0.7940, -0.1954],\n",
      "        [-0.4366,  1.9434, -0.2072],\n",
      "        [ 0.5694,  1.2808,  0.6021],\n",
      "        [ 0.1146,  1.1982,  0.0577],\n",
      "        [ 0.4352,  0.4125, -1.6486],\n",
      "        [ 2.2384, -1.4299, -0.5814],\n",
      "        [ 0.1500,  1.4044, -2.0266],\n",
      "        [ 1.4750,  0.5085,  0.8891]]) tensor([[ -6.6159],\n",
      "        [  6.4861],\n",
      "        [ -1.1465],\n",
      "        [ -4.9375],\n",
      "        [  5.8125],\n",
      "        [  0.8502],\n",
      "        [ -9.5113],\n",
      "        [  8.8806],\n",
      "        [-16.5225],\n",
      "        [ 12.5413]])\n",
      "tensor([[-1.6495, -0.8310, -0.0896],\n",
      "        [-1.1664,  0.5900,  0.4080],\n",
      "        [ 0.3574, -0.2872, -0.4282],\n",
      "        [ 2.3919, -0.4854,  0.8800],\n",
      "        [-0.2924, -1.4312,  0.0616],\n",
      "        [-0.5603,  1.4013,  1.1440],\n",
      "        [-1.3706,  0.1708, -0.6849],\n",
      "        [-0.1032,  0.3878,  0.6824],\n",
      "        [-0.6620, -0.3507, -0.1492],\n",
      "        [-0.3328,  0.0794,  0.1235]]) tensor([[ 3.0196],\n",
      "        [ 3.1136],\n",
      "        [ 2.4797],\n",
      "        [17.6849],\n",
      "        [ 8.9723],\n",
      "        [ 7.4661],\n",
      "        [-4.6100],\n",
      "        [ 8.1468],\n",
      "        [ 2.8718],\n",
      "        [ 4.2568]])\n",
      "tensor([[-0.1547, -1.1823,  0.3208],\n",
      "        [-0.5465,  0.8078, -0.5833],\n",
      "        [ 0.6140,  1.3981,  0.3390],\n",
      "        [ 0.7865,  0.3512, -1.9094],\n",
      "        [-0.2192,  1.1323, -0.6215],\n",
      "        [-0.0625, -0.3695,  0.6783],\n",
      "        [-0.3246, -1.0522,  0.0931],\n",
      "        [-0.0774,  0.3206, -0.5475],\n",
      "        [ 0.3459,  2.3851, -0.8127],\n",
      "        [ 0.6545,  1.1896,  0.1580]]) tensor([[ 10.4912],\n",
      "        [ -4.3106],\n",
      "        [  3.3792],\n",
      "        [-10.6988],\n",
      "        [ -5.0767],\n",
      "        [ 10.7535],\n",
      "        [  7.8693],\n",
      "        [ -1.4160],\n",
      "        [ -9.7200],\n",
      "        [  2.7388]])\n",
      "tensor([[-3.6562e-01, -1.5625e+00,  8.3460e-01],\n",
      "        [-3.2527e-01, -3.5964e-01, -6.2854e-01],\n",
      "        [-8.4559e-01,  1.7807e-01,  1.2459e+00],\n",
      "        [ 8.2004e-01, -7.0716e-04,  1.2772e+00],\n",
      "        [-3.0200e-01,  4.4073e-01, -1.6121e+00],\n",
      "        [ 5.0938e-01, -3.7623e-01, -5.5773e-01],\n",
      "        [-1.3704e+00, -4.8801e-01,  1.2777e+00],\n",
      "        [ 1.7469e+00,  7.2037e-01,  4.7745e-01],\n",
      "        [-2.9629e-01, -1.0240e+00,  1.0654e+00],\n",
      "        [-1.3615e+00,  1.1337e-01,  1.3800e+00]]) tensor([[ 15.4548],\n",
      "        [ -0.2631],\n",
      "        [ 11.8877],\n",
      "        [ 16.0653],\n",
      "        [-10.8051],\n",
      "        [  2.0329],\n",
      "        [ 13.3406],\n",
      "        [  9.0542],\n",
      "        [ 15.6031],\n",
      "        [ 12.1184]])\n",
      "tensor([[-0.7346,  2.2316,  1.3863],\n",
      "        [ 0.1772, -0.5206,  1.6154],\n",
      "        [-1.1286,  0.1461, -0.3138],\n",
      "        [-0.9132,  0.1593,  1.2713],\n",
      "        [-0.2944,  0.4562,  0.0229],\n",
      "        [-1.0843,  0.4302, -0.0899],\n",
      "        [ 0.3436,  1.0614,  1.1179],\n",
      "        [ 0.2494,  0.0501,  0.4710],\n",
      "        [-0.0826,  2.4583,  0.7278],\n",
      "        [-1.1447, -0.5780, -1.3182]]) tensor([[ 6.2171],\n",
      "        [19.2483],\n",
      "        [-1.0621],\n",
      "        [11.9860],\n",
      "        [ 2.2519],\n",
      "        [-0.1535],\n",
      "        [10.2229],\n",
      "        [ 8.3051],\n",
      "        [ 1.4944],\n",
      "        [-6.6806]])\n",
      "tensor([[-1.4557,  0.7716,  0.4476],\n",
      "        [ 1.5996, -0.9380,  1.0539],\n",
      "        [-0.7822, -0.8946, -0.3377],\n",
      "        [ 1.9988,  1.4660, -0.0820],\n",
      "        [-2.1675, -0.3226,  0.3644],\n",
      "        [ 0.4348, -0.6489,  1.2002],\n",
      "        [-1.1335, -0.6468, -1.5941],\n",
      "        [-0.2155, -0.1919,  0.3992],\n",
      "        [-0.8619,  1.2503,  1.8594],\n",
      "        [ 1.1005, -1.1596, -2.8019]]) tensor([[  2.2491],\n",
      "        [ 19.0181],\n",
      "        [  2.9707],\n",
      "        [  2.5661],\n",
      "        [  3.8816],\n",
      "        [ 16.8845],\n",
      "        [ -8.6439],\n",
      "        [  7.6161],\n",
      "        [ 13.0849],\n",
      "        [-12.0662]])\n",
      "tensor([[ 0.5384,  0.2976, -1.2682],\n",
      "        [-1.0645,  0.2661,  1.1458],\n",
      "        [-0.5862,  0.1061,  1.4697],\n",
      "        [ 0.4342,  1.2952,  1.0420],\n",
      "        [-0.5985,  0.2378,  0.4733],\n",
      "        [-1.7695, -1.0164, -0.6592],\n",
      "        [ 0.5181,  0.3469,  1.6882],\n",
      "        [ 1.4304,  1.0067,  0.5823],\n",
      "        [-0.6203, -1.6258, -0.2955],\n",
      "        [-0.8822, -0.8384, -0.8438]]) tensor([[-5.8857],\n",
      "        [10.3329],\n",
      "        [14.4234],\n",
      "        [ 9.0046],\n",
      "        [ 5.9823],\n",
      "        [-1.1649],\n",
      "        [17.5784],\n",
      "        [ 8.2884],\n",
      "        [ 6.1214],\n",
      "        [-1.4644]])\n",
      "tensor([[ 0.6015,  0.4265,  2.0681],\n",
      "        [-1.9608,  0.0510,  0.2560],\n",
      "        [ 0.1869, -0.0146,  0.9628],\n",
      "        [-0.0574,  1.6413,  1.4385],\n",
      "        [-0.0371, -0.4011,  2.4105],\n",
      "        [ 0.5087, -0.1716,  0.6358],\n",
      "        [-0.8271, -1.0670, -0.8951],\n",
      "        [ 0.3096, -0.1292, -1.5617],\n",
      "        [-0.0840, -0.6615, -1.2519],\n",
      "        [-0.1426,  1.9617,  0.9585]]) tensor([[20.4876],\n",
      "        [ 2.1589],\n",
      "        [12.3045],\n",
      "        [10.0188],\n",
      "        [24.7710],\n",
      "        [10.8721],\n",
      "        [-0.9854],\n",
      "        [-7.2435],\n",
      "        [-3.7212],\n",
      "        [ 4.9165]])\n",
      "tensor([[-0.9123,  0.7940, -0.2133],\n",
      "        [ 0.1472, -0.7646, -0.0239],\n",
      "        [-0.2083, -0.4534,  0.4332],\n",
      "        [-1.1923,  2.3460, -0.0193],\n",
      "        [ 1.4336, -1.2695, -0.7018],\n",
      "        [-0.8177,  1.1173,  0.4315],\n",
      "        [-0.6247,  1.6034,  1.5134],\n",
      "        [ 0.5480,  0.7317, -1.7344],\n",
      "        [-2.1180,  1.1637,  0.3789],\n",
      "        [-0.5238, -1.2175, -2.2584]]) tensor([[ -2.0320],\n",
      "        [  6.9204],\n",
      "        [  8.7908],\n",
      "        [ -6.3114],\n",
      "        [  5.7605],\n",
      "        [  2.2159],\n",
      "        [  9.6266],\n",
      "        [-11.0653],\n",
      "        [ -0.9570],\n",
      "        [-10.7842]])\n",
      "tensor([[ 0.8288,  0.0119,  1.4708],\n",
      "        [ 1.4938, -0.6940,  0.9277],\n",
      "        [-2.4067, -0.3105,  0.6052],\n",
      "        [-0.6599,  0.1305, -0.6354],\n",
      "        [-1.9399,  0.6306, -0.4909],\n",
      "        [-0.8952, -1.5353, -0.5353],\n",
      "        [ 0.6697, -0.3736, -0.9999],\n",
      "        [ 1.0559, -0.2162,  0.0869],\n",
      "        [-0.6120,  0.7743,  0.6352],\n",
      "        [ 1.2557, -1.4929, -2.6695]]) tensor([[17.5829],\n",
      "        [16.9805],\n",
      "        [ 5.2976],\n",
      "        [-2.6576],\n",
      "        [-5.7506],\n",
      "        [ 3.3452],\n",
      "        [-1.1819],\n",
      "        [ 7.7403],\n",
      "        [ 5.4223],\n",
      "        [-9.5554]])\n",
      "tensor([[-1.1840, -0.1044,  0.2085],\n",
      "        [ 1.2721, -0.9868,  0.4793],\n",
      "        [ 0.5369, -0.7062, -0.1738],\n",
      "        [-0.9916, -0.3728, -1.1678],\n",
      "        [-1.3558, -0.5259,  0.5249],\n",
      "        [-1.0399, -0.2457,  0.5930],\n",
      "        [-0.5664, -0.0102,  0.4224],\n",
      "        [-0.0330, -2.3939, -0.2852],\n",
      "        [-0.3306,  0.4144,  0.3721],\n",
      "        [-1.6545,  0.1662, -0.3019]]) tensor([[ 3.8613],\n",
      "        [13.9196],\n",
      "        [ 6.2859],\n",
      "        [-5.8623],\n",
      "        [ 7.4703],\n",
      "        [ 7.6970],\n",
      "        [ 6.4818],\n",
      "        [ 9.9948],\n",
      "        [ 5.0862],\n",
      "        [-2.0743]])\n",
      "tensor([[-0.0429, -1.3380, -1.2291],\n",
      "        [-0.1761, -1.4937, -0.7163],\n",
      "        [-0.6657,  0.4794,  0.7602],\n",
      "        [ 0.0932, -1.0845, -0.1542],\n",
      "        [-1.4760, -2.0888, -1.0024],\n",
      "        [ 0.2258, -0.9646, -1.3970],\n",
      "        [ 0.7045,  1.5546,  0.4560],\n",
      "        [ 0.0983, -0.4456, -0.3455],\n",
      "        [ 0.0406,  0.3570,  1.3659],\n",
      "        [-1.8005,  1.8916,  0.1285]]) tensor([[-1.1752],\n",
      "        [ 3.2121],\n",
      "        [ 7.3195],\n",
      "        [ 6.8496],\n",
      "        [ 0.3343],\n",
      "        [-3.2480],\n",
      "        [ 3.9812],\n",
      "        [ 3.1587],\n",
      "        [13.9911],\n",
      "        [-4.7996]])\n",
      "tensor([[-0.4287, -1.0515,  1.5868],\n",
      "        [-0.6831, -1.3444,  0.7226],\n",
      "        [-0.9312,  0.1243, -2.5361],\n",
      "        [-0.8179, -0.1450,  0.8819],\n",
      "        [ 1.3584,  0.7599,  1.0950],\n",
      "        [-1.0282,  0.1608,  1.6084],\n",
      "        [ 0.1204, -1.4182, -0.8058],\n",
      "        [ 0.3902, -0.0726,  0.8962],\n",
      "        [-0.3914,  0.4293, -0.3035],\n",
      "        [ 0.2206,  0.0356,  0.9676]]) tensor([[ 19.6037],\n",
      "        [ 13.1823],\n",
      "        [-18.3699],\n",
      "        [ 10.1248],\n",
      "        [ 13.1124],\n",
      "        [ 14.4471],\n",
      "        [  2.8298],\n",
      "        [ 12.4058],\n",
      "        [ -0.4827],\n",
      "        [ 12.2632]])\n",
      "tensor([[-0.2509,  0.5528,  0.7334],\n",
      "        [-0.1186, -0.4357, -2.3129],\n",
      "        [-0.6067,  0.4742, -0.2057],\n",
      "        [ 0.3560,  1.2507,  1.4536],\n",
      "        [-0.2948, -0.7009,  0.0987],\n",
      "        [ 1.2678, -0.4494, -0.7104],\n",
      "        [ 1.2031,  0.1176,  1.3345],\n",
      "        [-0.1468, -0.1198, -0.5905],\n",
      "        [ 0.6995, -0.6604, -0.2339],\n",
      "        [-0.3794, -0.4446,  0.0324]]) tensor([[  7.6824],\n",
      "        [-13.0645],\n",
      "        [ -0.2664],\n",
      "        [ 12.2870],\n",
      "        [  6.7911],\n",
      "        [  2.5659],\n",
      "        [ 16.8766],\n",
      "        [ -0.4094],\n",
      "        [  5.9791],\n",
      "        [  5.2056]])\n",
      "tensor([[ 0.0637,  0.9555,  0.8647],\n",
      "        [-0.0395, -0.2527,  1.5706],\n",
      "        [-1.1948, -0.1912, -0.7126],\n",
      "        [ 0.2533, -0.2445, -0.1563],\n",
      "        [ 0.6025, -0.1846,  0.1749],\n",
      "        [-1.0694,  1.4796,  0.3807],\n",
      "        [-2.2584,  0.8198,  0.6665],\n",
      "        [-0.0724, -0.3815,  0.5691],\n",
      "        [ 0.1155, -0.7425,  1.1164],\n",
      "        [ 0.4303,  0.3648, -1.9091]]) tensor([[  7.9938],\n",
      "        [ 17.5319],\n",
      "        [ -3.2405],\n",
      "        [  4.2830],\n",
      "        [  7.4568],\n",
      "        [  0.0972],\n",
      "        [  2.2279],\n",
      "        [  9.9170],\n",
      "        [ 15.8796],\n",
      "        [-11.4487]])\n",
      "tensor([[-0.4047,  0.8541,  0.1564],\n",
      "        [ 2.1414, -0.2648, -0.6813],\n",
      "        [-0.7074,  1.1390, -0.6223],\n",
      "        [-1.1534, -0.7581, -0.7470],\n",
      "        [-0.1900,  0.7819, -0.6189],\n",
      "        [-0.7098,  0.0484,  1.5891],\n",
      "        [-1.0647,  2.4139,  2.5714],\n",
      "        [ 0.5447, -0.3679, -0.8466],\n",
      "        [-1.5126,  1.2967,  0.5601],\n",
      "        [-0.7663, -2.7803, -0.7306]]) tensor([[ 1.7501],\n",
      "        [ 3.9263],\n",
      "        [-6.0586],\n",
      "        [-1.5294],\n",
      "        [-3.7915],\n",
      "        [15.3264],\n",
      "        [14.4185],\n",
      "        [-0.2370],\n",
      "        [ 1.2632],\n",
      "        [ 6.2821]])\n",
      "tensor([[-1.1384, -1.8007, -0.7034],\n",
      "        [ 0.7621, -0.2465, -0.6547],\n",
      "        [-0.3193,  0.4677,  0.2437],\n",
      "        [-0.1642,  0.3419, -0.0503],\n",
      "        [ 1.4810, -1.1702,  0.2158],\n",
      "        [-0.1971, -1.1044, -0.3540],\n",
      "        [ 0.9142, -0.7095,  0.7310],\n",
      "        [-0.6094,  0.5727,  0.7100],\n",
      "        [ 1.8813,  0.0274,  0.6926],\n",
      "        [ 0.6984, -1.1070, -0.7711]]) tensor([[ 2.4130],\n",
      "        [ 1.3092],\n",
      "        [ 3.9259],\n",
      "        [ 2.3144],\n",
      "        [12.8764],\n",
      "        [ 4.7433],\n",
      "        [14.2932],\n",
      "        [ 6.7127],\n",
      "        [13.3972],\n",
      "        [ 3.1917]])\n",
      "tensor([[ 1.2876, -0.4435, -0.8388],\n",
      "        [ 0.9830, -0.3548,  0.2992],\n",
      "        [-0.4081,  1.4496,  0.2930],\n",
      "        [-1.4879,  0.0875,  0.5738],\n",
      "        [-0.3515,  1.5633, -0.4104],\n",
      "        [-1.6272,  0.9667,  0.6200],\n",
      "        [-0.3656,  0.1164,  0.0806],\n",
      "        [-0.1476, -0.3553, -1.2258],\n",
      "        [-3.0419, -0.5725,  0.3231],\n",
      "        [ 0.3460, -0.2464, -0.3390]]) tensor([[ 1.5833],\n",
      "        [ 9.7654],\n",
      "        [ 0.8140],\n",
      "        [ 5.5400],\n",
      "        [-5.0861],\n",
      "        [ 2.6139],\n",
      "        [ 3.7202],\n",
      "        [-4.6904],\n",
      "        [ 2.6502],\n",
      "        [ 3.0353]])\n",
      "tensor([[ 5.8490e-04, -1.7101e+00, -8.5858e-02],\n",
      "        [-2.1055e+00, -2.4145e-01,  1.3545e+00],\n",
      "        [-7.9333e-01, -1.0587e+00,  2.6945e+00],\n",
      "        [ 1.8524e-01, -1.0019e-01,  5.2422e-01],\n",
      "        [-9.6360e-01, -1.2454e-01, -9.6343e-02],\n",
      "        [-5.1510e-03,  4.0147e-01,  9.0258e-01],\n",
      "        [ 9.5818e-01,  1.4259e-01, -1.3131e-01],\n",
      "        [-1.0893e+00, -3.9959e-01, -6.1155e-01],\n",
      "        [-1.8723e+00,  9.5141e-01,  7.9847e-01],\n",
      "        [-3.7345e-01, -8.5919e-01, -2.2240e+00]]) tensor([[  9.3306],\n",
      "        [ 11.6395],\n",
      "        [ 27.7588],\n",
      "        [  9.1016],\n",
      "        [  1.9359],\n",
      "        [ 10.0535],\n",
      "        [  4.5886],\n",
      "        [ -1.4964],\n",
      "        [  3.6027],\n",
      "        [-11.4222]])\n",
      "tensor([[ 2.2450,  1.5468,  0.0515],\n",
      "        [ 1.5952, -0.8597, -0.9905],\n",
      "        [ 0.8008,  0.0192,  0.5114],\n",
      "        [-0.3043, -0.7317, -0.0999],\n",
      "        [-0.0835, -0.5211,  1.8366],\n",
      "        [ 0.4598, -0.2360,  0.6652],\n",
      "        [ 0.8500, -2.0362,  0.1138],\n",
      "        [-0.1691, -0.2734,  0.3874],\n",
      "        [-0.6521, -0.9910,  0.3111],\n",
      "        [-0.4683, -0.2815, -0.8198]]) tensor([[ 3.8444],\n",
      "        [ 2.4136],\n",
      "        [ 9.8129],\n",
      "        [ 5.2502],\n",
      "        [20.4946],\n",
      "        [11.2377],\n",
      "        [13.7238],\n",
      "        [ 7.8981],\n",
      "        [ 8.7386],\n",
      "        [-2.3214]])\n",
      "tensor([[ 7.5542e-01,  2.4922e-01,  1.2086e+00],\n",
      "        [ 2.4825e-03,  9.2762e-01,  1.0170e+00],\n",
      "        [-2.5808e-01, -4.4318e-01, -1.7971e+00],\n",
      "        [-5.9316e-01, -1.7038e-01, -1.2256e+00],\n",
      "        [ 1.9226e+00, -5.8302e-02, -7.6841e-01],\n",
      "        [ 7.0318e-01,  2.0907e+00, -1.0766e+00],\n",
      "        [-1.0012e+00,  8.5021e-01, -7.3232e-02],\n",
      "        [-4.8135e-01, -1.8187e-01,  3.8130e-01],\n",
      "        [ 4.4068e-01, -6.4159e-01,  2.3159e-01],\n",
      "        [ 2.7041e+00, -5.5763e-01,  1.9745e+00]]) tensor([[ 14.5409],\n",
      "        [  9.2077],\n",
      "        [ -9.1954],\n",
      "        [ -6.2139],\n",
      "        [  2.1030],\n",
      "        [-10.1216],\n",
      "        [ -1.2825],\n",
      "        [  6.9069],\n",
      "        [  9.1095],\n",
      "        [ 27.3003]])\n",
      "tensor([[-0.0195, -0.4283,  1.0456],\n",
      "        [-0.3837, -0.1753,  1.4855],\n",
      "        [-0.3244, -1.0369, -0.9441],\n",
      "        [-0.4661,  0.2242, -1.0702],\n",
      "        [ 0.1224, -0.9048, -1.1185],\n",
      "        [-2.0271, -0.7312,  0.6901],\n",
      "        [ 0.3936, -1.1118, -0.7773],\n",
      "        [ 0.6034, -1.1041, -0.5871],\n",
      "        [ 0.7895, -0.9869,  1.7507],\n",
      "        [ 1.9826,  0.3625, -1.5953]]) tensor([[13.9866],\n",
      "        [15.9087],\n",
      "        [-0.4855],\n",
      "        [-6.0347],\n",
      "        [-1.4180],\n",
      "        [ 8.1509],\n",
      "        [ 2.5377],\n",
      "        [ 4.4654],\n",
      "        [23.1270],\n",
      "        [-5.8374]])\n",
      "tensor([[-0.0026,  0.2194, -1.2718],\n",
      "        [ 0.4707, -0.8697,  1.8624],\n",
      "        [-0.1564, -0.6858,  0.5211],\n",
      "        [-1.5075, -0.6363,  0.3202],\n",
      "        [-0.8426, -0.2772,  2.4178],\n",
      "        [-0.6733, -1.9436,  0.7270],\n",
      "        [-1.4194, -0.2539, -0.6016],\n",
      "        [-0.5195, -0.4871,  2.1789],\n",
      "        [ 1.4578,  0.5553,  0.9995],\n",
      "        [-0.9894, -0.0106, -0.9349]]) tensor([[-6.7347],\n",
      "        [22.9900],\n",
      "        [10.3875],\n",
      "        [ 5.9074],\n",
      "        [22.8160],\n",
      "        [15.2754],\n",
      "        [-2.5873],\n",
      "        [22.2411],\n",
      "        [13.2381],\n",
      "        [-5.2122]])\n",
      "tensor([[ 0.7107, -0.8830, -0.0138],\n",
      "        [ 1.2686,  1.1020,  0.0142],\n",
      "        [-0.4131, -1.3635,  0.4767],\n",
      "        [-1.3094, -0.6508, -2.2014],\n",
      "        [-0.7398, -0.9228, -0.0154],\n",
      "        [-1.8141, -0.6128, -0.6721],\n",
      "        [-1.5086,  0.9417, -1.3663],\n",
      "        [-2.3768, -1.0600, -1.4407],\n",
      "        [-0.0818, -0.8098, -0.0622],\n",
      "        [ 1.7185, -0.2307, -1.7303]]) tensor([[  8.5011],\n",
      "        [  3.0919],\n",
      "        [ 11.8240],\n",
      "        [-13.8117],\n",
      "        [  5.7387],\n",
      "        [ -2.7219],\n",
      "        [-12.9538],\n",
      "        [ -8.4739],\n",
      "        [  6.2858],\n",
      "        [ -5.4091]])\n",
      "tensor([[-0.3627, -0.7889, -0.2781],\n",
      "        [ 0.3623, -0.2260, -1.9572],\n",
      "        [ 0.5169,  0.1527,  0.0618],\n",
      "        [-0.1449, -0.6518,  0.2778],\n",
      "        [-0.8075, -1.2031,  0.2563],\n",
      "        [-0.6195, -1.3214, -0.7163],\n",
      "        [ 0.2357,  1.0681,  0.5348],\n",
      "        [ 1.0327, -0.2838,  0.6717],\n",
      "        [ 0.8293, -0.0077, -1.1041],\n",
      "        [-0.6747,  1.2690, -0.3365]]) tensor([[ 3.9257],\n",
      "        [-9.9643],\n",
      "        [ 5.2242],\n",
      "        [ 8.3619],\n",
      "        [ 8.7598],\n",
      "        [ 1.7179],\n",
      "        [ 5.3538],\n",
      "        [12.6069],\n",
      "        [-2.9623],\n",
      "        [-4.1435]])\n",
      "tensor([[-0.8229,  1.2191,  0.9396],\n",
      "        [-1.0738,  0.6730,  1.2564],\n",
      "        [ 1.1382, -1.2100, -2.1938],\n",
      "        [-0.8113,  1.4890,  0.3087],\n",
      "        [-1.0292,  0.1944,  0.8901],\n",
      "        [ 0.3270, -0.1537,  0.0325],\n",
      "        [-0.7123, -0.5487,  0.6221],\n",
      "        [ 0.9147,  0.9078, -0.9660],\n",
      "        [-2.0977, -1.0385,  0.1553],\n",
      "        [ 0.9085,  1.0364, -0.2130]]) tensor([[ 5.9210],\n",
      "        [ 9.8150],\n",
      "        [-6.9614],\n",
      "        [-0.0242],\n",
      "        [ 8.5911],\n",
      "        [ 5.6407],\n",
      "        [ 9.6203],\n",
      "        [-4.7865],\n",
      "        [ 4.7831],\n",
      "        [ 0.7773]])\n",
      "tensor([[ 0.7678,  0.7452,  0.0750],\n",
      "        [-0.1140, -1.9913, -0.3476],\n",
      "        [-2.8362, -0.1732, -0.1891],\n",
      "        [-0.6643, -0.3045,  1.0186],\n",
      "        [ 1.1135, -0.6703, -0.3019],\n",
      "        [ 0.0836, -0.1347, -0.1848],\n",
      "        [ 0.5571, -1.7937,  0.0985],\n",
      "        [-0.2228, -0.0589, -2.9727],\n",
      "        [ 0.4507, -0.6617, -0.8034],\n",
      "        [-0.6911,  0.4576, -0.3383]]) tensor([[  3.7777],\n",
      "        [  7.9667],\n",
      "        [ -2.3967],\n",
      "        [ 12.0521],\n",
      "        [  6.2885],\n",
      "        [  3.3456],\n",
      "        [ 12.2121],\n",
      "        [-19.8362],\n",
      "        [  0.9200],\n",
      "        [ -1.4532]])\n",
      "tensor([[ 0.5851, -0.2099,  0.2435],\n",
      "        [-1.5283,  0.8705, -0.2198],\n",
      "        [-0.0970,  1.3590,  1.6752],\n",
      "        [-0.7315, -0.5952,  0.8199],\n",
      "        [-0.3157,  0.4606,  0.1937],\n",
      "        [ 0.9757,  1.0800,  0.9089],\n",
      "        [-1.2072,  0.3574,  0.0945],\n",
      "        [-0.8306,  1.4800, -0.1332],\n",
      "        [ 0.4866, -1.0282,  0.5558],\n",
      "        [ 1.1437, -0.5266, -1.4846]]) tensor([[ 8.0385],\n",
      "        [-3.5721],\n",
      "        [12.7913],\n",
      "        [11.3030],\n",
      "        [ 3.5537],\n",
      "        [ 9.7252],\n",
      "        [ 1.3295],\n",
      "        [-3.5573],\n",
      "        [13.1245],\n",
      "        [-3.5953]])\n",
      "tensor([[-1.6342,  0.6155, -1.1606],\n",
      "        [ 0.8284, -1.8045,  0.2471],\n",
      "        [ 0.5624, -0.2607,  1.0468],\n",
      "        [-2.4674, -1.1637,  0.6043],\n",
      "        [ 1.3198,  0.1282,  0.6429],\n",
      "        [ 0.5258, -0.7709, -1.2453],\n",
      "        [-0.4742, -0.6537,  2.2024],\n",
      "        [ 0.2416, -1.8770, -0.3502],\n",
      "        [-1.0125, -1.1518,  0.2320],\n",
      "        [ 1.8493, -1.0156, -0.6740]]) tensor([[-10.4500],\n",
      "        [ 13.9530],\n",
      "        [ 14.5819],\n",
      "        [  8.0398],\n",
      "        [ 11.5515],\n",
      "        [ -2.0728],\n",
      "        [ 23.0814],\n",
      "        [  8.2554],\n",
      "        [  7.9309],\n",
      "        [  5.9665]])\n",
      "tensor([[ 1.6194,  0.0724, -1.2996],\n",
      "        [-0.4149, -0.1029,  0.3311],\n",
      "        [ 0.1736,  0.5772,  1.7547],\n",
      "        [ 1.4521,  0.3786, -1.7527],\n",
      "        [-1.6284, -0.8352, -0.4954],\n",
      "        [ 2.0837,  1.0308,  0.5821],\n",
      "        [-0.0867,  1.6088, -0.3956],\n",
      "        [-0.4928, -0.1474, -0.3900],\n",
      "        [-0.3535, -1.0530, -0.2511],\n",
      "        [ 1.3949,  1.4783, -0.2902]]) tensor([[-3.1926],\n",
      "        [ 6.3695],\n",
      "        [16.6276],\n",
      "        [-8.2063],\n",
      "        [-0.1893],\n",
      "        [ 9.5144],\n",
      "        [-4.6239],\n",
      "        [ 0.6038],\n",
      "        [ 5.0582],\n",
      "        [-0.3579]])\n",
      "tensor([[-3.8375e-01,  1.1288e+00, -1.5657e+00],\n",
      "        [-2.1110e-01, -1.0304e+00, -7.1466e-01],\n",
      "        [-9.4727e-01, -9.8433e-02, -8.2606e-01],\n",
      "        [-2.6887e-01, -1.2984e+00, -1.2379e+00],\n",
      "        [-9.5756e-01, -1.2810e-03, -2.4714e-01],\n",
      "        [-8.7920e-01,  7.3020e-01, -1.7431e+00],\n",
      "        [ 3.0207e+00, -7.9059e-01, -9.5463e-01],\n",
      "        [-1.3361e+00,  4.4014e-01, -1.4849e-01],\n",
      "        [-3.8489e-01,  1.9593e-01, -9.5708e-01],\n",
      "        [-3.8739e-01,  3.5684e-01,  7.5488e-02]]) tensor([[-12.9355],\n",
      "        [  1.5739],\n",
      "        [ -3.9558],\n",
      "        [ -1.8293],\n",
      "        [  0.3050],\n",
      "        [-13.9723],\n",
      "        [  5.2899],\n",
      "        [ -1.1690],\n",
      "        [ -4.8961],\n",
      "        [  2.8244]])\n",
      "tensor([[ 0.8630,  1.9825, -0.8582],\n",
      "        [ 0.4567, -2.6020, -0.1510],\n",
      "        [-0.1274,  1.7780, -0.3435],\n",
      "        [-0.6882, -0.6967,  0.9150],\n",
      "        [-0.4101,  1.0817,  0.2343],\n",
      "        [-1.3742, -0.9370,  0.4412],\n",
      "        [-0.4546, -0.7635, -1.5435],\n",
      "        [ 0.7985,  0.2472, -0.9533],\n",
      "        [ 0.0429,  0.1112,  0.1073],\n",
      "        [-0.8700, -0.4843, -0.4462]]) tensor([[-7.6775],\n",
      "        [12.7552],\n",
      "        [-4.8487],\n",
      "        [12.5073],\n",
      "        [ 1.5703],\n",
      "        [ 8.1576],\n",
      "        [-6.4629],\n",
      "        [-2.6627],\n",
      "        [ 4.7405],\n",
      "        [ 0.5405]])\n",
      "tensor([[-0.0965,  0.1832, -2.4420],\n",
      "        [-0.3330, -0.9915,  0.2304],\n",
      "        [-0.5471,  1.8155,  1.8667],\n",
      "        [-0.7687,  1.4894, -1.0890],\n",
      "        [-0.3558, -1.9699, -0.3038],\n",
      "        [-1.0644,  1.5036, -0.6524],\n",
      "        [-0.4679,  0.5420, -0.3888],\n",
      "        [ 0.3714,  0.0386, -0.0444],\n",
      "        [-0.9335, -0.5745, -0.0233],\n",
      "        [-1.1873, -0.0163, -0.7301]]) tensor([[-16.1497],\n",
      "        [  8.7492],\n",
      "        [ 11.8677],\n",
      "        [-11.1274],\n",
      "        [  7.7569],\n",
      "        [ -8.2721],\n",
      "        [ -1.6885],\n",
      "        [  4.4612],\n",
      "        [  4.0872],\n",
      "        [ -3.9580]])\n",
      "tensor([[ 0.6647, -0.3757,  0.5384],\n",
      "        [-1.6809,  0.1728,  0.9434],\n",
      "        [-1.2153,  1.7381,  0.1913],\n",
      "        [-1.0803,  0.6017, -0.1431],\n",
      "        [ 0.4330,  0.0955,  0.4198],\n",
      "        [-1.4286, -1.4754,  0.1529],\n",
      "        [ 0.3475,  1.6447,  1.5188],\n",
      "        [-0.9650, -0.9567, -0.0065],\n",
      "        [-0.0782,  0.1703, -0.5905],\n",
      "        [ 1.5020,  0.3749,  1.1562]]) tensor([[11.1349],\n",
      "        [ 7.8064],\n",
      "        [-2.5995],\n",
      "        [-1.1386],\n",
      "        [ 8.0957],\n",
      "        [ 7.5792],\n",
      "        [11.4427],\n",
      "        [ 5.4745],\n",
      "        [-1.2604],\n",
      "        [15.1767]])\n",
      "tensor([[-1.9181, -1.0973,  0.9480],\n",
      "        [-0.7305, -0.4470, -0.8150],\n",
      "        [-0.1584,  1.3733,  0.7763],\n",
      "        [-1.6823,  1.3853,  0.3085],\n",
      "        [-1.0241,  0.4386, -0.6645],\n",
      "        [ 0.5151,  1.0274,  0.4273],\n",
      "        [-0.2103,  1.6232,  0.0479],\n",
      "        [-0.5485, -1.8946, -0.4258],\n",
      "        [-1.0137,  1.4076,  1.2818],\n",
      "        [-1.6385, -1.2969,  0.7957]]) tensor([[11.6754],\n",
      "        [-2.2584],\n",
      "        [ 5.4357],\n",
      "        [-1.4119],\n",
      "        [-4.6690],\n",
      "        [ 5.1462],\n",
      "        [-1.3636],\n",
      "        [ 6.1252],\n",
      "        [ 7.6176],\n",
      "        [11.7080]])\n",
      "tensor([[-1.3274,  0.5009,  1.2001],\n",
      "        [ 0.1438, -0.1762,  1.9818],\n",
      "        [ 0.5403, -0.3681,  1.3613],\n",
      "        [-0.1240, -1.2716, -0.3126],\n",
      "        [-0.0895, -0.1733, -1.2110],\n",
      "        [-0.2098,  0.1140, -0.6935],\n",
      "        [-1.0612,  1.4590, -1.2231],\n",
      "        [ 0.0116, -0.1396, -0.6942],\n",
      "        [-1.1700,  0.0079, -1.2027],\n",
      "        [-1.4159, -0.3834, -1.5050]]) tensor([[  9.4479],\n",
      "        [ 20.9214],\n",
      "        [ 17.4292],\n",
      "        [  5.7858],\n",
      "        [ -5.0693],\n",
      "        [ -2.1755],\n",
      "        [-12.6645],\n",
      "        [ -0.8556],\n",
      "        [ -7.7826],\n",
      "        [ -9.3653]])\n",
      "tensor([[ 0.6301, -0.2066, -0.8188],\n",
      "        [ 0.3929, -1.0934,  0.9171],\n",
      "        [ 0.5664, -1.1062,  2.2176],\n",
      "        [-1.2687, -1.6847, -0.7607],\n",
      "        [-0.4264,  1.0771, -0.7583],\n",
      "        [-2.1029,  1.2002,  1.7610],\n",
      "        [-0.0244,  0.6464, -0.9014],\n",
      "        [-0.6036,  2.0689, -0.4678],\n",
      "        [-0.4749, -0.8230, -0.5483],\n",
      "        [-1.1360, -1.4017, -0.4835]]) tensor([[-0.3895],\n",
      "        [16.0225],\n",
      "        [26.8453],\n",
      "        [ 1.2933],\n",
      "        [-6.3646],\n",
      "        [10.0031],\n",
      "        [-5.2613],\n",
      "        [-7.7882],\n",
      "        [ 1.6558],\n",
      "        [ 2.8293]])\n",
      "tensor([[ 0.2296,  1.8124,  1.8126],\n",
      "        [ 2.5329,  0.0260,  0.3143],\n",
      "        [ 1.2400, -1.0311, -0.1978],\n",
      "        [-1.1193,  1.2649,  0.0908],\n",
      "        [ 1.6209,  0.1685,  0.7907],\n",
      "        [ 0.7862,  0.6970, -0.4496],\n",
      "        [-1.4676,  1.2253,  0.2221],\n",
      "        [-0.6475,  1.1390, -0.0269],\n",
      "        [-1.3647, -0.8628,  0.6844],\n",
      "        [ 0.3387, -0.6581, -0.8973]]) tensor([[12.9809],\n",
      "        [11.6982],\n",
      "        [ 8.6174],\n",
      "        [-1.6107],\n",
      "        [13.1887],\n",
      "        [-0.1944],\n",
      "        [-1.1225],\n",
      "        [-1.1837],\n",
      "        [ 9.8888],\n",
      "        [-0.0535]])\n",
      "tensor([[ 0.2974, -0.7291, -0.8498],\n",
      "        [ 1.4347,  1.9750,  0.6571],\n",
      "        [-0.6950, -2.1946,  0.9224],\n",
      "        [ 0.4256, -0.3278, -0.6559],\n",
      "        [ 0.5237, -1.1928,  0.6213],\n",
      "        [-0.2502, -0.4247, -1.6591],\n",
      "        [-0.6569,  0.5287,  0.2565],\n",
      "        [-1.1186,  0.2455,  0.6715],\n",
      "        [ 0.3782,  0.3269, -0.3198],\n",
      "        [ 0.0835,  1.4248,  1.2783]]) tensor([[ 0.4878],\n",
      "        [ 5.6195],\n",
      "        [17.6693],\n",
      "        [ 0.9288],\n",
      "        [14.2778],\n",
      "        [-8.1292],\n",
      "        [ 3.1365],\n",
      "        [ 6.5057],\n",
      "        [ 1.2844],\n",
      "        [ 9.7513]])\n",
      "tensor([[ 1.0017, -1.2952,  0.6431],\n",
      "        [ 1.3081, -0.2684, -0.1122],\n",
      "        [ 0.4180, -0.7710, -0.2470],\n",
      "        [-2.4392,  0.4406, -0.4313],\n",
      "        [ 0.8062,  0.3151,  0.3668],\n",
      "        [-1.1032, -0.6369, -1.1600],\n",
      "        [-0.3867,  1.8489,  0.0673],\n",
      "        [ 0.1449, -0.1465, -0.7277],\n",
      "        [-0.0530, -0.5914,  0.5547],\n",
      "        [ 1.1833,  0.1791, -1.4324]]) tensor([[15.7537],\n",
      "        [ 6.8447],\n",
      "        [ 5.6829],\n",
      "        [-5.6076],\n",
      "        [ 7.6580],\n",
      "        [-5.1135],\n",
      "        [-2.3110],\n",
      "        [-0.8454],\n",
      "        [10.5462],\n",
      "        [-5.5085]])\n",
      "tensor([[-0.5180,  0.3735, -0.4040],\n",
      "        [ 1.6765, -0.3050, -1.8199],\n",
      "        [ 0.7122,  1.2955, -0.2143],\n",
      "        [-0.1397,  0.3415,  1.2242],\n",
      "        [-0.5856,  1.2797,  0.3098],\n",
      "        [-0.4782, -0.4892,  0.4768],\n",
      "        [-0.5215, -0.2489,  0.6584],\n",
      "        [-1.0731,  2.2543,  2.0251],\n",
      "        [ 1.8253, -0.7602,  0.8978],\n",
      "        [ 1.5446,  0.8410, -0.2695]]) tensor([[-1.3527],\n",
      "        [-5.9671],\n",
      "        [-0.4882],\n",
      "        [12.5607],\n",
      "        [ 1.1463],\n",
      "        [ 8.7268],\n",
      "        [ 9.2673],\n",
      "        [10.5888],\n",
      "        [17.6255],\n",
      "        [ 2.2582]])\n",
      "tensor([[ 0.6145, -0.0135,  1.5963],\n",
      "        [ 1.0146,  1.7659,  1.1342],\n",
      "        [-1.4429,  0.0671, -0.5700],\n",
      "        [-0.1100, -1.1715, -0.4825],\n",
      "        [ 0.6540,  0.7789,  1.3744],\n",
      "        [-0.2217, -0.0199,  0.8010],\n",
      "        [-0.1680,  0.0147,  1.0644],\n",
      "        [-0.3728, -1.0428, -0.3453],\n",
      "        [ 1.1870, -1.2001, -0.3714],\n",
      "        [-0.4620,  1.0929, -0.1754]]) tensor([[18.2269],\n",
      "        [ 9.2998],\n",
      "        [-3.4718],\n",
      "        [ 4.1105],\n",
      "        [13.8446],\n",
      "        [10.2252],\n",
      "        [12.3357],\n",
      "        [ 4.2296],\n",
      "        [ 7.6910],\n",
      "        [-1.8506]])\n",
      "tensor([[ 0.1539,  0.6119,  0.6964],\n",
      "        [ 1.2464,  0.1492,  0.8994],\n",
      "        [ 0.8979,  0.6682,  1.0306],\n",
      "        [ 0.5906, -0.1517,  1.8420],\n",
      "        [ 0.5383, -0.7994,  1.5276],\n",
      "        [-0.1833, -1.0287, -2.0343],\n",
      "        [ 0.9497,  1.1195, -0.1450],\n",
      "        [-0.2452, -1.2450,  1.3162],\n",
      "        [-0.2865,  0.1276, -1.2871],\n",
      "        [-0.4064, -1.9217, -0.0651]]) tensor([[ 7.9822],\n",
      "        [13.3979],\n",
      "        [11.9603],\n",
      "        [20.6336],\n",
      "        [20.2295],\n",
      "        [-8.9416],\n",
      "        [ 1.1254],\n",
      "        [18.4836],\n",
      "        [-7.0857],\n",
      "        [ 9.4036]])\n",
      "tensor([[-0.5356,  2.0234, -0.8821],\n",
      "        [-0.5172, -0.4667,  0.3174],\n",
      "        [-0.9279, -1.3752, -1.2381],\n",
      "        [-2.0002,  1.7952, -0.6583],\n",
      "        [-1.1368,  0.6762, -0.6175],\n",
      "        [ 0.3750, -0.9197,  0.5567],\n",
      "        [-0.0716, -0.1249,  1.6969],\n",
      "        [ 1.7533, -1.0445, -0.9420],\n",
      "        [ 0.5182, -0.5561, -0.2598],\n",
      "        [-2.3428,  0.1303, -0.6198]]) tensor([[-10.7981],\n",
      "        [  7.2893],\n",
      "        [ -2.8872],\n",
      "        [-11.1787],\n",
      "        [ -5.3066],\n",
      "        [ 12.5186],\n",
      "        [ 18.0591],\n",
      "        [  3.7221],\n",
      "        [  5.0433],\n",
      "        [ -5.8874]])\n",
      "tensor([[ 0.0161, -1.0206,  1.3631],\n",
      "        [-0.6180,  0.7542,  1.2961],\n",
      "        [-0.1105,  1.0267, -0.4343],\n",
      "        [ 0.4494, -1.2456, -1.0425],\n",
      "        [-1.3056, -0.1987,  0.8365],\n",
      "        [ 1.3463,  1.5325, -1.1034],\n",
      "        [ 0.6284, -1.6585,  1.9343],\n",
      "        [-0.8610,  0.5122,  0.1495],\n",
      "        [-0.1034, -0.4745,  1.2901],\n",
      "        [ 0.3830, -1.4006,  0.8716]]) tensor([[18.6160],\n",
      "        [10.7639],\n",
      "        [-2.9936],\n",
      "        [ 0.9866],\n",
      "        [ 8.9644],\n",
      "        [-7.1480],\n",
      "        [26.5749],\n",
      "        [ 1.9287],\n",
      "        [15.9445],\n",
      "        [16.6982]])\n",
      "tensor([[-2.0478,  0.6983,  0.3734],\n",
      "        [-0.9496,  0.5585,  0.3975],\n",
      "        [-0.3877, -0.4861,  0.2872],\n",
      "        [-0.8314,  0.5523,  0.9527],\n",
      "        [ 2.2235,  0.8915, -0.2811],\n",
      "        [-1.4511, -0.0236, -0.5836],\n",
      "        [-0.7801,  0.3239, -0.6370],\n",
      "        [ 0.7107, -0.4503,  0.2929],\n",
      "        [-1.3945, -0.6339, -0.5454],\n",
      "        [ 0.7259, -0.7746, -1.6369]]) tensor([[ 0.7057],\n",
      "        [ 3.5724],\n",
      "        [ 7.3836],\n",
      "        [ 8.2586],\n",
      "        [ 3.3658],\n",
      "        [-3.2893],\n",
      "        [-3.5486],\n",
      "        [ 9.4778],\n",
      "        [-0.7768],\n",
      "        [-4.8124]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "20124507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0150],\n",
      "        [-0.0072],\n",
      "        [-0.0017],\n",
      "        [ 0.0181],\n",
      "        [-0.0161],\n",
      "        [ 0.0237],\n",
      "        [-0.0078],\n",
      "        [-0.0154],\n",
      "        [ 0.0058],\n",
      "        [-0.0037]], grad_fn=<AddmmBackward0>) tensor([[-0.3895],\n",
      "        [ 8.0897],\n",
      "        [-1.3057],\n",
      "        [ 2.1030],\n",
      "        [10.1771],\n",
      "        [ 1.4505],\n",
      "        [ 1.3295],\n",
      "        [ 5.2976],\n",
      "        [ 5.6724],\n",
      "        [15.4548]])\n",
      "tensor([[-0.0250],\n",
      "        [-0.0084],\n",
      "        [-0.0066],\n",
      "        [ 0.0022],\n",
      "        [ 0.0204],\n",
      "        [-0.0006],\n",
      "        [ 0.0040],\n",
      "        [ 0.0150],\n",
      "        [ 0.0020],\n",
      "        [-0.0013]], grad_fn=<AddmmBackward0>) tensor([[  1.4944],\n",
      "        [ -6.1937],\n",
      "        [  3.5537],\n",
      "        [ 11.1678],\n",
      "        [ -5.6819],\n",
      "        [  8.3619],\n",
      "        [  8.1229],\n",
      "        [-18.5283],\n",
      "        [  4.3992],\n",
      "        [  3.6172]])\n",
      "tensor([[ 0.0029],\n",
      "        [-0.0060],\n",
      "        [-0.0235],\n",
      "        [ 0.0039],\n",
      "        [-0.0224],\n",
      "        [-0.0015],\n",
      "        [ 0.0015],\n",
      "        [ 0.0168],\n",
      "        [ 0.0085],\n",
      "        [-0.0055]], grad_fn=<AddmmBackward0>) tensor([[  2.1722],\n",
      "        [ 11.9224],\n",
      "        [ 25.1375],\n",
      "        [  1.2844],\n",
      "        [ 26.8453],\n",
      "        [ -9.7200],\n",
      "        [  9.7654],\n",
      "        [-13.9723],\n",
      "        [-10.3533],\n",
      "        [  8.7268]])\n",
      "tensor([[ 0.0184],\n",
      "        [-0.0100],\n",
      "        [ 0.0048],\n",
      "        [-0.0077],\n",
      "        [ 0.0282],\n",
      "        [-0.0091],\n",
      "        [-0.0280],\n",
      "        [ 0.0496],\n",
      "        [ 0.0410],\n",
      "        [-0.0024]], grad_fn=<AddmmBackward0>) tensor([[ -9.5076],\n",
      "        [ 11.0782],\n",
      "        [  4.1583],\n",
      "        [ -3.3824],\n",
      "        [ -2.9516],\n",
      "        [ 21.1225],\n",
      "        [ 18.8951],\n",
      "        [-14.6615],\n",
      "        [-19.8362],\n",
      "        [ -5.0026]])\n",
      "tensor([[ 0.0130],\n",
      "        [ 0.0012],\n",
      "        [ 0.0021],\n",
      "        [ 0.0050],\n",
      "        [-0.0061],\n",
      "        [-0.0157],\n",
      "        [-0.0055],\n",
      "        [ 0.0020],\n",
      "        [-0.0123],\n",
      "        [ 0.0077]], grad_fn=<AddmmBackward0>) tensor([[ 1.8053],\n",
      "        [-5.0767],\n",
      "        [-1.3255],\n",
      "        [-0.1944],\n",
      "        [ 9.2119],\n",
      "        [23.1270],\n",
      "        [ 6.3695],\n",
      "        [10.4912],\n",
      "        [-0.9637],\n",
      "        [-6.2974]])\n",
      "tensor([[-0.0313],\n",
      "        [ 0.0068],\n",
      "        [-0.0196],\n",
      "        [ 0.0045],\n",
      "        [ 0.0014],\n",
      "        [-0.0129],\n",
      "        [ 0.0121],\n",
      "        [ 0.0154],\n",
      "        [ 0.0076],\n",
      "        [-0.0137]], grad_fn=<AddmmBackward0>) tensor([[ 19.7876],\n",
      "        [ -1.6415],\n",
      "        [ -4.7996],\n",
      "        [-10.2745],\n",
      "        [  9.3693],\n",
      "        [  3.6854],\n",
      "        [  2.7159],\n",
      "        [ -1.4767],\n",
      "        [  1.1391],\n",
      "        [ -8.3722]])\n",
      "tensor([[-0.0055],\n",
      "        [ 0.0121],\n",
      "        [ 0.0227],\n",
      "        [-0.0006],\n",
      "        [ 0.0087],\n",
      "        [ 0.0027],\n",
      "        [-0.0036],\n",
      "        [ 0.0055],\n",
      "        [-0.0173],\n",
      "        [-0.0011]], grad_fn=<AddmmBackward0>) tensor([[-5.6076],\n",
      "        [-5.9973],\n",
      "        [-1.5405],\n",
      "        [-1.0621],\n",
      "        [-6.5180],\n",
      "        [ 3.1732],\n",
      "        [ 7.2893],\n",
      "        [ 2.5445],\n",
      "        [ 8.5911],\n",
      "        [15.2754]])\n",
      "tensor([[ 4.8183e-03],\n",
      "        [-1.4997e-02],\n",
      "        [ 5.3180e-03],\n",
      "        [ 8.4192e-03],\n",
      "        [-1.6671e-02],\n",
      "        [-1.3628e-02],\n",
      "        [-2.2867e-02],\n",
      "        [-3.1902e-02],\n",
      "        [ 9.6896e-05],\n",
      "        [ 2.3257e-02]], grad_fn=<AddmmBackward0>) tensor([[-1.5003],\n",
      "        [10.0535],\n",
      "        [13.2642],\n",
      "        [-0.4094],\n",
      "        [15.2936],\n",
      "        [12.1877],\n",
      "        [20.4946],\n",
      "        [24.4538],\n",
      "        [13.1245],\n",
      "        [-5.5085]])\n",
      "tensor([[ 0.0042],\n",
      "        [ 0.0067],\n",
      "        [ 0.0333],\n",
      "        [-0.0156],\n",
      "        [-0.0226],\n",
      "        [ 0.0059],\n",
      "        [-0.0188],\n",
      "        [-0.0062],\n",
      "        [ 0.0113],\n",
      "        [-0.0062]], grad_fn=<AddmmBackward0>) tensor([[-3.2293],\n",
      "        [-7.7170],\n",
      "        [-5.9671],\n",
      "        [ 3.8710],\n",
      "        [ 9.2998],\n",
      "        [-2.5771],\n",
      "        [19.2483],\n",
      "        [ 5.9074],\n",
      "        [ 7.4968],\n",
      "        [11.2377]])\n",
      "tensor([[ 0.0229],\n",
      "        [-0.0308],\n",
      "        [ 0.0078],\n",
      "        [-0.0197],\n",
      "        [ 0.0344],\n",
      "        [ 0.0064],\n",
      "        [-0.0245],\n",
      "        [ 0.0047],\n",
      "        [ 0.0096],\n",
      "        [-0.0297]], grad_fn=<AddmmBackward0>) tensor([[  0.1989],\n",
      "        [ 22.2738],\n",
      "        [  3.1587],\n",
      "        [  9.6785],\n",
      "        [-13.0645],\n",
      "        [  3.4531],\n",
      "        [ 26.0652],\n",
      "        [ -2.5873],\n",
      "        [ -0.7222],\n",
      "        [ 11.4427]])\n",
      "tensor([[ 0.0044],\n",
      "        [ 0.0220],\n",
      "        [ 0.0199],\n",
      "        [-0.0063],\n",
      "        [-0.0087],\n",
      "        [ 0.0179],\n",
      "        [ 0.0080],\n",
      "        [-0.0133],\n",
      "        [ 0.0275],\n",
      "        [-0.0032]], grad_fn=<AddmmBackward0>) tensor([[  2.2582],\n",
      "        [ -8.6439],\n",
      "        [  3.1917],\n",
      "        [  5.8033],\n",
      "        [  6.4861],\n",
      "        [ -5.8857],\n",
      "        [  8.5011],\n",
      "        [ -2.3110],\n",
      "        [-10.6988],\n",
      "        [  8.4007]])\n",
      "tensor([[-0.0149],\n",
      "        [ 0.0274],\n",
      "        [ 0.0061],\n",
      "        [ 0.0180],\n",
      "        [ 0.0176],\n",
      "        [ 0.0257],\n",
      "        [ 0.0039],\n",
      "        [ 0.0025],\n",
      "        [ 0.0119],\n",
      "        [ 0.0107]], grad_fn=<AddmmBackward0>) tensor([[ 16.8766],\n",
      "        [ -5.4909],\n",
      "        [  3.6837],\n",
      "        [ -1.6470],\n",
      "        [-22.8149],\n",
      "        [  3.7221],\n",
      "        [  7.7403],\n",
      "        [  2.9728],\n",
      "        [  2.0329],\n",
      "        [  7.1899]])\n",
      "tensor([[ 0.0205],\n",
      "        [ 0.0041],\n",
      "        [ 0.0055],\n",
      "        [-0.0352],\n",
      "        [-0.0028],\n",
      "        [-0.0050],\n",
      "        [-0.0156],\n",
      "        [ 0.0005],\n",
      "        [-0.0248],\n",
      "        [ 0.0033]], grad_fn=<AddmmBackward0>) tensor([[-16.5225],\n",
      "        [  2.2092],\n",
      "        [  7.7497],\n",
      "        [  6.2171],\n",
      "        [ -2.0743],\n",
      "        [ -6.3578],\n",
      "        [ 12.3357],\n",
      "        [ -5.3066],\n",
      "        [ 10.7639],\n",
      "        [  9.4265]])\n",
      "tensor([[-0.0159],\n",
      "        [ 0.0042],\n",
      "        [ 0.0102],\n",
      "        [ 0.0033],\n",
      "        [-0.0015],\n",
      "        [ 0.0263],\n",
      "        [-0.0031],\n",
      "        [ 0.0054],\n",
      "        [ 0.0005],\n",
      "        [-0.0229]], grad_fn=<AddmmBackward0>) tensor([[12.6396],\n",
      "        [ 5.4126],\n",
      "        [13.9530],\n",
      "        [-3.7915],\n",
      "        [ 6.6195],\n",
      "        [-5.6352],\n",
      "        [ 3.7202],\n",
      "        [ 6.9204],\n",
      "        [ 0.5936],\n",
      "        [ 6.6955]])\n",
      "tensor([[ 0.0017],\n",
      "        [-0.0301],\n",
      "        [-0.0203],\n",
      "        [-0.0278],\n",
      "        [ 0.0116],\n",
      "        [-0.0195],\n",
      "        [ 0.0023],\n",
      "        [-0.0204],\n",
      "        [ 0.0306],\n",
      "        [ 0.0017]], grad_fn=<AddmmBackward0>) tensor([[  4.6739],\n",
      "        [ 15.1322],\n",
      "        [  7.8064],\n",
      "        [  0.7159],\n",
      "        [  6.4018],\n",
      "        [  5.4357],\n",
      "        [ -2.3333],\n",
      "        [  8.7944],\n",
      "        [-12.0729],\n",
      "        [  4.4612]])\n",
      "tensor([[-0.0123],\n",
      "        [-0.0094],\n",
      "        [-0.0061],\n",
      "        [ 0.0120],\n",
      "        [-0.0002],\n",
      "        [-0.0111],\n",
      "        [-0.0053],\n",
      "        [-0.0156],\n",
      "        [-0.0099],\n",
      "        [-0.0149]], grad_fn=<AddmmBackward0>) tensor([[ 9.2215],\n",
      "        [11.7080],\n",
      "        [ 9.7221],\n",
      "        [ 1.7949],\n",
      "        [ 2.5661],\n",
      "        [18.7500],\n",
      "        [-3.6183],\n",
      "        [ 2.2159],\n",
      "        [15.6031],\n",
      "        [17.4292]])\n",
      "tensor([[ 0.0107],\n",
      "        [-0.0019],\n",
      "        [ 0.0148],\n",
      "        [-0.0073],\n",
      "        [ 0.0222],\n",
      "        [ 0.0184],\n",
      "        [ 0.0054],\n",
      "        [-0.0082],\n",
      "        [-0.0030],\n",
      "        [ 0.0088]], grad_fn=<AddmmBackward0>) tensor([[ -1.5294],\n",
      "        [ -5.9429],\n",
      "        [ -2.6627],\n",
      "        [ -0.3946],\n",
      "        [ -9.5113],\n",
      "        [-18.2261],\n",
      "        [  6.2251],\n",
      "        [  5.1208],\n",
      "        [ 13.3972],\n",
      "        [ -1.1649]])\n",
      "tensor([[ 0.0188],\n",
      "        [ 0.0128],\n",
      "        [-0.0271],\n",
      "        [ 0.0187],\n",
      "        [ 0.0016],\n",
      "        [-0.0203],\n",
      "        [ 0.0023],\n",
      "        [-0.0165],\n",
      "        [-0.0067],\n",
      "        [-0.0111]], grad_fn=<AddmmBackward0>) tensor([[  8.3694],\n",
      "        [-10.9778],\n",
      "        [ 10.8594],\n",
      "        [ -4.6904],\n",
      "        [  5.6407],\n",
      "        [  2.6139],\n",
      "        [  3.6535],\n",
      "        [ 21.4106],\n",
      "        [ -2.3967],\n",
      "        [  3.8816]])\n",
      "tensor([[-0.0318],\n",
      "        [-0.0156],\n",
      "        [-0.0013],\n",
      "        [-0.0234],\n",
      "        [ 0.0097],\n",
      "        [-0.0020],\n",
      "        [-0.0140],\n",
      "        [ 0.0071],\n",
      "        [ 0.0064],\n",
      "        [-0.0171]], grad_fn=<AddmmBackward0>) tensor([[12.7913],\n",
      "        [14.5409],\n",
      "        [11.5647],\n",
      "        [ 9.4692],\n",
      "        [-5.2191],\n",
      "        [ 4.7405],\n",
      "        [ 5.5400],\n",
      "        [-4.9342],\n",
      "        [ 8.3771],\n",
      "        [15.5417]])\n",
      "tensor([[-0.0343],\n",
      "        [ 0.0157],\n",
      "        [ 0.0272],\n",
      "        [-0.0057],\n",
      "        [ 0.0059],\n",
      "        [ 0.0022],\n",
      "        [ 0.0002],\n",
      "        [-0.0014],\n",
      "        [ 0.0045],\n",
      "        [-0.0128]], grad_fn=<AddmmBackward0>) tensor([[ 27.7588],\n",
      "        [ -1.2107],\n",
      "        [-12.2147],\n",
      "        [ -1.8506],\n",
      "        [ -0.1893],\n",
      "        [  9.1095],\n",
      "        [  3.0196],\n",
      "        [ 17.6255],\n",
      "        [  0.6038],\n",
      "        [  2.2004]])\n",
      "tensor([[-0.0089],\n",
      "        [ 0.0135],\n",
      "        [ 0.0046],\n",
      "        [-0.0197],\n",
      "        [-0.0365],\n",
      "        [ 0.0237],\n",
      "        [-0.0068],\n",
      "        [-0.0060],\n",
      "        [-0.0078],\n",
      "        [ 0.0073]], grad_fn=<AddmmBackward0>) tensor([[  5.0862],\n",
      "        [ -1.4644],\n",
      "        [-12.6645],\n",
      "        [  9.2077],\n",
      "        [ 13.0849],\n",
      "        [ -2.7845],\n",
      "        [ 12.9208],\n",
      "        [  9.9170],\n",
      "        [ -1.8046],\n",
      "        [ 13.2525]])\n",
      "tensor([[ 0.0078],\n",
      "        [ 0.0075],\n",
      "        [ 0.0017],\n",
      "        [ 0.0022],\n",
      "        [-0.0031],\n",
      "        [ 0.0136],\n",
      "        [-0.0009],\n",
      "        [-0.0033],\n",
      "        [-0.0122],\n",
      "        [ 0.0260]], grad_fn=<AddmmBackward0>) tensor([[12.4211],\n",
      "        [ 7.2173],\n",
      "        [ 0.8407],\n",
      "        [ 0.0429],\n",
      "        [ 7.3839],\n",
      "        [-7.6018],\n",
      "        [ 8.7386],\n",
      "        [19.0181],\n",
      "        [ 8.1468],\n",
      "        [-9.8997]])\n",
      "tensor([[ 0.0064],\n",
      "        [-0.0153],\n",
      "        [ 0.0096],\n",
      "        [ 0.0057],\n",
      "        [-0.0206],\n",
      "        [ 0.0262],\n",
      "        [ 0.0046],\n",
      "        [ 0.0163],\n",
      "        [ 0.0220],\n",
      "        [ 0.0055]], grad_fn=<AddmmBackward0>) tensor([[ 5.8373],\n",
      "        [ 8.9644],\n",
      "        [10.9784],\n",
      "        [-4.8967],\n",
      "        [ 9.0046],\n",
      "        [-1.8892],\n",
      "        [ 5.2502],\n",
      "        [-9.3439],\n",
      "        [-2.8872],\n",
      "        [-1.4160]])\n",
      "tensor([[-0.0233],\n",
      "        [ 0.0008],\n",
      "        [ 0.0108],\n",
      "        [-0.0129],\n",
      "        [-0.0149],\n",
      "        [-0.0049],\n",
      "        [ 0.0004],\n",
      "        [-0.0112],\n",
      "        [-0.0129],\n",
      "        [ 0.0115]], grad_fn=<AddmmBackward0>) tensor([[14.4234],\n",
      "        [ 5.2056],\n",
      "        [ 4.7433],\n",
      "        [18.6160],\n",
      "        [26.5749],\n",
      "        [10.3244],\n",
      "        [-2.8084],\n",
      "        [12.5073],\n",
      "        [ 5.3538],\n",
      "        [-4.7865]])\n",
      "tensor([[ 0.0236],\n",
      "        [-0.0027],\n",
      "        [-0.0017],\n",
      "        [-0.0224],\n",
      "        [-0.0016],\n",
      "        [-0.0034],\n",
      "        [ 0.0032],\n",
      "        [-0.0131],\n",
      "        [-0.0198],\n",
      "        [ 0.0138]], grad_fn=<AddmmBackward0>) tensor([[  0.9866],\n",
      "        [  8.2306],\n",
      "        [ 12.6027],\n",
      "        [  2.2279],\n",
      "        [-10.7981],\n",
      "        [  4.2568],\n",
      "        [  4.1232],\n",
      "        [  4.8649],\n",
      "        [  5.1584],\n",
      "        [ -8.4516]])\n",
      "tensor([[ 0.0222],\n",
      "        [-0.0043],\n",
      "        [-0.0139],\n",
      "        [ 0.0043],\n",
      "        [ 0.0066],\n",
      "        [ 0.0156],\n",
      "        [-0.0066],\n",
      "        [-0.0119],\n",
      "        [-0.0128],\n",
      "        [ 0.0163]], grad_fn=<AddmmBackward0>) tensor([[ -1.0541],\n",
      "        [  6.1438],\n",
      "        [  4.7647],\n",
      "        [  0.4799],\n",
      "        [-10.4500],\n",
      "        [  2.6823],\n",
      "        [  9.8014],\n",
      "        [ 10.2252],\n",
      "        [  8.7572],\n",
      "        [  2.4130]])\n",
      "tensor([[-0.0095],\n",
      "        [-0.0169],\n",
      "        [ 0.0313],\n",
      "        [ 0.0132],\n",
      "        [ 0.0151],\n",
      "        [ 0.0178],\n",
      "        [ 0.0125],\n",
      "        [ 0.0147],\n",
      "        [ 0.0071],\n",
      "        [ 0.0239]], grad_fn=<AddmmBackward0>) tensor([[ 14.1217],\n",
      "        [ -6.6034],\n",
      "        [-18.3699],\n",
      "        [ -3.1204],\n",
      "        [ -4.6462],\n",
      "        [  0.8413],\n",
      "        [ -7.7826],\n",
      "        [  2.5494],\n",
      "        [  2.1982],\n",
      "        [ -2.0728]])\n",
      "tensor([[-0.0129],\n",
      "        [-0.0122],\n",
      "        [ 0.0003],\n",
      "        [ 0.0024],\n",
      "        [ 0.0301],\n",
      "        [-0.0025],\n",
      "        [-0.0032],\n",
      "        [-0.0233],\n",
      "        [ 0.0300],\n",
      "        [ 0.0126]], grad_fn=<AddmmBackward0>) tensor([[ 2.6672],\n",
      "        [10.9265],\n",
      "        [14.2778],\n",
      "        [ 0.1042],\n",
      "        [-4.8124],\n",
      "        [-0.6055],\n",
      "        [ 3.1174],\n",
      "        [ 4.2076],\n",
      "        [-9.9643],\n",
      "        [ 0.9288]])\n",
      "tensor([[-0.0251],\n",
      "        [-0.0196],\n",
      "        [ 0.0245],\n",
      "        [-0.0069],\n",
      "        [ 0.0095],\n",
      "        [ 0.0160],\n",
      "        [-0.0034],\n",
      "        [-0.0048],\n",
      "        [-0.0233],\n",
      "        [ 0.0190]], grad_fn=<AddmmBackward0>) tensor([[15.3264],\n",
      "        [12.5607],\n",
      "        [ 6.4465],\n",
      "        [ 2.7388],\n",
      "        [ 5.6829],\n",
      "        [-0.2370],\n",
      "        [16.9805],\n",
      "        [ 8.0957],\n",
      "        [ 5.9210],\n",
      "        [ 1.5833]])\n",
      "tensor([[ 0.0037],\n",
      "        [-0.0077],\n",
      "        [-0.0314],\n",
      "        [-0.0031],\n",
      "        [ 0.0065],\n",
      "        [ 0.0082],\n",
      "        [ 0.0258],\n",
      "        [-0.0069],\n",
      "        [ 0.0093],\n",
      "        [ 0.0318]], grad_fn=<AddmmBackward0>) tensor([[20.8727],\n",
      "        [-3.5721],\n",
      "        [24.7710],\n",
      "        [ 7.5221],\n",
      "        [ 8.9723],\n",
      "        [-3.2039],\n",
      "        [ 2.2759],\n",
      "        [21.0907],\n",
      "        [12.8764],\n",
      "        [-5.4091]])\n",
      "tensor([[ 0.0236],\n",
      "        [-0.0071],\n",
      "        [-0.0037],\n",
      "        [-0.0142],\n",
      "        [-0.0056],\n",
      "        [ 0.0022],\n",
      "        [ 0.0004],\n",
      "        [-0.0044],\n",
      "        [-0.0044],\n",
      "        [ 0.0240]], grad_fn=<AddmmBackward0>) tensor([[-3.1926],\n",
      "        [-3.0204],\n",
      "        [-8.2721],\n",
      "        [ 0.8140],\n",
      "        [ 8.1576],\n",
      "        [ 5.4745],\n",
      "        [-0.3579],\n",
      "        [10.5462],\n",
      "        [ 7.8981],\n",
      "        [-1.8293]])\n",
      "tensor([[-0.0041],\n",
      "        [ 0.0017],\n",
      "        [-0.0148],\n",
      "        [ 0.0172],\n",
      "        [ 0.0242],\n",
      "        [-0.0008],\n",
      "        [ 0.0247],\n",
      "        [-0.0007],\n",
      "        [-0.0083],\n",
      "        [ 0.0153]], grad_fn=<AddmmBackward0>) tensor([[  7.2122],\n",
      "        [  2.8718],\n",
      "        [ 16.0653],\n",
      "        [  0.4792],\n",
      "        [ -3.6017],\n",
      "        [ 11.0844],\n",
      "        [  8.8806],\n",
      "        [ 20.6698],\n",
      "        [ 13.2620],\n",
      "        [-13.4459]])\n",
      "tensor([[-0.0012],\n",
      "        [ 0.0138],\n",
      "        [ 0.0046],\n",
      "        [ 0.0180],\n",
      "        [-0.0025],\n",
      "        [-0.0175],\n",
      "        [ 0.0011],\n",
      "        [-0.0299],\n",
      "        [ 0.0053],\n",
      "        [ 0.0262]], grad_fn=<AddmmBackward0>) tensor([[ 10.7204],\n",
      "        [  4.0462],\n",
      "        [ -0.5775],\n",
      "        [  7.1968],\n",
      "        [-13.2366],\n",
      "        [ 19.1411],\n",
      "        [ 11.9012],\n",
      "        [ 19.7708],\n",
      "        [  5.3139],\n",
      "        [ -5.5348]])\n",
      "tensor([[-1.3996e-02],\n",
      "        [-4.6279e-03],\n",
      "        [-9.8351e-05],\n",
      "        [ 3.3822e-02],\n",
      "        [-3.3136e-02],\n",
      "        [-4.5566e-03],\n",
      "        [ 2.6205e-03],\n",
      "        [ 2.6100e-03],\n",
      "        [-2.6105e-02],\n",
      "        [ 8.8080e-03]], grad_fn=<AddmmBackward0>) tensor([[12.1137],\n",
      "        [13.1823],\n",
      "        [10.3119],\n",
      "        [-8.9416],\n",
      "        [17.6998],\n",
      "        [ 9.0542],\n",
      "        [-9.1752],\n",
      "        [-4.8782],\n",
      "        [20.9214],\n",
      "        [ 5.0433]])\n",
      "tensor([[ 0.0036],\n",
      "        [ 0.0042],\n",
      "        [-0.0019],\n",
      "        [-0.0110],\n",
      "        [ 0.0012],\n",
      "        [ 0.0114],\n",
      "        [ 0.0116],\n",
      "        [ 0.0245],\n",
      "        [ 0.0146],\n",
      "        [ 0.0130]], grad_fn=<AddmmBackward0>) tensor([[  0.2721],\n",
      "        [ -1.4188],\n",
      "        [ 20.1783],\n",
      "        [ -1.3636],\n",
      "        [ 18.7210],\n",
      "        [ -2.2584],\n",
      "        [ 10.7667],\n",
      "        [  4.5799],\n",
      "        [  7.7569],\n",
      "        [-14.8816]])\n",
      "tensor([[ 0.0135],\n",
      "        [ 0.0164],\n",
      "        [-0.0007],\n",
      "        [-0.0016],\n",
      "        [-0.0159],\n",
      "        [ 0.0160],\n",
      "        [ 0.0014],\n",
      "        [-0.0040],\n",
      "        [ 0.0239],\n",
      "        [-0.0292]], grad_fn=<AddmmBackward0>) tensor([[ 5.5271],\n",
      "        [-6.7347],\n",
      "        [-5.8874],\n",
      "        [ 0.4136],\n",
      "        [ 8.9381],\n",
      "        [ 1.2933],\n",
      "        [ 8.7492],\n",
      "        [15.7348],\n",
      "        [ 6.2821],\n",
      "        [20.4876]])\n",
      "tensor([[ 0.0486],\n",
      "        [-0.0082],\n",
      "        [ 0.0002],\n",
      "        [ 0.0500],\n",
      "        [-0.0127],\n",
      "        [-0.0245],\n",
      "        [ 0.0097],\n",
      "        [ 0.0014],\n",
      "        [ 0.0133],\n",
      "        [-0.0060]], grad_fn=<AddmmBackward0>) tensor([[-18.4421],\n",
      "        [  9.7071],\n",
      "        [  0.7773],\n",
      "        [-12.0662],\n",
      "        [  1.9171],\n",
      "        [  9.1228],\n",
      "        [-12.3204],\n",
      "        [  8.5879],\n",
      "        [  4.1105],\n",
      "        [  6.9069]])\n",
      "tensor([[-0.0049],\n",
      "        [ 0.0008],\n",
      "        [-0.0010],\n",
      "        [ 0.0003],\n",
      "        [-0.0090],\n",
      "        [ 0.0041],\n",
      "        [ 0.0094],\n",
      "        [ 0.0130],\n",
      "        [-0.0043],\n",
      "        [ 0.0096]], grad_fn=<AddmmBackward0>) tensor([[11.5515],\n",
      "        [ 7.4568],\n",
      "        [ 5.9458],\n",
      "        [-0.4827],\n",
      "        [-3.3799],\n",
      "        [-3.5486],\n",
      "        [ 2.6960],\n",
      "        [-2.5678],\n",
      "        [ 9.8129],\n",
      "        [ 4.2296]])\n",
      "tensor([[ 0.0045],\n",
      "        [-0.0156],\n",
      "        [-0.0102],\n",
      "        [-0.0228],\n",
      "        [-0.0128],\n",
      "        [ 0.0047],\n",
      "        [ 0.0131],\n",
      "        [ 0.0072],\n",
      "        [-0.0190],\n",
      "        [-0.0165]], grad_fn=<AddmmBackward0>) tensor([[ 11.6458],\n",
      "        [  8.7073],\n",
      "        [ -4.9375],\n",
      "        [ 21.8897],\n",
      "        [  7.9822],\n",
      "        [ 11.6982],\n",
      "        [-10.0374],\n",
      "        [ -8.0419],\n",
      "        [ 24.7720],\n",
      "        [ 20.4559]])\n",
      "tensor([[ 0.0037],\n",
      "        [ 0.0037],\n",
      "        [ 0.0138],\n",
      "        [-0.0144],\n",
      "        [ 0.0260],\n",
      "        [-0.0077],\n",
      "        [-0.0166],\n",
      "        [ 0.0301],\n",
      "        [-0.0239],\n",
      "        [-0.0017]], grad_fn=<AddmmBackward0>) tensor([[ 7.8693],\n",
      "        [ 3.3456],\n",
      "        [-6.4006],\n",
      "        [ 7.6824],\n",
      "        [-3.7364],\n",
      "        [-1.2825],\n",
      "        [22.4647],\n",
      "        [-1.0056],\n",
      "        [20.6255],\n",
      "        [ 3.8444]])\n",
      "tensor([[-0.0083],\n",
      "        [ 0.0021],\n",
      "        [-0.0051],\n",
      "        [-0.0060],\n",
      "        [-0.0246],\n",
      "        [ 0.0106],\n",
      "        [ 0.0051],\n",
      "        [-0.0021],\n",
      "        [-0.0063],\n",
      "        [ 0.0182]], grad_fn=<AddmmBackward0>) tensor([[  1.9287],\n",
      "        [ -1.7497],\n",
      "        [  2.5498],\n",
      "        [  8.3051],\n",
      "        [  9.4479],\n",
      "        [ -0.8556],\n",
      "        [-10.5731],\n",
      "        [ -0.2664],\n",
      "        [  1.3857],\n",
      "        [  3.2121]])\n",
      "tensor([[-0.0352],\n",
      "        [-0.0034],\n",
      "        [ 0.0085],\n",
      "        [ 0.0368],\n",
      "        [ 0.0141],\n",
      "        [ 0.0162],\n",
      "        [-0.0210],\n",
      "        [-0.0061],\n",
      "        [ 0.0149],\n",
      "        [-0.0075]], grad_fn=<AddmmBackward0>) tensor([[ 22.8160],\n",
      "        [  4.2394],\n",
      "        [ -1.0229],\n",
      "        [-10.7842],\n",
      "        [  3.7850],\n",
      "        [ -7.0857],\n",
      "        [ 13.9911],\n",
      "        [  3.8291],\n",
      "        [  1.3492],\n",
      "        [ 10.7535]])\n",
      "tensor([[ 0.0181],\n",
      "        [-0.0156],\n",
      "        [ 0.0092],\n",
      "        [ 0.0052],\n",
      "        [ 0.0185],\n",
      "        [ 0.0248],\n",
      "        [ 0.0225],\n",
      "        [ 0.0262],\n",
      "        [-0.0187],\n",
      "        [ 0.0035]], grad_fn=<AddmmBackward0>) tensor([[-9.3653],\n",
      "        [15.9445],\n",
      "        [ 5.2880],\n",
      "        [-2.7604],\n",
      "        [-2.9623],\n",
      "        [-8.1292],\n",
      "        [ 5.7605],\n",
      "        [-5.7069],\n",
      "        [-2.3052],\n",
      "        [ 4.1432]])\n",
      "tensor([[ 0.0054],\n",
      "        [ 0.0176],\n",
      "        [ 0.0097],\n",
      "        [ 0.0168],\n",
      "        [ 0.0024],\n",
      "        [-0.0263],\n",
      "        [ 0.0158],\n",
      "        [ 0.0086],\n",
      "        [ 0.0099],\n",
      "        [-0.0052]], grad_fn=<AddmmBackward0>) tensor([[-10.5054],\n",
      "        [ -5.0693],\n",
      "        [  5.9791],\n",
      "        [  0.9200],\n",
      "        [ 11.8594],\n",
      "        [  7.4661],\n",
      "        [ -0.9854],\n",
      "        [  6.2859],\n",
      "        [ -9.7960],\n",
      "        [  7.6161]])\n",
      "tensor([[-0.0128],\n",
      "        [ 0.0325],\n",
      "        [ 0.0335],\n",
      "        [-0.0269],\n",
      "        [ 0.0173],\n",
      "        [-0.0122],\n",
      "        [ 0.0110],\n",
      "        [-0.0043],\n",
      "        [-0.0106],\n",
      "        [-0.0001]], grad_fn=<AddmmBackward0>) tensor([[-1.6107],\n",
      "        [-9.5226],\n",
      "        [ 3.8670],\n",
      "        [17.0038],\n",
      "        [ 0.4878],\n",
      "        [ 2.6502],\n",
      "        [-9.5449],\n",
      "        [-4.6239],\n",
      "        [11.3030],\n",
      "        [ 7.9309]])\n",
      "tensor([[ 0.0047],\n",
      "        [ 0.0006],\n",
      "        [ 0.0287],\n",
      "        [-0.0260],\n",
      "        [-0.0249],\n",
      "        [-0.0066],\n",
      "        [ 0.0008],\n",
      "        [ 0.0206],\n",
      "        [-0.0223],\n",
      "        [-0.0032]], grad_fn=<AddmmBackward0>) tensor([[ 1.3243],\n",
      "        [-4.0404],\n",
      "        [-2.3354],\n",
      "        [ 9.7513],\n",
      "        [12.1184],\n",
      "        [ 5.0941],\n",
      "        [12.8244],\n",
      "        [-2.3554],\n",
      "        [ 9.4918],\n",
      "        [ 7.4114]])\n",
      "tensor([[ 0.0005],\n",
      "        [ 0.0122],\n",
      "        [ 0.0066],\n",
      "        [ 0.0038],\n",
      "        [-0.0090],\n",
      "        [ 0.0274],\n",
      "        [ 0.0024],\n",
      "        [ 0.0030],\n",
      "        [-0.0053],\n",
      "        [-0.0014]], grad_fn=<AddmmBackward0>) tensor([[ -1.6885],\n",
      "        [-12.0976],\n",
      "        [  2.2205],\n",
      "        [ 13.9196],\n",
      "        [  6.5037],\n",
      "        [ -5.8374],\n",
      "        [ -0.5153],\n",
      "        [ -3.2893],\n",
      "        [ -4.1435],\n",
      "        [  1.9359]])\n",
      "tensor([[-0.0066],\n",
      "        [-0.0180],\n",
      "        [-0.0150],\n",
      "        [ 0.0049],\n",
      "        [ 0.0024],\n",
      "        [-0.0120],\n",
      "        [-0.0149],\n",
      "        [-0.0264],\n",
      "        [ 0.0009],\n",
      "        [ 0.0134]], grad_fn=<AddmmBackward0>) tensor([[ 0.6192],\n",
      "        [ 0.0972],\n",
      "        [ 8.1214],\n",
      "        [-2.4372],\n",
      "        [ 4.0181],\n",
      "        [-8.1867],\n",
      "        [ 6.5057],\n",
      "        [12.2870],\n",
      "        [-0.8226],\n",
      "        [-8.2985]])\n",
      "tensor([[-0.0273],\n",
      "        [ 0.0052],\n",
      "        [ 0.0209],\n",
      "        [-0.0049],\n",
      "        [ 0.0007],\n",
      "        [-0.0237],\n",
      "        [-0.0135],\n",
      "        [-0.0096],\n",
      "        [-0.0007],\n",
      "        [ 0.0160]], grad_fn=<AddmmBackward0>) tensor([[ 16.6276],\n",
      "        [  0.7515],\n",
      "        [-14.9111],\n",
      "        [ 16.0225],\n",
      "        [  1.7147],\n",
      "        [ 13.4864],\n",
      "        [  6.1251],\n",
      "        [  9.2673],\n",
      "        [-10.4984],\n",
      "        [ -6.2139]])\n",
      "tensor([[ 0.0322],\n",
      "        [-0.0066],\n",
      "        [ 0.0161],\n",
      "        [ 0.0070],\n",
      "        [-0.0175],\n",
      "        [-0.0100],\n",
      "        [-0.0064],\n",
      "        [-0.0103],\n",
      "        [-0.0046],\n",
      "        [ 0.0113]], grad_fn=<AddmmBackward0>) tensor([[  1.1126],\n",
      "        [  9.5144],\n",
      "        [  3.8995],\n",
      "        [ -1.2604],\n",
      "        [ 19.6037],\n",
      "        [ 14.0541],\n",
      "        [-12.0320],\n",
      "        [  8.7865],\n",
      "        [  5.3081],\n",
      "        [ 12.2121]])\n",
      "tensor([[ 0.0001],\n",
      "        [ 0.0181],\n",
      "        [-0.0215],\n",
      "        [-0.0098],\n",
      "        [ 0.0210],\n",
      "        [ 0.0067],\n",
      "        [ 0.0028],\n",
      "        [-0.0106],\n",
      "        [ 0.0023],\n",
      "        [-0.0068]], grad_fn=<AddmmBackward0>) tensor([[ 5.2242],\n",
      "        [-0.4855],\n",
      "        [10.3329],\n",
      "        [13.2100],\n",
      "        [ 0.3343],\n",
      "        [-3.2405],\n",
      "        [10.8399],\n",
      "        [ 7.6970],\n",
      "        [15.7537],\n",
      "        [11.3488]])\n",
      "tensor([[ 0.0027],\n",
      "        [ 0.0090],\n",
      "        [ 0.0076],\n",
      "        [ 0.0047],\n",
      "        [-0.0233],\n",
      "        [ 0.0102],\n",
      "        [-0.0329],\n",
      "        [-0.0070],\n",
      "        [ 0.0079],\n",
      "        [-0.0171]], grad_fn=<AddmmBackward0>) tensor([[ -6.3646],\n",
      "        [ -2.1544],\n",
      "        [ -6.1911],\n",
      "        [ -6.5965],\n",
      "        [ 15.6285],\n",
      "        [-10.7124],\n",
      "        [  9.6266],\n",
      "        [ -4.0490],\n",
      "        [  6.8447],\n",
      "        [ 16.1134]])\n",
      "tensor([[ 0.0084],\n",
      "        [ 0.0082],\n",
      "        [ 0.0022],\n",
      "        [ 0.0011],\n",
      "        [-0.0073],\n",
      "        [ 0.0087],\n",
      "        [-0.0168],\n",
      "        [ 0.0044],\n",
      "        [ 0.0041],\n",
      "        [-0.0087]], grad_fn=<AddmmBackward0>) tensor([[ 5.0582],\n",
      "        [-2.1755],\n",
      "        [-0.4633],\n",
      "        [10.9427],\n",
      "        [ 3.9259],\n",
      "        [-5.2613],\n",
      "        [ 0.7057],\n",
      "        [ 8.4162],\n",
      "        [ 8.5060],\n",
      "        [ 1.7501]])\n",
      "tensor([[ 0.0113],\n",
      "        [-0.0089],\n",
      "        [-0.0100],\n",
      "        [-0.0113],\n",
      "        [ 0.0400],\n",
      "        [-0.0196],\n",
      "        [-0.0040],\n",
      "        [ 0.0247],\n",
      "        [-0.0394],\n",
      "        [-0.0276]], grad_fn=<AddmmBackward0>) tensor([[  9.3306],\n",
      "        [ 13.3979],\n",
      "        [ 12.5413],\n",
      "        [ 13.4722],\n",
      "        [-10.0931],\n",
      "        [  8.2586],\n",
      "        [ -1.1465],\n",
      "        [  2.4136],\n",
      "        [ 10.0031],\n",
      "        [ 10.2253]])\n",
      "tensor([[ 0.0125],\n",
      "        [-0.0186],\n",
      "        [ 0.0162],\n",
      "        [ 0.0062],\n",
      "        [-0.0104],\n",
      "        [-0.0076],\n",
      "        [-0.0134],\n",
      "        [ 0.0068],\n",
      "        [-0.0011],\n",
      "        [-0.0130]], grad_fn=<AddmmBackward0>) tensor([[ 2.1332],\n",
      "        [-1.4119],\n",
      "        [ 7.9667],\n",
      "        [ 4.6808],\n",
      "        [ 8.0619],\n",
      "        [14.7538],\n",
      "        [ 3.1136],\n",
      "        [ 3.3658],\n",
      "        [ 1.1254],\n",
      "        [ 8.7803]])\n",
      "tensor([[-0.0390],\n",
      "        [-0.0037],\n",
      "        [ 0.0268],\n",
      "        [ 0.0134],\n",
      "        [ 0.0058],\n",
      "        [ 0.0122],\n",
      "        [-0.0029],\n",
      "        [ 0.0173],\n",
      "        [-0.0541],\n",
      "        [ 0.0211]], grad_fn=<AddmmBackward0>) tensor([[15.3025],\n",
      "        [-0.1539],\n",
      "        [-9.1954],\n",
      "        [ 8.6174],\n",
      "        [13.1735],\n",
      "        [ 7.1046],\n",
      "        [ 8.0298],\n",
      "        [ 4.3095],\n",
      "        [14.4185],\n",
      "        [-3.7212]])\n",
      "tensor([[ 0.0042],\n",
      "        [ 0.0103],\n",
      "        [-0.0174],\n",
      "        [-0.0236],\n",
      "        [ 0.0348],\n",
      "        [ 0.0109],\n",
      "        [ 0.0008],\n",
      "        [ 0.0097],\n",
      "        [-0.0026],\n",
      "        [-0.0254]], grad_fn=<AddmmBackward0>) tensor([[ -9.1903],\n",
      "        [  6.1595],\n",
      "        [ -2.5995],\n",
      "        [  3.6027],\n",
      "        [-11.4222],\n",
      "        [  0.0553],\n",
      "        [  5.8738],\n",
      "        [ -7.4651],\n",
      "        [  4.4602],\n",
      "        [  9.8150]])\n",
      "tensor([[ 0.0068],\n",
      "        [ 0.0168],\n",
      "        [-0.0021],\n",
      "        [-0.0137],\n",
      "        [-0.0106],\n",
      "        [ 0.0060],\n",
      "        [ 0.0063],\n",
      "        [-0.0092],\n",
      "        [-0.0058],\n",
      "        [ 0.0247]], grad_fn=<AddmmBackward0>) tensor([[ 0.6324],\n",
      "        [ 1.2054],\n",
      "        [-0.4882],\n",
      "        [11.6754],\n",
      "        [ 8.0398],\n",
      "        [-3.9580],\n",
      "        [-7.8440],\n",
      "        [-0.1749],\n",
      "        [ 4.0452],\n",
      "        [-6.4002]])\n",
      "tensor([[ 0.0043],\n",
      "        [-0.0194],\n",
      "        [-0.0175],\n",
      "        [ 0.0006],\n",
      "        [ 0.0090],\n",
      "        [ 0.0016],\n",
      "        [-0.0147],\n",
      "        [-0.0093],\n",
      "        [ 0.0298],\n",
      "        [-0.0255]], grad_fn=<AddmmBackward0>) tensor([[  3.0145],\n",
      "        [  6.3912],\n",
      "        [ 18.1684],\n",
      "        [  8.7598],\n",
      "        [  1.1742],\n",
      "        [  6.9896],\n",
      "        [ 14.3410],\n",
      "        [  6.6466],\n",
      "        [-13.8117],\n",
      "        [  4.9165]])\n",
      "tensor([[ 4.5533e-03],\n",
      "        [ 2.8017e-02],\n",
      "        [ 7.5236e-03],\n",
      "        [-2.8243e-03],\n",
      "        [-1.1186e-02],\n",
      "        [-9.6470e-05],\n",
      "        [ 2.2165e-02],\n",
      "        [ 1.0801e-02],\n",
      "        [-7.9028e-03],\n",
      "        [-5.5154e-03]], grad_fn=<AddmmBackward0>) tensor([[ 4.2830],\n",
      "        [-3.5953],\n",
      "        [ 3.8309],\n",
      "        [ 1.1186],\n",
      "        [ 5.5678],\n",
      "        [-6.1444],\n",
      "        [ 5.9665],\n",
      "        [-4.8961],\n",
      "        [ 6.4818],\n",
      "        [ 7.4099]])\n",
      "tensor([[ 0.0067],\n",
      "        [ 0.0255],\n",
      "        [ 0.0001],\n",
      "        [-0.0294],\n",
      "        [ 0.0048],\n",
      "        [ 0.0057],\n",
      "        [ 0.0239],\n",
      "        [-0.0069],\n",
      "        [ 0.0014],\n",
      "        [-0.0149]], grad_fn=<AddmmBackward0>) tensor([[  9.3331],\n",
      "        [-10.3542],\n",
      "        [ 11.1823],\n",
      "        [ 17.7070],\n",
      "        [ -6.3669],\n",
      "        [ -2.6576],\n",
      "        [  4.9045],\n",
      "        [  8.0138],\n",
      "        [  8.6220],\n",
      "        [ 10.5937]])\n",
      "tensor([[-5.3377e-03],\n",
      "        [-2.4776e-04],\n",
      "        [-6.1253e-03],\n",
      "        [-1.8995e-02],\n",
      "        [-3.4167e-05],\n",
      "        [ 1.7202e-02],\n",
      "        [ 1.3832e-03],\n",
      "        [-7.0404e-03],\n",
      "        [-2.6144e-02],\n",
      "        [ 8.3839e-03]], grad_fn=<AddmmBackward0>) tensor([[ 4.5589],\n",
      "        [ 4.8399],\n",
      "        [13.1887],\n",
      "        [15.4828],\n",
      "        [ 0.3050],\n",
      "        [ 2.5659],\n",
      "        [ 7.5792],\n",
      "        [ 5.2901],\n",
      "        [12.1038],\n",
      "        [-2.8761]])\n",
      "tensor([[-0.0164],\n",
      "        [ 0.0015],\n",
      "        [-0.0040],\n",
      "        [ 0.0029],\n",
      "        [ 0.0429],\n",
      "        [-0.0006],\n",
      "        [ 0.0059],\n",
      "        [-0.0096],\n",
      "        [-0.0008],\n",
      "        [-0.0155]], grad_fn=<AddmmBackward0>) tensor([[  4.7244],\n",
      "        [ -1.3527],\n",
      "        [  0.3444],\n",
      "        [ -4.6690],\n",
      "        [-17.7683],\n",
      "        [ -6.0586],\n",
      "        [  0.5405],\n",
      "        [ -4.1111],\n",
      "        [ 25.2710],\n",
      "        [  7.0535]])\n",
      "tensor([[-0.0161],\n",
      "        [ 0.0108],\n",
      "        [-0.0455],\n",
      "        [-0.0220],\n",
      "        [ 0.0010],\n",
      "        [ 0.0034],\n",
      "        [-0.0099],\n",
      "        [ 0.0017],\n",
      "        [ 0.0004],\n",
      "        [ 0.0204]], grad_fn=<AddmmBackward0>) tensor([[16.5093],\n",
      "        [ 9.4036],\n",
      "        [10.5888],\n",
      "        [11.9860],\n",
      "        [ 2.6398],\n",
      "        [-7.6775],\n",
      "        [-3.5573],\n",
      "        [17.2961],\n",
      "        [ 5.3568],\n",
      "        [ 3.7164]])\n",
      "tensor([[ 0.0240],\n",
      "        [ 0.0153],\n",
      "        [-0.0041],\n",
      "        [ 0.0201],\n",
      "        [ 0.0054],\n",
      "        [-0.0089],\n",
      "        [ 0.0136],\n",
      "        [-0.0156],\n",
      "        [-0.0262],\n",
      "        [ 0.0038]], grad_fn=<AddmmBackward0>) tensor([[ 3.6579],\n",
      "        [ 1.5739],\n",
      "        [ 8.7908],\n",
      "        [ 2.8298],\n",
      "        [-0.4854],\n",
      "        [ 8.2884],\n",
      "        [-5.9651],\n",
      "        [15.8851],\n",
      "        [22.9632],\n",
      "        [12.7832]])\n",
      "tensor([[-2.7159e-02],\n",
      "        [-9.2302e-05],\n",
      "        [-1.4831e-02],\n",
      "        [-8.6276e-03],\n",
      "        [ 8.9079e-03],\n",
      "        [-1.7017e-02],\n",
      "        [-1.7495e-02],\n",
      "        [ 6.9308e-03],\n",
      "        [ 1.6615e-02],\n",
      "        [-2.0545e-02]], grad_fn=<AddmmBackward0>) tensor([[14.4471],\n",
      "        [-2.8144],\n",
      "        [13.1124],\n",
      "        [ 9.5299],\n",
      "        [ 6.8496],\n",
      "        [21.4672],\n",
      "        [ 7.9938],\n",
      "        [15.0023],\n",
      "        [ 7.6910],\n",
      "        [ 2.9683]])\n",
      "tensor([[ 0.0114],\n",
      "        [ 0.0091],\n",
      "        [-0.0024],\n",
      "        [ 0.0287],\n",
      "        [-0.0046],\n",
      "        [-0.0075],\n",
      "        [-0.0027],\n",
      "        [ 0.0178],\n",
      "        [-0.0075],\n",
      "        [-0.0163]], grad_fn=<AddmmBackward0>) tensor([[ 5.7858],\n",
      "        [-7.8527],\n",
      "        [ 0.0967],\n",
      "        [-6.0857],\n",
      "        [ 2.8244],\n",
      "        [ 0.8502],\n",
      "        [14.2932],\n",
      "        [-1.5755],\n",
      "        [ 7.0463],\n",
      "        [18.3608]])\n",
      "tensor([[-0.0136],\n",
      "        [-0.0005],\n",
      "        [-0.0117],\n",
      "        [-0.0127],\n",
      "        [-0.0191],\n",
      "        [-0.0129],\n",
      "        [ 0.0179],\n",
      "        [-0.0079],\n",
      "        [-0.0295],\n",
      "        [-0.0199]], grad_fn=<AddmmBackward0>) tensor([[17.5668],\n",
      "        [-1.4532],\n",
      "        [ 9.2237],\n",
      "        [ 8.1509],\n",
      "        [22.9900],\n",
      "        [12.2632],\n",
      "        [ 4.4805],\n",
      "        [-7.7882],\n",
      "        [16.0011],\n",
      "        [-0.9570]])\n",
      "tensor([[-0.0069],\n",
      "        [-0.0097],\n",
      "        [ 0.0017],\n",
      "        [ 0.0189],\n",
      "        [ 0.0172],\n",
      "        [ 0.0030],\n",
      "        [ 0.0208],\n",
      "        [ 0.0102],\n",
      "        [ 0.0149],\n",
      "        [ 0.0244]], grad_fn=<AddmmBackward0>) tensor([[-1.9406],\n",
      "        [-1.9848],\n",
      "        [ 6.7911],\n",
      "        [ 2.5377],\n",
      "        [ 8.0338],\n",
      "        [ 5.7387],\n",
      "        [15.3107],\n",
      "        [-4.1727],\n",
      "        [-5.8623],\n",
      "        [-6.4629]])\n",
      "tensor([[-0.0094],\n",
      "        [-0.0002],\n",
      "        [ 0.0266],\n",
      "        [-0.0040],\n",
      "        [ 0.0075],\n",
      "        [-0.0119],\n",
      "        [ 0.0095],\n",
      "        [ 0.0189],\n",
      "        [ 0.0034],\n",
      "        [-0.0026]], grad_fn=<AddmmBackward0>) tensor([[ 9.8888],\n",
      "        [-1.5787],\n",
      "        [-0.7851],\n",
      "        [ 0.3030],\n",
      "        [ 1.5336],\n",
      "        [13.2381],\n",
      "        [-5.2122],\n",
      "        [ 3.9263],\n",
      "        [-0.4993],\n",
      "        [ 9.7779]])\n",
      "tensor([[-0.0200],\n",
      "        [ 0.0090],\n",
      "        [ 0.0265],\n",
      "        [-0.0300],\n",
      "        [-0.0094],\n",
      "        [ 0.0017],\n",
      "        [-0.0110],\n",
      "        [-0.0049],\n",
      "        [-0.0381],\n",
      "        [ 0.0054]], grad_fn=<AddmmBackward0>) tensor([[18.2269],\n",
      "        [-5.2022],\n",
      "        [-6.6159],\n",
      "        [10.0188],\n",
      "        [16.3986],\n",
      "        [ 5.7424],\n",
      "        [14.5819],\n",
      "        [-4.3981],\n",
      "        [13.7079],\n",
      "        [ 6.2858]])\n",
      "tensor([[-0.0046],\n",
      "        [ 0.0033],\n",
      "        [-0.0148],\n",
      "        [ 0.0548],\n",
      "        [ 0.0383],\n",
      "        [-0.0170],\n",
      "        [-0.0314],\n",
      "        [-0.0081],\n",
      "        [ 0.0249],\n",
      "        [-0.0176]], grad_fn=<AddmmBackward0>) tensor([[ 11.5904],\n",
      "        [  6.2871],\n",
      "        [ 12.0521],\n",
      "        [-20.5613],\n",
      "        [-11.5590],\n",
      "        [ 18.2772],\n",
      "        [ 17.7860],\n",
      "        [ -1.5000],\n",
      "        [ -1.1752],\n",
      "        [ 17.5829]])\n",
      "tensor([[ 1.1555e-02],\n",
      "        [-1.0593e-02],\n",
      "        [-9.5957e-03],\n",
      "        [ 8.9819e-03],\n",
      "        [ 9.9919e-03],\n",
      "        [-1.9964e-02],\n",
      "        [ 1.8024e-02],\n",
      "        [ 1.3380e-02],\n",
      "        [ 6.6884e-05],\n",
      "        [-9.1054e-03]], grad_fn=<AddmmBackward0>) tensor([[-0.8454],\n",
      "        [11.6679],\n",
      "        [ 7.6005],\n",
      "        [ 2.4797],\n",
      "        [ 2.9237],\n",
      "        [20.0677],\n",
      "        [ 9.9948],\n",
      "        [ 1.3092],\n",
      "        [-4.1730],\n",
      "        [ 3.1365]])\n",
      "tensor([[ 0.0290],\n",
      "        [ 0.0094],\n",
      "        [-0.0167],\n",
      "        [-0.0054],\n",
      "        [-0.0087],\n",
      "        [-0.0206],\n",
      "        [-0.0299],\n",
      "        [-0.0038],\n",
      "        [-0.0255],\n",
      "        [ 0.0131]], grad_fn=<AddmmBackward0>) tensor([[ 5.2899],\n",
      "        [10.0954],\n",
      "        [ 9.7962],\n",
      "        [-1.1690],\n",
      "        [-1.1837],\n",
      "        [17.5319],\n",
      "        [ 7.6176],\n",
      "        [ 5.3845],\n",
      "        [21.4059],\n",
      "        [-7.2291]])\n",
      "tensor([[-4.0458e-03],\n",
      "        [-4.1660e-03],\n",
      "        [-2.4144e-05],\n",
      "        [-8.7744e-03],\n",
      "        [-2.5558e-04],\n",
      "        [-9.1719e-03],\n",
      "        [ 5.2399e-03],\n",
      "        [ 1.6582e-02],\n",
      "        [-2.4858e-04],\n",
      "        [-2.6140e-03]], grad_fn=<AddmmBackward0>) tensor([[ 7.6580],\n",
      "        [ 2.4566],\n",
      "        [ 8.0385],\n",
      "        [ 4.7028],\n",
      "        [18.1727],\n",
      "        [21.0747],\n",
      "        [ 6.9670],\n",
      "        [18.8173],\n",
      "        [ 1.1272],\n",
      "        [16.0536]])\n",
      "tensor([[-0.0087],\n",
      "        [-0.0127],\n",
      "        [ 0.0152],\n",
      "        [ 0.0036],\n",
      "        [-0.0062],\n",
      "        [-0.0129],\n",
      "        [-0.0017],\n",
      "        [-0.0009],\n",
      "        [-0.0048],\n",
      "        [-0.0038]], grad_fn=<AddmmBackward0>) tensor([[-11.1787],\n",
      "        [ 12.3045],\n",
      "        [  6.1252],\n",
      "        [-11.1274],\n",
      "        [  2.5586],\n",
      "        [ 15.1767],\n",
      "        [  8.2547],\n",
      "        [  7.8850],\n",
      "        [ -1.9831],\n",
      "        [ 10.3875]])\n",
      "tensor([[-0.0096],\n",
      "        [-0.0037],\n",
      "        [-0.0159],\n",
      "        [-0.0119],\n",
      "        [ 0.0097],\n",
      "        [ 0.0133],\n",
      "        [ 0.0103],\n",
      "        [ 0.0225],\n",
      "        [-0.0233],\n",
      "        [ 0.0077]], grad_fn=<AddmmBackward0>) tensor([[  1.8963],\n",
      "        [  4.7831],\n",
      "        [  7.3195],\n",
      "        [ 18.4836],\n",
      "        [ -8.9542],\n",
      "        [  3.3452],\n",
      "        [ 12.5562],\n",
      "        [-12.2802],\n",
      "        [  8.3986],\n",
      "        [ -8.6668]])\n",
      "tensor([[-0.0144],\n",
      "        [ 0.0081],\n",
      "        [ 0.0201],\n",
      "        [ 0.0326],\n",
      "        [-0.0017],\n",
      "        [ 0.0167],\n",
      "        [ 0.0068],\n",
      "        [ 0.0219],\n",
      "        [ 0.0080],\n",
      "        [ 0.0212]], grad_fn=<AddmmBackward0>) tensor([[ 10.1248],\n",
      "        [-14.3437],\n",
      "        [ -4.2807],\n",
      "        [-21.7873],\n",
      "        [  2.6064],\n",
      "        [  1.9974],\n",
      "        [ -4.7380],\n",
      "        [-11.0653],\n",
      "        [-12.9538],\n",
      "        [  9.7325]])\n",
      "tensor([[-0.0123],\n",
      "        [ 0.0087],\n",
      "        [-0.0230],\n",
      "        [-0.0062],\n",
      "        [-0.0027],\n",
      "        [-0.0119],\n",
      "        [ 0.0030],\n",
      "        [-0.0002],\n",
      "        [-0.0107],\n",
      "        [-0.0332]], grad_fn=<AddmmBackward0>) tensor([[ 3.5724],\n",
      "        [-3.9558],\n",
      "        [11.5572],\n",
      "        [14.4371],\n",
      "        [ 3.7777],\n",
      "        [ 8.6933],\n",
      "        [-9.2348],\n",
      "        [ 7.6654],\n",
      "        [12.4058],\n",
      "        [15.0143]])\n",
      "tensor([[ 0.0058],\n",
      "        [ 0.0014],\n",
      "        [ 0.0050],\n",
      "        [ 0.0114],\n",
      "        [ 0.0073],\n",
      "        [ 0.0142],\n",
      "        [ 0.0055],\n",
      "        [ 0.0146],\n",
      "        [-0.0215],\n",
      "        [ 0.0109]], grad_fn=<AddmmBackward0>) tensor([[-2.1062],\n",
      "        [ 8.6431],\n",
      "        [ 3.5527],\n",
      "        [-2.3214],\n",
      "        [ 3.8016],\n",
      "        [-8.9979],\n",
      "        [-2.4597],\n",
      "        [-0.2845],\n",
      "        [11.8877],\n",
      "        [ 2.8293]])\n",
      "tensor([[ 0.0188],\n",
      "        [-0.0161],\n",
      "        [-0.0068],\n",
      "        [-0.0019],\n",
      "        [-0.0188],\n",
      "        [-0.0197],\n",
      "        [-0.0228],\n",
      "        [-0.0217],\n",
      "        [-0.0041],\n",
      "        [-0.0206]], grad_fn=<AddmmBackward0>) tensor([[-10.8051],\n",
      "        [  2.2491],\n",
      "        [  2.7161],\n",
      "        [ -2.8501],\n",
      "        [ 10.1923],\n",
      "        [ 21.1538],\n",
      "        [  8.0087],\n",
      "        [ 14.4097],\n",
      "        [  2.2519],\n",
      "        [ 10.2229]])\n",
      "tensor([[ 0.0116],\n",
      "        [-0.0062],\n",
      "        [-0.0015],\n",
      "        [-0.0252],\n",
      "        [ 0.0218],\n",
      "        [-0.0146],\n",
      "        [ 0.0261],\n",
      "        [ 0.0061],\n",
      "        [ 0.0059],\n",
      "        [ 0.0057]], grad_fn=<AddmmBackward0>) tensor([[  1.3441],\n",
      "        [ -4.8487],\n",
      "        [ -5.1908],\n",
      "        [ 11.6395],\n",
      "        [ -0.8837],\n",
      "        [ 20.2295],\n",
      "        [-11.4487],\n",
      "        [  4.6038],\n",
      "        [  8.7108],\n",
      "        [ -0.7306]])\n",
      "tensor([[ 0.0075],\n",
      "        [-0.0021],\n",
      "        [ 0.0052],\n",
      "        [-0.0108],\n",
      "        [ 0.0024],\n",
      "        [ 0.0053],\n",
      "        [ 0.0327],\n",
      "        [-0.0133],\n",
      "        [ 0.0012],\n",
      "        [-0.0264]], grad_fn=<AddmmBackward0>) tensor([[  3.0353],\n",
      "        [  3.0919],\n",
      "        [-10.1216],\n",
      "        [ 15.8796],\n",
      "        [  3.2477],\n",
      "        [  7.2758],\n",
      "        [-16.1497],\n",
      "        [ -2.1037],\n",
      "        [ 18.8715],\n",
      "        [ -2.8696]])\n",
      "tensor([[ 0.0004],\n",
      "        [-0.0104],\n",
      "        [ 0.0419],\n",
      "        [-0.0035],\n",
      "        [ 0.0191],\n",
      "        [ 0.0034],\n",
      "        [-0.0019],\n",
      "        [ 0.0260],\n",
      "        [ 0.0156],\n",
      "        [ 0.0507]], grad_fn=<AddmmBackward0>) tensor([[ 4.7152],\n",
      "        [12.1254],\n",
      "        [-6.9614],\n",
      "        [ 7.9735],\n",
      "        [-3.3859],\n",
      "        [-1.5084],\n",
      "        [ 2.3144],\n",
      "        [-3.2480],\n",
      "        [ 1.7179],\n",
      "        [-9.5554]])\n",
      "tensor([[-0.0294],\n",
      "        [-0.0066],\n",
      "        [ 0.0270],\n",
      "        [-0.0352],\n",
      "        [ 0.0045],\n",
      "        [-0.0065],\n",
      "        [-0.0025],\n",
      "        [-0.0080],\n",
      "        [ 0.0249],\n",
      "        [ 0.0027]], grad_fn=<AddmmBackward0>) tensor([[ 22.2411],\n",
      "        [  3.8613],\n",
      "        [  0.6263],\n",
      "        [ 12.9809],\n",
      "        [  4.5886],\n",
      "        [ 14.2156],\n",
      "        [  7.3836],\n",
      "        [  9.6203],\n",
      "        [-11.8725],\n",
      "        [ -1.8240]])\n",
      "tensor([[-0.0025],\n",
      "        [-0.0087],\n",
      "        [ 0.0237],\n",
      "        [-0.0052],\n",
      "        [-0.0029],\n",
      "        [ 0.0128],\n",
      "        [-0.0214],\n",
      "        [-0.0050],\n",
      "        [-0.0323],\n",
      "        [-0.0186]], grad_fn=<AddmmBackward0>) tensor([[ 9.0006],\n",
      "        [ 7.3311],\n",
      "        [-7.2435],\n",
      "        [-0.1535],\n",
      "        [11.1349],\n",
      "        [-6.6312],\n",
      "        [13.8446],\n",
      "        [-2.0320],\n",
      "        [16.6063],\n",
      "        [19.2511]])\n",
      "tensor([[-0.0177],\n",
      "        [ 0.0169],\n",
      "        [-0.0069],\n",
      "        [-0.0120],\n",
      "        [ 0.0169],\n",
      "        [-0.0010],\n",
      "        [-0.0211],\n",
      "        [-0.0055],\n",
      "        [-0.0156],\n",
      "        [ 0.0012]], grad_fn=<AddmmBackward0>) tensor([[ 5.6091],\n",
      "        [ 8.2554],\n",
      "        [-2.2267],\n",
      "        [-6.5712],\n",
      "        [ 4.4654],\n",
      "        [12.5186],\n",
      "        [15.9087],\n",
      "        [-1.1386],\n",
      "        [ 6.1987],\n",
      "        [ 9.4778]])\n",
      "tensor([[-0.0210],\n",
      "        [ 0.0074],\n",
      "        [-0.0290],\n",
      "        [-0.0316],\n",
      "        [ 0.0261],\n",
      "        [-0.0161],\n",
      "        [ 0.0097],\n",
      "        [ 0.0005],\n",
      "        [ 0.0005],\n",
      "        [-0.0112]], grad_fn=<AddmmBackward0>) tensor([[ 1.2632],\n",
      "        [ 4.7112],\n",
      "        [16.1514],\n",
      "        [ 9.7781],\n",
      "        [-6.7236],\n",
      "        [-0.0242],\n",
      "        [-0.2631],\n",
      "        [ 2.8055],\n",
      "        [ 3.1516],\n",
      "        [ 1.5703]])\n",
      "tensor([[-0.0010],\n",
      "        [-0.0004],\n",
      "        [-0.0140],\n",
      "        [-0.0102],\n",
      "        [ 0.0052],\n",
      "        [-0.0157],\n",
      "        [-0.0121],\n",
      "        [ 0.0243],\n",
      "        [ 0.0192],\n",
      "        [ 0.0124]], grad_fn=<AddmmBackward0>) tensor([[ 4.1596],\n",
      "        [-2.9936],\n",
      "        [ 1.1463],\n",
      "        [ 5.1462],\n",
      "        [-0.5261],\n",
      "        [ 5.4223],\n",
      "        [11.5129],\n",
      "        [ 4.4553],\n",
      "        [12.7552],\n",
      "        [-0.1973]])\n",
      "tensor([[-0.0180],\n",
      "        [-0.0252],\n",
      "        [ 0.0073],\n",
      "        [ 0.0214],\n",
      "        [-0.0035],\n",
      "        [ 0.0057],\n",
      "        [-0.0113],\n",
      "        [-0.0200],\n",
      "        [ 0.0242],\n",
      "        [-0.0007]], grad_fn=<AddmmBackward0>) tensor([[-6.3114],\n",
      "        [ 9.4883],\n",
      "        [ 6.6368],\n",
      "        [-1.4180],\n",
      "        [11.8095],\n",
      "        [ 1.1099],\n",
      "        [16.8845],\n",
      "        [13.3406],\n",
      "        [ 6.9701],\n",
      "        [17.6849]])\n",
      "tensor([[-0.0121],\n",
      "        [-0.0102],\n",
      "        [ 0.0003],\n",
      "        [ 0.0014],\n",
      "        [-0.0174],\n",
      "        [ 0.0186],\n",
      "        [ 0.0034],\n",
      "        [-0.0110],\n",
      "        [ 0.0159],\n",
      "        [-0.0061]], grad_fn=<AddmmBackward0>) tensor([[14.9078],\n",
      "        [ 5.9823],\n",
      "        [ 4.0872],\n",
      "        [-4.3106],\n",
      "        [14.9600],\n",
      "        [-1.1819],\n",
      "        [-8.1590],\n",
      "        [ 2.1589],\n",
      "        [-5.1135],\n",
      "        [ 9.1016]])\n",
      "tensor([[ 0.0069],\n",
      "        [ 0.0180],\n",
      "        [-0.0151],\n",
      "        [ 0.0030],\n",
      "        [-0.0227],\n",
      "        [ 0.0405],\n",
      "        [ 0.0064],\n",
      "        [-0.0388],\n",
      "        [-0.0091],\n",
      "        [-0.0039]], grad_fn=<AddmmBackward0>) tensor([[-1.4964],\n",
      "        [16.0129],\n",
      "        [11.9603],\n",
      "        [-3.1081],\n",
      "        [ 9.3125],\n",
      "        [-1.1499],\n",
      "        [-2.7219],\n",
      "        [11.8677],\n",
      "        [16.4653],\n",
      "        [12.6069]])\n",
      "tensor([[ 0.0028],\n",
      "        [-0.0061],\n",
      "        [ 0.0122],\n",
      "        [ 0.0056],\n",
      "        [-0.0074],\n",
      "        [-0.0139],\n",
      "        [ 0.0174],\n",
      "        [ 0.0323],\n",
      "        [ 0.0177],\n",
      "        [ 0.0036]], grad_fn=<AddmmBackward0>) tensor([[ 1.0567],\n",
      "        [ 4.8035],\n",
      "        [ 6.2885],\n",
      "        [ 2.1109],\n",
      "        [ 1.0475],\n",
      "        [ 5.8125],\n",
      "        [ 2.9855],\n",
      "        [ 6.2837],\n",
      "        [-0.0535],\n",
      "        [-4.6100]])\n",
      "tensor([[-0.0026],\n",
      "        [-0.0040],\n",
      "        [ 0.0110],\n",
      "        [-0.0071],\n",
      "        [ 0.0118],\n",
      "        [ 0.0138],\n",
      "        [-0.0025],\n",
      "        [-0.0004],\n",
      "        [ 0.0113],\n",
      "        [ 0.0063]], grad_fn=<AddmmBackward0>) tensor([[ -0.6627],\n",
      "        [ -5.7506],\n",
      "        [  4.3133],\n",
      "        [ 22.3361],\n",
      "        [ -1.8666],\n",
      "        [-12.9355],\n",
      "        [ 16.6982],\n",
      "        [  5.9949],\n",
      "        [ -7.1480],\n",
      "        [ -0.7768]])\n",
      "tensor([[-0.0089],\n",
      "        [ 0.0072],\n",
      "        [-0.0130],\n",
      "        [ 0.0063],\n",
      "        [ 0.0013],\n",
      "        [-0.0092],\n",
      "        [ 0.0307],\n",
      "        [-0.0121],\n",
      "        [-0.0173],\n",
      "        [ 0.0090]], grad_fn=<AddmmBackward0>) tensor([[-1.2593],\n",
      "        [ 2.9707],\n",
      "        [ 2.3171],\n",
      "        [ 1.8552],\n",
      "        [ 6.1915],\n",
      "        [ 7.4703],\n",
      "        [-8.8928],\n",
      "        [13.9866],\n",
      "        [ 8.1245],\n",
      "        [15.3140]])\n",
      "tensor([[ 0.0051],\n",
      "        [-0.0108],\n",
      "        [ 0.0177],\n",
      "        [ 0.0081],\n",
      "        [ 0.0136],\n",
      "        [-0.0106],\n",
      "        [ 0.0119],\n",
      "        [ 0.0023],\n",
      "        [-0.0232],\n",
      "        [ 0.0269]], grad_fn=<AddmmBackward0>) tensor([[-4.6837],\n",
      "        [ 3.3792],\n",
      "        [-8.4739],\n",
      "        [ 8.6622],\n",
      "        [13.7238],\n",
      "        [-5.5292],\n",
      "        [-6.0347],\n",
      "        [-3.4718],\n",
      "        [18.0591],\n",
      "        [-1.5139]])\n",
      "tensor([[ 0.0106],\n",
      "        [-0.0237],\n",
      "        [-0.0235],\n",
      "        [-0.0286],\n",
      "        [-0.0156],\n",
      "        [-0.0155],\n",
      "        [-0.0193],\n",
      "        [-0.0022],\n",
      "        [-0.0053],\n",
      "        [ 0.0372]], grad_fn=<AddmmBackward0>) tensor([[ -1.0499],\n",
      "        [ 17.5784],\n",
      "        [ -1.5502],\n",
      "        [ 23.0814],\n",
      "        [  5.6195],\n",
      "        [  9.7252],\n",
      "        [ 13.7123],\n",
      "        [ -0.4293],\n",
      "        [  1.8010],\n",
      "        [-12.2554]])\n",
      "tensor([[-1.4408e-02],\n",
      "        [-1.2994e-02],\n",
      "        [-2.0003e-02],\n",
      "        [ 2.4027e-02],\n",
      "        [-2.1177e-02],\n",
      "        [-9.6972e-05],\n",
      "        [-2.2669e-02],\n",
      "        [-4.4895e-03],\n",
      "        [ 6.5786e-03],\n",
      "        [ 3.4700e-02]], grad_fn=<AddmmBackward0>) tensor([[27.3003],\n",
      "        [ 3.9812],\n",
      "        [14.8411],\n",
      "        [-5.9998],\n",
      "        [19.7562],\n",
      "        [11.8240],\n",
      "        [20.6336],\n",
      "        [ 6.1968],\n",
      "        [-0.9997],\n",
      "        [-8.4395]])\n",
      "tensor([[-0.0319],\n",
      "        [-0.0075],\n",
      "        [ 0.0002],\n",
      "        [-0.0060],\n",
      "        [ 0.0177],\n",
      "        [ 0.0129],\n",
      "        [-0.0298],\n",
      "        [ 0.0010],\n",
      "        [ 0.0099],\n",
      "        [ 0.0108]], grad_fn=<AddmmBackward0>) tensor([[21.0561],\n",
      "        [19.0597],\n",
      "        [-8.2876],\n",
      "        [10.8721],\n",
      "        [-6.6806],\n",
      "        [-2.9813],\n",
      "        [11.3203],\n",
      "        [ 4.5020],\n",
      "        [ 2.4436],\n",
      "        [ 1.6558]])\n",
      "tensor([[ 0.0072],\n",
      "        [-0.0157],\n",
      "        [ 0.0275],\n",
      "        [-0.0066],\n",
      "        [-0.0024],\n",
      "        [ 0.0115],\n",
      "        [-0.0026],\n",
      "        [-0.0218],\n",
      "        [-0.0155],\n",
      "        [-0.0048]], grad_fn=<AddmmBackward0>) tensor([[ 3.9257],\n",
      "        [-1.1225],\n",
      "        [-8.2063],\n",
      "        [ 1.4707],\n",
      "        [17.6693],\n",
      "        [ 6.1214],\n",
      "        [14.4080],\n",
      "        [13.2289],\n",
      "        [ 6.7127],\n",
      "        [-5.0861]])\n"
     ]
    }
   ],
   "source": [
    "for X, y in data_iter:\n",
    "    print(net(X),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "de7f78e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Step4: Define model &amp;amp;amp; initialization\n",
    " \n",
    "# Create a single layer feed-forward network with 2 inputs and 1 outputs.\n",
    " \n",
    "net = nn.Linear(3, 1)\n",
    " \n",
    "\n",
    " \n",
    "#Initialize model params\n",
    " \n",
    "net.weight.data.normal_(0, 0.01)\n",
    " \n",
    "net.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "eeab26bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "01c3a51c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\t\n",
    "#Step 6: Define optimization algorithm\n",
    "# implements a stochastic gradient descent optimization method\n",
    "trainer = torch.optim.SGD(net.parameters(), lr=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "57d21fb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[128], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m     l\u001b[38;5;241m.\u001b[39mbackward() \u001b[38;5;66;03m# back propagation\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mstep() \u001b[38;5;66;03m# parameter update\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     l \u001b[38;5;241m=\u001b[39m loss(net(\u001b[43mfeatures\u001b[49m), labels)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, loss \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ml\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124mf\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    " \n",
    "for epoch in range(num_epochs):\n",
    " \n",
    "    for X, y in data_iter:\n",
    " \n",
    "        l = loss(net(X) ,y)\n",
    " \n",
    "        trainer.zero_grad() #sets gradients to zero\n",
    " \n",
    "    l.backward() # back propagation\n",
    " \n",
    "    trainer.step() # parameter update\n",
    " \n",
    "    l = loss(net(features), labels)\n",
    " \n",
    "print(f'epoch {epoch + 1}, loss {l:f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668ab21e",
   "metadata": {},
   "source": [
    "# batch \n",
    "* https://deeplizard.com/learn/video/U4WB9p6ODjM\n",
    "* https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/\n",
    "* https://www.baeldung.com/cs/epoch-vs-batch-vs-mini-batch\n",
    "* https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/\n",
    "* https://machinelearningmastery.com/gentle-introduction-mini-batch-gradient-descent-configure-batch-size/\n",
    "* https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/\n",
    "* https://towardsdatascience.com/gradient-descent-algorithm-and-its-variants-10f652806a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf587501",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
